<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 171]
- [cs.CL](#cs.CL) [Total: 110]
- [cs.GR](#cs.GR) [Total: 14]
- [cs.AI](#cs.AI) [Total: 90]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific Tumor Dynamics](https://arxiv.org/abs/2510.03287)
*Moinak Bhattacharya,Gagandeep Singh,Prateek Prasanna*

Main category: cs.CV

TL;DR: 提出SoC-DT框架，结合反应扩散肿瘤生长模型、标准治疗干预和个性化因素，通过IMEX-SoC求解器预测治疗后肿瘤结构，在合成和真实胶质瘤数据上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确预测标准治疗下的肿瘤轨迹是肿瘤学的重要需求，传统反应扩散模型无法捕捉异质治疗范式下的肿瘤动态，需要能模拟标准治疗干预并考虑患者差异的计算框架。

Method: 开发SoC-DT可微分框架，整合反应扩散肿瘤生长模型、离散标准治疗干预（手术、化疗、放疗）以及基因组和人口统计学个性化；提出IMEX-SoC隐式-显式指数时间差分求解器确保稳定性、正性和可扩展性。

Result: 在合成数据和真实世界胶质瘤数据上评估，SoC-DT在预测肿瘤动态方面持续优于经典PDE基线和纯数据驱动的神经模型。

Conclusion: SoC-DT通过将机制可解释性与现代可微分求解器结合，为肿瘤学中患者特异性数字孪生建立了原则性基础，实现生物学一致的肿瘤动态估计。

Abstract: Accurate prediction of tumor trajectories under standard-of-care (SoC)
therapies remains a major unmet need in oncology. This capability is essential
for optimizing treatment planning and anticipating disease progression.
Conventional reaction-diffusion models are limited in scope, as they fail to
capture tumor dynamics under heterogeneous therapeutic paradigms. There is
hence a critical need for computational frameworks that can realistically
simulate SoC interventions while accounting for inter-patient variability in
genomics, demographics, and treatment regimens. We introduce Standard-of-Care
Digital Twin (SoC-DT), a differentiable framework that unifies
reaction-diffusion tumor growth models, discrete SoC interventions (surgery,
chemotherapy, radiotherapy) along with genomic and demographic personalization
to predict post-treatment tumor structure on imaging. An implicit-explicit
exponential time-differencing solver, IMEX-SoC, is also proposed, which ensures
stability, positivity, and scalability in SoC treatment situations. Evaluated
on both synthetic data and real world glioma data, SoC-DT consistently
outperforms classical PDE baselines and purely data-driven neural models in
predicting tumor dynamics. By bridging mechanistic interpretability with modern
differentiable solvers, SoC-DT establishes a principled foundation for
patient-specific digital twins in oncology, enabling biologically consistent
tumor dynamics estimation. Code will be made available upon acceptance.

</details>


### [2] [Visualizing Celebrity Dynamics in Video Content: A Proposed Approach Using Face Recognition Timestamp Data](https://arxiv.org/abs/2510.03292)
*Doğanay Demir,İlknur Durgar Elkahlout*

Main category: cs.CV

TL;DR: 提出一个结合分布式多GPU推理系统与交互式可视化平台的混合框架，用于分析视频剧集中的名人动态，支持大规模视频数据处理和多维度可视化分析。


<details>
  <summary>Details</summary>
Motivation: 在视频内容主导的时代，理解视频结构和动态变得越来越重要，需要高效处理大规模视频数据并提供直观的分析工具。

Method: 使用优化的ONNX模型、异构批量推理和高吞吐量并行处理，构建分布式多GPU推理系统，生成带时间戳的出现记录，并通过交互式可视化平台提供多种图表分析。

Result: 系统能够高效处理大量视频数据，生成全面的可视化分析，包括出现频率、时长分析、共现矩阵、网络图等，揭示名人知名度、屏幕时间分布、时间动态等模式。

Conclusion: 该工作通过结合分布式识别与结构化可视化分析，为娱乐分析、内容创作策略和观众参与研究开辟了新的可能性。

Abstract: In an era dominated by video content, understanding its structure and
dynamics has become increasingly important. This paper presents a hybrid
framework that combines a distributed multi-GPU inference system with an
interactive visualization platform for analyzing celebrity dynamics in video
episodes. The inference framework efficiently processes large volumes of video
data by leveraging optimized ONNX models, heterogeneous batch inference, and
high-throughput parallelism, ensuring scalable generation of timestamped
appearance records. These records are then transformed into a comprehensive
suite of visualizations, including appearance frequency charts, duration
analyses, pie charts, co-appearance matrices, network graphs, stacked area
charts, seasonal comparisons, and heatmaps. Together, these visualizations
provide multi-dimensional insights into video content, revealing patterns in
celebrity prominence, screen-time distribution, temporal dynamics,
co-appearance relationships, and intensity across episodes and seasons. The
interactive nature of the system allows users to dynamically explore data,
identify key moments, and uncover evolving relationships between individuals.
By bridging distributed recognition with structured, visually-driven analytics,
this work enables new possibilities for entertainment analytics, content
creation strategies, and audience engagement studies.

</details>


### [3] [Domain-Robust Marine Plastic Detection Using Vision Models](https://arxiv.org/abs/2510.03294)
*Saanvi Kataria*

Main category: cs.CV

TL;DR: 本研究比较了CNN和视觉变换器模型在跨域水下塑料检测中的性能，发现轻量级MobileNetV2表现最佳，而零样本模型CLIP和Gemini在精度和召回率方面各有优劣。


<details>
  <summary>Details</summary>
Motivation: 海洋塑料污染是紧迫的环境威胁，需要可靠的水下碎片检测自动化系统。但训练在一个数据集上的视觉系统常因域偏移而在新图像上性能下降。

Method: 在标记的水下数据集上训练CNN（MobileNetV2、ResNet-18、EfficientNet-B0）和视觉变换器（DeiT-Tiny、ViT-B16），然后在来自不同来源的跨域测试集上评估。同时评估了零样本模型CLIP ViT-L14和Gemini 2.0 Flash。

Result: 轻量级MobileNetV2提供最强的跨域性能（F1 0.97），超越更大模型。所有微调模型都达到高精度（约99%），但召回率不同。零样本CLIP敏感但易产生假阳性，Gemini则相反。

Conclusion: 紧凑CNN通过监督训练能有效泛化用于跨域水下检测，而大型预训练视觉语言模型提供互补优势。

Abstract: Marine plastic pollution is a pressing environmental threat, making reliable
automation for underwater debris detection essential. However, vision systems
trained on one dataset often degrade on new imagery due to domain shift. This
study benchmarks models for cross-domain robustness, training convolutional
neural networks - CNNs (MobileNetV2, ResNet-18, EfficientNet-B0) and vision
transformers (DeiT-Tiny, ViT-B16) on a labeled underwater dataset and then
evaluates them on a balanced cross-domain test set built from plastic-positive
images drawn from a different source and negatives from the training domain.
Two zero-shot models were assessed, CLIP ViT-L14 and Google's Gemini 2.0 Flash,
that leverage pretraining to classify images without fine-tuning. Results show
the lightweight MobileNetV2 delivers the strongest cross-domain performance (F1
0.97), surpassing larger models. All fine-tuned models achieved high Precision
(around 99%), but differ in Recall, indicating varying sensitivity to plastic
instances. Zero-shot CLIP is comparatively sensitive (Recall around 80%) yet
prone to false positives (Precision around 56%), whereas Gemini exhibits the
inverse profile (Precision around 99%, Recall around 81%). Error analysis
highlights recurring confusions with coral textures, suspended particulates,
and specular glare. Overall, compact CNNs with supervised training can
generalize effectively for cross-domain underwater detection, while large
pretrained vision-language models provide complementary strengths.

</details>


### [4] [Multimodal Arabic Captioning with Interpretable Visual Concept Integration](https://arxiv.org/abs/2510.03295)
*Passant Elchafei,Amany Fashwan*

Main category: cs.CV

TL;DR: VLCAP是一个阿拉伯语图像描述框架，通过CLIP视觉标签检索和多模态文本生成相结合，生成可解释且文化连贯的阿拉伯语图像描述。


<details>
  <summary>Details</summary>
Motivation: 传统的端到端图像描述方法缺乏可解释性，VLCAP旨在通过基于视觉概念的生成方法，为阿拉伯语图像描述提供更可解释和上下文准确的解决方案。

Method: 使用三种多语言编码器（mCLIP、AraCLIP、Jina V4）进行视觉标签检索，构建混合词汇表，然后将检索到的标签转换为阿拉伯语提示，与原始图像一起输入到视觉语言模型中进行描述生成。

Result: mCLIP + Gemini Pro Vision组合在BLEU-1（5.34%）和余弦相似度（60.01%）上表现最佳，而AraCLIP + Qwen-VL组合在LLM-judge评分（36.33%）上最高。

Conclusion: VLCAP框架能够生成文化连贯且上下文准确的阿拉伯语图像描述，为阿拉伯语图像理解提供了可解释的解决方案。

Abstract: We present VLCAP, an Arabic image captioning framework that integrates
CLIP-based visual label retrieval with multimodal text generation. Rather than
relying solely on end-to-end captioning, VLCAP grounds generation in
interpretable Arabic visual concepts extracted with three multilingual
encoders, mCLIP, AraCLIP, and Jina V4, each evaluated separately for label
retrieval. A hybrid vocabulary is built from training captions and enriched
with about 21K general domain labels translated from the Visual Genome dataset,
covering objects, attributes, and scenes. The top-k retrieved labels are
transformed into fluent Arabic prompts and passed along with the original image
to vision-language models. In the second stage, we tested Qwen-VL and Gemini
Pro Vision for caption generation, resulting in six encoder-decoder
configurations. The results show that mCLIP + Gemini Pro Vision achieved the
best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL
obtained the highest LLM-judge score (36.33%). This interpretable pipeline
enables culturally coherent and contextually accurate Arabic captions.

</details>


### [5] [Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes](https://arxiv.org/abs/2510.03297)
*Akshar Gothi*

Main category: cs.CV

TL;DR: 对比EfficientNet-B0和ViT-Base在SpaceNet数据集上的性能，包括不平衡和平衡标签分布两种场景，评估准确率、F1分数、模型大小和推理延迟等指标。


<details>
  <summary>Details</summary>
Motivation: 比较卷积神经网络和视觉Transformer在实际应用中的性能差异，特别是在不同标签分布情况下的表现，为模型选择提供参考。

Method: 在SpaceNet数据集上进行控制实验，使用不平衡的五类分割和平衡重采样分割（每类700张图像），采用相同的预处理、轻量级数据增强和40轮训练预算。

Result: 在不平衡分割中，EfficientNet-B0达到93%测试准确率且延迟更低；ViT-Base也达到93%但参数更多。在平衡分割中，两者表现都很强，EfficientNet-B0达到99%，ViT-Base保持竞争力。

Conclusion: 平衡标签分布可以缩小架构差距，但CNN在效率方面仍保持优势。

Abstract: We present a controlled comparison of a convolutional neural network
(EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two
label-distribution regimes: a naturally imbalanced five-class split and a
balanced-resampled split with 700 images per class (70:20:10 train/val/test).
With matched preprocessing (224x224, ImageNet normalization), lightweight
augmentations, and a 40-epoch budget on a single NVIDIA P100, we report
accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics
(model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93%
test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive
at 93% with a larger parameter count and runtime. On the balanced split, both
models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains
competitive, indicating that balancing narrows architecture gaps while CNNs
retain an efficiency edge. We release manifests, logs, and per-image
predictions to support reproducibility.

</details>


### [6] [A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety](https://arxiv.org/abs/2510.03314)
*Shucheng Zhang,Yan Shi,Bingzhang Wang,Yuang Zhang,Muhammad Monjurul Karim,Kehua Chen,Chenxi Liu,Mehrdad Nasri,Yinhai Wang*

Main category: cs.CV

TL;DR: 本文综述了基于摄像头的AI感知系统在弱势道路使用者安全保护方面的最新进展，涵盖检测分类、跟踪重识别、轨迹预测和意图识别四个核心任务，并指出了数据、模型和部署方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统基础设施措施在动态城市环境中保护弱势道路使用者效果有限，而现有AI应用调查主要关注检测任务，缺乏对全面VRU理解和保护所需的其他视觉任务的系统覆盖。

Method: 系统性地回顾了过去五年基于摄像头的AI感知系统在VRU安全方面的进展，重点分析了四个核心任务：检测与分类、跟踪与重识别、轨迹预测、意图识别与预测。

Result: 建立了AI赋能的主动式VRU保护解决方案的技术框架，识别了当前研究的主要进展和趋势。

Conclusion: 通过将视觉AI进展与实际部署考虑相结合，为开发下一代感知系统以增强VRU安全提供了基础参考，并指出了数据、模型和部署方面的四个主要开放挑战。

Abstract: Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and
cyclists, remains a critical global challenge, as conventional
infrastructure-based measures often prove inadequate in dynamic urban
environments. Recent advances in artificial intelligence (AI), particularly in
visual perception and reasoning, open new opportunities for proactive and
context-aware VRU protection. However, existing surveys on AI applications for
VRUs predominantly focus on detection, offering limited coverage of other
vision-based tasks that are essential for comprehensive VRU understanding and
protection. This paper presents a state-of-the-art review of recent progress in
camera-based AI sensing systems for VRU safety, with an emphasis on
developments from the past five years and emerging research trends. We
systematically examine four core tasks, namely detection and classification,
tracking and reidentification, trajectory prediction, and intent recognition
and prediction, which together form the backbone of AI-empowered proactive
solutions for VRU protection in intelligent transportation systems. To guide
future research, we highlight four major open challenges from the perspectives
of data, model, and deployment. By linking advances in visual AI with practical
considerations for real-world implementation, this survey aims to provide a
foundational reference for the development of next-generation sensing systems
to enhance VRU safety.

</details>


### [7] [The View From Space: Navigating Instrumentation Differences with EOFMs](https://arxiv.org/abs/2510.03316)
*Ryan P. Demilt,Nicholas LaHaye,Karis Tenneson*

Main category: cs.CV

TL;DR: 地球观测基础模型对传感器架构高度敏感，理解这种差异对模型开发和使用至关重要


<details>
  <summary>Details</summary>
Motivation: 现有地球观测基础模型大多在单一模态数据上训练，然后跨模态应用，但传感器架构对模型内部表征的影响尚不明确

Method: 分析不同传感器架构对EOFMs表征空间的影响

Result: 发现EOFMs的表征空间对传感器架构高度敏感

Conclusion: 理解传感器架构差异为当前EOFMs设计提供了重要视角，指明了基于稳健遥感科学的发展方向

Abstract: Earth Observation Foundation Models (EOFMs) have exploded in prevalence as
tools for processing the massive volumes of remotely sensed and other earth
observation data, and for delivering impact on the many essential earth
monitoring tasks. An emerging trend posits using the outputs of pre-trained
models as 'embeddings' which summarize high dimensional data to be used for
generic tasks such as similarity search and content-specific queries. However,
most EOFM models are trained only on single modalities of data and then applied
or benchmarked by matching bands across different modalities. It is not clear
from existing work what impact diverse sensor architectures have on the
internal representations of the present suite of EOFMs. We show in this work
that the representation space of EOFMs is highly sensitive to sensor
architecture and that understanding this difference gives a vital perspective
on the pitfalls of current EOFM design and signals for how to move forward as
model developers, users, and a community guided by robust remote-sensing
science.

</details>


### [8] [Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring](https://arxiv.org/abs/2510.03317)
*Günel Aghakishiyeva,Jiayi Zhou,Saagar Arya,James David Poling,Holly R. Houliston,Jamie N. Womble,David W. Johnston,Brinnae Bent*

Main category: cs.CV

TL;DR: 提出了一种基于修复引导的扰动解释技术，通过生成照片级真实、掩码定位的编辑来揭示生态监测视觉模型中驱动预测的细粒度形态线索，提高AI在生态学中的可信度。


<details>
  <summary>Details</summary>
Motivation: 生态监测中自动化视觉模型的不透明预测限制了信任和现场应用，需要能够产生领域相关见解的解释方法。

Method: 使用修复引导的基于扰动的解释技术，通过Segment-Anything-Model精炼的掩码支持对象移除/替换和背景替换两种干预方式，生成保持场景上下文的照片级真实编辑。

Result: 该方法能够定位诊断结构，避免传统扰动的删除伪影，通过重新评分扰动图像和专家评审验证了生态合理性和可解释性。

Conclusion: 该解释技术为生态学中AI的更可信部署提供了领域相关的见解，支持专家验证。

Abstract: Ecological monitoring is increasingly automated by vision models, yet opaque
predictions limit trust and field adoption. We present an inpainting-guided,
perturbation-based explanation technique that produces photorealistic,
mask-localized edits that preserve scene context. Unlike masking or blurring,
these edits stay in-distribution and reveal which fine-grained morphological
cues drive predictions in tasks such as species recognition and trait
attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for
harbor seal detection in Glacier Bay drone imagery, using
Segment-Anything-Model-refined masks to support two interventions: (i) object
removal/replacement (e.g., replacing seals with plausible ice/water or boats)
and (ii) background replacement with original animals composited onto new
scenes. Explanations are assessed by re-scoring perturbed images (flip rate,
confidence drop) and by expert review for ecological plausibility and
interpretability. The resulting explanations localize diagnostic structures,
avoid deletion artifacts common to traditional perturbations, and yield
domain-relevant insights that support expert validation and more trustworthy
deployment of AI in ecology.

</details>


### [9] [Advances in Medical Image Segmentation: A Comprehensive Survey with a Focus on Lumbar Spine Applications](https://arxiv.org/abs/2510.03318)
*Ahmed Kabil,Ghada Khoriba,Mina Yousef,Essam A. Rashed*

Main category: cs.CV

TL;DR: 这篇论文对医学图像分割方法进行了系统性综述，涵盖从传统图像处理技术到现代深度学习方法的演进，特别关注了深度学习架构、注意力机制、半监督学习等先进技术，并包含腰椎分割的案例研究。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在精准诊断、治疗规划和病情监测中具有关键作用。本文旨在弥合传统图像处理技术与现代深度学习方法之间的差距，为研究人员和从业者提供全面的技术概览。

Method: 采用系统性综述方法，涵盖阈值分割、边缘检测、区域分割、聚类算法、模型基技术等传统方法，以及CNN、FCN、U-Net等深度学习架构，还包括注意力机制、半监督学习、GANs和Transformer模型。

Result: 综述展示了医学图像分割领域的技术演进，从基础图像处理到先进深度学习方法的过渡，并识别了混合架构、跨模态学习、联邦学习等新兴趋势。

Conclusion: 尽管医学图像分割领域取得了显著进展，但仍面临数据集偏差、领域适应、模型可解释性以及临床工作流集成等关键挑战，需要进一步研究解决。

Abstract: Medical Image Segmentation (MIS) stands as a cornerstone in medical image
analysis, playing a pivotal role in precise diagnostics, treatment planning,
and monitoring of various medical conditions. This paper presents a
comprehensive and systematic survey of MIS methodologies, bridging the gap
between traditional image processing techniques and modern deep learning
approaches. The survey encompasses thresholding, edge detection, region-based
segmentation, clustering algorithms, and model-based techniques while also
delving into state-of-the-art deep learning architectures such as Convolutional
Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely
adopted U-Net and its variants. Moreover, integrating attention mechanisms,
semi-supervised learning, generative adversarial networks (GANs), and
Transformer-based models is thoroughly explored. In addition to covering
established methods, this survey highlights emerging trends, including hybrid
architectures, cross-modality learning, federated and distributed learning
frameworks, and active learning strategies, which aim to address challenges
such as limited labeled datasets, computational complexity, and model
generalizability across diverse imaging modalities. Furthermore, a specialized
case study on lumbar spine segmentation is presented, offering insights into
the challenges and advancements in this relatively underexplored anatomical
region. Despite significant progress in the field, critical challenges persist,
including dataset bias, domain adaptation, interpretability of deep learning
models, and integration into real-world clinical workflows.

</details>


### [10] [DECOR: Deep Embedding Clustering with Orientation Robustness](https://arxiv.org/abs/2510.03328)
*Fiona Victoria Stanley Jothiraj,Arunaggiri Pandian Karunanidhi,Seth A. Eichmeyer*

Main category: cs.CV

TL;DR: DECOR是一个面向晶圆缺陷检测的深度聚类框架，通过考虑晶圆图的方位变化，能够在不完美数据条件下可靠地对复杂缺陷模式进行聚类。


<details>
  <summary>Details</summary>
Motivation: 半导体制造中晶圆缺陷的早期检测对产品良率优化至关重要，但原始晶圆数据通常复杂、无标签、不平衡且可能包含多种缺陷，需要设计在这样不完美数据条件下仍可靠的聚类方法。

Method: DECOR框架通过深度聚类结合方位鲁棒性，明确考虑晶圆图中的方位变化，确保空间相似的缺陷无论其旋转或对齐方式如何都能被一致地聚类。

Result: 在MixedWM38数据集上的实验表明，DECOR能够无需手动调参即可发现聚类，且性能优于现有的聚类基准方法。

Conclusion: DECOR为自动化视觉检测系统提供了一个可靠且可扩展的解决方案。

Abstract: In semiconductor manufacturing, early detection of wafer defects is critical
for product yield optimization. However, raw wafer data from wafer quality
tests are often complex, unlabeled, imbalanced and can contain multiple defects
on a single wafer, making it crucial to design clustering methods that remain
reliable under such imperfect data conditions. We introduce DECOR, a deep
clustering with orientation robustness framework that groups complex defect
patterns from wafer maps into consistent clusters. We evaluate our method on
the open source MixedWM38 dataset, demonstrating its ability to discover
clusters without manual tuning. DECOR explicitly accounts for orientation
variations in wafer maps, ensuring that spatially similar defects are
consistently clustered regardless of its rotation or alignment. Experiments
indicate that our method outperforms existing clustering baseline methods, thus
providing a reliable and scalable solution in automated visual inspection
systems.

</details>


### [11] [Error correction in multiclass image classification of facial emotion on unbalanced samples](https://arxiv.org/abs/2510.03337)
*Andrey A. Lebedev,Victor B. Kazantsev,Sergey V. Stasenko*

Main category: cs.CV

TL;DR: 该论文提出了一种基于LSTM和注意力机制的面部表情分类方法，用于处理类别不平衡问题，并通过错误校正技术提高对小类别的识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决面部表情分类中类别不平衡的问题，特别是某些情绪类别数量远多于其他类别的情况，这对于实际应用如反欺诈系统中的罕见事件检测具有重要意义。

Method: 使用基于LSTM的神经网络模型，结合注意力机制聚焦于面部关键区域进行情绪识别。通过训练六个类别的子集，然后对第七个类别进行错误校正。

Result: 实验表明所有类别都能进行校正，但效果各异：某些类别恢复较好，其他较差。在测试样本中，校正某些类别时小类别的关键质量指标有所提升。

Conclusion: 该方法可有效应用于面部表情分析系统，以及在类别分布倾斜情况下需要稳定分类的任务中，特别适用于寻找罕见事件的应用场景。

Abstract: This paper considers the problem of error correction in multi-class
classification of face images on unbalanced samples. The study is based on the
analysis of a data frame containing images labeled by seven different emotional
states of people of different ages. Particular attention is paid to the problem
of class imbalance, in which some emotions significantly prevail over others.
To solve the classification problem, a neural network model based on LSTM with
an attention mechanism focusing on key areas of the face that are informative
for emotion recognition is used. As part of the experiments, the model is
trained on all possible configurations of subsets of six classes with
subsequent error correction for the seventh class, excluded at the training
stage. The results show that correction is possible for all classes, although
the degree of success varies: some classes are better restored, others are
worse. In addition, on the test sample, when correcting some classes, an
increase in key quality metrics for small classes was recorded, which indicates
the promise of the proposed approach in solving applied problems related to the
search for rare events, for example, in anti-fraud systems. Thus, the proposed
method can be effectively applied in facial expression analysis systems and in
tasks requiring stable classification under skewed class distribution.

</details>


### [12] [OpusAnimation: Code-Based Dynamic Chart Generation](https://arxiv.org/abs/2510.03341)
*Bozheng Li,Miao Yang,Zhenhan Chen,Jiawang Cao,Mushui Liu,Yi Lu,Yongliang Wu,Bin Zhang,Yangguang Ji,Licheng Tang,Jay Wu,Wenbo Zhu*

Main category: cs.CV

TL;DR: 提出了DCG-Bench基准测试，用于评估多模态大语言模型在动态图表生成任务中的能力，并开发了Qwen2.5-VL-DCG-3B模型，在三个任务上平均性能提升8.31%。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在静态图表生成和理解方面已有显著进展，但在动态图表生成和理解方面的潜力尚未充分探索。

Method: 构建了DCG-8K高质量数据集，采用两阶段训练方法，提出联合代码视觉奖励的组相对策略优化来训练专家模型。

Result: 模型在三个任务上平均性能提升8.31%，仅用3B参数就达到了与专有模型相当的性能。

Conclusion: 提出的训练方法有效，填补了动态图表生成领域的研究空白，代码和数据集将公开提供。

Abstract: Dynamic Chart Generation (DCG) involves producing code-rendered animated
visualizations as charts. While recent advances in multi-modal large language
models (MLLMs) have significantly improved their capability on static chart
generation and comprehension, MLLMs' potential for handling dynamic chart
generation and understanding remains underexplored. To bridge this research
gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first
benchmark evaluating MLLM's capability on dynamic chart generation tasks from
three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and
Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with
annotations covering instruction-code-video triplets and QA pairs for both code
and video evaluation. Based on DCG-8K, we explored a two-stage training recipe,
proposing Joint-Code-Visual Reward for group relative policy optimization to
construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking
result reveals shortcomings of existing MLLMs in the visual-to-chart task, and
our model beats the best open-sourced MLLM with an average 8.31% performance
gain across three tasks, and shows on par performance against proprietary
models with only 3B parameters, proving the effectiveness of our training
recipe. Our code and dataset will be publicly available.

</details>


### [13] [Visual Odometry with Transformers](https://arxiv.org/abs/2510.03348)
*Vlardimir Yugay,Duy-Kien Nguyen,Theo Gevers,Cees G. M. Snoek,Martin R. Oswald*

Main category: cs.CV

TL;DR: VoT是一个端到端的单目视觉里程计Transformer模型，直接预测相机运动而无需估计密集几何，消除了传统方法中的手工组件需求。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉里程计方法依赖复杂pipeline、相机标定和超参数调优的问题，以及现有大规模3D模型在处理长视频和精确逐帧估计方面的局限性。

Method: 使用Transformer架构处理单目帧序列，通过时空注意力建模全局关系，直接预测相机运动，仅使用相机位姿进行监督，可灵活集成各种预训练编码器。

Result: VoT在更大数据集上有效扩展，受益于更强的预训练骨干网络，在不同相机运动和标定设置下泛化良好，性能优于传统方法且运行速度快3倍以上。

Conclusion: 端到端的单目视觉里程计方法是可行的，VoT通过Transformer架构实现了无需手工组件的直接相机运动预测，展现了优越的性能和泛化能力。

Abstract: Modern monocular visual odometry methods typically combine pre-trained deep
learning components with optimization modules, resulting in complex pipelines
that rely heavily on camera calibration and hyperparameter tuning, and often
struggle in unseen real-world scenarios. Recent large-scale 3D models trained
on massive amounts of multi-modal data have partially alleviated these
challenges, providing generalizable dense reconstruction and camera pose
estimation. Still, they remain limited in handling long videos and providing
accurate per-frame estimates, which are required for visual odometry. In this
work, we demonstrate that monocular visual odometry can be addressed
effectively in an end-to-end manner, thereby eliminating the need for
handcrafted components such as bundle adjustment, feature matching, camera
calibration, or dense 3D reconstruction. We introduce VoT, short for Visual
odometry Transformer, which processes sequences of monocular frames by
extracting features and modeling global relationships through temporal and
spatial attention. Unlike prior methods, VoT directly predicts camera motion
without estimating dense geometry and relies solely on camera poses for
supervision. The framework is modular and flexible, allowing seamless
integration of various pre-trained encoders as feature extractors. Experimental
results demonstrate that VoT scales effectively with larger datasets, benefits
substantially from stronger pre-trained backbones, generalizes across diverse
camera motions and calibration settings, and outperforms traditional methods
while running more than 3 times faster. The code will be released.

</details>


### [14] [Inference-Time Search using Side Information for Diffusion-based Image Reconstruction](https://arxiv.org/abs/2510.03352)
*Mahdi Farahbakhsh,Vishnu Teja Kunde,Dileep Kalathil,Krishna Narayanan,Jean-Francois Chamberland*

Main category: cs.CV

TL;DR: 提出了一种基于侧信息的推理时搜索算法，用于改进扩散模型在逆问题中的图像重建质量，能够平衡探索与利用，避免梯度引导方法中的奖励黑客伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型方法通常忽略侧信息，而在严重不适定问题中，侧信息能显著提升重建质量。梯度引导方法容易产生奖励黑客伪影，需要更可靠的引导机制。

Method: 设计了一种推理时搜索算法，利用侧信息指导采样过程，平衡探索与利用。该方法可无缝集成到现有扩散基图像重建流程中。

Result: 在多种逆问题（框内修复、超分辨率、运动/高斯/非线性/盲去模糊等）上实验表明，该方法能持续提升扩散基图像重建算法的定性和定量性能，优于包括奖励梯度引导算法在内的其他基线方法。

Conclusion: 提出的侧信息搜索方法为扩散模型在逆问题中的应用提供了更准确可靠的解决方案，能够有效利用侧信息提升重建质量，避免梯度引导的缺陷。

Abstract: Diffusion models have emerged as powerful priors for solving inverse
problems. However, existing approaches typically overlook side information that
could significantly improve reconstruction quality, especially in severely
ill-posed settings. In this work, we propose a novel inference-time search
algorithm that guides the sampling process using the side information in a
manner that balances exploration and exploitation. This enables more accurate
and reliable reconstructions, providing an alternative to the gradient-based
guidance that is prone to reward-hacking artifacts. Our approach can be
seamlessly integrated into a wide range of existing diffusion-based image
reconstruction pipelines. Through extensive experiments on a number of inverse
problems, such as box inpainting, super-resolution, and various deblurring
tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that
our approach consistently improves the qualitative and quantitative performance
of diffusion-based image reconstruction algorithms. We also show the superior
performance of our approach with respect to other baselines, including reward
gradient-based guidance algorithms. The code is available at
\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this
repository}.

</details>


### [15] [Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges, and Applications](https://arxiv.org/abs/2510.03353)
*Larissa S. Gomes,Gustavo P. Almeida,Bryan U. Moreira,Marco Quiroz,Breno Xavier,Lucas Soares,Stephanie L. Brião,Felipe G. Oliveira,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: 本文对声纳图像数据集进行了全面综述，系统梳理了不同声纳模态的公开数据集，分析了应用场景，并提供了数据集比较和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 声纳图像在水下探索、自主导航和生态系统监测中很重要，但缺乏公开、标注良好的数据集限制了机器学习模型的发展，需要系统梳理现有资源。

Method: 通过映射不同声纳模态（SSS、FLS、SAS、MBES、DIDSON）的公开数据集，分析分类、检测、分割和3D重建等应用，制作主表和时序图进行比较。

Result: 生成了包含数据集特征、规模和标注细节的综合比较表，识别了现有数据集的空白和不足。

Conclusion: 该综述为水下声学数据分析领域的研究人员提供了基础指南，有助于推动声纳图像处理技术的发展。

Abstract: Sonar images are relevant for advancing underwater exploration, autonomous
navigation, and ecosystem monitoring. However, the progress depends on data
availability. The scarcity of publicly available, well-annotated sonar image
datasets creates a significant bottleneck for the development of robust machine
learning models. This paper presents a comprehensive and concise review of the
current landscape of sonar image datasets, seeking not only to catalog existing
resources but also to contextualize them, identify gaps, and provide a clear
roadmap, serving as a base guide for researchers of any kind who wish to start
or advance in the field of underwater acoustic data analysis. We mapped
publicly accessible datasets across various sonar modalities, including Side
Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS),
Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar
(DIDSON). An analysis was conducted on applications such as classification,
detection, segmentation, and 3D reconstruction. This work focuses on
state-of-the-art advancements, incorporating newly released datasets. The
findings are synthesized into a master table and a chronological timeline,
offering a clear and accessible comparison of characteristics, sizes, and
annotation details datasets.

</details>


### [16] [Learned Display Radiance Fields with Lensless Cameras](https://arxiv.org/abs/2510.03356)
*Ziyang Chen,Yuta Itoh,Kaan Akşit*

Main category: cs.CV

TL;DR: 提出了一种无需专业设备的显示器校准方法，通过无透镜相机和隐式神经表示算法从多视角捕获显示器特性。


<details>
  <summary>Details</summary>
Motivation: 传统显示器校准需要专业设备和暗室环境，对大多数用户来说难以实现，因此需要开发更便捷的校准方案。

Method: 结合无透镜相机和基于隐式神经表示的算法，从46.6°×37.6°的视角锥内高效重建显示器发出的光场。

Result: 能够从多视角捕获显示器特性，实现光场重建。

Conclusion: 该方法为轻松实现显示器校准和特性表征迈出了初步但重要的步骤。

Abstract: Calibrating displays is a basic and regular task that content creators must
perform to maintain optimal visual experience, yet it remains a troublesome
issue. Measuring display characteristics from different viewpoints often
requires specialized equipment and a dark room, making it inaccessible to most
users. To avoid specialized hardware requirements in display calibrations, our
work co-designs a lensless camera and an Implicit Neural Representation based
algorithm for capturing display characteristics from various viewpoints. More
specifically, our pipeline enables efficient reconstruction of light fields
emitted from a display from a viewing cone of 46.6{\deg} X 37.6{\deg}. Our
emerging pipeline paves the initial steps towards effortless display
calibration and characterization.

</details>


### [17] [Provenance Networks: End-to-End Exemplar-Based Explainability](https://arxiv.org/abs/2510.03361)
*Ali Kayyam,Anusha Madan Gopal,M. Anthony Lewis*

Main category: cs.CV

TL;DR: 提出溯源网络，一种新型神经网络模型，通过将预测直接关联到支持性训练样本来实现端到端的可解释性，类似于学习的KNN方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度网络的不透明性、幻觉问题和数据贡献者信用分配问题，提高模型的透明度、鲁棒性和可信度。

Method: 在模型架构中嵌入可解释性，学习将每个预测链接到相关的训练样本，通过联合优化主任务和可解释性目标来实现。

Result: 能够系统研究记忆与泛化的权衡，验证输入是否在训练集中，检测错误标签或异常数据，增强对输入扰动的鲁棒性，识别相似输入对新数据点的贡献。

Conclusion: 溯源网络为现有可解释性技术提供了补充方法，虽然增加了计算成本且目前适用于中等规模数据集，但显著提升了神经模型的透明度和可信度。

Abstract: We introduce provenance networks, a novel class of neural models designed to
provide end-to-end, training-data-driven explainability. Unlike conventional
post-hoc methods, provenance networks learn to link each prediction directly to
its supporting training examples as part of the model's normal operation,
embedding interpretability into the architecture itself. Conceptually, the
model operates similarly to a learned KNN, where each output is justified by
concrete exemplars weighted by relevance in the feature space. This approach
facilitates systematic investigations of the trade-off between memorization and
generalization, enables verification of whether a given input was included in
the training set, aids in the detection of mislabeled or anomalous data points,
enhances resilience to input perturbations, and supports the identification of
similar inputs contributing to the generation of a new data point. By jointly
optimizing the primary task and the explainability objective, provenance
networks offer insights into model behavior that traditional deep networks
cannot provide. While the model introduces additional computational cost and
currently scales to moderately sized datasets, it provides a complementary
approach to existing explainability techniques. In particular, it addresses
critical challenges in modern deep learning, including model opaqueness,
hallucination, and the assignment of credit to data contributors, thereby
improving transparency, robustness, and trustworthiness in neural models.

</details>


### [18] [Unified Unsupervised Anomaly Detection via Matching Cost Filtering](https://arxiv.org/abs/2510.03363)
*Zhe Zhang,Mingxiu Cai,Gaochang Wu,Jing Zhang,Lingqiao Liu,Dacheng Tao,Tianyou Chai,Xiatian Zhu*

Main category: cs.CV

TL;DR: 本文提出统一成本过滤(UCF)框架，用于改进无监督异常检测(UAD)方法。UCF通过构建异常成本体积并应用可学习的过滤模块来减少匹配噪声，在单模态和多模态UAD场景中均取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有UAD方法存在匹配噪声问题，且单模态和多模态方法研究相互孤立，缺乏统一视角。本文旨在为单模态和多模态UAD提供统一的匹配视角解决方案。

Method: 提出统一成本过滤(UCF)框架：1)构建测试样本与正常样本的异常成本体积；2)使用可学习的过滤模块，结合测试样本的多层注意力引导，减少匹配噪声并突出细微异常。

Result: 在22个多样化基准测试中，UCF显著提升了多种UAD方法的性能，在单模态(RGB)和多模态(RGB-3D、RGB-Text)UAD场景中均达到新的SOTA结果。

Conclusion: UCF是一个通用的后处理细化框架，能够有效处理匹配噪声问题，为单模态和多模态UAD提供了统一的解决方案，具有广泛的应用前景。

Abstract: Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level
anomalies using only normal training data, with wide applications such as
industrial inspection and medical analysis, where anomalies are scarce due to
privacy concerns and cold-start constraints. Existing methods, whether
reconstruction-based (restoring normal counterparts) or embedding-based
(pretrained representations), fundamentally conduct image- or feature-level
matching to generate anomaly maps. Nonetheless, matching noise has been largely
overlooked, limiting their detection ability. Beyond earlier focus on unimodal
RGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB--3D
and RGB--Text, enabled by point cloud sensing and vision--language models.
Despite shared challenges, these lines remain largely isolated, hindering a
comprehensive understanding and knowledge transfer. In this paper, we advocate
unified UAD for both unimodal and multimodal settings in the matching
perspective. Under this insight, we present Unified Cost Filtering (UCF), a
generic post-hoc refinement framework for refining anomaly cost volume of any
UAD model. The cost volume is constructed by matching a test sample against
normal samples from the same or different modalities, followed by a learnable
filtering module with multi-layer attention guidance from the test sample,
mitigating matching noise and highlighting subtle anomalies. Comprehensive
experiments on 22 diverse benchmarks demonstrate the efficacy of UCF in
enhancing a variety of UAD methods, consistently achieving new state-of-the-art
results in both unimodal (RGB) and multimodal (RGB--3D, RGB--Text) UAD
scenarios. Code and models will be released at
https://github.com/ZHE-SAPI/CostFilter-AD.

</details>


### [19] [Textured Gaussians for Enhanced 3D Scene Appearance Modeling](https://arxiv.org/abs/2411.18625)
*Brian Chao,Hung-Yu Tseng,Lorenzo Porzi,Chen Gao,Tuotuo Li,Qinbo Li,Ayush Saraf,Jia-Bin Huang,Johannes Kopf,Gordon Wetzstein,Changil Kim*

Main category: cs.CV

TL;DR: 本文提出了一种增强3D高斯泼溅的方法，通过为每个高斯添加纹理映射来提升其表达能力，解决了原始方法中每个高斯只能表示单一颜色和简单椭球体的问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅虽然重建和渲染质量高、速度快，但每个高斯只能表示单一颜色和简单椭球体，表达能力有限。本文旨在通过纹理映射增强高斯的表达能力。

Method: 受传统图形学中纹理和alpha映射的启发，为每个高斯添加alpha、RGB或RGBA纹理映射，使每个高斯能够表示更丰富的纹理模式和几何结构。

Result: 在多种标准基准数据集和自定义捕获数据上验证，使用相似或更少的高斯数量实现了图像质量的提升，alpha-only纹理映射能显著提高表达能力，RGB纹理映射达到最高表达能力。

Conclusion: 通过纹理映射增强的高斯泼溅方法能够显著提升3D重建和渲染的表达能力，在保持效率的同时获得更好的图像质量。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a state-of-the-art 3D
reconstruction and rendering technique due to its high-quality results and fast
training and rendering time. However, pixels covered by the same Gaussian are
always shaded in the same color up to a Gaussian falloff scaling factor.
Furthermore, the finest geometric detail any individual Gaussian can represent
is a simple ellipsoid. These properties of 3DGS greatly limit the expressivity
of individual Gaussian primitives. To address these issues, we draw inspiration
from texture and alpha mapping in traditional graphics and integrate it with
3DGS. Specifically, we propose a new generalized Gaussian appearance
representation that augments each Gaussian with alpha~(A), RGB, or RGBA texture
maps to model spatially varying color and opacity across the extent of each
Gaussian. As such, each Gaussian can represent a richer set of texture patterns
and geometric structures, instead of just a single color and ellipsoid as in
naive Gaussian Splatting. Surprisingly, we found that the expressivity of
Gaussians can be greatly improved by using alpha-only texture maps, and further
augmenting Gaussians with RGB texture maps achieves the highest expressivity.
We validate our method on a wide variety of standard benchmark datasets and our
own custom captures at both the object and scene levels. We demonstrate image
quality improvements over existing methods while using a similar or lower
number of Gaussians.

</details>


### [20] [Visual Language Model as a Judge for Object Detection in Industrial Diagrams](https://arxiv.org/abs/2510.03376)
*Sanjukta Ghosh*

Main category: cs.CV

TL;DR: 本文提出了一种使用视觉语言模型(VLMs)评估工业图纸中物体检测结果质量的框架，能够识别缺失或不一致的检测，实现自动化质量评估并提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 工业图纸数字化过程中缺乏自动评估物体检测结果质量的方法，这阻碍了数字孪生和智能工业自动化的发展。

Method: 利用视觉语言模型的多模态能力，通过识别缺失或不一致的检测结果来评估物体检测质量，并指导检测结果的改进。

Result: 该方法能够自动评估物体检测结果的质量，识别检测中的问题，并有效提升复杂工业图纸上的整体检测性能。

Conclusion: 提出的基于VLM的框架填补了工业图纸数字化中自动质量评估的空白，为构建更可靠的数字孪生系统提供了重要支持。

Abstract: Industrial diagrams such as piping and instrumentation diagrams (P&IDs) are
essential for the design, operation, and maintenance of industrial plants.
Converting these diagrams into digital form is an important step toward
building digital twins and enabling intelligent industrial automation. A
central challenge in this digitalization process is accurate object detection.
Although recent advances have significantly improved object detection
algorithms, there remains a lack of methods to automatically evaluate the
quality of their outputs. This paper addresses this gap by introducing a
framework that employs Visual Language Models (VLMs) to assess object detection
results and guide their refinement. The approach exploits the multimodal
capabilities of VLMs to identify missing or inconsistent detections, thereby
enabling automated quality assessment and improving overall detection
performance on complex industrial diagrams.

</details>


### [21] [Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning](https://arxiv.org/abs/2510.03441)
*Chashi Mahiul Islam,Oteo Mamo,Samuel Jacob Chacko,Xiuwen Liu,Weikuan Yu*

Main category: cs.CV

TL;DR: 提出了SpatialViLT，一种增强的视觉语言模型，通过整合深度图、3D坐标和边缘图等空间特征来改进3D场景和复杂物体配置的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在多模态推理方面取得进展，但在3D场景和复杂物体配置的空间推理方面仍面临挑战。

Method: 采用多任务学习框架，整合空间特征（深度图、3D坐标、边缘图）来丰富多模态嵌入。提出了SpatialViLT和MaskedSpatialViLT两个变体，以及结合两者的SpatialEnsemble方法。

Result: 在具有挑战性的视觉空间推理数据集上，模型在方向、拓扑和邻近关系等空间推理类别中表现出色，达到了最先进的准确率。

Conclusion: 这项工作在增强AI系统空间智能方面迈出了重要一步，对于高级多模态理解和实际应用至关重要。

Abstract: Vision-language models (VLMs) have advanced multimodal reasoning but still
face challenges in spatial reasoning for 3D scenes and complex object
configurations. To address this, we introduce SpatialViLT, an enhanced VLM that
integrates spatial features like depth maps, 3D coordinates, and edge maps
through a multi-task learning framework. This approach enriches multimodal
embeddings with spatial understanding. We propose two variants: SpatialViLT and
MaskedSpatialViLT, focusing on full and masked object regions, respectively.
Additionally, SpatialEnsemble combines both approaches, achieving
state-of-the-art accuracy. Our models excel in spatial reasoning categories
such as directional, topological, and proximity relations, as demonstrated on
the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a
significant step in enhancing the spatial intelligence of AI systems, crucial
for advanced multimodal understanding and real-world applications.

</details>


### [22] [Denoising of Two-Phase Optically Sectioned Structured Illumination Reconstructions Using Encoder-Decoder Networks](https://arxiv.org/abs/2510.03452)
*Allison Davis,Yezhi Shen,Xiaoyu Ji,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文研究了使用编码器-解码器网络减少两相光学切片结构照明显微镜中的残余伪影，通过合成训练数据解决缺乏干净地面真实数据的问题。


<details>
  <summary>Details</summary>
Motivation: 两相光学切片结构照明显微镜中，减少采集时间会引入残余伪影，传统去噪方法难以有效抑制，且监督训练受限于缺乏干净的光学切片地面真实数据。

Method: 使用非对称去噪自编码器和U-Net网络，通过将真实伪影场应用于合成图像来创建合成训练对，然后在真实OS-SI图像上进行评估。

Result: 两种网络都提高了图像清晰度，各自在不同类型的伪影抑制方面表现优异。

Conclusion: 合成训练能够实现OS-SI图像的监督去噪，编码器-解码器网络有潜力简化重建工作流程。

Abstract: Structured illumination (SI) enhances image resolution and contrast by
projecting patterned light onto a sample. In two-phase optical-sectioning SI
(OS-SI), reduced acquisition time introduces residual artifacts that
conventional denoising struggles to suppress. Deep learning offers an
alternative to traditional methods; however, supervised training is limited by
the lack of clean, optically sectioned ground-truth data. We investigate
encoder-decoder networks for artifact reduction in two-phase OS-SI, using
synthetic training pairs formed by applying real artifact fields to synthetic
images. An asymmetrical denoising autoencoder (DAE) and a U-Net are trained on
the synthetic data, then evaluated on real OS-SI images. Both networks improve
image clarity, with each excelling against different artifact types. These
results demonstrate that synthetic training enables supervised denoising of
OS-SI images and highlight the potential of encoder-decoder networks to
streamline reconstruction workflows.

</details>


### [23] [PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology](https://arxiv.org/abs/2510.03455)
*Sejuti Majumder,Saarthak Kapse,Moinak Bhattacharya,Xuan Xu,Alisa Yurovsky,Prateek Prasanna*

Main category: cs.CV

TL;DR: PEaRL是一个多模态框架，通过通路激活分数整合组织病理学和空间转录组学，使用transformer编码通路信号并通过对比学习与组织学特征对齐，在多个癌症数据集中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖少量高变基因，限制了预测范围并忽略了协调的生物学程序，需要更全面地整合组织形态和分子功能。

Method: 使用ssGSEA计算通路激活分数，通过transformer编码通路信号，利用对比学习将通路特征与组织学特征对齐。

Result: 在三个癌症ST数据集中，PEaRL在基因和通路水平表达预测方面均优于现有方法，Pearson相关系数分别提高达58.9%和20.4%。

Conclusion: 基于通路的转录组表示能产生更生物学忠实和可解释的多模态模型，推动计算病理学超越基因级嵌入。

Abstract: Integrating histopathology with spatial transcriptomics (ST) provides a
powerful opportunity to link tissue morphology with molecular function. Yet
most existing multimodal approaches rely on a small set of highly variable
genes, which limits predictive scope and overlooks the coordinated biological
programs that shape tissue phenotypes. We present PEaRL (Pathway Enhanced
Representation Learning), a multimodal framework that represents
transcriptomics through pathway activation scores computed with ssGSEA. By
encoding biologically coherent pathway signals with a transformer and aligning
them with histology features via contrastive learning, PEaRL reduces
dimensionality, improves interpretability, and strengthens cross-modal
correspondence. Across three cancer ST datasets (breast, skin, and lymph node),
PEaRL consistently outperforms SOTA methods, yielding higher accuracy for both
gene- and pathway-level expression prediction (up to 58.9 percent and 20.4
percent increase in Pearson correlation coefficient compared to SOTA). These
results demonstrate that grounding transcriptomic representation in pathways
produces more biologically faithful and interpretable multimodal models,
advancing computational pathology beyond gene-level embeddings.

</details>


### [24] [DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical Image Segmentation and Prognosis](https://arxiv.org/abs/2510.03483)
*Numan Saeed,Tausifa Jan Saleem,Fadillah Maani,Muhammad Ridzuan,Hu Wang,Mohammad Yaqub*

Main category: cs.CV

TL;DR: DuPLUS是一个用于多模态医学图像分析的新型深度学习框架，通过分层语义提示和双提示机制实现细粒度任务控制，在分割和预后预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像分析中任务特定模型缺乏泛化性和预后能力的问题，以及现有通用方法语义理解不足和条件控制简单的问题。

Method: 提出基于视觉-语言的分层语义提示框架，采用独特的双提示机制和文本控制架构，支持参数高效微调以适应新任务和模态。

Result: 在10个不同解剖结构的医学数据集上，在8个数据集上优于现有最优方法；在头颈癌数据集上预后预测的Concordance Index达到0.69。

Conclusion: DuPLUS是一个多功能且临床相关的医学图像分析解决方案，能够快速适应新任务和不同中心的模态数据。

Abstract: Deep learning for medical imaging is hampered by task-specific models that
lack generalizability and prognostic capabilities, while existing 'universal'
approaches suffer from simplistic conditioning and poor medical semantic
understanding. To address these limitations, we introduce DuPLUS, a deep
learning framework for efficient multi-modal medical image analysis. DuPLUS
introduces a novel vision-language framework that leverages hierarchical
semantic prompts for fine-grained control over the analysis task, a capability
absent in prior universal models. To enable extensibility to other medical
tasks, it includes a hierarchical, text-controlled architecture driven by a
unique dual-prompt mechanism. For segmentation, DuPLUS is able to generalize
across three imaging modalities, ten different anatomically various medical
datasets, encompassing more than 30 organs and tumor types. It outperforms the
state-of-the-art task specific and universal models on 8 out of 10 datasets. We
demonstrate extensibility of its text-controlled architecture by seamless
integration of electronic health record (EHR) data for prognosis prediction,
and on a head and neck cancer dataset, DuPLUS achieved a Concordance Index (CI)
of 0.69. Parameter-efficient fine-tuning enables rapid adaptation to new tasks
and modalities from varying centers, establishing DuPLUS as a versatile and
clinically relevant solution for medical image analysis. The code for this work
is made available at: https://anonymous.4open.science/r/DuPLUS-6C52

</details>


### [25] [Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms](https://arxiv.org/abs/2510.03501)
*Lyes Saad Saoud,Loic Lesobre,Enrico Sorato,Irfan Hussain*

Main category: cs.CV

TL;DR: 提出了一种移动优化的两阶段深度学习框架，通过线程化并行执行YOLOv10检测和MobileSAM分割，在保护优先物种Houbara鸨上实现了高精度实时动物检测和分割。


<details>
  <summary>Details</summary>
Motivation: 自然环境中实时动物检测和分割对野生动物保护至关重要，但由于计算资源有限和许多物种的隐蔽外观，这些任务仍然具有挑战性。

Method: 集成线程检测模型(TDM)来并行化YOLOv10检测和MobileSAM分割，通过线程化减少延迟，YOLOv10处理检测而MobileSAM执行轻量级分割，两者并发执行以提高资源利用效率。

Result: 在Houbara鸨上实现mAP50为0.9627，mAP75为0.7731，mAP95为0.7178，MobileSAM mIoU为0.7421，YOLOv10每帧处理时间为43.7毫秒，确认实时就绪性。

Conclusion: 该框架通过线程化并行处理显著提高了实时性能，为野生动物保护提供了有效的非侵入性监测解决方案，并发布了包含40,000张标注图像的Houbara数据集。

Abstract: Real-time animal detection and segmentation in natural environments are vital
for wildlife conservation, enabling non-invasive monitoring through remote
camera streams. However, these tasks remain challenging due to limited
computational resources and the cryptic appearance of many species. We propose
a mobile-optimized two-stage deep learning framework that integrates a
Threading Detection Model (TDM) to parallelize YOLOv10-based detection and
MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach
improves real-time performance by reducing latency through threading. YOLOv10
handles detection while MobileSAM performs lightweight segmentation, both
executed concurrently for efficient resource use. On the cryptic Houbara
Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627,
mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10
operates at 43.7 ms per frame, confirming real-time readiness. We introduce a
curated Houbara dataset of 40,000 annotated images to support model training
and evaluation across diverse conditions. The code and dataset used in this
study are publicly available on GitHub at
https://github.com/LyesSaadSaoud/mobile-houbara-detseg. For interactive demos
and additional resources, visit
https://lyessaadsaoud.github.io/LyesSaadSaoud-Threaded-YOLO-SAM-Houbara.

</details>


### [26] [Platonic Transformers: A Solid Choice For Equivariance](https://arxiv.org/abs/2510.03511)
*Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers*

Main category: cs.CV

TL;DR: Platonic Transformer通过将注意力机制与柏拉图立体对称群的参考框架结合，实现了对连续平移和柏拉图对称性的等变性，同时保持了标准Transformer的架构和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer缺乏对几何对称性的归纳偏置，而现有的等变方法往往通过复杂、计算密集的设计牺牲了Transformer的效率和灵活性。

Method: 通过定义相对于柏拉图立体对称群参考框架的注意力机制，引入原则性的权重共享方案，实现连续平移和柏拉图对称性的联合等变性。

Result: 在计算机视觉（CIFAR-10）、3D点云（ScanObjectNN）和分子属性预测（QM9、OMol25）等多个基准测试中，Platonic Transformer通过利用几何约束实现了有竞争力的性能，且无需额外成本。

Conclusion: Platonic Transformer成功解决了Transformer缺乏几何对称性归纳偏置的问题，同时保持了标准Transformer的效率和灵活性，为几何感知的深度学习提供了有效的解决方案。

Abstract: While widespread, Transformers lack inductive biases for geometric symmetries
common in science and computer vision. Existing equivariant methods often
sacrifice the efficiency and flexibility that make Transformers so effective
through complex, computationally intensive designs. We introduce the Platonic
Transformer to resolve this trade-off. By defining attention relative to
reference frames from the Platonic solid symmetry groups, our method induces a
principled weight-sharing scheme. This enables combined equivariance to
continuous translations and Platonic symmetries, while preserving the exact
architecture and computational cost of a standard Transformer. Furthermore, we
show that this attention is formally equivalent to a dynamic group convolution,
which reveals that the model learns adaptive geometric filters and enables a
highly scalable, linear-time convolutional variant. Across diverse benchmarks
in computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular
property prediction (QM9, OMol25), the Platonic Transformer achieves
competitive performance by leveraging these geometric constraints at no
additional cost.

</details>


### [27] [Domain Generalization for Semantic Segmentation: A Survey](https://arxiv.org/abs/2510.03540)
*Manuel Schwonberg,Hanno Gottschalk*

Main category: cs.CV

TL;DR: 这篇论文是关于领域泛化语义分割的综述，重点讨论了深度神经网络在未知领域的泛化挑战，以及向基于基础模型的领域泛化范式的转变。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在未知领域的泛化能力仍然是一个重大挑战，特别是在语义分割任务中，这对生物医学和自动驾驶等领域至关重要。

Method: 作者对现有方法进行了聚类和回顾，识别了向基于基础模型的领域泛化范式的转变，并提供了各种方法的性能比较。

Result: 性能比较显示基础模型对领域泛化有显著影响，这标志着该领域的一个重要发展方向。

Conclusion: 这篇综述旨在推动领域泛化研究，并激励科学家探索新的研究方向，特别是在基础模型的应用方面。

Abstract: The generalization of deep neural networks to unknown domains is a major
challenge despite their tremendous progress in recent years. For this reason,
the dynamic area of domain generalization (DG) has emerged. In contrast to
unsupervised domain adaptation, there is no access to or knowledge about the
target domains, and DG methods aim to generalize across multiple different
unseen target domains. Domain generalization is particularly relevant for the
task semantic segmentation which is used in several areas such as biomedicine
or automated driving. This survey provides a comprehensive overview of the
rapidly evolving topic of domain generalized semantic segmentation. We cluster
and review existing approaches and identify the paradigm shift towards
foundation-model-based domain generalization. Finally, we provide an extensive
performance comparison of all approaches, which highlights the significant
influence of foundation models on domain generalization. This survey seeks to
advance domain generalization research and inspire scientists to explore new
research directions.

</details>


### [28] [From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy](https://arxiv.org/abs/2510.03543)
*Evandros Kaklamanos,Kristjana Kristinsdottir,Jonathan Huang,Dustin Carlson,Rajesh Keswani,John Pandolfino,Mozziyar Etemadi*

Main category: cs.CV

TL;DR: 提出了一种基于transformer的自动化内窥镜报告生成模型，采用两阶段训练框架来减轻胃肠科医生的文档负担。


<details>
  <summary>Details</summary>
Motivation: 内窥镜检查（如EGD和结肠镜检查）的文档记录给胃肠科医生带来沉重负担，导致临床工作流程效率低下和医生职业倦怠。

Method: 使用基于transformer的视觉编码器和文本解码器，采用两阶段训练：先在图像/文本描述对上预训练以捕获通用视觉语言特征，然后在图像/报告对上微调以生成有临床意义的发现。

Result: 该方法不仅简化了文档记录过程，还有望减轻医生工作负担并改善患者护理。

Conclusion: 提出的自动化报告生成模型能够有效解决内窥镜检查的文档负担问题，具有临床应用价值。

Abstract: Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and
colonoscopy play a critical role in diagnosing and managing gastrointestinal
(GI) disorders. However, the documentation burden associated with these
procedures place significant strain on gastroenterologists, contributing to
inefficiencies in clinical workflows and physician burnout. To address this
challenge, we propose a novel automated report generation model that leverages
a transformer-based vision encoder and text decoder within a two-stage training
framework. In the first stage, both components are pre-trained on image/text
caption pairs to capture generalized vision-language features, followed by
fine-tuning on images/report pairs to generate clinically meaningful findings.
Our approach not only streamlines the documentation process but also holds
promise for reducing physician workload and improving patient care.

</details>


### [29] [SketchPlan: Diffusion Based Drone Planning From Human Sketches](https://arxiv.org/abs/2510.03545)
*Sixten Norelius,Aaron O. Feldman,Mac Schwager*

Main category: cs.CV

TL;DR: SketchPlan是一个基于扩散模型的无人机路径规划系统，通过手绘草图在深度图像上生成3D飞行路径，实现零样本从模拟到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 解决无人机导航中如何准确理解人类手绘意图并生成安全3D飞行路径的问题，特别是在未见过的真实环境中。

Method: 包含SketchAdapter（将手绘草图映射到2D投影路径）和DiffPath（从2D投影和深度图像推断3D轨迹的扩散模型），使用合成数据集和少量人工标注数据进行训练。

Result: 在真实世界无人机测试中，低/中障碍物环境下成功率100%，高障碍物环境下成功率40%，比关键消融实验提升20-60%的任务完成率。

Conclusion: 混合人工标注和自动标注数据的训练方法以及模块化设计显著提升了系统理解人类意图和推断3D路径的能力，实现了有效的零样本迁移。

Abstract: We propose SketchPlan, a diffusion-based planner that interprets 2D
hand-drawn sketches over depth images to generate 3D flight paths for drone
navigation. SketchPlan comprises two components: a SketchAdapter that learns to
map the human sketches to projected 2D paths, and DiffPath, a diffusion model
that infers 3D trajectories from 2D projections and a first person view depth
image. Our model achieves zero-shot sim-to-real transfer, generating accurate
and safe flight paths in previously unseen real-world environments. To train
the model, we build a synthetic dataset of 32k flight paths using a diverse set
of photorealistic 3D Gaussian Splatting scenes. We automatically label the data
by computing 2D projections of the 3D flight paths onto the camera plane, and
use this to train the DiffPath diffusion model. However, since real human 2D
sketches differ significantly from ideal 2D projections, we additionally label
872 of the 3D flight paths with real human sketches and use this to train the
SketchAdapter to infer the 2D projection from the human sketch. We demonstrate
SketchPlan's effectiveness in both simulated and real-world experiments, and
show through ablations that training on a mix of human labeled and auto-labeled
data together with a modular design significantly boosts its capabilities to
correctly interpret human intent and infer 3D paths. In real-world drone tests,
SketchPlan achieved 100\% success in low/medium clutter and 40\% in unseen
high-clutter environments, outperforming key ablations by 20-60\% in task
completion.

</details>


### [30] [Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing](https://arxiv.org/abs/2510.03548)
*Danial Samadi Vahdati,Tai Duc Nguyen,Ekta Prashnani,Koki Nagano,David Luebke,Orazio Gallo,Matthew Stamm*

Main category: cs.CV

TL;DR: 提出了一种针对AI视频会议系统中身份劫持攻击的防御方法，通过从姿态-表情潜在空间中提取生物特征来检测非法身份替换，无需查看重建的RGB视频。


<details>
  <summary>Details</summary>
Motivation: AI视频会议系统通过传输紧凑的姿态-表情潜在空间来减少带宽，但该潜在空间可被操纵，使攻击者能够实时劫持受害者身份。由于每帧都是合成的，现有的深度伪造和合成视频检测器完全失效。

Method: 利用姿态-表情潜在空间包含驱动身份生物特征的关键观察，提出姿态条件化的大间隔对比编码器，从传输的潜在空间中分离出持久的身份线索，同时消除瞬时的姿态和表情信息。

Result: 在多个说话头生成模型上的实验表明，该方法始终优于现有的傀儡攻击防御方法，能够实时运行，并在分布外场景中表现出强大的泛化能力。

Conclusion: 该方法通过简单的余弦测试在视频渲染时标记非法身份替换，为AI视频会议系统提供了有效的生物特征泄漏防御解决方案。

Abstract: AI-based talking-head videoconferencing systems reduce bandwidth by sending a
compact pose-expression latent and re-synthesizing RGB at the receiver, but
this latent can be puppeteered, letting an attacker hijack a victim's likeness
in real time. Because every frame is synthetic, deepfake and synthetic video
detectors fail outright. To address this security problem, we exploit a key
observation: the pose-expression latent inherently contains biometric
information of the driving identity. Therefore, we introduce the first
biometric leakage defense without ever looking at the reconstructed RGB video:
a pose-conditioned, large-margin contrastive encoder that isolates persistent
identity cues inside the transmitted latent while cancelling transient pose and
expression. A simple cosine test on this disentangled embedding flags illicit
identity swaps as the video is rendered. Our experiments on multiple
talking-head generation models show that our method consistently outperforms
existing puppeteering defenses, operates in real-time, and shows strong
generalization to out-of-distribution scenarios.

</details>


### [31] [Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!](https://arxiv.org/abs/2510.03550)
*Junbao Zhou,Yuan Zhou,Kesen Zhao,Qingshan Xu,Beier Zhu,Richang Hong,Hanwang Zhang*

Main category: cs.CV

TL;DR: 提出REVEL任务和DragStream方法，实现自回归视频扩散模型的流式、细粒度拖拽控制，解决潜在分布漂移和上下文干扰问题


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频扩散模型难以实现流式、细粒度的输出控制，无法保证与用户期望的一致性

Method: 训练免费方法DragStream，包含自适应分布自校正策略和空间-频率选择性优化机制，利用相邻帧统计约束潜在嵌入漂移，选择性传播视觉线索

Result: 方法可无缝集成到现有自回归视频扩散模型中，大量实验验证了DragStream的有效性

Conclusion: REVEL任务和DragStream方法成功解决了视频流式拖拽操作中的潜在分布漂移和上下文干扰问题，实现了灵活的视频编辑和动画效果

Abstract: Achieving streaming, fine-grained control over the outputs of autoregressive
video diffusion models remains challenging, making it difficult to ensure that
they consistently align with user expectations. To bridge this gap, we propose
\textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new
task that enables users to modify generated videos \emph{anytime} on
\emph{anything} via fine-grained, interactive drag. Beyond DragVideo and
SG-I2V, REVEL unifies drag-style video manipulation as editing and animating
video frames with both supporting user-specified translation, deformation, and
rotation effects, making drag operations versatile. In resolving REVEL, we
observe: \emph{i}) drag-induced perturbations accumulate in latent space,
causing severe latent distribution drift that halts the drag process;
\emph{ii}) streaming drag is easily disturbed by context frames, thereby
yielding visually unnatural outcomes. We thus propose a training-free approach,
\textbf{DragStream}, comprising: \emph{i}) an adaptive distribution
self-rectification strategy that leverages neighboring frames' statistics to
effectively constrain the drift of latent embeddings; \emph{ii}) a
spatial-frequency selective optimization mechanism, allowing the model to fully
exploit contextual information while mitigating its interference via
selectively propagating visual cues along generation. Our method can be
seamlessly integrated into existing autoregressive video diffusion models, and
extensive experiments firmly demonstrate the effectiveness of our DragStream.

</details>


### [32] [GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis](https://arxiv.org/abs/2510.03555)
*Peiran Quan,Zifan Gu,Zhuo Zhao,Qin Zhou,Donghan M. Yang,Ruichen Rong,Yang Xie,Guanghua Xiao*

Main category: cs.CV

TL;DR: GAS-MIL是一个集成框架，能够无缝整合多个基础模型的特征，保留其互补优势，无需手动特征选择或大量任务特定微调，在多种癌症分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 基础模型为计算病理学提供了强大的通用特征提取器，但为特定诊断任务调整和基准测试单个模型通常耗时且资源密集，特别是考虑到其规模和多样性。

Method: 提出了Group-Aggregative Selection多实例学习(GAS-MIL)框架，这是一个灵活的集成框架，能够无缝整合多个基础模型的特征，保留其互补优势，无需手动特征选择或大量任务特定微调。

Result: 在三个癌症数据集（前列腺癌PANDA、卵巢癌UBC-OCEAN、乳腺癌TCGA-BrCa）的分类任务中，GAS-MIL相对于单个基础模型和已建立的多实例学习方法，始终实现优越或相当的性能。

Conclusion: 通过实现异构基础模型的高效集成，GAS-MIL简化了病理学模型部署，并为未来多模态和精准肿瘤学应用提供了可扩展的基础。

Abstract: Foundation models (FMs) have transformed computational pathology by providing
powerful, general-purpose feature extractors. However, adapting and
benchmarking individual FMs for specific diagnostic tasks is often
time-consuming and resource-intensive, especially given their scale and
diversity. To address this challenge, we introduce Group-Aggregative Selection
Multi-Instance Learning (GAS-MIL), a flexible ensemble framework that
seamlessly integrates features from multiple FMs, preserving their
complementary strengths without requiring manual feature selection or extensive
task-specific fine-tuning. Across classification tasks in three cancer
datasets-prostate (PANDA), ovarian (UBC-OCEAN), and breast (TCGA-BrCa)-GAS-MIL
consistently achieves superior or on-par performance relative to individual FMs
and established MIL methods, demonstrating its robustness and generalizability.
By enabling efficient integration of heterogeneous FMs, GAS-MIL streamlines
model deployment for pathology and provides a scalable foundation for future
multimodal and precision oncology applications.

</details>


### [33] [Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted First Aid](https://arxiv.org/abs/2510.03558)
*Shen Chang,Renran Tian,Nicole Adams,Nan Kong*

Main category: cs.CV

TL;DR: 提出无人机辅助纳洛酮递送模拟数据集(DANDSD)，开发基于视频的实时情景感知评估框架，使用图嵌入和Transformer模型来评估旁观者在阿片类药物过量紧急情况下的情景感知能力。


<details>
  <summary>Details</summary>
Motivation: 解决在无人机递送纳洛酮应对阿片类药物过量紧急情况时，对未经医疗培训的旁观者进行实时情景感知评估的研究空白，以支持适应性无人机系统的开发。

Method: 创建DANDSD数据集模拟阿片类药物过量紧急情况，使用图嵌入和Transformer模型整合几何、运动学和交互图特征来评估旁观者的情景感知。

Result: 实现了高性能的情景感知预测，在时间分割准确度上比FINCH基线高出9%的帧平均准确率和5%的交并比。

Conclusion: 该工作支持开发能够有效指导旁观者的适应性无人机系统，最终改善紧急响应结果和挽救生命。

Abstract: Rapid naloxone delivery via drones offers a promising solution for responding
to opioid overdose emergencies (OOEs), by extending lifesaving interventions to
medically untrained bystanders before emergency medical services (EMS) arrive.
Recognizing the critical role of bystander situational awareness (SA) in
human-autonomy teaming (HAT), we address a key research gap in real-time SA
assessment by introducing the Drone-Assisted Naloxone Delivery Simulation
Dataset (DANDSD). This pioneering dataset captures HAT during simulated OOEs,
where college students without medical training act as bystanders tasked with
administering intranasal naloxone to a mock overdose victim. Leveraging this
dataset, we propose a video-based real-time SA assessment framework that
utilizes graph embeddings and transformer models to assess bystander SA in real
time. Our approach integrates visual perception and comprehension cues--such as
geometric, kinematic, and interaction graph features--and achieves
high-performance SA prediction. It also demonstrates strong temporal
segmentation accuracy, outperforming the FINCH baseline by 9% in Mean over
Frames (MoF) and 5% in Intersection over Union (IoU). This work supports the
development of adaptive drone systems capable of guiding bystanders
effectively, ultimately improving emergency response outcomes and saving lives.

</details>


### [34] [Evaluating OCR performance on food packaging labels in South Africa](https://arxiv.org/abs/2510.03570)
*Mayimunah Nagayi,Alice Khan,Tamryn Frank,Rina Swart,Clement Nyirenda*

Main category: cs.CV

TL;DR: 评估四种开源OCR系统(Tesseract、EasyOCR、PaddleOCR、TrOCR)在食品包装图像上的性能，重点关注成分表和营养信息提取能力。


<details>
  <summary>Details</summary>
Motivation: 食品包装OCR对于合规性和营养监测很重要，但由于多语言文本、密集布局、字体变化、反光和曲面等挑战而困难。

Method: 使用231个产品(1,628张图像)的数据集，评估速度和覆盖率，并创建113张图像(60个产品)的真值子集进行准确性评估。

Result: Tesseract获得最低字符错误率(0.912)和最高BLEU分数(0.245)，EasyOCR在准确性和多语言支持间取得良好平衡，PaddleOCR覆盖率接近完全但速度较慢，TrOCR表现最差。

Conclusion: 研究为包装OCR提供了特定基准，建立了基线，并指出了布局感知方法和文本定位的发展方向。

Abstract: This study evaluates four open-source Optical Character Recognition (OCR)
systems which are Tesseract, EasyOCR, PaddleOCR, and TrOCR on real world food
packaging images. The aim is to assess their ability to extract ingredient
lists and nutrition facts panels. Accurate OCR for packaging is important for
compliance and nutrition monitoring but is challenging due to multilingual
text, dense layouts, varied fonts, glare, and curved surfaces. A dataset of 231
products (1,628 images) was processed by all four models to assess speed and
coverage, and a ground truth subset of 113 images (60 products) was created for
accuracy evaluation. Metrics include Character Error Rate (CER), Word Error
Rate (WER), BLEU, ROUGE-L, F1, coverage, and execution time. On the ground
truth subset, Tesseract achieved the lowest CER (0.912) and the highest BLEU
(0.245). EasyOCR provided a good balance between accuracy and multilingual
support. PaddleOCR achieved near complete coverage but was slower because it
ran on CPU only due to GPU incompatibility, and TrOCR produced the weakest
results despite GPU acceleration. These results provide a packaging-specific
benchmark, establish a baseline, and highlight directions for layout-aware
methods and text localization.

</details>


### [35] [FrameOracle: Learning What to See and How Much to See in Videos](https://arxiv.org/abs/2510.03584)
*Chaoyu Li,Tianzhi Li,Fei Tao,Zhenyu Zhao,Ziqian Wu,Maozheng Zhao,Juntong Song,Cheng Niu,Pooyan Fazli*

Main category: cs.CV

TL;DR: FrameOracle是一个轻量级即插即用模块，通过预测最相关帧和所需帧数来解决视频语言模型输入帧数限制问题，显著提升视频理解效率。


<details>
  <summary>Details</summary>
Motivation: 现有帧采样策略无法适应信息密度和任务复杂度的变化，导致效率低下和信息丢失，需要更智能的帧选择方法。

Method: 采用四阶段课程学习训练，前三阶段使用跨模态相似度等弱代理信号，最后阶段利用新构建的FrameOracle-41K数据集提供的强监督关键帧标注。

Result: 在5个VLM和6个基准测试中，FrameOracle将16帧输入平均减少到10.4帧且无精度损失；从64帧候选帧中平均减少到13.9帧，精度提升1.4%。

Conclusion: FrameOracle实现了最先进的效率-精度权衡，为可扩展视频理解提供了有效解决方案。

Abstract: Vision-language models (VLMs) have advanced video understanding, but their
performance is limited by the number of input frames they can process. Existing
frame sampling strategies, such as uniform or fixed-budget selection, often
fail to adapt to variations in information density or task complexity,
resulting in inefficiency and information loss. To address this, we present
FrameOracle, a lightweight and plug-and-play module that predicts both (1)
which frames are most relevant to a given query and (2) how many frames are
needed. FrameOracle is trained using a four-stage curriculum, with the first
three stages relying on weak proxy signals such as cross-modal similarity. In
the final stage, it leverages stronger supervision from a new dataset we
introduce, FrameOracle-41K, the first large-scale VideoQA collection to provide
keyframe annotations specifying the minimal set of frames required to answer
each question. Extensive experiments across five VLMs and six benchmarks
demonstrate that FrameOracle reduces 16-frame inputs to an average of 10.4
frames without any loss in accuracy. When starting from 64-frame candidates, it
reduces the input to an average of 13.9 frames while improving accuracy by
1.4%, achieving state-of-the-art efficiency-accuracy trade-offs for scalable
video understanding.

</details>


### [36] [A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games](https://arxiv.org/abs/2510.03591)
*Faliu Yi,Sherif Abdelfattah,Wei Huang,Adrian Brown*

Main category: cs.CV

TL;DR: 提出了一种混合协同微调(CFT)方法，通过整合标记和未标记数据来改进游戏视觉缺陷检测，减少对目标游戏标记数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 游戏视觉缺陷的手动识别成本高且需要专业知识，而监督模型依赖大量标记数据，但这类缺陷出现频率低，导致数据获取困难。

Method: 采用混合协同微调方法，利用目标游戏和同领域游戏的标记样本，并结合未标记数据来增强特征表示学习。

Result: 实验结果显示该方法在多种游戏环境中优于传统基线方法，即使仅使用50%目标游戏标记数据也能保持竞争力。

Conclusion: CFT方法提高了游戏视觉缺陷检测的可扩展性和适应性，有效减少了特定目标游戏标记数据的需求。

Abstract: Manual identification of visual bugs in video games is a resource-intensive
and costly process, often demanding specialized domain knowledge. While
supervised visual bug detection models offer a promising solution, their
reliance on extensive labeled datasets presents a significant challenge due to
the infrequent occurrence of such bugs. To overcome this limitation, we propose
a hybrid Co-FineTuning (CFT) method that effectively integrates both labeled
and unlabeled data. Our approach leverages labeled samples from the target game
and diverse co-domain games, additionally incorporating unlabeled data to
enhance feature representation learning. This strategy maximizes the utility of
all available data, substantially reducing the dependency on labeled examples
from the specific target game. The developed framework demonstrates enhanced
scalability and adaptability, facilitating efficient visual bug detection
across various game titles. Our experimental results show the robustness of the
proposed method for game visual bug detection, exhibiting superior performance
compared to conventional baselines across multiple gaming environments.
Furthermore, CFT maintains competitive performance even when trained with only
50% of the labeled data from the target game.

</details>


### [37] [Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation](https://arxiv.org/abs/2510.03598)
*Alexander V. Mantzaris*

Main category: cs.CV

TL;DR: HRM模型在MNIST上表现良好（约98%准确率），但在CIFAR-10和CIFAR-100等小尺寸自然图像数据集上过拟合严重，性能远不如简单的卷积神经网络。


<details>
  <summary>Details</summary>
Motivation: 探究HRM模型（包含两个Transformer模块、DEQ风格训练、深度监督等特性）能否作为实用的图像分类器。

Method: 在MNIST、CIFAR-10和CIFAR-100数据集上测试HRM，采用原始训练策略：无数据增强、相同优化器家族、一周期预热后余弦衰减、标签平滑。

Result: HRM在MNIST上达到约98%测试准确率，但在CIFAR-10上仅65.0%（CNN为77.2%），在CIFAR-100上仅29.7%（CNN为45.3%），且训练速度慢30倍。

Conclusion: 对于无增强的小分辨率图像分类，现有HRM模型不如简单卷积架构，但模型修改可能带来显著改进。

Abstract: This paper asks whether the Hierarchical Reasoning Model (HRM) with the two
Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep
supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical
image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a
deliberately raw regime: no data augmentation, identical optimizer family with
one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes
stably and performs well on MNIST ($\approx 98\%$ test accuracy), but on small
natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches
65.0\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains
77.2\% while training $\sim 30\times$ faster per epoch; on CIFAR-100, HRM
achieves only 29.7\% test accuracy despite 91.5\% train accuracy, while the
same CNN reaches 45.3\% test with 50.5\% train accuracy. Loss traces and error
analyses indicate healthy optimization but insufficient image-specific
inductive bias for HRM in this regime. It is concluded that, for
small-resolution image classification without augmentation, HRM is not
competitive with even simple convolutional architectures as the HRM currently
exist but this does not exclude possibilities that modifications to the model
may allow it to improve greatly.

</details>


### [38] [Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops](https://arxiv.org/abs/2510.03606)
*Mattia Scardecchia*

Main category: cs.CV

TL;DR: DINOv2通过多裁剪视图增强和自蒸馏方法，在自监督学习领域超越了弱监督方法，在多个下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 自监督学习(SSL)能够学习到既包含高层语义又包含细粒度空间结构的通用视觉特征，DINOv2在此领域取得了新的突破。

Method: 采用多裁剪视图增强和基于均值教师的自蒸馏方法，结合transformer骨干网络。

Result: DINOv2在大多数基准测试中超越了弱监督方法(如OpenCLIP)，并在各种下游任务中表现出卓越性能。

Conclusion: DINOv2虽然存在一些局限性，但对自监督学习领域产生了重要影响，并为未来研究指明了方向。

Abstract: Recent advances in self-supervised learning (SSL) have made it possible to
learn general-purpose visual features that capture both the high-level
semantics and the fine-grained spatial structure of images. Most notably, the
recent DINOv2 has established a new state of the art by surpassing weakly
supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we
examine the core ideas behind its approach, multi-crop view augmentation and
self-distillation with a mean teacher, and trace their development in previous
work. We then compare the performance of DINO and DINOv2 with other SSL and WSL
methods across various downstream tasks, and highlight some remarkable emergent
properties of their learned features with transformer backbones. We conclude by
briefly discussing DINOv2's limitations, its impact, and future research
directions.

</details>


### [39] [Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL](https://arxiv.org/abs/2510.03608)
*Ruitao Wu,Yifan Zhao,Guangyao Chen,Jia Li*

Main category: cs.CV

TL;DR: 本文提出Diffusion-Classifier Synergy (DCS)框架，通过扩散模型和FSCIL分类器之间的协同进化循环，解决小样本类增量学习中的数据稀缺和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 当前FSCIL方法因依赖有限数据集而泛化能力不足，直接应用扩散模型进行数据增强会导致语义错位或无效指导。需要建立扩散模型与分类器之间的协同机制。

Method: DCS采用奖励对齐学习策略，基于分类器状态构建动态多层面奖励函数来指导扩散模型。特征层面使用原型锚定的最大均值差异和维度方差匹配确保语义一致性和多样性；logits层面通过置信度重校准和跨会话混淆感知机制促进探索性图像生成和类间区分性。

Result: 在FSCIL基准测试中达到最先进性能，显著提升了知识保留和新类学习能力。

Conclusion: 通过扩散模型与分类器的协同进化循环，DCS框架有效解决了FSCIL中的数据稀缺和稳定性-可塑性权衡问题，实现了更好的泛化性能。

Abstract: Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially
learn new classes from minimal examples without forgetting prior knowledge, a
task complicated by the stability-plasticity dilemma and data scarcity. Current
FSCIL methods often struggle with generalization due to their reliance on
limited datasets. While diffusion models offer a path for data augmentation,
their direct application can lead to semantic misalignment or ineffective
guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel
framework that establishes a mutual boosting loop between diffusion model and
FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a
dynamic, multi-faceted reward function derived from the classifier's state
directs the diffusion model. This reward system operates at two levels: the
feature level ensures semantic coherence and diversity using prototype-anchored
maximum mean discrepancy and dimension-wise variance matching, while the logits
level promotes exploratory image generation and enhances inter-class
discriminability through confidence recalibration and cross-session
confusion-aware mechanisms. This co-evolutionary process, where generated
images refine the classifier and an improved classifier state yields better
reward signals, demonstrably achieves state-of-the-art performance on FSCIL
benchmarks, significantly enhancing both knowledge retention and new class
learning.

</details>


### [40] [MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations](https://arxiv.org/abs/2510.03666)
*Jiang Wu,Sichao Wu,Yinsong Ma,Guangyuan Yu,Haoyuan Xu,Lifang Zheng,Jingliang Duan*

Main category: cs.CV

TL;DR: MonitorVLM是一个基于视觉-语言模型的安全违规检测框架，专门用于从监控视频流中自动检测矿业工人的不安全行为，通过领域特定数据集、条款过滤和行为放大模块显著提升了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统人工检查在矿业等高危领域存在劳动密集、易出错且难以适应大规模动态环境的问题，迫切需要智能自动化安全监控解决方案。

Method: 提出MonitorVLM框架，包含三个关键创新：1) 包含9000个VQA样本的领域特定违规数据集；2) 动态选择Top-K相关条款的条款过滤模块；3) 增强工人区域的行为放大模块以改进细粒度动作识别。

Result: 实验结果显示MonitorVLM显著优于基线模型，在精度、召回率和F1分数上分别提升22.01%、34.22%和28.37%，同时推理延迟降低13.56%。

Conclusion: 该研究证明了多模态大模型在提升矿业及其他领域职业安全监控方面的潜力，并通过轻量级Web界面实现自动违规报告功能。

Abstract: Industrial accidents, particularly in high-risk domains such as surface and
underground mining, are frequently caused by unsafe worker behaviors.
Traditional manual inspection remains labor-intensive, error-prone, and
insufficient for large-scale, dynamic environments, highlighting the urgent
need for intelligent and automated safety monitoring. In this paper, we present
MonitorVLM, a novel vision--language framework designed to detect safety
violations directly from surveillance video streams. MonitorVLM introduces
three key innovations: (1) a domain-specific violation dataset comprising 9,000
vision--question--answer (VQA) samples across 40 high-frequency mining
regulations, enriched with augmentation and auxiliary detection cues; (2) a
clause filter (CF) module that dynamically selects the Top-$K$ most relevant
clauses, reducing inference latency by 13.56\% while maintaining accuracy; and
(3) a behavior magnifier (BM) module that enhances worker regions to improve
fine-grained action recognition, yielding additional gains of 3.45% in
precision and 8.62% in recall. Experimental results demonstrate that MonitorVLM
significantly outperforms baseline vision--language models, achieving
improvements of 22.01% in precision, 34.22\% in recall, and 28.37% in F1 score
over the 72B unfine-tuned baseline. A lightweight web-based interface further
integrates MonitorVLM into practical workflows, enabling automatic violation
reporting with video timestamping. This study highlights the potential of
multimodal large models to enhance occupational safety monitoring in mining and
beyond.

</details>


### [41] [A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems](https://arxiv.org/abs/2510.03675)
*Siva Sai,Saksham Gupta,Vinay Chamola,Rajkumar Buyya*

Main category: cs.CV

TL;DR: 提出了一种结合引导分类和扩散技术的混合模型，用于智能交通系统中的事故检测，在公开数据集上达到97.32%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决传统分类方法在处理复杂数据分布时的局限性，利用扩散模型对复杂数据分布的强大理解能力来改进事故检测。

Method: 使用微调的ExceptionNet架构输出作为扩散模型的输入，将图像张量作为条件，通过时间嵌入和图像协变量嵌入来动态调整网络行为，采用云基实现以解决计算密集问题。

Result: 在图像事故检测任务中表现最佳，准确率达到97.32%，通过消融研究分析了时间步调度器、编码技术等关键扩散特性。

Conclusion: 该混合扩散模型框架在智能交通系统事故检测中表现出色，克服了传统分类方法的不足，为复杂场景下的检测任务提供了有效解决方案。

Abstract: The integration of Diffusion Models into Intelligent Transportation Systems
(ITS) is a substantial improvement in the detection of accidents. We present a
novel hybrid model integrating guidance classification with diffusion
techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input
for our proposed diffusion model and processing image tensors as our
conditioning, our approach creates a robust classification framework. Our model
consists of multiple conditional modules, which aim to modulate the linear
projection of inputs using time embeddings and image covariate embeddings,
allowing the network to adapt its behavior dynamically throughout the diffusion
process. To address the computationally intensive nature of diffusion models,
our implementation is cloud-based, enabling scalable and efficient processing.
Our strategy overcomes the shortcomings of conventional classification
approaches by leveraging diffusion models inherent capacity to effectively
understand complicated data distributions. We investigate important diffusion
characteristics, such as timestep schedulers, timestep encoding techniques,
timestep count, and architectural design changes, using a thorough ablation
study, and have conducted a comprehensive evaluation of the proposed model
against the baseline models on a publicly available dataset. The proposed
diffusion model performs best in image-based accident detection with an
accuracy of 97.32%.

</details>


### [42] [SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection](https://arxiv.org/abs/2510.03689)
*Zhengyi Liu,Xinrui Wang,Xianyong Fang,Zhengzheng Tu,Linbo Wang*

Main category: cs.CV

TL;DR: 提出了SAMSOD模型，通过单模态监督增强非主导模态学习，使用梯度解冲突减少冲突梯度对模型收敛的影响，并利用解耦适配器分别处理高低激活神经元来提升RGB-T显著目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在微调Segment Anything Model时忽略了两种模态的不平衡收敛问题以及高低激活之间的显著梯度差异，这限制了性能的进一步提升。

Method: 使用单模态监督增强非主导模态学习，采用梯度解冲突技术减少冲突梯度影响，并利用两个解耦适配器分别掩码高低激活神经元以增强背景学习。

Result: 在RGB-T SOD基准数据集上的基础实验以及在涂鸦监督RGB-T SOD、全监督RGB-D SOD数据集和全监督RGB-D轨道表面缺陷检测上的泛化性实验均证明了方法的有效性。

Conclusion: SAMSOD模型通过解决模态不平衡收敛和梯度差异问题，在RGB-T显著目标检测任务中表现出色，并具有良好的泛化能力。

Abstract: RGB-T salient object detection (SOD) aims to segment attractive objects by
combining RGB and thermal infrared images. To enhance performance, the Segment
Anything Model has been fine-tuned for this task. However, the imbalance
convergence of two modalities and significant gradient difference between high-
and low- activations are ignored, thereby leaving room for further performance
enhancement. In this paper, we propose a model called \textit{SAMSOD}, which
utilizes unimodal supervision to enhance the learning of non-dominant modality
and employs gradient deconfliction to reduce the impact of conflicting
gradients on model convergence. The method also leverages two decoupled
adapters to separately mask high- and low-activation neurons, emphasizing
foreground objects by enhancing background learning. Fundamental experiments on
RGB-T SOD benchmark datasets and generalizability experiments on scribble
supervised RGB-T SOD, fully supervised RGB-D SOD datasets and full-supervised
RGB-D rail surface defect detection all demonstrate the effectiveness of our
proposed method.

</details>


### [43] [Referring Expression Comprehension for Small Objects](https://arxiv.org/abs/2510.03701)
*Kanoko Goto,Takumi Hirose,Mahiro Ukai,Shuhei Kurita,Nakamasa Inoue*

Main category: cs.CV

TL;DR: 提出针对小物体的指代表达理解数据集SOREC和渐进式迭代缩放适配器PIZA，显著提升了小物体定位精度


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言学习在指代表达理解任务上取得显著进展，但在自动驾驶等实际应用中，定位极小物体仍然是一个重大挑战

Method: 构建了包含10万对指代表达和边界框的SOREC数据集，并提出了参数高效的渐进式迭代缩放适配器PIZA用于微调模型

Result: 在SOREC数据集上应用PIZA到GroundingDINO模型，准确率得到显著提升

Conclusion: 提出的SOREC数据集和PIZA方法有效解决了小物体定位的挑战，相关资源已公开

Abstract: Referring expression comprehension (REC) aims to localize the target object
described by a natural language expression. Recent advances in vision-language
learning have led to significant performance improvements in REC tasks.
However, localizing extremely small objects remains a considerable challenge
despite its importance in real-world applications such as autonomous driving.
To address this issue, we introduce a novel dataset and method for REC
targeting small objects. First, we present the small object REC (SOREC)
dataset, which consists of 100,000 pairs of referring expressions and
corresponding bounding boxes for small objects in driving scenarios. Second, we
propose the progressive-iterative zooming adapter (PIZA), an adapter module for
parameter-efficient fine-tuning that enables models to progressively zoom in
and localize small objects. In a series of experiments, we apply PIZA to
GroundingDINO and demonstrate a significant improvement in accuracy on the
SOREC dataset. Our dataset, codes and pre-trained models are publicly available
on the project page.

</details>


### [44] [Artery-Vein Segmentation from Fundus Images using Deep Learning](https://arxiv.org/abs/2510.03717)
*Sharan SK,Subin Sahayam,Umarani Jayaraman,Lakshmi Priya A*

Main category: cs.CV

TL;DR: 提出了一种基于注意力机制的Attention-WNet深度学习模型，用于视网膜血管分割中的动静脉分类，在HRF和DRIVE数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视网膜血管分割为动脉和静脉是视网膜血管分析的前提，这种分析可以为识别和诊断各种视网膜眼病提供潜在见解和生物标志物。血管规律性和宽度的改变可以作为全身血管系统健康的指标，帮助识别高风险患者。

Method: 将注意力机制整合到WNet深度学习模型中，构建了Attention-WNet模型，用于视网膜动静脉分割。

Result: 在公开可用的HRF和DRIVE数据集上进行了测试，提出的方法在性能上优于文献中其他最先进的模型。

Conclusion: 基于注意力机制的Attention-WNet模型在视网膜动静脉分割任务中表现出色，为视网膜血管分析提供了有效的解决方案。

Abstract: Segmenting of clinically important retinal blood vessels into arteries and
veins is a prerequisite for retinal vessel analysis. Such analysis can provide
potential insights and bio-markers for identifying and diagnosing various
retinal eye diseases. Alteration in the regularity and width of the retinal
blood vessels can act as an indicator of the health of the vasculature system
all over the body. It can help identify patients at high risk of developing
vasculature diseases like stroke and myocardial infarction. Over the years,
various Deep Learning architectures have been proposed to perform retinal
vessel segmentation. Recently, attention mechanisms have been increasingly used
in image segmentation tasks. The work proposes a new Deep Learning approach for
artery-vein segmentation. The new approach is based on the Attention mechanism
that is incorporated into the WNet Deep Learning model, and we call the model
as Attention-WNet. The proposed approach has been tested on publicly available
datasets such as HRF and DRIVE datasets. The proposed approach has outperformed
other state-of-art models available in the literature.

</details>


### [45] [Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models](https://arxiv.org/abs/2510.03721)
*Leander Girrbach,Stephan Alaniz,Genevieve Smith,Trevor Darrell,Zeynep Akata*

Main category: cs.CV

TL;DR: 该研究为LAION-400M数据集创建了人物中心标注，揭示了训练数据中的人口统计偏见，并证明CLIP和Stable Diffusion中60-70%的性别偏见可由数据中的直接共现线性解释。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多模态数据集缺乏人口统计标注的问题，以理解训练数据在产生模型偏见中的作用。

Method: 通过验证的自动标注流程，结合目标检测、多模态字幕生成和微调分类器，为LAION-400M数据集创建人物中心标注，包括边界框、感知性别和种族/民族标签。

Result: 发现数据中存在人口统计不平衡和有害关联，如男性和被感知为黑人或中东裔的个体与犯罪相关和负面内容的不成比例关联。

Conclusion: 建立了数据集组成与下游模型偏见之间的大规模实证联系，揭示了训练数据在模型偏见形成中的关键作用。

Abstract: Vision-language models trained on large-scale multimodal datasets show strong
demographic biases, but the role of training data in producing these biases
remains unclear. A major barrier has been the lack of demographic annotations
in web-scale datasets such as LAION-400M. We address this gap by creating
person-centric annotations for the full dataset, including over 276 million
bounding boxes, perceived gender and race/ethnicity labels, and automatically
generated captions. These annotations are produced through validated automatic
labeling pipelines combining object detection, multimodal captioning, and
finetuned classifiers. Using them, we uncover demographic imbalances and
harmful associations, such as the disproportionate linking of men and
individuals perceived as Black or Middle Eastern with crime-related and
negative content. We also show that 60-70% of gender bias in CLIP and Stable
Diffusion can be linearly explained by direct co-occurrences in the data. Our
resources establish the first large-scale empirical link between dataset
composition and downstream model bias.

</details>


### [46] [Mapping Rio de Janeiro's favelas: general-purpose vs. satellite-specific neural networks](https://arxiv.org/abs/2510.03725)
*Thomas Hallopeau,Joris Guérin,Laurent Demagistri,Youssef Fouzai,Renata Gracie,Vanderlei Pascoal De Matos,Helen Gurgel,Nadine Dessay*

Main category: cs.CV

TL;DR: 比较两种预训练神经网络在检测里约热内卢贫民窟方面的性能：通用网络（大数据量）与专用卫星图像网络（任务特定性），探究任务特异性与数据量哪个对性能影响更大。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习检测非正规住区的方法尚未充分利用最近预训练神经网络的潜力，需要研究任务特异性与数据量之间的权衡。

Method: 使用两种预训练神经网络：1）在大型多样化通用图像数据集上预训练的通用网络；2）在卫星图像上预训练的专用网络，比较它们在检测里约热内卢贫民窟方面的性能。

Result: 研究比较了两种网络的性能，但具体结果未在摘要中提供。

Conclusion: 该研究旨在确定在非正规住区检测中，任务特异性与数据量哪个因素对性能影响更大，为选择合适的预训练策略提供指导。

Abstract: While deep learning methods for detecting informal settlements have already
been developed, they have not yet fully utilized the potential offered by
recent pretrained neural networks. We compare two types of pretrained neural
networks for detecting the favelas of Rio de Janeiro: 1. Generic networks
pretrained on large diverse datasets of unspecific images, 2. A specialized
network pretrained on satellite imagery. While the latter is more specific to
the target task, the former has been pretrained on significantly more images.
Hence, this research investigates whether task specificity or data volume
yields superior performance in urban informal settlement detection.

</details>


### [47] [LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes](https://arxiv.org/abs/2510.03747)
*Zuomin Qu,Yimao Guo,Qianyue Hu,Wei Lu*

Main category: cs.CV

TL;DR: 提出LoRA补丁方法，通过向Deepfake生成器注入可插拔的LoRA模块来绕过现有防御系统，同时提出防御性LoRA补丁作为补充解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的主动防御系统缺乏鲁棒性和可靠性，需要揭示其弱点并开发更强大的防御策略。

Method: 使用LoRA补丁技术，结合可学习门控机制防止梯度爆炸，并引入多模态特征对齐损失实现语义级特征对齐。

Result: 仅用1000个面部样本和单轮微调就能成功绕过多种主动防御系统。

Conclusion: 揭示了当前防御范式的关键弱点，强调需要更鲁棒的Deepfake防御策略。

Abstract: Deepfakes pose significant societal risks, motivating the development of
proactive defenses that embed adversarial perturbations in facial images to
prevent manipulation. However, in this paper, we show that these preemptive
defenses often lack robustness and reliability. We propose a novel approach,
Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch
into Deepfake generators to bypass state-of-the-art defenses. A learnable
gating mechanism adaptively controls the effect of the LoRA patch and prevents
gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature
Alignment (MMFA) loss, encouraging the features of adversarial outputs to align
with those of the desired outputs at the semantic level. Beyond bypassing, we
present defensive LoRA patching, embedding visible warnings in the outputs as a
complementary solution to mitigate this newly identified security
vulnerability. With only 1,000 facial examples and a single epoch of
fine-tuning, LoRA patching successfully defeats multiple proactive defenses.
These results reveal a critical weakness in current paradigms and underscore
the need for more robust Deepfake defense strategies. Our code is available at
https://github.com/ZOMIN28/LoRA-Patching.

</details>


### [48] [The Overlooked Value of Test-time Reference Sets in Visual Place Recognition](https://arxiv.org/abs/2510.03751)
*Mubariz Zaffar,Liangliang Nan,Sebastian Scherer,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: 提出参考集微调(RSF)方法，通过在测试时参考集上微调VPR模型，显著提升在具有显著训练-测试域差距的挑战性数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VPR方法在测试环境与训练数据集差异较大时表现不佳，需要利用测试时参考集中的域特定信息来弥合域差距。

Method: 在测试前可用的参考集上对SOTA VPR模型进行微调，利用参考集中的图像和姿态信息提升模型在目标域的适应性。

Result: 在挑战性数据集上平均提升Recall@1约2.3%，微调后的模型保持泛化能力，且RSF方法在不同测试数据集上均有效。

Conclusion: RSF是一种简单有效的技术，能够利用测试时参考集信息显著提升VPR模型在域差距较大场景下的性能。

Abstract: Given a query image, Visual Place Recognition (VPR) is the task of retrieving
an image of the same place from a reference database with robustness to
viewpoint and appearance changes. Recent works show that some VPR benchmarks
are solved by methods using Vision-Foundation-Model backbones and trained on
large-scale and diverse VPR-specific datasets. Several benchmarks remain
challenging, particularly when the test environments differ significantly from
the usual VPR training datasets. We propose a complementary, unexplored source
of information to bridge the train-test domain gap, which can further improve
the performance of State-of-the-Art (SOTA) VPR methods on such challenging
benchmarks. Concretely, we identify that the test-time reference set, the
"map", contains images and poses of the target domain, and must be available
before the test-time query is received in several VPR applications. Therefore,
we propose to perform simple Reference-Set-Finetuning (RSF) of VPR models on
the map, boosting the SOTA (~2.3% increase on average for Recall@1) on these
challenging datasets. Finetuned models retain generalization, and RSF works
across diverse test datasets.

</details>


### [49] [Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization](https://arxiv.org/abs/2510.03763)
*Jiaxin Deng,Junbiao Pang*

Main category: cs.CV

TL;DR: ARSAM通过自适应采样-重用-混合分解梯度来加速SAM，在保持模型泛化能力的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: SAM虽然能提高模型泛化能力，但计算成本是SGD的两倍，需要找到方法来降低这种计算开销。

Method: 将SAM梯度分解为SGD梯度和二阶梯度在一阶梯度上的投影(PSF)，通过自适应重用PSF和及时更新PSF来加速训练。

Result: 在CIFAR-10/100上达到与SAM相当的准确率，速度提升约40%，并在人体姿态估计、模型量化等挑战任务中保持性能。

Conclusion: ARSAM在保持SAM泛化优势的同时显著加速训练，具有广泛的实用性。

Abstract: Sharpness-Aware Minimization (SAM) improves model generalization but doubles
the computational cost of Stochastic Gradient Descent (SGD) by requiring twice
the gradient calculations per optimization step. To mitigate this, we propose
Adaptively sampling-Reusing-mixing decomposed gradients to significantly
accelerate SAM (ARSAM). Concretely, we firstly discover that SAM's gradient can
be decomposed into the SGD gradient and the Projection of the Second-order
gradient onto the First-order gradient (PSF). Furthermore, we observe that the
SGD gradient and PSF dynamically evolve during training, emphasizing the
growing role of the PSF to achieve a flat minima. Therefore, ARSAM is proposed
to the reused PSF and the timely updated PSF still maintain the model's
generalization ability. Extensive experiments show that ARSAM achieves
state-of-the-art accuracies comparable to SAM across diverse network
architectures. On CIFAR-10/100, ARSAM is comparable to SAM while providing a
speedup of about 40\%. Moreover, ARSAM accelerates optimization for the various
challenge tasks (\textit{e.g.}, human pose estimation, and model quantization)
without sacrificing performance, demonstrating its broad practicality.% The
code is publicly accessible at: https://github.com/ajiaaa/ARSAM.

</details>


### [50] [CoPA: Hierarchical Concept Prompting and Aggregating Network for Explainable Diagnosis](https://arxiv.org/abs/2510.03767)
*Yiheng Dong,Yi Lin,Xin Yang*

Main category: cs.CV

TL;DR: CoPA框架通过概念提示和聚合机制，从视觉编码器的多层提取概念表示，解决了传统概念瓶颈模型仅依赖最终层特征的问题，提升了概念捕获能力和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在临床诊断中需要透明度，但现有概念瓶颈方法仅使用最终层特征，忽略了浅层和多尺度特征，缺乏有效的概念编码指导，限制了细粒度概念的提取能力。

Method: 提出CoPA框架，包含概念感知嵌入生成器(CEG)从视觉编码器各层提取概念表示，以及概念提示调优(CPT)引导模型放大关键概念相关视觉线索，最后聚合各层视觉表示与文本概念表示对齐。

Result: 在三个公共数据集上的实验结果表明，CoPA在概念和疾病预测性能上优于现有最先进方法。

Conclusion: CoPA通过多层概念捕获和提示引导机制，有效提取和利用图像中的概念信息，显著提升了概念瓶颈模型在临床诊断中的性能。

Abstract: The transparency of deep learning models is essential for clinical
diagnostics. Concept Bottleneck Model provides clear decision-making processes
for diagnosis by transforming the latent space of black-box models into
human-understandable concepts. However, concept-based methods still face
challenges in concept capture capabilities. These methods often rely on encode
features solely from the final layer, neglecting shallow and multiscale
features, and lack effective guidance in concept encoding, hindering
fine-grained concept extraction. To address these issues, we introduce Concept
Prompting and Aggregating (CoPA), a novel framework designed to capture
multilayer concepts under prompt guidance. This framework utilizes the
Concept-aware Embedding Generator (CEG) to extract concept representations from
each layer of the visual encoder. Simultaneously, these representations serve
as prompts for Concept Prompt Tuning (CPT), steering the model towards
amplifying critical concept-related visual cues. Visual representations from
each layer are aggregated to align with textual concept representations. With
the proposed method, valuable concept-wise information in the images is
captured and utilized effectively, thus improving the performance of concept
and disease prediction. Extensive experimental results demonstrate that CoPA
outperforms state-of-the-art methods on three public datasets. Code is
available at https://github.com/yihengd/CoPA.

</details>


### [51] [Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation](https://arxiv.org/abs/2510.03769)
*Shimaa Elbana,Ahmad Kamal,Shahd Ahmed Ali,Ahmad Al-Kabbany*

Main category: cs.CV

TL;DR: ZFP压缩技术能在保持脑血管分割质量的同时，显著减少3D医学影像数据量，压缩比高达22.89:1，Dice系数仅从0.8774降至0.87656。


<details>
  <summary>Details</summary>
Motivation: 3D医学影像数据集规模和复杂性不断增加，阻碍了协作研究和可移植性，需要找到既能压缩数据又不影响自动分割性能的解决方案。

Method: 在包含真实血管分割的大规模3D医学数据集上，应用ZFP压缩技术的误差容忍和固定速率两种模式，并与未压缩基准进行分割质量对比。

Result: ZFP实现了显著的数据压缩（最高22.89:1压缩比），同时保持了高保真度，平均Dice系数为0.87656，与基准的0.8774几乎相同。

Conclusion: ZFP是促进大规模医学数据集高效和可访问研究的可行且强大工具，有助于推动更广泛的社区协作。

Abstract: The increasing size and complexity of medical imaging datasets, particularly
in 3D formats, present significant barriers to collaborative research and
transferability. This study investigates whether the ZFP compression technique
can mitigate these challenges without compromising the performance of automated
cerebrovascular segmentation, a critical first step in intracranial aneurysm
detection. We apply ZFP in both its error tolerance and fixed-rate modes to a
large scale, and one of the most recent, datasets in the literature, 3D medical
dataset containing ground-truth vascular segmentations. The segmentation
quality on the compressed volumes is rigorously compared to the uncompressed
baseline (Dice approximately equals 0.8774). Our findings reveal that ZFP can
achieve substantial data reduction--up to a 22.89:1 ratio in error tolerance
mode--while maintaining a high degree of fidelity, with the mean Dice
coefficient remaining high at 0.87656. These results demonstrate that ZFP is a
viable and powerful tool for enabling more efficient and accessible research on
large-scale medical datasets, fostering broader collaboration across the
community.

</details>


### [52] [MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based Fusion for Medical Image Segmentation](https://arxiv.org/abs/2510.03786)
*T-Mai Bui,Fares Bougourzi,Fadi Dornaika,Vinh Truong Hoang*

Main category: cs.CV

TL;DR: 提出了一种混合分割架构，集成CNN、Transformer和Mamba注意力融合机制，通过三分支编码器捕获局部、全局和长程依赖关系，在医学图像分割任务中实现了精度和效率的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在医学图像分割中多为任务特定，性能在不同模态和解剖区域间差异较大，且难以平衡模型复杂度和性能，特别是在需要高精度和高效率的临床环境中。

Method: 使用三分支编码器集成CNN、Transformer和Mamba注意力融合机制，结合多尺度注意力CNN解码器重建细粒度分割图，并通过共注意力门增强特征选择和跨尺度通信。

Result: 在多个基准数据集上的广泛实验表明，该方法在精度和泛化能力上优于现有最先进方法，同时保持可比较的计算复杂度。

Conclusion: 该架构通过有效平衡效率和效果，为多样化医学成像任务提供了实用且可扩展的解决方案。

Abstract: In recent years, deep learning has shown near-expert performance in
segmenting complex medical tissues and tumors. However, existing models are
often task-specific, with performance varying across modalities and anatomical
regions. Balancing model complexity and performance remains challenging,
particularly in clinical settings where both accuracy and efficiency are
critical. To address these issues, we propose a hybrid segmentation
architecture featuring a three-branch encoder that integrates CNNs,
Transformers, and a Mamba-based Attention Fusion (MAF) mechanism to capture
local, global, and long-range dependencies. A multi-scale attention-based CNN
decoder reconstructs fine-grained segmentation maps while preserving contextual
consistency. Additionally, a co-attention gate enhances feature selection by
emphasizing relevant spatial and semantic information across scales during both
encoding and decoding, improving feature interaction and cross-scale
communication. Extensive experiments on multiple benchmark datasets show that
our approach outperforms state-of-the-art methods in accuracy and
generalization, while maintaining comparable computational complexity. By
effectively balancing efficiency and effectiveness, our architecture offers a
practical and scalable solution for diverse medical imaging tasks. Source code
and trained models will be publicly released upon acceptance to support
reproducibility and further research.

</details>


### [53] [Road Damage and Manhole Detection using Deep Learning for Smart Cities: A Polygonal Annotation Approach](https://arxiv.org/abs/2510.03797)
*Rasel Hossen,Diptajoy Mistry,Mushiur Rahman,Waki As Sami Atikur Rahman Hridoy,Sajib Saha,Muhammad Ibrahim*

Main category: cs.CV

TL;DR: 使用YOLOv9算法和多边形标注进行道路损坏和井盖检测的深度学习方法，在孟加拉国达卡收集的数据集上训练，整体准确率78.1%，对损坏和未损坏类别表现良好，但井盖检测因类别不平衡面临挑战。


<details>
  <summary>Details</summary>
Motivation: 城市安全和基础设施维护是智慧城市发展的关键组成部分。手动监测道路损坏耗时、成本高且容易出错，需要自动化解决方案。

Method: 采用YOLOv9算法，使用多边形标注而非传统边界框标注，以更精确地定位道路缺陷。开发了包含1000多张图像的数据集，主要从孟加拉国达卡收集，用于训练三个类别的YOLO模型：损坏、未损坏和井盖。

Result: 整体图像级准确率达到78.1%。YOLOv9模型在损坏类别（86.7% F1分数）和未损坏类别（89.2% F1分数）上表现强劲，但井盖检测面临挑战（18.2% F1分数），主要由于类别不平衡问题。

Conclusion: 该方法为发展中国家监测城市基础设施提供了高效且可扩展的解决方案，多边形标注提高了定位精度，但需要解决类别不平衡问题以进一步提升性能。

Abstract: Urban safety and infrastructure maintenance are critical components of smart
city development. Manual monitoring of road damages is time-consuming, highly
costly, and error-prone. This paper presents a deep learning approach for
automated road damage and manhole detection using the YOLOv9 algorithm with
polygonal annotations. Unlike traditional bounding box annotation, we employ
polygonal annotations for more precise localization of road defects. We develop
a novel dataset comprising more than one thousand images which are mostly
collected from Dhaka, Bangladesh. This dataset is used to train a YOLO-based
model for three classes, namely Broken, Not Broken, and Manhole. We achieve
78.1% overall image-level accuracy. The YOLOv9 model demonstrates strong
performance for Broken (86.7% F1-score) and Not Broken (89.2% F1-score)
classes, with challenges in Manhole detection (18.2% F1-score) due to class
imbalance. Our approach offers an efficient and scalable solution for
monitoring urban infrastructure in developing countries.

</details>


### [54] [Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2510.03821)
*Venkata Narendra Kotyada,Revanth Eranki,Nagesh Bhattu Sristy*

Main category: cs.CV

TL;DR: 提出了一种结合对比学习和扩散模型的非配对图像翻译方法，通过时间相关的对比学习保留域不变特征，引导预训练的SDE进行图像翻译。


<details>
  <summary>Details</summary>
Motivation: 非配对图像翻译需要在不使用对齐样本的情况下学习源域和目标域之间的映射。扩散模型能生成高质量多样化的输出，对比学习能学习语义相似性，两者都适合非配对场景。

Method: 使用时间相关的对比学习方法，将图像与其域不变特征作为正样本对进行SimCLR训练，然后使用学习到的对比模型引导预训练的SDE进行图像翻译。

Result: 在三个常见的非配对图像翻译任务上与多个基线方法进行比较，使用四个评估指标。Contrastive-SDE在多个指标上达到与最先进方法相当的结果，收敛速度显著更快，且无需标签监督或分类器训练。

Conclusion: 该方法为非配对图像翻译任务提供了更高效的替代方案，结合了扩散模型和对比学习的优势，实现了快速收敛和无监督学习。

Abstract: Unpaired image-to-image translation involves learning mappings between source
domain and target domain in the absence of aligned or corresponding samples.
Score based diffusion models have demonstrated state-of-the-art performance in
generative tasks. Their ability to approximate complex data distributions
through stochastic differential equations (SDEs) enables them to generate
high-fidelity and diverse outputs, making them particularly well-suited for
unpaired I2I settings. In parallel, contrastive learning provides a powerful
framework for learning semantic similarities without the need for explicit
supervision or paired data. By pulling together representations of semantically
similar samples and pushing apart dissimilar ones, contrastive methods are
inherently aligned with the objectives of unpaired translation. Its ability to
selectively enforce semantic consistency at the feature level makes contrastive
learning particularly effective for guiding generation in unpaired scenarios.
In this work, we propose a time-dependent contrastive learning approach where a
model is trained with SimCLR by considering an image and its domain invarient
feature as a positive pair, enabling the preservation of domain-invariant
features and the discarding of domain-specific ones. The learned contrastive
model then guides the inference of a pretrained SDE for the I2I translation
task. We empirically compare Contrastive-SDE with several baselines across
three common unpaired I2I tasks, using four metrics for evaluation.
Constrastive-SDE achieves comparable results to the state-of-the-art on several
metrics. Furthermore, we observe that our model converges significantly faster
and requires no label supervision or classifier training, making it a more
efficient alternative for this task.

</details>


### [55] [LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization](https://arxiv.org/abs/2510.03827)
*Xueyang Zhou,Yangming Xu,Guiyao Tie,Yongchao Chen,Guowen Zhang,Duanfeng Chu,Pan Zhou,Lichao Sun*

Main category: cs.CV

TL;DR: LIBERO-PRO是一个扩展的VLA模型基准测试，通过四种扰动维度系统评估模型性能，发现现有模型在标准测试中表现优异但在泛化设置下性能崩溃至0%，揭示了模型依赖记忆而非真正理解的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LIBERO基准测试的训练和评估设置存在问题，导致性能估计被夸大且无法公平比较模型。需要引入更严格的评估方法来检验模型的真实泛化能力和理解能力。

Method: 扩展LIBERO基准为LIBERO-PRO，在四个维度引入合理扰动：操作对象、初始状态、任务指令和环境设置，系统评估模型在不同扰动下的性能表现。

Result: 实验结果显示，现有模型在标准LIBERO评估中达到90%以上准确率，但在泛化设置下性能崩溃至0.0%。模型表现出对训练集中动作序列和环境布局的死记硬背，而非真正的任务理解。

Conclusion: 当前评估实践存在严重缺陷，呼吁社区放弃误导性方法，采用能够稳健评估模型泛化能力和理解能力的评估方法。

Abstract: LIBERO has emerged as a widely adopted benchmark for evaluating
Vision-Language-Action (VLA) models; however, its current training and
evaluation settings are problematic, often leading to inflated performance
estimates and preventing fair model comparison. To address these issues, we
introduce LIBERO-PRO, an extended LIBERO benchmark that systematically
evaluates model performance under reasonable perturbations across four
dimensions: manipulated objects, initial states, task instructions, and
environments. Experimental results reveal that, although existing models
achieve over 90% accuracy under the standard LIBERO evaluation, their
performance collapses to 0.0% under our generalized setting. Crucially, this
discrepancy exposes the models' reliance on rote memorization of action
sequences and environment layouts from the training set, rather than genuine
task understanding or environmental perception. For instance, models persist in
executing grasping actions when the target object is replaced with irrelevant
items, and their outputs remain unchanged even when given corrupted
instructions or even messy tokens. These findings expose the severe flaws in
current evaluation practices, and we call on the community to abandon
misleading methodologies in favor of robust assessments of model generalization
and comprehension. Our code is available at:
https://github.com/Zxy-MLlab/LIBERO-PRO.

</details>


### [56] [Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models](https://arxiv.org/abs/2510.03840)
*Pranav Sharma,Shivank Garg,Durga Toshniwal*

Main category: cs.CV

TL;DR: 该论文介绍了Mirage数据集，包含具有可见伪影的AI生成图像，并研究大型视觉语言模型在可解释AI图像检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成图像越来越难以被标准检测器识别，但人类仍能区分。研究旨在解决检测器与人类判断之间的差异。

Method: 构建Mirage数据集，包含多样化的AI生成图像；评估大型视觉语言模型在检测AI生成图像方面的能力。

Result: 大型视觉语言模型能有效检测具有可见伪影的AI生成图像，但在缺乏此类线索的图像上性能下降。

Conclusion: 大型视觉语言模型在可解释AI图像检测方面具有潜力，但需要改进以处理缺乏可见伪影的图像。

Abstract: Recent advances in image generation models have led to models that produce
synthetic images that are increasingly difficult for standard AI detectors to
identify, even though they often remain distinguishable by humans. To identify
this discrepancy, we introduce \textbf{Mirage}, a curated dataset comprising a
diverse range of AI-generated images exhibiting visible artifacts, where
current state-of-the-art detection methods largely fail. Furthermore, we
investigate whether Large Vision-Language Models (LVLMs), which are
increasingly employed as substitutes for human judgment in various tasks, can
be leveraged for explainable AI image detection. Our experiments on both Mirage
and existing benchmark datasets demonstrate that while LVLMs are highly
effective at detecting AI-generated images with visible artifacts, their
performance declines when confronted with images lacking such cues.

</details>


### [57] [UGround: Towards Unified Visual Grounding with Unrolled Transformers](https://arxiv.org/abs/2510.03853)
*Rui Qian,Xin Yin,Chuanhang Deng,Zhiyuan Peng,Jian Xiong,Wei Zhai,Dejing Dou*

Main category: cs.CV

TL;DR: UGround提出了一种统一的视觉定位范式，通过动态选择Transformer中间层作为"掩码提示"，解决了现有方法依赖固定最后一层和"<SEG>作为提示"的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定位方法存在两个主要问题：(1)依赖固定的最后一隐藏层，导致层间传播误差累积；(2)使用<SEG>作为提示，缺乏明确的空间线索。

Method: 提出Policy-Prompted Masking方法，包含随机跳跃连接(SSC)和掩码作为提示(MasP)。SSC通过强化学习动态选择连接层，MasP使用相似度图作为软逻辑掩码来提示SAM生成掩码。

Result: UGround首次在单一框架内统一了从传统参考表达式分割到推理分割、单目标到多目标、正查询到错误前提的视觉定位任务。

Conclusion: UGround通过动态层选择和明确空间线索，有效解决了现有视觉定位方法的局限性，为统一视觉定位提供了新范式。

Abstract: We present UGround, a \textbf{U}nified visual \textbf{Ground}ing paradigm
that dynamically selects intermediate layers across \textbf{U}nrolled
transformers as ``mask as prompt'', diverging from the prevailing pipeline that
leverages the fixed last hidden layer as ``\texttt{<SEG>} as prompt''. UGround
addresses two primary challenges posed by the prevailing paradigm: (1) its
reliance on the fixed last hidden layer, which sequentially amplifies
cumulative errors arising from layer-by-layer propagation without intermediate
correction, and (2) its use of \texttt{<SEG>} as a prompt, which implicitly
projects textual embeddings into visual space without explicit spatial cues
(\eg, coordinates). Central to UGround is Policy-Prompted Masking, which
comprises two key components: Stochastic Skip Connection (SSC) and Mask as
Prompt (MasP). SSC is a reinforcement learning policy that, via stochastic
sampling, allows each \texttt{<SEG>} token to slide across unrolled transformer
layers, enabling dynamic layer selection at which it connects to the vision
model (\eg, SAM) in a skip-connection fashion. Given the selected hidden layer,
MasP uses the similarity map derived from the \texttt{<SEG>} token and image
tokens as a soft logit mask to prompt SAM for mask generation, offering
explicit spatial cues through its activation regions. To validate the
effectiveness of UGround, we, for the first time, have unified visual grounding
within a single framework from an attribute perspective, spanning from
traditional refer expression segmentation to newly proposed reasoning
segmentation, single-target to multi-target, positive query to false premise
(empty target). All codes and models are publicly available at
\href{https://github.com/rui-qian/UGround}{https://github.com/rui-qian/UGround}.

</details>


### [58] [Optimized Minimal 4D Gaussian Splatting](https://arxiv.org/abs/2510.03857)
*Minseo Lee,Byeonghyeon Lee,Lucas Yunkyu Lee,Eunsoo Lee,Sangmin Kim,Seunghyeon Song,Joo Chan Lee,Jong Hwan Ko,Jaesik Park,Eunbyung Park*

Main category: cs.CV

TL;DR: OMG4是一个优化的4D高斯泼溅框架，通过三阶段渐进式修剪（采样、修剪、合并）和隐式外观压缩，显著减少模型存储开销，在保持重建质量的同时将模型大小减少超过60%。


<details>
  <summary>Details</summary>
Motivation: 4D高斯泼溅技术虽然能实时渲染动态场景，但面临存储开销过大的挑战，需要数百万个高斯函数来实现高保真重建。现有方法在压缩比或视觉质量方面仍有局限。

Method: 采用三阶段渐进式修剪：高斯采样识别关键基元、高斯修剪去除冗余、高斯合并融合相似基元；集成隐式外观压缩和广义子向量量化技术。

Result: 在标准基准数据集上的实验表明，OMG4显著优于现有最先进方法，模型大小减少超过60%的同时保持重建质量。

Conclusion: OMG4在紧凑4D场景表示方面迈出了重要一步，为广泛应用开辟了新可能性。

Abstract: 4D Gaussian Splatting has emerged as a new paradigm for dynamic scene
representation, enabling real-time rendering of scenes with complex motions.
However, it faces a major challenge of storage overhead, as millions of
Gaussians are required for high-fidelity reconstruction. While several studies
have attempted to alleviate this memory burden, they still face limitations in
compression ratio or visual quality. In this work, we present OMG4 (Optimized
Minimal 4D Gaussian Splatting), a framework that constructs a compact set of
salient Gaussians capable of faithfully representing 4D Gaussian models. Our
method progressively prunes Gaussians in three stages: (1) Gaussian Sampling to
identify primitives critical to reconstruction fidelity, (2) Gaussian Pruning
to remove redundancies, and (3) Gaussian Merging to fuse primitives with
similar characteristics. In addition, we integrate implicit appearance
compression and generalize Sub-Vector Quantization (SVQ) to 4D representations,
further reducing storage while preserving quality. Extensive experiments on
standard benchmark datasets demonstrate that OMG4 significantly outperforms
recent state-of-the-art methods, reducing model sizes by over 60% while
maintaining reconstruction quality. These results position OMG4 as a
significant step forward in compact 4D scene representation, opening new
possibilities for a wide range of applications. Our source code is available at
https://minshirley.github.io/OMG4/.

</details>


### [59] [Cross-View Open-Vocabulary Object Detection in Aerial Imagery](https://arxiv.org/abs/2510.03858)
*Jyoti Kini,Rohit Gupta,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放词汇目标检测框架，通过结构化域对齐将地面视图的预训练模型知识迁移到航空图像领域，解决了跨域检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测模型在固定类别集上训练，缺乏灵活性且扩展新类别成本高。开放词汇检测能够识别未见类别，但航空图像与地面视图存在域偏移、视角变化和尺度差异，需要专门的适应策略。

Method: 采用对比图像到图像对齐增强航空与地面视图嵌入的相似性，并使用多实例词汇关联来对齐航空图像与文本嵌入，实现结构化域对齐。

Result: 在xView、DOTAv2、VisDrone、DIOR和HRRSD数据集上的实验验证了方法的有效性，零样本设置下在DOTAv2提升+6.32 mAP，VisDrone提升+4.16 mAP，HRRSD提升+3.46 mAP。

Conclusion: 该方法为航空应用中的目标检测系统提供了更灵活和可扩展的解决方案，显著优于微调的封闭词汇模型性能。

Abstract: Traditional object detection models are typically trained on a fixed set of
classes, limiting their flexibility and making it costly to incorporate new
categories. Open-vocabulary object detection addresses this limitation by
enabling models to identify unseen classes without explicit training.
Leveraging pretrained models contrastively trained on abundantly available
ground-view image-text classification pairs provides a strong foundation for
open-vocabulary object detection in aerial imagery. Domain shifts, viewpoint
variations, and extreme scale differences make direct knowledge transfer across
domains ineffective, requiring specialized adaptation strategies. In this
paper, we propose a novel framework for adapting open-vocabulary
representations from ground-view images to solve object detection in aerial
imagery through structured domain alignment. The method introduces contrastive
image-to-image alignment to enhance the similarity between aerial and
ground-view embeddings and employs multi-instance vocabulary associations to
align aerial images with text embeddings. Extensive experiments on the xView,
DOTAv2, VisDrone, DIOR, and HRRSD datasets are used to validate our approach.
Our open-vocabulary model achieves improvements of +6.32 mAP on DOTAv2, +4.16
mAP on VisDrone (Images), and +3.46 mAP on HRRSD in the zero-shot setting when
compared to finetuned closed-vocabulary dataset-specific model performance,
thus paving the way for more flexible and scalable object detection systems in
aerial applications.

</details>


### [60] [Exploring the Challenge and Value of Deep Learning in Automated Skin Disease Diagnosis](https://arxiv.org/abs/2510.03869)
*Runhao Liu,Ziming Chen,Peng Zhang*

Main category: cs.CV

TL;DR: 这篇综述论文探讨了深度学习在皮肤癌诊断中的应用，重点分析了当前面临的挑战及解决方案，并讨论了DL模型在临床工作流程中的整合潜力。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见和最致命的癌症之一，早期检测和诊断对改善患者预后至关重要。深度学习在提高皮肤疾病自动诊断的准确性和效率方面显示出巨大潜力。

Method: 采用基于PRISMA框架的综合方法，综述了应对深度学习皮肤癌诊断挑战的创新方法，包括数据增强、混合模型和特征融合等。

Result: 研究分析了深度学习在皮肤病变检测和分类中的最新进展，识别了复杂特征、图像噪声、类内变异、类间相似性和数据不平衡等主要挑战。

Conclusion: 深度学习有潜力彻底改变皮肤疾病诊断并改善临床决策，但需要持续的技术进步来充分释放其在皮肤病学护理中的变革潜力。

Abstract: Skin cancer is one of the most prevalent and deadly forms of cancer
worldwide, which highlights the critical importance of early detection and
diagnosis in improving patient outcomes. Deep learning (DL) has shown
significant promise in enhancing the accuracy and efficiency of automated skin
disease diagnosis, particularly in detecting and evaluating skin lesions and
classification. However, there are still several challenges for DL-based skin
cancer diagnosis, including complex features, image noise, intra-class
variation, inter-class similarity, and data imbalance. By synthesizing recent
research, this review discusses innovative approaches to cope with these
challenges, such as data augmentation, hybrid models, and feature fusion, etc.
Furthermore, the review highlights the integration of DL models into clinical
workflows, offering insights into the potential of deep learning to
revolutionize skin disease diagnosis and improve clinical decision-making. This
article follows a comprehensive methodology based on the PRISMA framework and
emphasizes the need for continued advancements to fully unlock the
transformative potential of DL in dermatological care.

</details>


### [61] [SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks](https://arxiv.org/abs/2510.03870)
*Nikolaos Kaparinos,Vasileios Mezaris*

Main category: cs.CV

TL;DR: 提出SDAKD方法，通过引入学生判别器解决GAN知识蒸馏中的容量不匹配问题，在图像超分辨率任务上取得优于现有方法的性能


<details>
  <summary>Details</summary>
Motivation: GANs在生成任务中表现优异但计算需求大，难以部署在资源受限设备上。知识蒸馏是GAN压缩的有前景方向，但由于学生生成器与教师判别器之间的容量不匹配，有效训练小型学生生成器具有挑战性

Method: 提出学生判别器辅助知识蒸馏(SDAKD)，引入学生判别器缓解容量不匹配问题。采用三阶段训练策略，并在最后两个阶段集成适配的特征图蒸馏方法

Result: 在GCFSR和Real-ESRGAN两个高性能超分辨率GAN上评估SDAKD，实验显示相比基线和SOTA GAN知识蒸馏方法取得一致改进

Conclusion: SDAKD方法有效解决了GAN知识蒸馏中的容量不匹配问题，为资源受限设备上的GAN部署提供了有效解决方案

Abstract: Generative Adversarial Networks (GANs) achieve excellent performance in
generative tasks, such as image super-resolution, but their computational
requirements make difficult their deployment on resource-constrained devices.
While knowledge distillation is a promising research direction for GAN
compression, effectively training a smaller student generator is challenging
due to the capacity mismatch between the student generator and the teacher
discriminator. In this work, we propose Student Discriminator Assisted
Knowledge Distillation (SDAKD), a novel GAN distillation methodology that
introduces a student discriminator to mitigate this capacity mismatch. SDAKD
follows a three-stage training strategy, and integrates an adapted feature map
distillation approach in its last two training stages. We evaluated SDAKD on
two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our
experiments demonstrate consistent improvements over the baselines and SOTA GAN
knowledge distillation methods. The SDAKD source code will be made openly
available upon acceptance of the paper.

</details>


### [62] [PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and Postural Diagnosis](https://arxiv.org/abs/2510.03873)
*Saja Al-Dabet,Sherzod Turaev,Nazar Zaki,Arif O. Khan,Luai Eldweik*

Main category: cs.CV

TL;DR: 提出了PoseGaze-AHP数据集，这是首个专门用于AI驱动眼源性异常头位诊断的公开资源，同步捕捉头位和注视运动信息。


<details>
  <summary>Details</summary>
Motivation: 现有数据集分别关注头位和眼动，限制了眼源性异常头位综合诊断方法的发展和AI在该领域的进步。

Method: 使用Claude 3.5 Sonnet模型通过迭代过程从医学文献中提取结构化临床数据，采用逐步、分层和复杂提示策略，然后使用神经头像框架将提取的记录系统化插补并转换为3D表示。

Result: 数据集包含7,920张图像，涵盖广泛的眼部疾病谱，提取方法总体准确率达到91.92%。

Conclusion: PoseGaze-AHP是首个公开可用的资源，专门用于AI驱动的眼源性异常头位诊断，支持开发准确且符合隐私要求的诊断工具。

Abstract: Diagnosing ocular-induced abnormal head posture (AHP) requires a
comprehensive analysis of both head pose and ocular movements. However,
existing datasets focus on these aspects separately, limiting the development
of integrated diagnostic approaches and restricting AI-driven advancements in
AHP analysis. To address this gap, we introduce PoseGaze-AHP, a novel 3D
dataset that synchronously captures head pose and gaze movement information for
ocular-induced AHP assessment. Structured clinical data were extracted from
medical literature using large language models (LLMs) through an iterative
process with the Claude 3.5 Sonnet model, combining stepwise, hierarchical, and
complex prompting strategies. The extracted records were systematically imputed
and transformed into 3D representations using the Neural Head Avatar (NHA)
framework. The dataset includes 7,920 images generated from two head textures,
covering a broad spectrum of ocular conditions. The extraction method achieved
an overall accuracy of 91.92%, demonstrating its reliability for clinical
dataset construction. PoseGaze-AHP is the first publicly available resource
tailored for AI-driven ocular-induced AHP diagnosis, supporting the development
of accurate and privacy-compliant diagnostic tools.

</details>


### [63] [DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human](https://arxiv.org/abs/2510.03874)
*Yunhao Li,Sijing Wu,Yucheng Zhu,Huiyu Duan,Zicheng Zhang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一个大规模动态数字人质量评估数据集DHQA-4D，并开发了基于多模态大模型的DynaMesh-Rater方法，用于评估带纹理和不带纹理的4D人体网格质量。


<details>
  <summary>Details</summary>
Motivation: 随着3D扫描和重建技术的发展，基于4D网格的动态数字人化身越来越流行，但在采集、压缩和传输过程中容易受到各种噪声影响，影响用户体验，因此需要有效的质量评估方法。

Method: 首先构建DHQA-4D数据集，包含32个高质量4D人体网格序列和1920个失真样本。然后提出DynaMesh-Rater方法，从投影2D视频提取视觉特征、从裁剪视频片段提取运动特征、从4D网格提取几何特征，最后使用多模态大模型整合这些特征并进行LoRA微调来预测质量分数。

Result: 在DHQA-4D数据集上的大量实验结果表明，DynaMesh-Rater方法优于之前的质量评估方法。

Conclusion: 该研究为动态4D数字人质量评估提供了有效的数据集和方法，能够同时处理带纹理和不带纹理的4D网格，在游戏制作、动画生成和远程沉浸式通信等领域具有应用价值。

Abstract: With the rapid development of 3D scanning and reconstruction technologies,
dynamic digital human avatars based on 4D meshes have become increasingly
popular. A high-precision dynamic digital human avatar can be applied to
various fields such as game production, animation generation, and remote
immersive communication. However, these 4D human avatar meshes are prone to
being degraded by various types of noise during the processes of collection,
compression, and transmission, thereby affecting the viewing experience of
users. In light of this fact, quality assessment of dynamic 4D digital humans
becomes increasingly important. In this paper, we first propose a large-scale
dynamic digital human quality assessment dataset, DHQA-4D, which contains 32
high-quality real-scanned 4D human mesh sequences, 1920 distorted textured 4D
human meshes degraded by 11 textured distortions, as well as their
corresponding textured and non-textured mean opinion scores (MOSs). Equipped
with DHQA-4D dataset, we analyze the influence of different types of distortion
on human perception for textured dynamic 4D meshes and non-textured dynamic 4D
meshes. Additionally, we propose DynaMesh-Rater, a novel large multimodal model
(LMM) based approach that is able to assess both textured 4D meshes and
non-textured 4D meshes. Concretely, DynaMesh-Rater elaborately extracts
multi-dimensional features, including visual features from a projected 2D
video, motion features from cropped video clips, and geometry features from the
4D human mesh to provide comprehensive quality-related information. Then we
utilize a LMM model to integrate the multi-dimensional features and conduct a
LoRA-based instruction tuning technique to teach the LMM model to predict the
quality scores. Extensive experimental results on the DHQA-4D dataset
demonstrate the superiority of our DynaMesh-Rater method over previous quality
assessment methods.

</details>


### [64] [Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive Spatial Feature Fusion](https://arxiv.org/abs/2510.03876)
*Runhao Liu,Ziming Chen,Peng Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于自适应空间特征融合(ASFF)的改进ResNet-50模型，用于皮肤癌分类，通过多尺度特征融合提高特征表示能力并减少过拟合。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类面临类间相似度高、类内变异性大以及图像噪声等挑战，需要更有效的特征表示方法。

Method: 在ResNet-50基础上引入自适应特征融合机制，采用双分支设计融合高层语义和中层细节特征，通过全局平均池化和全连接层生成自适应权重进行加权融合。

Result: 在ISIC 2020数据集子集(3297张图像)上测试，准确率达到93.18%，AUC值分别为0.9670(P-R曲线)和0.9717(ROC曲线)，优于5种经典CNN模型。

Conclusion: 该方法通过自适应特征融合有效提升了皮肤癌分类性能，为计算机辅助诊断提供了更有效的解决方案。

Abstract: Skin cancer classification remains a challenging problem due to high
inter-class similarity, intra-class variability, and image noise in dermoscopic
images. To address these issues, we propose an improved ResNet-50 model
enhanced with Adaptive Spatial Feature Fusion (ASFF), which adaptively
integrates multi-scale semantic and surface features to improve feature
representation and reduce overfitting. The ResNet-50 model is enhanced with an
adaptive feature fusion mechanism to achieve more effective multi-scale feature
extraction and improve overall performance. Specifically, a dual-branch design
fuses high-level semantic and mid-level detail features, which are processed
through global average pooling and fully connected layers to generate adaptive
weights for weighted fusion, thereby strengthening feature learning and
reducing the impact of noise on classification. The method is evaluated on a
subset of the ISIC 2020 dataset containing 3297 benign and malignant skin
lesion images. Experimental results show that the proposed ASFF-based ResNet-50
achieves the best overall performance compared with 5 classic convolutional
neural networks (CNNs) models. The proposed model reached an accuracy of 93.18%
along with higher precision, recall, specificity, and F1 score. The improved
model achieves an AUC value of 0.9670 and 0.9717 in the P-R and ROC curve,
respectively. Then, the evaluation based on Grad-CAM further proved that the
improved model adaptively focuses on lesion-relevant regions while suppressing
irrelevant background information, thereby validating its enhanced feature
learning capability from a deep representation perspective. These findings
demonstrate that the proposed approach provides a more effective and efficient
solution for computer-aided skin cancer diagnosis.

</details>


### [65] [Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional Neural Networks](https://arxiv.org/abs/2510.03878)
*Ajo Babu George,Sreehari J R Ajo Babu George,Sreehari J R Ajo Babu George,Sreehari J R*

Main category: cs.CV

TL;DR: 开发了一个多模态深度学习框架，通过加权集成DenseNet-121 CNN来整合临床、放射学和病理学图像，提高口腔鳞状细胞癌的早期检测能力。


<details>
  <summary>Details</summary>
Motivation: 口腔鳞状细胞癌晚期诊断导致高死亡率，超过50%的病例在晚期被发现，5年生存率低于50%，需要改进早期检测方法。

Method: 使用公开数据集训练三个DenseNet-121 CNN模型，分别对应不同医学成像模态，采用数据增强和模态特定预处理，通过验证加权集成策略融合预测结果。

Result: 放射学模态验证准确率100%，病理学模态95.12%，临床图像63.10%（视觉异质性导致），集成模型在多模态验证集上达到84.58%的总体准确率。

Conclusion: 多模态集成框架提供了一种非侵入性的AI辅助分诊工具，增强了高风险病变的早期识别，支持临床决策，符合全球肿瘤学指南以减少诊断延迟和改善患者预后。

Abstract: Aims Late diagnosis of Oral Squamous Cell Carcinoma (OSCC) contributes
significantly to its high global mortality rate, with over 50\% of cases
detected at advanced stages and a 5-year survival rate below 50\% according to
WHO statistics. This study aims to improve early detection of OSCC by
developing a multimodal deep learning framework that integrates clinical,
radiological, and histopathological images using a weighted ensemble of
DenseNet-121 convolutional neural networks (CNNs). Material and Methods A
retrospective study was conducted using publicly available datasets
representing three distinct medical imaging modalities. Each modality-specific
dataset was used to train a DenseNet-121 CNN via transfer learning.
Augmentation and modality-specific preprocessing were applied to increase
robustness. Predictions were fused using a validation-weighted ensemble
strategy. Evaluation was performed using accuracy, precision, recall, F1-score.
Results High validation accuracy was achieved for radiological (100\%) and
histopathological (95.12\%) modalities, with clinical images performing lower
(63.10\%) due to visual heterogeneity. The ensemble model demonstrated improved
diagnostic robustness with an overall accuracy of 84.58\% on a multimodal
validation dataset of 55 samples. Conclusion The multimodal ensemble framework
bridges gaps in the current diagnostic workflow by offering a non-invasive,
AI-assisted triage tool that enhances early identification of high-risk
lesions. It supports clinicians in decision-making, aligning with global
oncology guidelines to reduce diagnostic delays and improve patient outcomes.

</details>


### [66] [Exploring Instruction Data Quality for Explainable Image Quality Assessment](https://arxiv.org/abs/2510.03880)
*Yunhao Li,Sijing Wu,Huiyu Duan,Yucheng Zhu,Qi Jia,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文挑战了扩展定律，提出了一种基于聚类的数据选择方法IQA-Select，仅使用10%的数据就能达到甚至超过全量微调的性能，显著降低可解释图像质量评估的计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前可解释图像质量评估方法依赖大规模指令调优数据集，但这会导致高昂的计算成本和数据冗余问题，反而损害模型性能。

Method: 提出三阶段聚类数据选择框架：聚类特征提取、聚类配额分配、聚类采样策略，并开发了IQA-Select方法。

Result: 在Q-Bench和AesBench数据集上，仅使用10%选择的数据分别达到了全量微调102.1%和103.7%的性能。

Conclusion: 数据质量比数据量更重要，IQA-Select方法能有效减少计算成本同时提升性能，证明了在可解释IQA任务中数据选择的重要性。

Abstract: In recent years, with the rapid development of powerful multimodal large
language models (MLLMs), explainable image quality assessment (IQA) has
gradually become popular, aiming at providing quality-related descriptions and
answers of images. To achieve this goal, recent methods seek to construct a
large-scale instruction tuning dataset to empower the MLLM with quality
perception ability following the well-known scaling law. However, a large
amount of instruction tuning data may cause substantial computational costs and
redundant data, which in turn will cause harm to the performance of the model.
To cope with this problem, in this paper, we challenge the scaling law and
systematically investigate the role of data quality of the instruction tuning
dataset for explainable IQA. Using a powerful pre-trained MLLM, we first
investigate the changes in model performance after fine-tuning with different
sizes of instruction tuning data. We find that selecting a subset of the data
set randomly using an appropriate ratio can even lead to better results than
training with the entire instruction tuning dataset, demonstrating the
redundancy of current explainable IQA instruction tuning data. Beyond randomly
sampling a subset, we propose a clustering-based data selection framework with
three stages: clustering feature extraction, cluster quota allocation, and
cluster sampling strategy. Then we systematically analyze the choices of each
stage and propose a simple but efficient data selection method IQA-Select for
explainable IQA. The experimental results demonstrate that IQA-Select can
achieve 102.1% and 103.7% performance of full fine-tuning using only 10%
selected data in Q-Bench and AesBench respectively, significantly reducing
computational costs while achieving better performance.

</details>


### [67] [Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert](https://arxiv.org/abs/2510.03896)
*Mingyu Liu,Zheng Huang,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Yating Wang,Haoyi Zhu,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 提出了一种基于通用动作专家的框架，使用稀疏3D轨迹作为中间表示，将VLM的高级规划能力与低级物理动作模块连接起来。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型在将推理能力转化为物理世界时泛化能力差，而双系统方法存在动作模块的语义模糊问题，需要在新环境中重新收集数据。

Method: 使用VLM生成粗略3D路径点，然后由通用动作专家通过采样实时点云观测将其细化为密集可执行动作序列，采用"动作预训练、点云微调"的训练范式。

Result: 该方法结合了VLM在视觉理解和规划方面的广泛泛化能力与动作专家在动作级别的细粒度泛化能力。

Conclusion: 提出的框架通过稀疏3D轨迹中间表示有效解决了VLM到物理动作的转换问题，实现了更好的训练效率和鲁棒泛化。

Abstract: Although Vision-Language Models (VLM) have demonstrated impressive planning
and reasoning capabilities, translating these abilities into the physical world
introduces significant challenges. Conventional Vision-Language-Action (VLA)
models, which integrate reasoning and action into a monolithic architecture,
generalize poorly because they are constrained by scarce, narrow-domain data.
While recent dual-system approaches attempt to decouple "thinking" from
"acting", they are often constrained by semantic ambiguities within the action
module. This ambiguity makes large-scale, cross-task training infeasible.
Consequently, these systems typically necessitate fine-tuning on newly
collected data when deployed to novel environments, and the cooperation
mechanism between the two systems remains ill-defined. To address these
limitations, we introduce, for the first time, a framework centered around a
generalizable action expert. Our approach utilizes sparse 3D trajectories as an
intermediate representation, effectively bridging the high-level planning
capabilities of the VLM with the low-level physical action module. During the
planning phase, the VLM is only required to generate coarse 3D waypoints. These
waypoints are then processed by our generalizable action expert, which refines
them into dense, executable action sequences by sampling real-time point cloud
observations of the environment. To promote training efficiency and robust
generalization, we introduce a novel "Action Pre-training, Pointcloud
Fine-tuning" paradigm. Our method combines the broad generalization
capabilities of VLMs in visual understanding and planning with the
fine-grained, action-level generalization of action expert.

</details>


### [68] [Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models](https://arxiv.org/abs/2510.03903)
*Md. Atabuzzaman,Andrew Zhang,Chris Thomas*

Main category: cs.CV

TL;DR: 提出了一种将零样本细粒度图像分类转化为视觉问答框架的新方法，利用大视觉语言模型的综合理解能力，通过注意力干预技术提升性能，并在多个基准测试中优于现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在视觉语言推理任务中表现出色，但其在需要精确区分视觉相似类别的零样本细粒度图像分类任务中的潜力尚未充分探索。

Method: 将零样本细粒度图像分类转化为视觉问答框架，利用LVLMs的综合理解能力而非直接生成类名，采用新颖的注意力干预技术增强模型性能，并开发更全面精确的类别描述基准。

Result: 在多个细粒度图像分类基准测试中进行了广泛实验，所提方法始终优于当前最优方法，证明了方法的有效性。

Conclusion: 该方法不仅证明了自身有效性，还展示了大视觉语言模型在零样本细粒度分类任务中的更广泛潜力。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive performance
on vision-language reasoning tasks. However, their potential for zero-shot
fine-grained image classification, a challenging task requiring precise
differentiation between visually similar categories, remains underexplored. We
present a novel method that transforms zero-shot fine-grained image
classification into a visual question-answering framework, leveraging LVLMs'
comprehensive understanding capabilities rather than relying on direct class
name generation. We enhance model performance through a novel attention
intervention technique. We also address a key limitation in existing datasets
by developing more comprehensive and precise class description benchmarks. We
validate the effectiveness of our method through extensive experimentation
across multiple fine-grained image classification benchmarks. Our proposed
method consistently outperforms the current state-of-the-art (SOTA) approach,
demonstrating both the effectiveness of our method and the broader potential of
LVLMs for zero-shot fine-grained classification tasks. Code and Datasets:
https://github.com/Atabuzzaman/Fine-grained-classification

</details>


### [69] [From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance](https://arxiv.org/abs/2510.03906)
*Ardalan Aryashad,Parsa Razmara,Amin Mahjoub,Seyedarmin Azizi,Mahdi Salmani,Arad Firouzkouhi*

Main category: cs.CV

TL;DR: 本文对自动驾驶感知系统在雾天条件下的去雾方法进行了系统评估，比较了传统滤波器、现代去雾网络、链式组合方法以及视觉语言模型等多种方案，建立了以任务为导向的去雾方法基准。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在雾天条件下特别脆弱，现有的去雾方法虽然能提升图像保真度，但并不总能改善下游检测和分割性能，且大多基于合成数据，真实世界适用性存疑。

Method: 使用Foggy Cityscapes数据集，系统评估了经典滤波器、现代去雾网络、链式组合（滤波器→模型、模型→滤波器）以及基于提示的视觉语言图像编辑模型等多种去雾流程，同时评估图像质量和下游任务性能。

Result: 分析揭示了去雾方法何时有效、链式组合何时产生协同或退化效应，以及VLM编辑器与专用方法的比较。VLM评判的定性评分与任务指标（特别是mAP）显示出强相关性。

Conclusion: 研究建立了透明、任务导向的去雾方法基准，明确了预处理在恶劣天气下真正改善自动驾驶感知的条件。

Abstract: Autonomous driving perception systems are particularly vulnerable in foggy
conditions, where light scattering reduces contrast and obscures fine details
critical for safe operation. While numerous defogging methods exist-from
handcrafted filters to learned restoration models-improvements in image
fidelity do not consistently translate into better downstream detection and
segmentation. Moreover, prior evaluations often rely on synthetic data, leaving
questions about real-world transferability. We present a structured empirical
study that benchmarks a comprehensive set of pipelines, including (i) classical
filters, (ii) modern defogging networks, (iii) chained variants
(filter$\rightarrow$model, model$\rightarrow$filter), and (iv) prompt-driven
visual--language image editing models (VLM) applied directly to foggy images.
Using Foggy Cityscapes, we assess both image quality and downstream performance
on object detection (mAP) and segmentation (PQ, RQ, SQ). Our analysis reveals
when defogging helps, when chaining yields synergy or degradation, and how
VLM-based editors compare to dedicated approaches. In addition, we evaluate
qualitative rubric-based scores from a VLM judge and quantify their alignment
with task metrics, showing strong correlations with mAP. Together, these
results establish a transparent, task-oriented benchmark for defogging methods
and highlight the conditions under which preprocessing genuinely improves
autonomous perception in adverse weather.

</details>


### [70] [Generating Human Motion Videos using a Cascaded Text-to-Video Framework](https://arxiv.org/abs/2510.03909)
*Hyelin Nam,Hyojun Go,Byeongjun Park,Byung-Hoon Kim,Hyungjin Chung*

Main category: cs.CV

TL;DR: CAMEO是一个用于通用人体运动视频生成的级联框架，通过连接文本到运动(T2M)模型和条件视频扩散模型(VDM)，解决了训练和推理过程中的子优化问题。


<details>
  <summary>Details</summary>
Motivation: 尽管视频扩散模型(VDM)进展迅速，但在通用人体视频生成方面仍未被充分探索，大多数工作局限于图像到视频设置或舞蹈视频等狭窄领域。

Method: 提出了CAMEO级联框架，通过精心设计的组件桥接T2M模型和条件VDM，包括分析准备文本提示和视觉条件来有效训练VDM，以及引入相机感知条件模块自动选择与输入文本对齐的视角。

Result: 在MovieGen基准和新引入的T2M-VDM组合基准上证明了方法的有效性，展示了其在多样化用例中的多功能性。

Conclusion: CAMEO框架成功解决了通用人体运动视频生成的挑战，通过级联方法实现了文本到运动到视频的连贯生成，减少了人工干预并提高了生成质量。

Abstract: Human video generation is becoming an increasingly important task with broad
applications in graphics, entertainment, and embodied AI. Despite the rapid
progress of video diffusion models (VDMs), their use for general-purpose human
video generation remains underexplored, with most works constrained to
image-to-video setups or narrow domains like dance videos. In this work, we
propose CAMEO, a cascaded framework for general human motion video generation.
It seamlessly bridges Text-to-Motion (T2M) models and conditional VDMs,
mitigating suboptimal factors that may arise in this process across both
training and inference through carefully designed components. Specifically, we
analyze and prepare both textual prompts and visual conditions to effectively
train the VDM, ensuring robust alignment between motion descriptions,
conditioning signals, and the generated videos. Furthermore, we introduce a
camera-aware conditioning module that connects the two stages, automatically
selecting viewpoints aligned with the input text to enhance coherence and
reduce manual intervention. We demonstrate the effectiveness of our approach on
both the MovieGen benchmark and a newly introduced benchmark tailored to the
T2M-VDM combination, while highlighting its versatility across diverse use
cases.

</details>


### [71] [OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications](https://arxiv.org/abs/2510.03915)
*Sagar Bharadwaj,Harrison Williams,Luke Wang,Michael Liang,Tao Jin,Srinivasan Seshan,Anthony Rowe*

Main category: cs.CV

TL;DR: OpenFLAME是一个联邦化视觉定位系统，通过分布式方式解决大规模AR应用中的6DoF定位问题，允许不同组织独立维护自己的VPS服务。


<details>
  <summary>Details</summary>
Motivation: 现有集中式VPS解决方案无法覆盖私人室内空间，存在隐私担忧、监管限制和维护瓶颈。需要一种分布式方法来扩大覆盖范围并保护隐私。

Method: 提出联邦化图像定位概念，允许组织独立3D扫描和维护自己的VPS服务，同时提供跨地图数据管理和合并的参考解决方案，无需共享私有数据。

Result: 系统解决了VPS服务分片带来的挑战，包括跨空间定位结果一致性、服务质量控制、位置匹配等问题。

Conclusion: OpenFLAME通过联邦化方法实现了分布式VPS后端，支持访问控制、分布式维护和更大覆盖范围，为未来AR应用提供了可行的定位解决方案。

Abstract: World-scale augmented reality (AR) applications need a ubiquitous 6DoF
localization backend to anchor content to the real world consistently across
devices. Large organizations such as Google and Niantic are 3D scanning outdoor
public spaces in order to build their own Visual Positioning Systems (VPS).
These centralized VPS solutions fail to meet the needs of many future AR
applications -- they do not cover private indoor spaces because of privacy
concerns, regulations, and the labor bottleneck of updating and maintaining 3D
scans. In this paper, we present OpenFLAME, a federated VPS backend that allows
independent organizations to 3D scan and maintain a separate VPS service for
their own spaces. This enables access control of indoor 3D scans, distributed
maintenance of the VPS backend, and encourages larger coverage. Sharding of VPS
services introduces several unique challenges -- coherency of localization
results across spaces, quality control of VPS services, selection of the right
VPS service for a location, and many others. We introduce the concept of
federated image-based localization and provide reference solutions for managing
and merging data across maps without sharing private data.

</details>


### [72] [Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition](https://arxiv.org/abs/2510.03921)
*Arushi Dashore,Aryan Anumala,Emily Hui,Olivia Yang*

Main category: cs.CV

TL;DR: 开发了一个结合CNN-LSTM模型提取生物力学特征和LLM生成反馈的新框架，用于网球击球分析，旨在提供技术上准确且可操作的反馈。


<details>
  <summary>Details</summary>
Motivation: 现有系统虽然整合了生物力学运动线索和深度学习技术，但未能将生物力学洞察转化为对球员和教练有意义且可操作的语言反馈。

Method: 使用CNN-LSTM模型从运动数据中提取关键生物力学特征（如关节角度、肢体速度和动力链模式），并分析这些特征与击球效果和受伤风险的关系，然后利用大语言模型生成反馈。

Result: 该方法在THETIS数据集上进行了实验评估，重点关注分类性能和可解释性。

Conclusion: 该框架弥合了可解释AI与运动生物力学之间的差距，能够生成技术上准确、生物力学基础扎实且对最终用户可操作的反馈。

Abstract: Automated tennis stroke analysis has advanced significantly with the
integration of biomechanical motion cues alongside deep learning techniques,
enhancing stroke classification accuracy and player performance evaluation.
Despite these advancements, existing systems often fail to connect
biomechanical insights with actionable language feedback that is both
accessible and meaningful to players and coaches. This research project
addresses this gap by developing a novel framework that extracts key
biomechanical features (such as joint angles, limb velocities, and kinetic
chain patterns) from motion data using Convolutional Neural Network Long
Short-Term Memory (CNN-LSTM)-based models. These features are analyzed for
relationships influencing stroke effectiveness and injury risk, forming the
basis for feedback generation using large language models (LLMs). Leveraging
the THETIS dataset and feature extraction techniques, our approach aims to
produce feedback that is technically accurate, biomechanically grounded, and
actionable for end-users. The experimental setup evaluates this framework on
classification performance and interpretability, bridging the gap between
explainable AI and sports biomechanics.

</details>


### [73] [Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs](https://arxiv.org/abs/2510.03955)
*Sameep Vani,Shreyas Jena,Maitreya Patel,Chitta Baral,Somak Aditya,Yezhou Yang*

Main category: cs.CV

TL;DR: 提出了TimeWarp方法，通过创建针对性的合成时间数据集来改进视频大语言模型的细粒度时间理解能力，显著提升了在时间理解基准测试上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在一般视频理解任务中表现良好，但在需要细粒度时间理解的任务上表现不佳，原因是缺乏视觉复杂性和时间细微差别的微调数据集，导致模型过度依赖语言推理而非真正理解视频动态。

Method: 提出TimeWarp方法，系统性地创建针对性的合成时间数据集，通过微调模型响应来鼓励其关注输入视频内容，并构建了一个大规模偏好数据集来捕捉常被忽略的复杂时间动态。

Result: 应用该方法后，现有模型在时间理解基准测试上的性能显著提升，在七个基准测试中都取得了绝对性能改进。

Conclusion: TimeWarp方法通过创建针对性的时间数据集有效提升了视频大语言模型的时间理解能力，证明了所提出数据集在推进视频大语言模型时间理解方面的有效性。

Abstract: While Video Large Language Models (Video-LLMs) have demonstrated remarkable
performance across general video understanding benchmarks-particularly in video
captioning and descriptive tasks-they consistently underperform on tasks that
require fine-grained temporal understanding. This limitation arises due to the
lack of visual complexity and temporal nuance in current fine-tuning datasets,
leading these models to rely heavily on language-based reasoning rather than
truly understanding video dynamics. In this work, we propose TimeWarp, a
systematic method to create a targeted synthetic temporal dataset to fine-tune
the model's responses to encourage it to focus on the given input video. We
introduce a large-scale preference dataset, created using TimeWarp, that
captures intricate temporal dynamics often overlooked, grounding the model's
responses to visual and temporal information. We demonstrate that when our
method is applied to existing models, it significantly improves performance on
temporal understanding benchmarks, highlighting the effectiveness of our
proposed datasets in advancing temporal understanding in Video-LLMs, resulting
in an absolute improvement in performance across seven benchmarks. Code is
available at https://github.com/sameepv21/timewarp.

</details>


### [74] [No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models](https://arxiv.org/abs/2510.03978)
*Min Woo Sun,Alejandro Lozano,Javier Gamazo Tejero,Vishwesh Nath,Xiao Xiao Sun,James Burgess,Yuhui Zhang,Kun Yuan,Robert Tibshirani,Sean Huver,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文研究了在生物医学视觉语言模型中扩展文本编码器上下文长度的影响，发现更长的上下文能带来更好的检索和分类性能，并提出了BIOMEDICA-LongCAP数据集和BMC-LongCLIP模型。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型通常预训练时使用短文本窗口(<77个token)，这导致长格式的生物医学描述被截断。然而，大规模开源文献中的生物医学描述有很大部分远超77个token，因此需要研究长上下文预训练的影响。

Method: 通过扩展视觉语言模型中文本编码器的上下文长度，使用BIOMEDICA-LongCAP数据集（包含100万图像-描述对，具有来自全文文章的上下文感知描述）训练BMC-LongCLIP模型，文本编码器支持最多512个token的窗口。

Result: BMC-LongCLIP将上下文容量扩展了6.6倍，token浪费从55%减少到2.2%。在长描述检索基准测试中，Recall@1实现了高达+30%的绝对增益，分类平均改进+2%，且比短上下文模型收敛更快。

Conclusion: 长上下文建模是推进生物医学视觉语言模型的一个有前景的方向，更长的上下文能够利用长格式描述中提供的额外监督信息，显著提升模型性能。

Abstract: Embedding vision-language models (VLMs) are typically pretrained with short
text windows (<77 tokens), which forces the truncation of long-format captions.
Yet, the distribution of biomedical captions from large-scale open source
literature reveals that a huge portion of captions far exceed 77 tokens. To
this end, we investigate the impact of pretraining on long-format biomedical
captions by extending the context length of text encoders in VLMs. We find that
longer context (thus, enabling additional supervision provided in long-format
captions) correlates with better retrieval and classification performance.
Given this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M
image-caption pairs enriched with context-aware descriptions from full-text
articles, providing longer and additional textual supervision. Using
BIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a
text encoder supporting windows of up to 512 tokens. Our model extends context
capacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption
retrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in
Recall@1 and +2% average improvements in classification, while also converging
faster than short-context. Our results demonstrate that long-context modeling
is a promising direction for advancing biomedical VLMs.

</details>


### [75] [Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2510.03993)
*Yaxin Hou,Bo Han,Yuheng Jia,Hui Liu,Junhui Hou*

Main category: cs.CV

TL;DR: 提出CPG框架解决长尾半监督学习中未标记数据分布未知的问题，通过可控伪标签生成和动态优化循环，使模型不受未标记数据分布影响，在多个基准数据集上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有长尾半监督学习方法假设未标记数据遵循预定义分布，但实际上未标记数据的分布是未知且任意的，这限制了现有方法的性能。

Method: CPG框架包含：1) 动态可控过滤机制选择可靠伪标签；2) 基于更新后标记数据分布构建贝叶斯最优分类器；3) 类感知自适应增强模块改善少数类表示；4) 辅助分支最大化数据利用率。

Result: 在多个常用基准数据集上的综合评估显示，CPG实现了持续改进，在准确率上超越最先进方法高达15.97%。

Conclusion: CPG通过可控伪标签生成和自增强优化循环，有效解决了未标记数据分布未知的问题，显著提升了长尾半监督学习的性能。

Abstract: Current long-tailed semi-supervised learning methods assume that labeled data
exhibit a long-tailed distribution, and unlabeled data adhere to a typical
predefined distribution (i.e., long-tailed, uniform, or inverse long-tailed).
However, the distribution of the unlabeled data is generally unknown and may
follow an arbitrary distribution. To tackle this challenge, we propose a
Controllable Pseudo-label Generation (CPG) framework, expanding the labeled
dataset with the progressively identified reliable pseudo-labels from the
unlabeled dataset and training the model on the updated labeled dataset with a
known distribution, making it unaffected by the unlabeled data distribution.
Specifically, CPG operates through a controllable self-reinforcing optimization
cycle: (i) at each training step, our dynamic controllable filtering mechanism
selectively incorporates reliable pseudo-labels from the unlabeled dataset into
the labeled dataset, ensuring that the updated labeled dataset follows a known
distribution; (ii) we then construct a Bayes-optimal classifier using logit
adjustment based on the updated labeled data distribution; (iii) this improved
classifier subsequently helps identify more reliable pseudo-labels in the next
training step. We further theoretically prove that this optimization cycle can
significantly reduce the generalization error under some conditions.
Additionally, we propose a class-aware adaptive augmentation module to further
improve the representation of minority classes, and an auxiliary branch to
maximize data utilization by leveraging all labeled and unlabeled samples.
Comprehensive evaluations on various commonly used benchmark datasets show that
CPG achieves consistent improvements, surpassing state-of-the-art methods by up
to \textbf{15.97\%} in accuracy. The code is available at
https://github.com/yaxinhou/CPG.

</details>


### [76] [Enhancing OCR for Sino-Vietnamese Language Processing via Fine-tuned PaddleOCRv5](https://arxiv.org/abs/2510.04003)
*Minh Hoang Nguyen,Su Nguyen Thiet*

Main category: cs.CV

TL;DR: 本文提出了一种基于PaddleOCRv5的微调方法，用于提升古典汉语（汉喃）文本的字符识别准确率，在噪声图像条件下将准确率从37.5%提升至50.0%。


<details>
  <summary>Details</summary>
Motivation: 现有OCR系统在处理越南历史文献中的古典汉语文本时，面临扫描质量差、字形不规范和手写变体等挑战，需要专门优化。

Method: 使用精选的越南古典汉语手稿子集对PaddleOCRv5的文本识别模块进行微调，构建完整的训练流程包括预处理、LMDB转换、评估和可视化。

Result: 实验结果显示，微调后模型在噪声图像条件下的准确率显著提升，从37.5%提高到50.0%。

Conclusion: 该方法有效提升了古典汉语文本识别性能，并开发了交互式演示系统，支持汉越语义对齐、机器翻译和历史语言学研究等下游应用。

Abstract: Recognizing and processing Classical Chinese (Han-Nom) texts play a vital
role in digitizing Vietnamese historical documents and enabling cross-lingual
semantic research. However, existing OCR systems struggle with degraded scans,
non-standard glyphs, and handwriting variations common in ancient sources. In
this work, we propose a fine-tuning approach for PaddleOCRv5 to improve
character recognition on Han-Nom texts. We retrain the text recognition module
using a curated subset of ancient Vietnamese Chinese manuscripts, supported by
a full training pipeline covering preprocessing, LMDB conversion, evaluation,
and visualization. Experimental results show a significant improvement over the
base model, with exact accuracy increasing from 37.5 percent to 50.0 percent,
particularly under noisy image conditions. Furthermore, we develop an
interactive demo that visually compares pre- and post-fine-tuning recognition
results, facilitating downstream applications such as Han-Vietnamese semantic
alignment, machine translation, and historical linguistics research. The demo
is available at https://huggingface.co/spaces/MinhDS/Fine-tuned-PaddleOCRv5.

</details>


### [77] [Fit Pixels, Get Labels: Meta-learned Implicit Networks for Image Segmentation](https://arxiv.org/abs/2510.04021)
*Kushal Vyas,Ashok Veeraraghavan,Guha Balakrishnan*

Main category: cs.CV

TL;DR: MetaSeg是一个用于医学图像分割的元学习框架，通过隐式神经表示同时预测像素强度和类别标签，只需少量参数就能达到与U-Net相当的分割性能。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示在信号表示方面表现出色，但难以直接应用于分割等预测任务。需要一种方法让INR能够学习信号的语义结构分布。

Method: 使用底层INR同时预测像素强度值和类别标签，通过元学习在训练数据集上找到最优初始参数，使得INR只需微调即可适应未见过的测试图像并自动解码类别标签。

Result: 在2D和3D脑部MRI分割任务上评估，Dice分数与常用的U-Net模型相当，但参数数量减少了90%。

Conclusion: MetaSeg为医学图像分割提供了一个新颖、可扩展的替代方案，相比传统的资源密集型架构如U-Net和视觉变换器更具优势。

Abstract: Implicit neural representations (INRs) have achieved remarkable successes in
learning expressive yet compact signal representations. However, they are not
naturally amenable to predictive tasks such as segmentation, where they must
learn semantic structures over a distribution of signals. In this study, we
introduce MetaSeg, a meta-learning framework to train INRs for medical image
segmentation. MetaSeg uses an underlying INR that simultaneously predicts per
pixel intensity values and class labels. It then uses a meta-learning procedure
to find optimal initial parameters for this INR over a training dataset of
images and segmentation maps, such that the INR can simply be fine-tuned to fit
pixels of an unseen test image, and automatically decode its class labels. We
evaluated MetaSeg on 2D and 3D brain MRI segmentation tasks and report Dice
scores comparable to commonly used U-Net models, but with $90\%$ fewer
parameters. MetaSeg offers a fresh, scalable alternative to traditional
resource-heavy architectures such as U-Nets and vision transformers for medical
image segmentation. Our project is available at
https://kushalvyas.github.io/metaseg.html .

</details>


### [78] [Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved Reasoning](https://arxiv.org/abs/2510.04022)
*Chendong Wang,Donglin Bai,Yifan Yang,Xiao Jin,Anlan Zhang,Rui Wang,Shiqi Jiang,Yuqing Yang,Hao Wu,Qi Dai,Chong Luo,Ting Cao,Lili Qiu,Suman Banerjee*

Main category: cs.CV

TL;DR: Video-in-the-Loop (ViTL) 是一个两阶段长视频问答框架，通过局部化问题相关片段和重新分配视觉token来在固定token预算下实现高效长视频理解。


<details>
  <summary>Details</summary>
Motivation: 解决长视频问答中固定token预算下的效率问题，通过智能选择关键帧来提高性能。

Method: 两阶段方法：1) 使用低帧率浏览定位问题相关时间区间；2) 在更高有效帧率下重新分配视觉token进行回答，输出包含时间区间和最终选项的可解释结果。

Result: 在固定token预算下，ViTL在长视频问答和时间定位任务上达到8.6%的性能提升，同时减少50%的帧输入，区间感知token重新分配始终优于均匀采样。

Conclusion: ViTL和配套数据集提供了一个可解释、计算效率高的解决方案，可用于可扩展的长视频问答。

Abstract: We present \emph{Video-in-the-Loop} (ViTL), a two-stage long-video QA
framework that preserves a fixed token budget by first \emph{localizing}
question-relevant interval(s) with a low-fps skim and then \emph{answering} via
span-aware reallocation of visual tokens at higher effective frame rate,
emitting an interleaved output with both spans and the final option for direct
attribution. We also introduce \dataname{}, which converts description based
event graphs into \emph{span-grounded} multiple-choice QA by pairing each
question with \emph{ground-truth} time span(s) and related reasoning. ViTL is
trained end-to-end with an interleaved group-relative objective that couples
temporal IoU for localization with answer correctness, allowing credit to flow
from answers back to spans without increasing compute. Under fixed token
budgets, ViTL attains up to 8.6% with 50% less frame input on long-video QA and
temporal grounding (e.g., Charades-STA, ActivityNet-Captions) and ablations
show that span-aware token reallocation consistently surpasses uniform
sampling. Together, \dataname{} and ViTL provide an interpretable,
compute-efficient recipe for scalable long-video QA.

</details>


### [79] [Enhancing Fake News Video Detection via LLM-Driven Creative Process Simulation](https://arxiv.org/abs/2510.04024)
*Yuyan Bu,Qiang Sheng,Juan Cao,Shaofei Wang,Peng Qi,Yuhui Shi,Beizhe Hu*

Main category: cs.CV

TL;DR: 提出了AgentAug数据增强框架，通过模拟典型创作过程生成多样化的假新闻视频，结合基于不确定性采样的主动学习策略，提升短视频假新闻检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测器主要依赖模式特征，但由于训练数据有限且多样性不足，导致模式偏见和性能受限。真实场景中视频素材与假新闻事件存在复杂的多对多关系，现有数据集未能充分反映这种关系。

Method: AgentAug框架实现四种假新闻创作类别的LLM驱动流水线，模拟典型创作过程生成多样化假新闻视频，并结合基于不确定性采样的主动学习策略选择有用的增强样本。

Result: 在两个基准数据集上的实验结果表明，AgentAug能够持续提升短视频假新闻检测器的性能。

Conclusion: AgentAug通过模拟真实假新闻创作过程的数据增强方法，有效解决了训练数据不足和多样性缺乏的问题，显著提升了假新闻视频检测效果。

Abstract: The emergence of fake news on short video platforms has become a new
significant societal concern, necessitating automatic video-news-specific
detection. Current detectors primarily rely on pattern-based features to
separate fake news videos from real ones. However, limited and less diversified
training data lead to biased patterns and hinder their performance. This
weakness stems from the complex many-to-many relationships between video
material segments and fabricated news events in real-world scenarios: a single
video clip can be utilized in multiple ways to create different fake
narratives, while a single fabricated event often combines multiple distinct
video segments. However, existing datasets do not adequately reflect such
relationships due to the difficulty of collecting and annotating large-scale
real-world data, resulting in sparse coverage and non-comprehensive learning of
the characteristics of potential fake news video creation. To address this
issue, we propose a data augmentation framework, AgentAug, that generates
diverse fake news videos by simulating typical creative processes. AgentAug
implements multiple LLM-driven pipelines of four fabrication categories for
news video creation, combined with an active learning strategy based on
uncertainty sampling to select the potentially useful augmented samples during
training. Experimental results on two benchmark datasets demonstrate that
AgentAug consistently improves the performance of short video fake news
detectors.

</details>


### [80] [Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance Existing Frameworks](https://arxiv.org/abs/2510.04034)
*Linn Bieske,Carla Lorente*

Main category: cs.CV

TL;DR: 该研究通过优化超参数来提升prompt-to-prompt图像编辑框架的精度和可靠性，提出了三种方法：词替换、注意力重加权和CL P2P框架。


<details>
  <summary>Details</summary>
Motivation: 当前基于稳定扩散模型的图像编辑方法虽然简化了编辑过程，但结果存在不一致性（如发色变化不一致），需要提高精度和可靠性。

Method: 1. 全面研究"词替换"方法；2. 开发"注意力重加权方法"以提高适应性；3. 提出"CL P2P"框架解决循环不一致等现有限制。

Result: 研究揭示了超参数设置与神经网络模型架构选择（特别是注意力机制）之间的相互作用，这些因素显著影响生成图像的构图和质量。

Conclusion: 该工作有助于理解和改进超参数与注意力机制之间的交互，提升文本驱动图像编辑的精度和可靠性。

Abstract: Recent advances in image editing have shifted from manual pixel manipulation
to employing deep learning methods like stable diffusion models, which now
leverage cross-attention mechanisms for text-driven control. This transition
has simplified the editing process but also introduced variability in results,
such as inconsistent hair color changes. Our research aims to enhance the
precision and reliability of prompt-to-prompt image editing frameworks by
exploring and optimizing hyperparameters. We present a comprehensive study of
the "word swap" method, develop an "attention re-weight method" for better
adaptability, and propose the "CL P2P" framework to address existing
limitations like cycle inconsistency. This work contributes to understanding
and improving the interaction between hyperparameter settings and the
architectural choices of neural network models, specifically their attention
mechanisms, which significantly influence the composition and quality of the
generated images.

</details>


### [81] [\textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding](https://arxiv.org/abs/2510.04039)
*Bin Lei,Nuo Xu,Ali Payani,Mingyi Hong,Chunhua Liao,Yu Cao,Caiwen Ding*

Main category: cs.CV

TL;DR: GUI-Spotlight是一个用于图像基础推理的模型，通过动态调用多个专用工具迭代缩小屏幕相关区域，显著提高视觉定位准确性，在ScreenSpot-Pro基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在图形用户界面系统中的实际应用受到视觉定位可靠性的限制，无法准确执行指针级操作如点击或拖动。

Method: 引入GUI-Spotlight模型，训练用于图像基础推理，动态调用多个专用工具迭代缩小屏幕相关区域。

Result: 在ScreenSpot-Pro基准测试中，仅使用18.5K训练样本的GUI-Spotlight达到52.8%准确率，超越V2P-7B（50.6%，9.6M样本）和GTA-1-7B（50.1%，1.56M样本）。

Conclusion: GUI-Spotlight通过迭代聚焦方法有效解决了视觉定位问题，显著提升了多模态大语言模型在图形用户界面系统中的实用性。

Abstract: Multimodal large language models (MLLMs) have markedly expanded the
competence of graphical user-interface (GUI) systems, propelling them beyond
controlled simulations into complex, real-world environments across diverse
platforms. However, practical usefulness is still bounded by the reliability of
visual grounding, i.e., mapping textual references to exact on-screen elements.
This limitation prevents the system from accurately performing pointer-level
actions such as clicking or dragging. To address it, we introduce GUI-Spotlight
-- a model trained for image-grounded reasoning that dynamically invokes
multiple specialized tools to iteratively narrow its focus to the relevant
region of the screen, thereby substantially improving visual grounding
accuracy. On the ScreenSpot-Pro benchmark, GUI-Spotlight trained with only
18.5K training samples achieves 52.8\% accuracy, surpassing V2P-7B (50.6\% with
9.6M training samples) and GTA-1-7B (50.1\% with 1.56M training samples).

</details>


### [82] [Quantization Range Estimation for Convolutional Neural Networks](https://arxiv.org/abs/2510.04044)
*Bingtao Yang,Yujia Wang,Mengzhi Jiao,Hongwei Huo*

Main category: cs.CV

TL;DR: 提出一种用于后训练量化的范围估计方法，通过层间局部最小值最小化量化误差，在ResNet系列和Inception-v3模型上显著提升了低比特量化的精度表现。


<details>
  <summary>Details</summary>
Motivation: 低比特量化在保持模型精度方面是一个具有挑战性的问题，需要有效的后训练量化方法来减少深度神经网络模型的存储需求。

Method: 将范围估计建模为通过层间局部最小值最小化量化误差的优化问题，证明该问题具有局部凸性，并提出高效的搜索算法在变换权重空间中寻找最优解。

Result: 在图像分类任务中，8位和6位量化几乎无精度损失，4位量化的精度也显著提升，在ResNet系列和Inception-v3模型上超越了现有最佳性能。

Conclusion: 提出的范围估计方法有效提升了后训练量化的性能，特别是在低比特设置下，为深度神经网络模型的存储优化提供了实用解决方案。

Abstract: Post-training quantization for reducing the storage of deep neural network
models has been demonstrated to be an effective way in various tasks. However,
low-bit quantization while maintaining model accuracy is a challenging problem.
In this paper, we present a range estimation method to improve the quantization
performance for post-training quantization. We model the range estimation into
an optimization problem of minimizing quantization errors by layer-wise local
minima. We prove this problem is locally convex and present an efficient search
algorithm to find the optimal solution. We propose the application of the above
search algorithm to the transformed weights space to do further improvement in
practice. Our experiments demonstrate that our method outperforms
state-of-the-art performance generally on top-1 accuracy for image
classification tasks on the ResNet series models and Inception-v3 model. The
experimental results show that the proposed method has almost no loss of top-1
accuracy in 8-bit and 6-bit settings for image classifications, and the
accuracy of 4-bit quantization is also significantly improved. The code is
available at https://github.com/codeiscommitting/REQuant.

</details>


### [83] [MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation](https://arxiv.org/abs/2510.04057)
*Zhenyu Pan,Yucheng Lu,Han Liu*

Main category: cs.CV

TL;DR: MetaFind是一个面向元宇宙场景生成的三模态组合检索框架，通过从大规模存储库中检索3D资产来解决空间、语义和风格约束不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D资产检索方法存在的两个核心挑战：(i)忽略空间、语义和风格约束的不一致资产检索；(ii)缺乏专门为3D资产检索设计的标准化检索范式。

Method: 提出灵活的检索机制，支持任意文本、图像和3D模态组合作为查询，通过可插拔的等变布局编码器ESSGNN联合建模对象级特征和场景级布局结构。

Result: 经验评估表明，MetaFind在各种检索任务中相比基线方法具有更好的空间和风格一致性。

Conclusion: MetaFind框架通过三模态组合检索和等变布局编码，显著提升了3D资产检索的空间推理和风格一致性，支持迭代式场景构建。

Abstract: We present MetaFind, a scene-aware tri-modal compositional retrieval
framework designed to enhance scene generation in the metaverse by retrieving
3D assets from large-scale repositories. MetaFind addresses two core
challenges: (i) inconsistent asset retrieval that overlooks spatial, semantic,
and stylistic constraints, and (ii) the absence of a standardized retrieval
paradigm specifically tailored for 3D asset retrieval, as existing approaches
mainly rely on general-purpose 3D shape representation models. Our key
innovation is a flexible retrieval mechanism that supports arbitrary
combinations of text, image, and 3D modalities as queries, enhancing spatial
reasoning and style consistency by jointly modeling object-level features
(including appearance) and scene-level layout structures. Methodologically,
MetaFind introduces a plug-and-play equivariant layout encoder ESSGNN that
captures spatial relationships and object appearance features, ensuring
retrieved 3D assets are contextually and stylistically coherent with the
existing scene, regardless of coordinate frame transformations. The framework
supports iterative scene construction by continuously adapting retrieval
results to current scene updates. Empirical evaluations demonstrate the
improved spatial and stylistic consistency of MetaFind in various retrieval
tasks compared to baseline methods.

</details>


### [84] [Ordinal Encoding as a Regularizer in Binary Loss for Solar Flare Prediction](https://arxiv.org/abs/2510.04063)
*Chetraj Pandey,Jinsu Hong,Anli Ji,Rafal A. Angryk,Berkay Aydin*

Main category: cs.CV

TL;DR: 提出了一种改进的损失函数，将耀斑子类间的序数信息整合到二元交叉熵损失中，通过序数感知的正则化方法来提高太阳耀斑预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的二元分类框架忽略了耀斑子类间的序数关系，导致模型在预测阈值附近容易出现误分类。研究表明，大多数误分类发生在预测阈值附近，说明模型难以区分强度相似但位于二元阈值两侧的事件。

Method: 提出修改的损失函数，在传统二元交叉熵损失基础上整合耀斑标签子类间的序数信息，作为序数感知的数据驱动正则化方法，对预测阈值附近的错误预测施加更重的惩罚。

Result: 通过将序数加权整合到损失函数中，利用数据的序数特性来增强模型的学习过程，从而改善整体性能。

Conclusion: 该方法通过考虑耀斑子类的序数关系，能够有效减少预测阈值附近的误分类，提高太阳耀斑预测模型的准确性。

Abstract: The prediction of solar flares is typically formulated as a binary
classification task, distinguishing events as either Flare (FL) or No-Flare
(NF) according to a specified threshold (for example, greater than or equal to
C-class, M-class, or X-class). However, this binary framework neglects the
inherent ordinal relationships among the sub-classes contained within each
category (FL and NF). Several studies on solar flare prediction have
empirically shown that the most frequent misclassifications occur near this
prediction threshold. This suggests that the models struggle to differentiate
events that are similar in intensity but fall on opposite sides of the binary
threshold. To mitigate this limitation, we propose a modified loss function
that integrates the ordinal information among the sub-classes of the binarized
flare labels into the conventional binary cross-entropy (BCE) loss. This
approach serves as an ordinality-aware, data-driven regularization method that
penalizes the incorrect predictions of flare events in close proximity to the
prediction threshold more heavily than those away from the boundary during
model optimization. By incorporating ordinal weighting into the loss function,
we aim to enhance the model's learning process by leveraging the ordinal
characteristics of the data, thereby improving its overall performance.

</details>


### [85] [QuantDemoire: Quantization with Outlier Aware for Image Demoiréing](https://arxiv.org/abs/2510.04066)
*Zheng Chen,Kewei Zhang,Xiaoyang Liu,Weihang Zhang,Mengfan Wang,Yifan Fu,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出了QuantDemoire，一种专为去摩尔纹任务设计的后训练量化框架，通过异常值感知量化器和频率感知校准策略，在低比特量化下保持性能


<details>
  <summary>Details</summary>
Motivation: 现有去摩尔纹深度学习方法需要大量计算资源，难以在边缘设备部署。直接应用现有量化方法会导致严重的性能下降，主要原因是分布异常值和平滑区域表示弱化

Method: 包含两个关键组件：1) 异常值感知量化器，使用基于采样的范围估计减少激活异常值，并将少量极端权重保留为FP16；2) 频率感知校准策略，在微调过程中强调低频和中频分量

Result: 在W4A4配置下比现有量化方法性能提升超过4dB，同时大幅减少参数和计算量，同时保持质量

Conclusion: QuantDemoire框架有效解决了去摩尔纹模型量化中的关键问题，实现了高效的边缘设备部署

Abstract: Demoir\'eing aims to remove moir\'e artifacts that often occur in images.
While recent deep learning-based methods have achieved promising results, they
typically require substantial computational resources, limiting their
deployment on edge devices. Model quantization offers a compelling solution.
However, directly applying existing quantization methods to demoir\'eing models
introduces severe performance degradation. The main reasons are distribution
outliers and weakened representations in smooth regions. To address these
issues, we propose QuantDemoire, a post-training quantization framework
tailored to demoir\'eing. It contains two key components. **First}, we
introduce an outlier-aware quantizer to reduce errors from outliers. It uses
sampling-based range estimation to reduce activation outliers, and keeps a few
extreme weights in FP16 with negligible cost. **Second**, we design a
frequency-aware calibration strategy. It emphasizes low- and mid-frequency
components during fine-tuning, which mitigates banding artifacts caused by
low-bit quantization. Extensive experiments validate that our QuantDemoire
achieves large reductions in parameters and computation while maintaining
quality. Meanwhile, it outperforms existing quantization methods by over **4
dB** on W4A4. Code is released at:
https://github.com/zhengchen1999/QuantDemoire.

</details>


### [86] [Diffusion Low Rank Hybrid Reconstruction for Sparse View Medical Imaging](https://arxiv.org/abs/2510.04069)
*Zongyin Deng,Qing Zhou,Yuhao Fang,Zijian Wang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: TV-LoRA是一种结合扩散生成先验和多正则化约束的低剂量稀疏视图CT重建方法，在ADMM框架下实现高效3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决极端稀疏视图下CT重建的病态问题和纹理丢失问题，结合生成先验和物理约束来提升重建质量。

Method: 结合扩散生成先验（NCSN++与SDE建模）和各向异性TV与核范数（LoRA）正则化，采用ADMM框架，使用2D切片策略配合FFT加速和张量并行优化。

Result: 在AAPM-2016、CTHD和LIDC数据集上，TV-LoRA在SSIM、纹理恢复、边缘清晰度和伪影抑制方面均优于基准方法，展现出强鲁棒性和泛化性。

Conclusion: TV-LoRA在低剂量稀疏采样场景下实现了高保真、高效的3D CT重建，具有广泛的临床应用前景。

Abstract: This work presents TV-LoRA, a novel method for low-dose sparse-view CT
reconstruction that combines a diffusion generative prior (NCSN++ with SDE
modeling) and multi-regularization constraints, including anisotropic TV and
nuclear norm (LoRA), within an ADMM framework. To address ill-posedness and
texture loss under extremely sparse views, TV-LoRA integrates generative and
physical constraints, and utilizes a 2D slice-based strategy with FFT
acceleration and tensor-parallel optimization for efficient inference.
Experiments on AAPM-2016, CTHD, and LIDC datasets with
$N_{\mathrm{view}}=8,4,2$ show that TV-LoRA consistently surpasses benchmarks
in SSIM, texture recovery, edge clarity, and artifact suppression,
demonstrating strong robustness and generalizability. Ablation studies confirm
the complementary effects of LoRA regularization and diffusion priors, while
the FFT-PCG module provides a speedup. Overall, Diffusion + TV-LoRA achieves
high-fidelity, efficient 3D CT reconstruction and broad clinical applicability
in low-dose, sparse-sampling scenarios.

</details>


### [87] [TOPO-Bench: An Open-Source Topological Mapping Evaluation Framework with Quantifiable Perceptual Aliasing](https://arxiv.org/abs/2510.04100)
*Jiaming Wang,Diwen Liu,Jizhuo Chen,Harold Soh*

Main category: cs.CV

TL;DR: 该论文提出了拓扑地图评估的新协议，包括拓扑一致性度量、数据集模糊性量化方法，并发布了标准化的基准数据集和基线系统。


<details>
  <summary>Details</summary>
Motivation: 拓扑地图领域缺乏标准化的评估指标、数据集和协议，现有系统在不同环境和标准下评估，无法进行公平可复现的比较，且感知混淆问题未被充分量化。

Method: 形式化拓扑一致性作为拓扑地图的基本属性，使用定位精度作为替代度量；提出数据集模糊性的首个定量度量方法；构建具有校准模糊性水平的多样化基准数据集；实现并发布深度学习基线系统。

Result: 实验和分析揭示了当前方法在感知混淆下的局限性，为拓扑地图研究提供了新的见解。

Conclusion: 所有数据集、基线和评估工具都已开源，旨在促进拓扑地图研究的一致性和可复现性。

Abstract: Topological mapping offers a compact and robust representation for
navigation, but progress in the field is hindered by the lack of standardized
evaluation metrics, datasets, and protocols. Existing systems are assessed
using different environments and criteria, preventing fair and reproducible
comparisons. Moreover, a key challenge - perceptual aliasing - remains
under-quantified, despite its strong influence on system performance. We
address these gaps by (1) formalizing topological consistency as the
fundamental property of topological maps and showing that localization accuracy
provides an efficient and interpretable surrogate metric, and (2) proposing the
first quantitative measure of dataset ambiguity to enable fair comparisons
across environments. To support this protocol, we curate a diverse benchmark
dataset with calibrated ambiguity levels, implement and release deep-learned
baseline systems, and evaluate them alongside classical methods. Our
experiments and analysis yield new insights into the limitations of current
approaches under perceptual aliasing. All datasets, baselines, and evaluation
tools are fully open-sourced to foster consistent and reproducible research in
topological mapping.

</details>


### [88] [Learning Efficient Meshflow and Optical Flow from Event Cameras](https://arxiv.org/abs/2510.04111)
*Xinglong Luo,Ao Luo,Kunming Luo,Zhengning Wang,Ping Tan,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于事件相机的网格流估计方法，创建了高分辨率事件网格流数据集HREM，并开发了轻量级网络EEMFlow进行快速准确的网格流估计，同时通过密度自适应模块ADM提升模型在不同事件密度下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机流估计方法存在两个主要问题：缺乏专门的网格流数据集和方法，以及对事件数据密度挑战的研究不足。本文旨在填补这些空白。

Method: 1. 创建大规模高分辨率事件网格流数据集HREM；2. 提出轻量级EEMFlow网络，采用编码器-解码器架构；3. 引入置信度诱导细节补全模块CDC支持稠密光流；4. 提出自适应密度模块ADM优化输入事件密度。

Result: EEMFlow模型在性能和运行效率上表现优异，比现有最优方法快30倍。ADM模块显著提升了EEMFlow和EEMFlow+的性能，分别提高8%和10%。

Conclusion: 本文提出的HREM数据集、EEMFlow网络和ADM模块有效解决了事件相机网格流估计中的关键挑战，为相关研究提供了重要基础。

Abstract: In this paper, we explore the problem of event-based meshflow estimation, a
novel task that involves predicting a spatially smooth sparse motion field from
event cameras. To start, we review the state-of-the-art in event-based flow
estimation, highlighting two key areas for further research: i) the lack of
meshflow-specific event datasets and methods, and ii) the underexplored
challenge of event data density. First, we generate a large-scale
High-Resolution Event Meshflow (HREM) dataset, which showcases its superiority
by encompassing the merits of high resolution at 1280x720, handling dynamic
objects and complex motion patterns, and offering both optical flow and
meshflow labels. These aspects have not been fully explored in previous works.
Besides, we propose Efficient Event-based MeshFlow (EEMFlow) network, a
lightweight model featuring a specially crafted encoder-decoder architecture to
facilitate swift and accurate meshflow estimation. Furthermore, we upgrade
EEMFlow network to support dense event optical flow, in which a
Confidence-induced Detail Completion (CDC) module is proposed to preserve sharp
motion boundaries. We conduct comprehensive experiments to show the exceptional
performance and runtime efficiency (30x faster) of our EEMFlow model compared
to the recent state-of-the-art flow method. As an extension, we expand HREM
into HREM+, a multi-density event dataset contributing to a thorough study of
the robustness of existing methods across data with varying densities, and
propose an Adaptive Density Module (ADM) to adjust the density of input event
data to a more optimal range, enhancing the model's generalization ability. We
empirically demonstrate that ADM helps to significantly improve the performance
of EEMFlow and EEMFlow+ by 8% and 10%, respectively. Code and dataset are
released at https://github.com/boomluo02/EEMFlowPlus.

</details>


### [89] [Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation](https://arxiv.org/abs/2510.04125)
*Seunghyun Lee,Tae-Kyun Kim*

Main category: cs.CV

TL;DR: 提出了一种新的6D物体姿态估计方法，通过预训练编码器和联合学习策略加速训练收敛，并引入采样指导机制消除额外评估网络需求，在多个基准测试中达到最先进精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的6D姿态估计方法存在训练收敛慢、需要端到端学习编码器、以及需要额外网络来筛选姿态假设的问题。

Method: 1) 预训练编码器并使用直接姿态回归头，通过回归头和去噪扩散头联合学习网络；2) 提出基于时间相关分数缩放的采样指导机制，有效平衡探索与利用。

Result: 在REAL275、HouseCat6D和ROPE等多个基准测试中实现了最先进的精度，即使使用单姿态推理也能达到高精度，同时在训练和推理方面更高效。

Conclusion: 该方法简单有效，通过预训练和采样指导解决了现有方法的局限性，在6D物体姿态估计任务中表现出色。

Abstract: Latest diffusion models have shown promising results in category-level 6D
object pose estimation by modeling the conditional pose distribution with depth
image input. The existing methods, however, suffer from slow convergence during
training, learning its encoder with the diffusion denoising network in
end-to-end fashion, and require an additional network that evaluates sampled
pose hypotheses to filter out low-quality pose candidates. In this paper, we
propose a novel pipeline that tackles these limitations by two key components.
First, the proposed method pretrains the encoder with the direct pose
regression head, and jointly learns the networks via the regression head and
the denoising diffusion head, significantly accelerating training convergence
while achieving higher accuracy. Second, sampling guidance via time-dependent
score scaling is proposed s.t. the exploration-exploitation trade-off is
effectively taken, eliminating the need for the additional evaluation network.
The sampling guidance maintains multi-modal characteristics of symmetric
objects at early denoising steps while ensuring high-quality pose generation at
final steps. Extensive experiments on multiple benchmarks including REAL275,
HouseCat6D, and ROPE, demonstrate that the proposed method, simple yet
effective, achieves state-of-the-art accuracies even with single-pose
inference, while being more efficient in both training and inference.

</details>


### [90] [Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs](https://arxiv.org/abs/2510.04142)
*Xiaoyu Yang,Jie Lu,En Yu*

Main category: cs.CV

TL;DR: 本文提出了一种解决多模态大语言模型蒸馏中概念漂移问题的新方法——自主偏好优化(APO)，通过"学习、比较、批判"范式来提升学生模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型蒸馏过程中，多个教师模型产生的推理轨迹存在概念漂移问题，导致推理分布不可预测地演变并将偏见传递给学生模型，最终损害其性能。

Method: 提出自主偏好优化(APO)方法，将多教师模型的非平稳推理动态建模为多流推理轨迹的下一个token预测。采用"学习、比较、批判"范式：学生模型先学习并自蒸馏偏好的思维方式，然后对教师模型的漂移推理进行批判性反思，通过APO进行概念对齐。

Result: 大量实验证明该方法在知识蒸馏中具有优越的一致性、鲁棒性和泛化性能。同时贡献了包含170,982个蒸馏推理轨迹的大规模数据集CXR-MAX。

Conclusion: 提出的APO方法能够有效解决多教师模型蒸馏中的概念漂移问题，生成鲁棒、一致且可泛化的学生模型。

Abstract: This paper identifies a critical yet underexplored challenge in distilling
from multimodal large language models (MLLMs): the reasoning trajectories
generated by multiple drifting teachers exhibit concept drift, whereby their
reasoning distributions evolve unpredictably and transmit biases to the student
model, ultimately compromising its performance. To tackle this issue, we
pioneer a theoretical connection between concept drift and knowledge
distillation, casting the non-stationary reasoning dynamics from multiple MLLM
teachers as next-token prediction of multi-stream reasoning trajectories.Guided
by concept drift, we introduce the "learn, compare, critique" paradigm,
culminating in autonomous preference optimization (APO). Under the active
guidance of the teachers, the student model first learns and self-distils
preferred thinking by comparing multiple teachers. It then engages in critical
reflection over the drifting inference from teachers, performing concept
alignment through APO, ultimately yielding a robust, consistent, and
generalizable model.Extensive experiments demonstrate our superior performance
of consistency, robustness and generalization within knowledge distillation.
Besides, we also contributed a large-scale dataset, CXR-MAX (Multi-teachers
Alignment X-rays), comprising 170,982 distilled reasoning trajectories derived
from publicly accessible MLLMs based on MIMIC-CXR. Our code and data are public
at: https://anonymous.4open.science/r/Autonomous-Distillation/.

</details>


### [91] [Automating construction safety inspections using a multi-modal vision-language RAG framework](https://arxiv.org/abs/2510.04145)
*Chenxin Wang,Elyas Asadi Shamsabadi,Zhaohui Chen,Luming Shen,Alireza Ahmadian Fard Fini,Daniel Dias-da-Costa*

Main category: cs.CV

TL;DR: SiteShield是一个基于多模态大视觉语言模型的检索增强生成框架，用于自动化建筑安全检查报告，整合视觉和音频输入，在真实数据上表现优于单模态LLM。


<details>
  <summary>Details</summary>
Motivation: 传统建筑安全检查方法效率低下，需要处理大量信息。现有应用存在响应不相关、模态输入受限和幻觉问题，LLM应用受限于训练数据和实时适应性。

Method: 开发SiteShield多模态LVLM RAG框架，整合视觉和音频输入，用于自动化安全检查报告生成。

Result: SiteShield在真实数据上表现优于无RAG的单模态LLM，F1得分0.82，汉明损失0.04，精确率0.76，召回率0.96。

Conclusion: SiteShield为增强信息检索和安全报告生成效率提供了新途径。

Abstract: Conventional construction safety inspection methods are often inefficient as
they require navigating through large volume of information. Recent advances in
large vision-language models (LVLMs) provide opportunities to automate safety
inspections through enhanced visual and linguistic understanding. However,
existing applications face limitations including irrelevant or unspecific
responses, restricted modal inputs and hallucinations. Utilisation of Large
Language Models (LLMs) for this purpose is constrained by availability of
training data and frequently lack real-time adaptability. This study introduces
SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG)
framework for automating construction safety inspection reports by integrating
visual and audio inputs. Using real-world data, SiteShield outperformed
unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04,
precision of 0.76, and recall of 0.96. The findings indicate that SiteShield
offers a novel pathway to enhance information retrieval and efficiency in
generating safety reports.

</details>


### [92] [BLADE: Bias-Linked Adaptive DEbiasing](https://arxiv.org/abs/2510.04174)
*Piyush Arora,Navlika Singh,Vasubhya Diwan,Pratik Mazumder*

Main category: cs.CV

TL;DR: BLADE是一种无需先验偏置知识或偏置冲突样本的生成式去偏框架，通过训练生成模型在偏置域间转换图像并保留任务相关特征，然后基于图像对偏置的敏感性自适应地优化图像。


<details>
  <summary>Details</summary>
Motivation: 神经网络容易学习训练数据中的隐式偏置和伪相关，这些偏置通常更普遍且易于学习，导致模型依赖表面模式而非任务相关特征。现有方法需要偏置先验知识或偏置冲突样本，这在现实场景中往往不切实际。

Method: BLADE首先训练生成模型在偏置域间转换图像并保留任务相关特征，然后基于图像对偏置的敏感性自适应地优化每张图像。通过将图像与其偏置转换后的合成对应物对齐（共享任务特征但偏置不同），同时与共享相同偏置的样本错位，来鼓励鲁棒表示。

Result: 在多个基准数据集上评估显示，BLADE显著优于最先进方法。在损坏的CIFAR-10数据集的最差组设置下，比最接近的基线方法绝对提升了约18%，建立了偏置缓解的新基准。

Conclusion: BLADE展示了在没有显式监督的情况下开发更鲁棒深度学习模型的潜力，通过生成式方法有效缓解神经网络中的隐式偏置问题。

Abstract: Neural networks have revolutionized numerous fields, yet they remain
vulnerable to a critical flaw: the tendency to learn implicit biases, spurious
correlations between certain attributes and target labels in training data.
These biases are often more prevalent and easier to learn, causing models to
rely on superficial patterns rather than task-relevant features necessary for
generalization. Existing methods typically rely on strong assumptions, such as
prior knowledge of these biases or access to bias-conflicting samples, i.e.,
samples that contradict spurious correlations and counterbalance bias-aligned
samples, samples that conform to these spurious correlations. However, such
assumptions are often impractical in real-world settings. We propose BLADE
({B}ias-{L}inked {A}daptive {DE}biasing), a generative debiasing framework that
requires no prior knowledge of bias or bias-conflicting samples. BLADE first
trains a generative model to translate images across bias domains while
preserving task-relevant features. Then, it adaptively refines each image with
its synthetic counterpart based on the image's susceptibility to bias. To
encourage robust representations, BLADE aligns an image with its
bias-translated synthetic counterpart that shares task-relevant features but
differs in bias, while misaligning it with samples sharing the same bias. We
evaluate BLADE on multiple benchmark datasets and show that it significantly
outperforms state-of-the-art methods. Notably, it exceeds the closest baseline
by an absolute margin of around 18% on the corrupted CIFAR-10 dataset under the
worst group setting, establishing a new benchmark in bias mitigation and
demonstrating its potential for developing more robust deep learning models
without explicit supervision.

</details>


### [93] [From Segments to Concepts: Interpretable Image Classification via Concept-Guided Segmentation](https://arxiv.org/abs/2510.04180)
*Ran Eisenberg,Amit Rozner,Ethan Fetaya,Ofir Lindenbaum*

Main category: cs.CV

TL;DR: 提出了SEG-MIL-CBM框架，将概念引导的图像分割与注意力多实例学习结合，通过语义区域推理实现透明、空间定位的概念级解释，无需概念标注。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络缺乏可解释性，在安全关键应用中限制信任。现有概念瓶颈模型需要昂贵概念标注且缺乏空间定位，无法识别支持每个概念的区域。

Method: 集成概念引导图像分割到注意力多实例学习框架，将分割区域作为实例，学习跨区域证据聚合，通过语义区域推理对齐高层概念。

Result: 在涉及伪相关、输入损坏和大规模基准测试中实现稳健性能，同时提供透明、概念级解释。

Conclusion: SEG-MIL-CBM通过语义区域推理实现了无需概念标注的透明、空间定位解释，在保持性能的同时提高了模型可信度。

Abstract: Deep neural networks have achieved remarkable success in computer vision;
however, their black-box nature in decision-making limits interpretability and
trust, particularly in safety-critical applications. Interpretability is
crucial in domains where errors have severe consequences. Existing models not
only lack transparency but also risk exploiting unreliable or misleading
features, which undermines both robustness and the validity of their
explanations. Concept Bottleneck Models (CBMs) aim to improve transparency by
reasoning through human-interpretable concepts. Still, they require costly
concept annotations and lack spatial grounding, often failing to identify which
regions support each concept. We propose SEG-MIL-CBM, a novel framework that
integrates concept-guided image segmentation into an attention-based multiple
instance learning (MIL) framework, where each segmented region is treated as an
instance and the model learns to aggregate evidence across them. By reasoning
over semantically meaningful regions aligned with high-level concepts, our
model highlights task-relevant evidence, down-weights irrelevant cues, and
produces spatially grounded, concept-level explanations without requiring
annotations of concepts or groups. SEG-MIL-CBM achieves robust performance
across settings involving spurious correlations (unintended dependencies
between background and label), input corruptions (perturbations that degrade
visual quality), and large-scale benchmarks, while providing transparent,
concept-level explanations.

</details>


### [94] [Let Features Decide Their Own Solvers: Hybrid Feature Caching for Diffusion Transformers](https://arxiv.org/abs/2510.04188)
*Shikang Zheng,Guantao Chen,Qinming Zhou,Yuqi Lin,Lixuan He,Chang Zou,Peiliang Cai,Jiacheng Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: HyCa是一个基于混合ODE求解器的缓存框架，通过维度级缓存策略加速扩散变换器的采样过程，在多个模型上实现5-6倍无损加速。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在图像和视频合成中具有最先进的保真度，但其迭代采样过程由于每个时间步都需要昂贵的transformer前向传播而成为主要瓶颈。现有缓存方法对所有特征维度采用统一策略，忽略了它们异质的动态行为。

Method: 将隐藏特征演化建模为跨维度的ODE混合，引入HyCa框架应用维度级缓存策略，基于混合ODE求解器思想。

Result: 在多个模型上实现显著加速：FLUX 5.55倍、HunyuanVideo 5.56倍、Qwen-Image和Qwen-Image-Edit 6.24倍，且无需重新训练。

Conclusion: HyCa通过维度级缓存策略有效解决了扩散变换器采样瓶颈，实现了跨多个领域和模型的近无损加速。

Abstract: Diffusion Transformers offer state-of-the-art fidelity in image and video
synthesis, but their iterative sampling process remains a major bottleneck due
to the high cost of transformer forward passes at each timestep. To mitigate
this, feature caching has emerged as a training-free acceleration technique
that reuses or forecasts hidden representations. However, existing methods
often apply a uniform caching strategy across all feature dimensions, ignoring
their heterogeneous dynamic behaviors. Therefore, we adopt a new perspective by
modeling hidden feature evolution as a mixture of ODEs across dimensions, and
introduce HyCa, a Hybrid ODE solver inspired caching framework that applies
dimension-wise caching strategies. HyCa achieves near-lossless acceleration
across diverse domains and models, including 5.55 times speedup on FLUX, 5.56
times speedup on HunyuanVideo, 6.24 times speedup on Qwen-Image and
Qwen-Image-Edit without retraining.

</details>


### [95] [A Modular Conditional Diffusion Framework for Image Reconstruction](https://arxiv.org/abs/2411.05993)
*Magauiya Zhussip,Iaroslav Koshelev,Stamatis Lefkimmiatis*

Main category: cs.CV

TL;DR: 提出了DP-IR模块化扩散概率图像修复框架，结合预训练IR网络和生成DPMs，只需训练小模块(0.7M参数)，采样效率提升4倍以上，在多个图像修复任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有DPMs在盲图像修复中表现出色，但存在任务特定性、训练计算成本高的问题，限制了其在缺乏强大计算资源和大量训练数据的用户中的广泛应用。

Method: 设计模块化扩散概率IR框架，结合预训练IR网络和生成DPMs，仅需训练小型任务特定模块，采用高效采样策略减少神经网络评估次数。

Result: 在burst JDD-SR、动态场景去模糊和超分辨率等四个基准测试中，感知质量优于现有方法，保真度指标保持竞争力，采样效率提升4倍以上。

Conclusion: DP-IR框架成功解决了DPMs在图像修复应用中的实际部署问题，实现了高性能与低计算成本的平衡，为广泛采用提供了可行方案。

Abstract: Diffusion Probabilistic Models (DPMs) have been recently utilized to deal
with various blind image restoration (IR) tasks, where they have demonstrated
outstanding performance in terms of perceptual quality. However, the
task-specific nature of existing solutions and the excessive computational
costs related to their training, make such models impractical and challenging
to use for different IR tasks than those that were initially trained for. This
hinders their wider adoption, especially by those who lack access to powerful
computational resources and vast amount of training data. In this work we aim
to address the above issues and enable the successful adoption of DPMs in
practical IR-related applications. Towards this goal, we propose a modular
diffusion probabilistic IR framework (DP-IR), which allows us to combine the
performance benefits of existing pre-trained state-of-the-art IR networks and
generative DPMs, while it requires only the additional training of a relatively
small module (0.7M params) related to the particular IR task of interest.
Moreover, the architecture of the proposed framework allows for a sampling
strategy that leads to at least four times reduction of neural function
evaluations without suffering any performance loss, while it can also be
combined with existing acceleration techniques such as DDIM. We evaluate our
model on four benchmarks for the tasks of burst JDD-SR, dynamic scene
deblurring, and super-resolution. Our method outperforms existing approaches in
terms of perceptual quality while it retains a competitive performance with
respect to fidelity metrics.

</details>


### [96] [World-To-Image: Grounding Text-to-Image Generation with Agent-Driven World Knowledge](https://arxiv.org/abs/2510.04201)
*Moo Hyun Son,Jintaek Oh,Sun Bin Mun,Jaechul Roh,Sehyun Choi*

Main category: cs.CV

TL;DR: World-To-Image框架通过代理驱动的世界知识增强文本到图像生成，解决模型对新颖或分布外实体生成质量下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在处理新颖或分布外实体时性能显著下降，因为模型存在固有的知识截止限制。

Method: 设计一个代理动态搜索网络获取基础模型未知概念的图像，然后进行多模态提示优化，引导生成模型实现准确合成。

Result: 在NICE基准测试中，World-To-Image在语义对齐和视觉美学方面显著优于最先进方法，准确率提升8.1%。

Conclusion: 该框架在不到三次迭代中高效实现结果，为构建能更好反映不断变化的现实世界的文本到图像系统铺平了道路。

Abstract: While text-to-image (T2I) models can synthesize high-quality images, their
performance degrades significantly when prompted with novel or
out-of-distribution (OOD) entities due to inherent knowledge cutoffs. We
introduce World-To-Image, a novel framework that bridges this gap by empowering
T2I generation with agent-driven world knowledge. We design an agent that
dynamically searches the web to retrieve images for concepts unknown to the
base model. This information is then used to perform multimodal prompt
optimization, steering powerful generative backbones toward an accurate
synthesis. Critically, our evaluation goes beyond traditional metrics,
utilizing modern assessments like LLMGrader and ImageReward to measure true
semantic fidelity. Our experiments show that World-To-Image substantially
outperforms state-of-the-art methods in both semantic alignment and visual
aesthetics, achieving +8.1% improvement in accuracy-to-prompt on our curated
NICE benchmark. Our framework achieves these results with high efficiency in
less than three iterations, paving the way for T2I systems that can better
reflect the ever-changing real world. Our demo code is available
here\footnote{https://github.com/mhson-kyle/World-To-Image}.

</details>


### [97] [MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned Semantic Clustering](https://arxiv.org/abs/2510.04220)
*Lixuan He,Shikang Zheng,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出MASC框架，通过构建层次化语义树来优化自回归图像生成模型，将平坦的视觉词汇表转换为结构化预测空间，显著提升训练效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型使用平坦的无结构视觉词汇表，忽视了嵌入空间的内在结构，导致预测任务复杂，训练效率低下且生成质量受限。

Method: MASC框架从码本内在结构直接构建层次化语义树，采用几何感知距离度量和密度驱动的凝聚构造来建模标记嵌入的底层流形。

Result: 训练速度提升高达57%，LlamaGen-XL的FID从2.87降至2.58，显著改善生成质量，使自回归框架与最先进方法具有竞争力。

Conclusion: 结构化预测空间与架构创新同等重要，MASC证明了通过利用嵌入空间内在结构可以显著提升自回归生成模型的可扩展性。

Abstract: Autoregressive (AR) models have shown great promise in image generation, yet
they face a fundamental inefficiency stemming from their core component: a
vast, unstructured vocabulary of visual tokens. This conventional approach
treats tokens as a flat vocabulary, disregarding the intrinsic structure of the
token embedding space where proximity often correlates with semantic
similarity. This oversight results in a highly complex prediction task, which
hinders training efficiency and limits final generation quality. To resolve
this, we propose Manifold-Aligned Semantic Clustering (MASC), a principled
framework that constructs a hierarchical semantic tree directly from the
codebook's intrinsic structure. MASC employs a novel geometry-aware distance
metric and a density-driven agglomerative construction to model the underlying
manifold of the token embeddings. By transforming the flat, high-dimensional
prediction task into a structured, hierarchical one, MASC introduces a
beneficial inductive bias that significantly simplifies the learning problem
for the AR model. MASC is designed as a plug-and-play module, and our extensive
experiments validate its effectiveness: it accelerates training by up to 57%
and significantly improves generation quality, reducing the FID of LlamaGen-XL
from 2.87 to 2.58. MASC elevates existing AR frameworks to be highly
competitive with state-of-the-art methods, establishing that structuring the
prediction space is as crucial as architectural innovation for scalable
generative modeling.

</details>


### [98] [Zoom-In to Sort AI-Generated Images Out](https://arxiv.org/abs/2510.04225)
*Yikun Ji,Yan Hong,Bowen Deng,jun lan,Huijia Zhu,Weiqiang Wang,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: ZoomIn是一个两阶段取证框架，通过扫描图像定位可疑区域并进行聚焦分析，提高AI生成图像检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: AI生成图像的快速增长模糊了真实与合成内容的边界，对数字完整性构成严重威胁。现有的视觉语言模型在检测高质量合成图像的细微伪影方面存在不足。

Method: 提出ZoomIn两阶段取证框架：第一阶段扫描图像定位可疑区域，第二阶段对放大区域进行聚焦分析。使用MagniFake数据集（20,000张真实和高质量合成图像，带边界框和取证解释）进行训练。

Result: 方法达到96.39%的准确率，具有强大的泛化能力，同时提供基于视觉证据的人类可理解解释。

Conclusion: ZoomIn框架在AI生成图像检测方面实现了高准确性和可解释性的平衡，为数字取证提供了有效的解决方案。

Abstract: The rapid growth of AI-generated imagery has blurred the boundary between
real and synthetic content, raising critical concerns for digital integrity.
Vision-language models (VLMs) offer interpretability through explanations but
often fail to detect subtle artifacts in high-quality synthetic images. We
propose ZoomIn, a two-stage forensic framework that improves both accuracy and
interpretability. Mimicking human visual inspection, ZoomIn first scans an
image to locate suspicious regions and then performs a focused analysis on
these zoomed-in areas to deliver a grounded verdict. To support training, we
introduce MagniFake, a dataset of 20,000 real and high-quality synthetic images
annotated with bounding boxes and forensic explanations, generated through an
automated VLM-based pipeline. Our method achieves 96.39% accuracy with robust
generalization, while providing human-understandable explanations grounded in
visual evidence.

</details>


### [99] [A Recursive Pyramidal Algorithm for Solving the Image Registration Problem](https://arxiv.org/abs/2510.04231)
*Stefan Dirnstorfer*

Main category: cs.CV

TL;DR: 提出了一种简单、端到端可训练的图像配准算法，只需几行Python代码即可实现，在训练数据少、训练时间短的场景下仍能获得准确结果。


<details>
  <summary>Details</summary>
Motivation: 解决图像配准问题，即找到使两幅图像对应点位置一致的变换，需要一种简单高效的算法来应对训练数据有限、训练时间短或代码复杂度受限的场景。

Method: 采用端到端可训练的简单算法，在19x15输入窗口上使用74张图像进行训练，仅需十几行Python代码即可实现。

Result: 该算法在立体视觉等应用中表现出色，在训练数据少、训练时间短的情况下仍能获得准确的配准结果。

Conclusion: 该算法简洁高效，可作为在训练数据、训练时间或代码复杂度受限的相关场景中的良好起点。

Abstract: The problem of image registration is finding a transformation that aligns two
images, such that the corresponding points are in the same location. This paper
introduces a simple, end-to-end trainable algorithm that is implementable in a
few lines of Python code. The approach is shown to work with very little
training data and training time, while achieving accurate results in some
settings. An example application to stereo vision was trained from 74 images on
a 19x15 input window. With just a dozen lines of Python code this algorithm
excels in brevity and may serve as a good start in related scenarios with
limitations to training data, training time or code complexity.

</details>


### [100] [Detection of retinal diseases using an accelerated reused convolutional network](https://arxiv.org/abs/2510.04232)
*Amin Ahmadi Kasani,Hedieh Sajedi*

Main category: cs.CV

TL;DR: 提出了一种名为ArConv的新型卷积层，通过重新设计和优化卷积层来创建轻量级神经网络模型，该模型仅含130万参数，在RfMiD数据集上比MobileNetV2表现更好。


<details>
  <summary>Details</summary>
Motivation: 提高深度神经网络的可访问性，使其能够在移动设备上运行，用于眼部疾病的早期诊断，解决现有方法计算复杂度高的问题。

Method: 重新设计和优化卷积层，提出新型ArConv卷积层，构建轻量级通用模型，参数数量仅为130万。

Result: 在RfMiD数据集测试中，准确率达到0.9328，优于MobileNetV2的0.9266，同时模型参数更少。

Conclusion: 通过优化卷积层设计，成功创建了适用于移动设备的轻量级神经网络模型，在保持高精度的同时显著降低了计算复杂度。

Abstract: Convolutional neural networks are continually evolving, with some efforts
aimed at improving accuracy, others at increasing speed, and some at enhancing
accessibility. Improving accessibility broadens the application of neural
networks across a wider range of tasks, including the detection of eye
diseases. Early diagnosis of eye diseases and consulting an ophthalmologist can
prevent many vision disorders. Given the importance of this issue, various
datasets have been collected from the cornea to facilitate the process of
making neural network models. However, most of the methods introduced in the
past are computationally complex. In this study, we tried to increase the
accessibility of deep neural network models. We did this at the most
fundamental level, specifically by redesigning and optimizing the convolutional
layers. By doing so, we created a new general model that incorporates our novel
convolutional layer named ArConv layers. Thanks to the efficient performance of
this new layer, the model has suitable complexity for use in mobile phones and
can perform the task of diagnosing the presence of disease with high accuracy.
The final model we present contains only 1.3 million parameters. In comparison
to the MobileNetV2 model, which has 2.2 million parameters, our model
demonstrated better accuracy when trained and evaluated on the RfMiD dataset
under identical conditions, achieving an accuracy of 0.9328 versus 0.9266 on
the RfMiD test set.

</details>


### [101] [Scaling Sequence-to-Sequence Generative Neural Rendering](https://arxiv.org/abs/2510.04236)
*Shikun Liu,Kam Woh Ng,Wonbong Jang,Jiadong Guo,Junlin Han,Haozhe Liu,Yiannis Douratsos,Juan C. Pérez,Zijian Zhou,Chi Phung,Tao Xiang,Juan-Manuel Pérez-Rúa*

Main category: cs.CV

TL;DR: Kaleido是一个用于照片级真实感神经渲染的生成模型，将3D建模视为视频的特殊子域，通过序列到序列的图像合成实现生成式视角合成，无需显式3D表示。


<details>
  <summary>Details</summary>
Motivation: 传统神经渲染方法依赖显式3D表示和大量相机标注数据，Kaleido旨在通过统一3D和视频建模，利用大规模视频数据进行预训练，减少对稀缺3D数据的依赖。

Method: 采用掩码自回归框架和仅解码器的整流流变换器，将3D建模视为序列到序列任务，支持任意数量参考视图生成任意数量目标视图，统一处理3D和视频数据。

Result: 在多个视角合成基准测试中达到最先进水平，零样本性能在少视图设置中显著优于其他生成方法，在多视图设置中首次达到逐场景优化方法的质量。

Conclusion: Kaleido证明了通过统一3D和视频建模，利用大规模视频数据预训练可以显著提升神经渲染性能，为生成式视角合成提供了新的有效范式。

Abstract: We present Kaleido, a family of generative models designed for
photorealistic, unified object- and scene-level neural rendering. Kaleido
operates on the principle that 3D can be regarded as a specialised sub-domain
of video, expressed purely as a sequence-to-sequence image synthesis task.
Through a systemic study of scaling sequence-to-sequence generative neural
rendering, we introduce key architectural innovations that enable our model to:
i) perform generative view synthesis without explicit 3D representations; ii)
generate any number of 6-DoF target views conditioned on any number of
reference views via a masked autoregressive framework; and iii) seamlessly
unify 3D and video modelling within a single decoder-only rectified flow
transformer. Within this unified framework, Kaleido leverages large-scale video
data for pre-training, which significantly improves spatial consistency and
reduces reliance on scarce, camera-labelled 3D datasets -- all without any
architectural modifications. Kaleido sets a new state-of-the-art on a range of
view synthesis benchmarks. Its zero-shot performance substantially outperforms
other generative methods in few-view settings, and, for the first time, matches
the quality of per-scene optimisation methods in many-view settings.

</details>


### [102] [The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation](https://arxiv.org/abs/2510.04243)
*Jincan Lou,Jingkun Chen,Haoquan Li,Hang Li,Wenjian Huang,Weihua Chen,Fan Wang,Jianguo Zhang*

Main category: cs.CV

TL;DR: 提出CoSSeg-TTA框架，在nnU-Netv2基础上结合半监督均值教师方案和领域适应模块，用于GED4 MRI的肝脏分割，解决标注数据有限和跨中心域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 对比增强MRI肝脏分割面临标注数据有限、增强协议异质性和跨扫描器域偏移等挑战，现有图像翻译方法在单模态场景下存在结构扭曲和不稳定训练问题。

Method: 基于nnU-Netv2构建紧凑分割框架，集成半监督均值教师方案利用未标注数据，采用随机直方图风格外观转换和可训练对比感知网络的领域适应模块，以及持续测试时适应策略。

Result: 在广泛实验中，该框架持续优于nnU-Netv2基线，获得更高的Dice分数和Hausdorff距离，在低标注条件下对未见域表现出强泛化能力。

Conclusion: CoSSeg-TTA框架有效解决了GED4 MRI肝脏分割中的领域泛化问题，通过半监督学习和领域适应策略实现了优越的分割性能。

Abstract: Accurate liver segmentation from contrast-enhanced MRI is essential for
diagnosis, treatment planning, and disease monitoring. However, it remains
challenging due to limited annotated data, heterogeneous enhancement protocols,
and significant domain shifts across scanners and institutions. Traditional
image-to-image translation frameworks have made great progress in domain
generalization, but their application is not straightforward. For example,
Pix2Pix requires image registration, and cycle-GAN cannot be integrated
seamlessly into segmentation pipelines. Meanwhile, these methods are originally
used to deal with cross-modality scenarios, and often introduce structural
distortions and suffer from unstable training, which may pose drawbacks in our
single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a
compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary
phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised
mean teacher scheme to exploit large amounts of unlabeled volumes. A domain
adaptation module, incorporating a randomized histogram-based style appearance
transfer function and a trainable contrast-aware network, enriches domain
diversity and mitigates cross-center variability. Furthermore, a continual
test-time adaptation strategy is employed to improve robustness during
inference. Extensive experiments demonstrate that our framework consistently
outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff
Distance while exhibiting strong generalization to unseen domains under
low-annotation conditions.

</details>


### [103] [Concept-Based Masking: A Patch-Agnostic Defense Against Adversarial Patch Attacks](https://arxiv.org/abs/2510.04245)
*Ayushi Mehrotra,Derek Peng,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 提出一种基于概念解释的补丁不可知防御方法，通过抑制最具影响力的概念激活向量来中和对抗性补丁攻击，无需显式检测补丁位置或大小。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法通常需要先验知识（如补丁大小或位置），限制了实际应用。对抗性补丁攻击通过局部扰动强制目标错误分类，对深度学习模型构成实际威胁。

Method: 利用基于概念的解释来识别和抑制最具影响力的概念激活向量，从而在不显式检测补丁的情况下中和补丁效应。

Result: 在Imagenette数据集上使用ResNet-50进行评估，相比最先进的PatchCleanser方法，获得了更高的鲁棒性和清洁准确率，在不同补丁大小和位置下保持强劲性能。

Conclusion: 结果表明将可解释性与鲁棒性结合具有前景，概念驱动的防御可作为对抗对抗性补丁攻击的可扩展策略。

Abstract: Adversarial patch attacks pose a practical threat to deep learning models by
forcing targeted misclassifications through localized perturbations, often
realized in the physical world. Existing defenses typically assume prior
knowledge of patch size or location, limiting their applicability. In this
work, we propose a patch-agnostic defense that leverages concept-based
explanations to identify and suppress the most influential concept activation
vectors, thereby neutralizing patch effects without explicit detection.
Evaluated on Imagenette with a ResNet-50, our method achieves higher robust and
clean accuracy than the state-of-the-art PatchCleanser, while maintaining
strong performance across varying patch sizes and locations. Our results
highlight the promise of combining interpretability with robustness and suggest
concept-driven defenses as a scalable strategy for securing machine learning
models against adversarial patch attacks.

</details>


### [104] [Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition](https://arxiv.org/abs/2510.04282)
*Yu Kiu,Lau,Chao Chen,Ge Jin,Chen Feng*

Main category: cs.CV

TL;DR: 提出Adapt-STformer方法，通过循环可变形Transformer编码器实现灵活高效的序列视觉位置识别，在保持性能的同时显著提升效率和降低内存使用


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的Seq-VPR方法在追求性能时牺牲了灵活性和效率，无法满足实际应用中对序列长度可变性、快速推理和低内存使用的需求

Method: 提出循环可变形Transformer编码器(Recurrent-DTE)，采用迭代循环机制融合多帧序列信息，支持可变序列长度

Result: 在Nordland、Oxford和NuScenes数据集上，召回率提升高达17%，序列提取时间减少36%，内存使用降低35%

Conclusion: Adapt-STformer在保持高性能的同时，实现了灵活性和效率的平衡，满足了实时应用的约束要求

Abstract: Sequential Visual Place Recognition (Seq-VPR) leverages transformers to
capture spatio-temporal features effectively; however, existing approaches
prioritize performance at the expense of flexibility and efficiency. In
practice, a transformer-based Seq-VPR model should be flexible to the number of
frames per sequence (seq-length), deliver fast inference, and have low memory
usage to meet real-time constraints. To our knowledge, no existing
transformer-based Seq-VPR method achieves both flexibility and efficiency. To
address this gap, we propose Adapt-STformer, a Seq-VPR method built around our
novel Recurrent Deformable Transformer Encoder (Recurrent-DTE), which uses an
iterative recurrent mechanism to fuse information from multiple sequential
frames. This design naturally supports variable seq-lengths, fast inference,
and low memory usage. Experiments on the Nordland, Oxford, and NuScenes
datasets show that Adapt-STformer boosts recall by up to 17% while reducing
sequence extraction time by 36% and lowering memory usage by 35% compared to
the second-best baseline.

</details>


### [105] [ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation](https://arxiv.org/abs/2510.04290)
*Jay Zhangjie Wu,Xuanchi Ren,Tianchang Shen,Tianshi Cao,Kai He,Yifan Lu,Ruiyuan Gao,Enze Xie,Shiyi Lan,Jose M. Alvarez,Jun Gao,Sanja Fidler,Zian Wang,Huan Ling*

Main category: cs.CV

TL;DR: ChronoEdit将图像编辑重新定义为视频生成问题，利用预训练视频生成模型的时间一致性来确保物理一致性，并通过时间推理阶段生成合理的编辑轨迹。


<details>
  <summary>Details</summary>
Motivation: 当前大型生成模型在图像编辑和上下文图像生成方面取得了显著进展，但在确保物理一致性方面存在关键差距，这对于世界模拟相关任务尤为重要。

Method: 1) 将输入和编辑图像视为视频的首尾帧，利用预训练视频生成模型捕捉物体外观和隐含物理特性；2) 引入时间推理阶段，在推理时联合去噪目标帧和推理token，想象合理的编辑轨迹；3) 推理token在几步后被丢弃以避免完整视频渲染的高计算成本。

Result: 提出了PBench-Edit基准测试，验证了ChronoEdit在视觉保真度和物理合理性方面优于最先进的基线方法。

Conclusion: ChronoEdit通过将图像编辑重新定义为视频生成问题，有效解决了物理一致性问题，在图像编辑任务中表现出优越性能。

Abstract: Recent advances in large generative models have significantly advanced image
editing and in-context image generation, yet a critical gap remains in ensuring
physical consistency, where edited objects must remain coherent. This
capability is especially vital for world simulation related tasks. In this
paper, we present ChronoEdit, a framework that reframes image editing as a
video generation problem. First, ChronoEdit treats the input and edited images
as the first and last frames of a video, allowing it to leverage large
pretrained video generative models that capture not only object appearance but
also the implicit physics of motion and interaction through learned temporal
consistency. Second, ChronoEdit introduces a temporal reasoning stage that
explicitly performs editing at inference time. Under this setting, the target
frame is jointly denoised with reasoning tokens to imagine a plausible editing
trajectory that constrains the solution space to physically viable
transformations. The reasoning tokens are then dropped after a few steps to
avoid the high computational cost of rendering a full video. To validate
ChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for
contexts that require physical consistency, and demonstrate that ChronoEdit
surpasses state-of-the-art baselines in both visual fidelity and physical
plausibility. Code and models for both the 14B and 2B variants of ChronoEdit
will be released on the project page:
https://research.nvidia.com/labs/toronto-ai/chronoedit

</details>


### [106] [CARE-PD: A Multi-Site Anonymized Clinical Dataset for Parkinson's Disease Gait Assessment](https://arxiv.org/abs/2510.04312)
*Vida Adeli,Ivan Klabucar,Javad Rajabi,Benjamin Filtjens,Soroush Mehraban,Diwei Wang,Hyewon Seo,Trung-Hieu Hoang,Minh N. Do,Candice Muller,Claudia Oliveira,Daniel Boari Coelho,Pieter Ginis,Moran Gilat,Alice Nieuwboer,Joke Spildooren,Lucas Mckay,Hyeokhyen Kwon,Gari Clifford,Christine Esper,Stewart Factor,Imari Genias,Amirhossein Dadashzadeh,Leia Shum,Alan Whone,Majid Mirmehdi,Andrea Iaboni,Babak Taati*

Main category: cs.CV

TL;DR: CARE-PD是最大的公开帕金森病3D步态数据集，包含9个队列的多中心数据，支持临床评分预测和运动预训练任务，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 帕金森病的客观步态评估因缺乏大规模、多样化且临床标注的运动数据集而受限。

Method: 将RGB视频或运动捕捉数据通过统一预处理流程转换为匿名SMPL网格，支持监督临床评分预测和无监督运动预训练任务。

Result: 在CARE-PD上预训练可将MPJPE从60.8mm降至7.5mm，帕金森病严重程度macro-F1提升17个百分点。

Conclusion: CARE-PD展示了临床策划的多样化训练数据的价值，所有数据和基准代码已公开供非商业研究使用。

Abstract: Objective gait assessment in Parkinson's Disease (PD) is limited by the
absence of large, diverse, and clinically annotated motion datasets. We
introduce CARE-PD, the largest publicly available archive of 3D mesh gait data
for PD, and the first multi-site collection spanning 9 cohorts from 8 clinical
centers. All recordings (RGB video or motion capture) are converted into
anonymized SMPL meshes via a harmonized preprocessing pipeline. CARE-PD
supports two key benchmarks: supervised clinical score prediction (estimating
Unified Parkinson's Disease Rating Scale, UPDRS, gait scores) and unsupervised
motion pretext tasks (2D-to-3D keypoint lifting and full-body 3D
reconstruction). Clinical prediction is evaluated under four generalization
protocols: within-dataset, cross-dataset, leave-one-dataset-out, and
multi-dataset in-domain adaptation. To assess clinical relevance, we compare
state-of-the-art motion encoders with a traditional gait-feature baseline,
finding that encoders consistently outperform handcrafted features. Pretraining
on CARE-PD reduces MPJPE (from 60.8mm to 7.5mm) and boosts PD severity macro-F1
by 17 percentage points, underscoring the value of clinically curated, diverse
training data. CARE-PD and all benchmark code are released for non-commercial
research at https://neurips2025.care-pd.ca/.

</details>


### [107] [GenAR: Next-Scale Autoregressive Generation for Spatial Gene Expression Prediction](https://arxiv.org/abs/2510.04315)
*Jiarui Ouyang,Yihui Wang,Yihang Gao,Yingxue Xu,Shu Yang,Hao Chen*

Main category: cs.CV

TL;DR: GenAR是一个多尺度自回归框架，通过从粗到细的方式从H&E染色图像预测空间转录组学基因表达，将基因聚类为层次组以捕获跨基因依赖关系，并将表达建模为免码书的离散标记生成来直接预测原始计数。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学(ST)成本高昂，而从广泛可用的H&E染色图像预测基因表达是一个经济有效的替代方案。现有方法存在两个问题：(i)独立预测每个基因，忽略了共表达结构；(ii)将任务视为连续回归，而表达实际上是离散计数，这会导致生物学上不可信的输出并复杂化下游分析。

Method: GenAR采用多尺度自回归框架，从粗到细地细化预测。方法包括：将基因聚类为层次组以暴露跨基因依赖关系；将表达建模为免码书的离散标记生成来直接预测原始计数；在解码过程中融合组织学和空间嵌入。

Result: 在四个不同组织类型的空间转录组学数据集上的广泛实验结果表明，GenAR实现了最先进的性能。

Conclusion: GenAR框架通过离散建模和从粗到细的分解，避免了log诱导的偏差，并与原则性的条件分解保持一致，为精准医学和经济有效的分子分析提供了潜在应用价值。

Abstract: Spatial Transcriptomics (ST) offers spatially resolved gene expression but
remains costly. Predicting expression directly from widely available
Hematoxylin and Eosin (H&E) stained images presents a cost-effective
alternative. However, most computational approaches (i) predict each gene
independently, overlooking co-expression structure, and (ii) cast the task as
continuous regression despite expression being discrete counts. This mismatch
can yield biologically implausible outputs and complicate downstream analyses.
We introduce GenAR, a multi-scale autoregressive framework that refines
predictions from coarse to fine. GenAR clusters genes into hierarchical groups
to expose cross-gene dependencies, models expression as codebook-free discrete
token generation to directly predict raw counts, and conditions decoding on
fused histological and spatial embeddings. From an information-theoretic
perspective, the discrete formulation avoids log-induced biases and the
coarse-to-fine factorization aligns with a principled conditional
decomposition. Extensive experimental results on four Spatial Transcriptomics
datasets across different tissue types demonstrate that GenAR achieves
state-of-the-art performance, offering potential implications for precision
medicine and cost-effective molecular profiling. Code is publicly available at
https://github.com/oyjr/genar.

</details>


### [108] [RAP: 3D Rasterization Augmented End-to-End Planning](https://arxiv.org/abs/2510.04333)
*Lan Feng,Yang Gao,Eloi Zablocki,Quanyi Li,Wuyang Li,Sichao Liu,Matthieu Cord,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出RAP方法，通过轻量级3D栅格化和特征对齐技术，为端到端驾驶规划提供可扩展的数据增强，无需逼真渲染即可实现最先进的闭环鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 模仿学习训练的端到端驾驶策略缺乏恢复数据，小错误会迅速累积导致失败。现有方法使用神经渲染或游戏引擎生成数字孪生，但成本高昂且主要用于评估。研究发现逼真性对训练规划器不重要，重要的是语义保真度和可扩展性。

Method: 提出3D栅格化方法，用轻量级栅格化标注基元替代昂贵渲染，支持反事实恢复操作和跨智能体视图合成。引入栅格到真实特征空间对齐来弥合仿真与现实差距。这些组件构成RAP数据增强管道。

Result: RAP在四个主要基准测试中排名第一：NAVSIM v1/v2、Waymo开放数据集基于视觉的端到端驾驶和Bench2Drive，实现了最先进的闭环鲁棒性和长尾泛化能力。

Conclusion: 轻量级栅格化配合特征对齐足以扩展端到端训练，为逼真渲染提供了实用替代方案。

Abstract: Imitation learning for end-to-end driving trains policies only on expert
demonstrations. Once deployed in a closed loop, such policies lack recovery
data: small mistakes cannot be corrected and quickly compound into failures. A
promising direction is to generate alternative viewpoints and trajectories
beyond the logged path. Prior work explores photorealistic digital twins via
neural rendering or game engines, but these methods are prohibitively slow and
costly, and thus mainly used for evaluation. In this work, we argue that
photorealism is unnecessary for training end-to-end planners. What matters is
semantic fidelity and scalability: driving depends on geometry and dynamics,
not textures or lighting. Motivated by this, we propose 3D Rasterization, which
replaces costly rendering with lightweight rasterization of annotated
primitives, enabling augmentations such as counterfactual recovery maneuvers
and cross-agent view synthesis. To transfer these synthetic views effectively
to real-world deployment, we introduce a Raster-to-Real feature-space alignment
that bridges the sim-to-real gap. Together, these components form Rasterization
Augmented Planning (RAP), a scalable data augmentation pipeline for planning.
RAP achieves state-of-the-art closed-loop robustness and long-tail
generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo
Open Dataset Vision-based E2E Driving, and Bench2Drive. Our results show that
lightweight rasterization with feature alignment suffices to scale E2E
training, offering a practical alternative to photorealistic rendering. Project
page: https://alan-lanfeng.github.io/RAP/.

</details>


### [109] [Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise for Momentary Trajectory Prediction](https://arxiv.org/abs/2510.04365)
*Yuhao Luo,Yuang Zhang,Kehua Chen,Xinyu Zheng,Shucheng Zhang,Sikai Chen,Yinhai Wang*

Main category: cs.CV

TL;DR: 提出了Diffusion^2框架，用于解决瞬时轨迹预测问题，通过两个顺序连接的扩散模型分别生成未观测的历史轨迹和预测未来轨迹。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和人机交互中，当行人突然从盲区出现时，往往缺乏足够的观测数据（瞬时轨迹），这使得准确预测变得困难并增加了交通事故风险。

Method: 使用两个扩散模型：一个用于向后预测生成未观测的历史轨迹，另一个用于向前预测未来轨迹。设计了双头参数化机制估计不确定性和时间自适应噪声模块动态调节噪声尺度。

Result: 在ETH/UCY和Stanford Drone数据集上达到了最先进的瞬时轨迹预测性能。

Conclusion: Diffusion^2框架有效解决了瞬时轨迹预测问题，显著提升了在极端场景下的行人轨迹预测准确性。

Abstract: Accurate pedestrian trajectory prediction is crucial for ensuring safety and
efficiency in autonomous driving and human-robot interaction scenarios. Earlier
studies primarily utilized sufficient observational data to predict future
trajectories. However, in real-world scenarios, such as pedestrians suddenly
emerging from blind spots, sufficient observational data is often unavailable
(i.e. momentary trajectory), making accurate prediction challenging and
increasing the risk of traffic accidents. Therefore, advancing research on
pedestrian trajectory prediction under extreme scenarios is critical for
enhancing traffic safety. In this work, we propose a novel framework termed
Diffusion^2, tailored for momentary trajectory prediction. Diffusion^2 consists
of two sequentially connected diffusion models: one for backward prediction,
which generates unobserved historical trajectories, and the other for forward
prediction, which forecasts future trajectories. Given that the generated
unobserved historical trajectories may introduce additional noise, we propose a
dual-head parameterization mechanism to estimate their aleatoric uncertainty
and design a temporally adaptive noise module that dynamically modulates the
noise scale in the forward diffusion process. Empirically, Diffusion^2 sets a
new state-of-the-art in momentary trajectory prediction on ETH/UCY and Stanford
Drone datasets.

</details>


### [110] [MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator](https://arxiv.org/abs/2510.04390)
*Xuehai He,Shijie Zhou,Thivyanth Venkateswaran,Kaizhi Zheng,Ziyu Wan,Achuta Kadambi,Xin Eric Wang*

Main category: cs.CV

TL;DR: MorphoSim是一个语言引导的4D场景生成框架，能够创建多视角一致且支持对象级控制的动态环境，通过轨迹引导生成和特征场蒸馏技术实现交互式编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频模型局限于2D视图且交互性有限，无法满足机器人领域对可控、可编辑时空环境的需求。

Method: 集成轨迹引导生成与特征场蒸馏，从自然语言指令生成动态环境，支持对象操控、重新着色、移除等操作，并可从任意视角观察场景。

Result: 实验表明MorphoSim在保持高场景保真度的同时实现了可控性和可编辑性。

Conclusion: MorphoSim为机器人领域提供了可扩展的训练数据、可复现的评估和灵活的任务设计能力。

Abstract: World models that support controllable
  and editable spatiotemporal environments are valuable
  for robotics, enabling scalable training data, repro ducible evaluation, and
flexible task design. While
  recent text-to-video models generate realistic dynam ics, they are
constrained to 2D views and offer limited
  interaction. We introduce MorphoSim, a language guided framework that
generates 4D scenes with
  multi-view consistency and object-level controls. From
  natural language instructions, MorphoSim produces
  dynamic environments where objects can be directed,
  recolored, or removed, and scenes can be observed
  from arbitrary viewpoints. The framework integrates
  trajectory-guided generation with feature field dis tillation, allowing edits
to be applied interactively
  without full re-generation. Experiments show that Mor phoSim maintains high
scene fidelity while enabling
  controllability and editability. The code is available
  at https://github.com/eric-ai-lab/Morph4D.

</details>


### [111] [Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting](https://arxiv.org/abs/2510.04401)
*Xuyang Guo,Zekai Huang,Zhenmei Shi,Zhao Song,Jiahao Zhang*

Main category: cs.CV

TL;DR: 该论文提出了VLMCountBench基准测试，专门评估视觉语言模型在简单几何形状计数任务中的表现，发现当前VLMs在组合计数方面存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在各种任务上表现出色，但作者质疑它们是否能正确计数物体，特别是在组合场景中。

Method: 创建VLMCountBench基准测试，使用基本几何形状（如三角形、圆形）及其组合，在严格控制变量的条件下系统研究颜色、大小和提示词优化等因素的影响。

Result: 实验结果显示，VLMs在单一形状类型计数时表现可靠，但在多种形状类型组合的计数任务中出现大量失败。

Conclusion: 当前视觉语言模型在组合计数方面存在根本性局限，这为未来研究指明了重要方向。

Abstract: Vision-Language Models (VLMs) have become a central focus of today's AI
community, owing to their impressive abilities gained from training on
large-scale vision-language data from the Web. These models have demonstrated
strong performance across diverse tasks, including image understanding, video
understanding, complex visual reasoning, and embodied AI. Despite these
noteworthy successes, a fundamental question remains: Can VLMs count objects
correctly? In this paper, we introduce a simple yet effective benchmark,
VLMCountBench, designed under a minimalist setting with only basic geometric
shapes (e.g., triangles, circles) and their compositions, focusing exclusively
on counting tasks without interference from other factors. We adopt strict
independent variable control and systematically study the effects of simple
properties such as color, size, and prompt refinement in a controlled ablation.
Our empirical results reveal that while VLMs can count reliably when only one
shape type is present, they exhibit substantial failures when multiple shape
types are combined (i.e., compositional counting). This highlights a
fundamental empirical limitation of current VLMs and motivates important
directions for future research.

</details>


### [112] [CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning](https://arxiv.org/abs/2510.04410)
*Venkata Bharath Reddy Reddem,Akshay P Sarashetti,Ranjith Merugu,Amit Satish Unde*

Main category: cs.CV

TL;DR: CodeFormer++是一个用于盲人脸恢复的新框架，通过分解任务为身份保护恢复、高质量生成和动态融合，解决了现有方法在视觉质量和身份保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有盲人脸恢复方法在集成生成先验时，往往面临视觉质量和身份保真度之间的权衡，导致身份失真或退化去除不理想。

Method: 将BFR分解为三个子任务：身份保护恢复、高质量生成和动态融合；提出基于学习的可变形人脸配准模块、纹理引导恢复网络，并集成深度度量学习。

Result: 在真实世界和合成数据集上的广泛实验表明，CodeFormer++在视觉保真度和身份一致性方面都实现了优越性能。

Conclusion: CodeFormer++通过最大化生成先验的效用，实现了高质量人脸恢复同时保持身份信息，解决了现有方法的局限性。

Abstract: Blind face restoration (BFR) has attracted increasing attention with the rise
of generative methods. Most existing approaches integrate generative priors
into the restoration pro- cess, aiming to jointly address facial detail
generation and identity preservation. However, these methods often suffer from
a trade-off between visual quality and identity fidelity, leading to either
identity distortion or suboptimal degradation removal. In this paper, we
present CodeFormer++, a novel framework that maximizes the utility of
generative priors for high-quality face restoration while preserving identity.
We decompose BFR into three sub-tasks: (i) identity- preserving face
restoration, (ii) high-quality face generation, and (iii) dynamic fusion of
identity features with realistic texture details. Our method makes three key
contributions: (1) a learning-based deformable face registration module that
semantically aligns generated and restored faces; (2) a texture guided
restoration network to dynamically extract and transfer the texture of
generated face to boost the quality of identity-preserving restored face; and
(3) the integration of deep metric learning for BFR with the generation of
informative positive and hard negative samples to better fuse identity-
preserving and generative features. Extensive experiments on real-world and
synthetic datasets demonstrate that, the pro- posed CodeFormer++ achieves
superior performance in terms of both visual fidelity and identity consistency.

</details>


### [113] [A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering](https://arxiv.org/abs/2510.04428)
*Yuanhao Zou,Shengji Jin,Andong Deng,Youpeng Zhao,Jun Wang,Chen Chen*

Main category: cs.CV

TL;DR: 提出A.I.R.方法，一种无需训练的自适应、迭代、基于推理的帧选择方法，用于视频问答中的高效帧选择，平衡了计算成本和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前视频问答中的帧选择方法面临关键权衡：基于轻量级相似性模型的方法无法捕捉复杂查询的细微差别，而使用VLM进行深度分析的方法计算成本过高。

Method: 利用强大的VLM对复杂查询进行深度语义分析，并在成本效益高的迭代循环中处理少量高潜力帧批次。

Result: 在各种VideoQA基准测试中，该方法优于现有帧选择方法，显著提升了基础VLM的性能，并大幅提高了计算效率。

Conclusion: A.I.R.方法有效解决了视频问答中帧选择的准确性与计算效率之间的权衡问题。

Abstract: Effectively applying Vision-Language Models (VLMs) to Video Question
Answering (VideoQA) hinges on selecting a concise yet comprehensive set of
frames, as processing entire videos is computationally infeasible. However,
current frame selection methods face a critical trade-off: approaches relying
on lightweight similarity models, such as CLIP, often fail to capture the
nuances of complex queries, resulting in inaccurate similarity scores that
cannot reflect the authentic query-frame relevance, which further undermines
frame selection. Meanwhile, methods that leverage a VLM for deeper analysis
achieve higher accuracy but incur prohibitive computational costs. To address
these limitations, we propose A.I.R., a training-free approach for Adaptive,
Iterative, and Reasoning-based frame selection. We leverage a powerful VLM to
perform deep, semantic analysis on complex queries, and this analysis is
deployed within a cost-effective iterative loop that processes only a small
batch of the most high-potential frames at a time. Extensive experiments on
various VideoQA benchmarks demonstrate that our approach outperforms existing
frame selection methods, significantly boosts the performance of the foundation
VLM, and achieves substantial gains in computational efficiency over other
VLM-based techniques.

</details>


### [114] [REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization](https://arxiv.org/abs/2510.04450)
*Qiyuan He,Yicong Li,Haotian Ye,Jinghao Wang,Xinyao Liao,Pheng-Ann Heng,Stefano Ermon,James Zou,Angela Yao*

Main category: cs.CV

TL;DR: 提出reAR训练策略，通过token-wise正则化解决视觉自回归生成中的生成器-分词器不一致问题，显著提升图像生成质量


<details>
  <summary>Details</summary>
Motivation: 视觉自回归生成性能落后于扩散模型，核心瓶颈在于生成器与分词器的不一致性——AR生成的token可能无法被分词器良好解码

Method: 引入token-wise正则化目标：在预测下一个token时，因果变换器同时学习恢复当前token的视觉嵌入，并在噪声上下文中预测目标token的嵌入

Result: 在ImageNet上，gFID从3.02降至1.86，IS提升至316.9；应用于先进分词器时，仅用1.77亿参数实现gFID 1.42，匹配6.75亿参数扩散模型性能

Conclusion: reAR是一种简单有效的训练策略，无需改变分词器、生成顺序或推理流程，就能显著提升视觉自回归生成质量

Abstract: Visual autoregressive (AR) generation offers a promising path toward unifying
vision and language models, yet its performance remains suboptimal against
diffusion models. Prior work often attributes this gap to tokenizer limitations
and rasterization ordering. In this work, we identify a core bottleneck from
the perspective of generator-tokenizer inconsistency, i.e., the AR-generated
tokens may not be well-decoded by the tokenizer. To address this, we propose
reAR, a simple training strategy introducing a token-wise regularization
objective: when predicting the next token, the causal transformer is also
trained to recover the visual embedding of the current token and predict the
embedding of the target token under a noisy context. It requires no changes to
the tokenizer, generation order, inference pipeline, or external models.
Despite its simplicity, reAR substantially improves performance. On ImageNet,
it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard
rasterization-based tokenizer. When applied to advanced tokenizers, it achieves
a gFID of 1.42 with only 177M parameters, matching the performance with larger
state-of-the-art diffusion models (675M).

</details>


### [115] [SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection](https://arxiv.org/abs/2510.04472)
*Baber Jan,Saeed Anwar,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais*

Main category: cs.CV

TL;DR: SPEGNet提出了一种统一的伪装目标检测架构，通过通道校准和空间增强整合多尺度特征，避免传统方法因复杂组件累积导致的计算负担和细节丢失。


<details>
  <summary>Details</summary>
Motivation: 当前伪装目标检测方法依赖累积复杂组件（如边界模块、注意力机制等），造成计算负担且需要降低分辨率处理，导致丢失细微细节。需要一种统一设计来解决碎片化问题。

Method: 采用通道校准和空间增强整合多尺度特征，边界直接从上下文丰富的表示中产生，保持语义-空间对齐。通过渐进式细化实现尺度自适应边缘调制，在中间分辨率达到峰值影响。

Result: 在CAMO数据集上达到0.887 Sα，COD10K上0.890，NC4K上0.895，并具有实时推理速度。能够处理从微小复杂物体到大型模式相似物体的各种尺度，同时处理遮挡和模糊边界。

Conclusion: SPEGNet在边界精度和区域一致性之间取得平衡，通过统一设计有效解决了传统方法因组件累积导致的复杂性和细节丢失问题，实现了高效准确的伪装目标检测。

Abstract: Camouflaged object detection segments objects with intrinsic similarity and
edge disruption. Current detection methods rely on accumulated complex
components. Each approach adds components such as boundary modules, attention
mechanisms, and multi-scale processors independently. This accumulation creates
a computational burden without proportional gains. To manage this complexity,
they process at reduced resolutions, eliminating fine details essential for
camouflage. We present SPEGNet, addressing fragmentation through a unified
design. The architecture integrates multi-scale features via channel
calibration and spatial enhancement. Boundaries emerge directly from
context-rich representations, maintaining semantic-spatial alignment.
Progressive refinement implements scale-adaptive edge modulation with peak
influence at intermediate resolutions. This design strikes a balance between
boundary precision and regional consistency. SPEGNet achieves 0.887 $S_\alpha$
on CAMO, 0.890 on COD10K, and 0.895 on NC4K, with real-time inference speed.
Our approach excels across scales, from tiny, intricate objects to large,
pattern-similar ones, while handling occlusion and ambiguous boundaries. Code,
model weights, and results are available on
\href{https://github.com/Baber-Jan/SPEGNet}{https://github.com/Baber-Jan/SPEGNet}.

</details>


### [116] [MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models](https://arxiv.org/abs/2510.04477)
*Soo Yong Kim,Suin Cho,Vincent-Daniel Yun,Gyeongyeon Hwang*

Main category: cs.CV

TL;DR: MedCLM是一个自动化管道，将检测数据集转换为具有链式思维推理的大规模医学视觉问答数据，通过集成CoT课程策略实现最先进的医学VQA性能。


<details>
  <summary>Details</summary>
Motivation: 弥合临床诊断推理与AI之间的差距是医学成像中的核心挑战，需要开发能够生成逐步推理的医学视觉语言模型。

Method: 提出MedCLM自动化管道，将检测数据集转换为具有CoT推理的医学VQA数据，并采用集成CoT课程策略，包含简单（显式病灶框）、中等（隐式定位）和困难（弱监督推理）三个阶段。

Result: MedCLM在多个医学VQA基准测试中达到了最先进的性能，为开发临床对齐的医学视觉语言模型提供了可扩展框架。

Conclusion: MedCLM通过将检测数据转换为具有链式思维推理的VQA数据，并结合课程学习策略，成功提升了医学视觉语言模型的临床诊断推理能力。

Abstract: Bridging clinical diagnostic reasoning with AI remains a central challenge in
medical imaging. We introduce MedCLM, an automated pipeline that converts
detection datasets into large-scale medical visual question answering (VQA)
data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ
segmentation and structured rationales. These contextual signals enable medical
vision-language models to generate question-answer pairs with step-by-step
reasoning. To utilize this data effectively, we propose an Integrated
CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes
for visual grounding, a Medium stage that encourages implicit localization, and
a Hard stage for weakly supervised reasoning. Experimental results demonstrate
that MedCLM attains state-of-the-art performance on several medical VQA
benchmarks, providing a scalable framework for developing clinically aligned
medical vision-language models.

</details>


### [117] [VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery](https://arxiv.org/abs/2510.04479)
*Nonghai Zhang,Zeyu Zhang,Jiazi Wang,Yang Zhao,Hao Tang*

Main category: cs.CV

TL;DR: 提出了首个用于古希腊陶器分析的3D视觉问答数据集VaseVQA-3D和VaseVLM模型，解决了文化遗产领域视觉语言模型面临的数据稀缺和领域知识不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在通用任务上表现良好，但在文化遗产等专业领域面临数据稀缺和领域知识不足的挑战，特别是在3D陶器文物分析方面。

Method: 构建了包含664个古希腊陶器3D模型及对应问答数据的VaseVQA-3D数据集，并开发了VaseVLM模型，通过领域自适应训练提升模型性能。

Result: 在VaseVQA-3D数据集上，R@1指标提升12.8%，词汇相似度提升6.6%，显著改善了3D陶器文物的识别与理解能力。

Conclusion: 该方法有效解决了文化遗产领域的专业任务挑战，为数字遗产保护研究提供了新的技术途径。

Abstract: Vision-Language Models (VLMs) have achieved significant progress in
multimodal understanding tasks, demonstrating strong capabilities particularly
in general tasks such as image captioning and visual reasoning. However, when
dealing with specialized cultural heritage domains like 3D vase artifacts,
existing models face severe data scarcity issues and insufficient domain
knowledge limitations. Due to the lack of targeted training data, current VLMs
struggle to effectively handle such culturally significant specialized tasks.
To address these challenges, we propose the VaseVQA-3D dataset, which serves as
the first 3D visual question answering dataset for ancient Greek pottery
analysis, collecting 664 ancient Greek vase 3D models with corresponding
question-answer data and establishing a complete data construction pipeline. We
further develop the VaseVLM model, enhancing model performance in vase artifact
analysis through domain-adaptive training. Experimental results validate the
effectiveness of our approach, where we improve by 12.8% on R@1 metrics and by
6.6% on lexical similarity compared with previous state-of-the-art on the
VaseVQA-3D dataset, significantly improving the recognition and understanding
of 3D vase artifacts, providing new technical pathways for digital heritage
preservation research.

</details>


### [118] [TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement](https://arxiv.org/abs/2510.04483)
*Hao Fang,Zechao Zhan,Weixin Feng,Ziwei Huang,XuBin Li,Tiezheng Ge*

Main category: cs.CV

TL;DR: TBStar-Edit是一个专门为电商领域设计的图像编辑模型，通过数据工程、模型架构设计和训练策略，在保持产品外观和布局完整性的同时实现精确高保真的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的通用图像生成和编辑模型在电商场景中经常遇到一致性问题，无法很好地保持产品外观和布局的完整性。

Method: 1）建立全面的数据构建流水线；2）设计包含基础模型、模式转换模块和一致性增强模块的分层模型框架；3）采用两阶段训练策略：第一阶段进行编辑模式转换，第二阶段进行一致性增强。

Result: 在自建的电商基准测试中，TBStar-Edit在客观指标（VIE Score）和主观用户偏好方面均优于现有的通用领域编辑模型。

Conclusion: TBStar-Edit通过专门针对电商场景的优化设计，有效解决了通用图像编辑模型在电商领域的一致性问题，实现了更好的编辑效果。

Abstract: Recent advances in image generation and editing technologies have enabled
state-of-the-art models to achieve impressive results in general domains.
However, when applied to e-commerce scenarios, these general models often
encounter consistency limitations. To address this challenge, we introduce
TBStar-Edit, an new image editing model tailored for the e-commerce domain.
Through rigorous data engineering, model architecture design and training
strategy, TBStar-Edit achieves precise and high-fidelity image editing while
maintaining the integrity of product appearance and layout. Specifically, for
data engineering, we establish a comprehensive data construction pipeline,
encompassing data collection, construction, filtering, and augmentation, to
acquire high-quality, instruction-following, and strongly consistent editing
data to support model training. For model architecture design, we design a
hierarchical model framework consisting of a base model, pattern shifting
modules, and consistency enhancement modules. For model training, we adopt a
two-stage training strategy to enhance the consistency preservation: first
stage for editing pattern shifting, and second stage for consistency
enhancement. Each stage involves training different modules with separate
datasets. Finally, we conduct extensive evaluations of TBStar-Edit on a
self-proposed e-commerce benchmark, and the results demonstrate that
TBStar-Edit outperforms existing general-domain editing models in both
objective metrics (VIE Score) and subjective user preference.

</details>


### [119] [Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation](https://arxiv.org/abs/2510.04504)
*Zijing Hu,Yunze Tong,Fengda Zhang,Junkun Yuan,Jun Xiao,Kun Kuang*

Main category: cs.CV

TL;DR: 提出异步扩散模型，通过为不同像素分配不同时间步长，让提示相关区域比无关区域更渐进地降噪，从而利用更清晰的像素间上下文，显著改善文本到图像的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型采用同步降噪，所有像素同时从随机噪声演变为清晰图像，导致提示相关区域只能参考相同噪声水平的无关区域，无法获得清晰上下文，最终损害文本到图像的对齐效果。

Method: 提出异步扩散模型框架，为不同像素分配不同的时间步长，重新制定逐像素降噪过程。通过动态调节单个像素的时间步长调度，让提示相关区域比无关区域更渐进地降噪。

Result: 大量实验表明，异步扩散模型能够显著提高各种提示下的文本到图像对齐效果。

Conclusion: 异步扩散模型通过异步降噪机制，让提示相关区域能够利用更清晰的像素间上下文，从而在最终图像中实现更好的对齐效果。

Abstract: Diffusion models have achieved impressive results in generating high-quality
images. Yet, they often struggle to faithfully align the generated images with
the input prompts. This limitation arises from synchronous denoising, where all
pixels simultaneously evolve from random noise to clear images. As a result,
during generation, the prompt-related regions can only reference the unrelated
regions at the same noise level, failing to obtain clear context and ultimately
impairing text-to-image alignment. To address this issue, we propose
asynchronous diffusion models -- a novel framework that allocates distinct
timesteps to different pixels and reformulates the pixel-wise denoising
process. By dynamically modulating the timestep schedules of individual pixels,
prompt-related regions are denoised more gradually than unrelated regions,
thereby allowing them to leverage clearer inter-pixel context. Consequently,
these prompt-related regions achieve better alignment in the final images.
Extensive experiments demonstrate that our asynchronous diffusion models can
significantly improve text-to-image alignment across diverse prompts. The code
repository for this work is available at https://github.com/hu-zijing/AsynDM.

</details>


### [120] [TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling](https://arxiv.org/abs/2510.04533)
*Hyunmin Cho,Donghoon Ahn,Susung Hong,Jee Eun Kim,Seungryong Kim,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: 提出TAG方法，通过放大分数估计的切向分量来修正扩散模型的采样轨迹，提高生成质量而不修改基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像生成中存在语义不一致或幻觉问题，现有推理时引导方法依赖外部信号或架构修改，计算开销大。

Method: 利用中间样本作为投影基础，放大分数估计的切向分量来修正采样轨迹，基于一阶泰勒展开形式化指导过程。

Result: TAG是一个即插即用、架构无关的模块，能以最小计算开销提高扩散采样保真度。

Conclusion: TAG为扩散引导提供了新视角，通过直接操作轨迹信号实现高效指导。

Abstract: Recent diffusion models achieve the state-of-the-art performance in image
generation, but often suffer from semantic inconsistencies or hallucinations.
While various inference-time guidance methods can enhance generation, they
often operate indirectly by relying on external signals or architectural
modifications, which introduces additional computational overhead. In this
paper, we propose Tangential Amplifying Guidance (TAG), a more efficient and
direct guidance method that operates solely on trajectory signals without
modifying the underlying diffusion model. TAG leverages an intermediate sample
as a projection basis and amplifies the tangential components of the estimated
scores with respect to this basis to correct the sampling trajectory. We
formalize this guidance process by leveraging a first-order Taylor expansion,
which demonstrates that amplifying the tangential component steers the state
toward higher-probability regions, thereby reducing inconsistencies and
enhancing sample quality. TAG is a plug-and-play, architecture-agnostic module
that improves diffusion sampling fidelity with minimal computational addition,
offering a new perspective on diffusion guidance.

</details>


### [121] [Conditional Representation Learning for Customized Tasks](https://arxiv.org/abs/2510.04564)
*Honglin Liu,Chao Sun,Peng Hu,Yunfan Li,Xi Peng*

Main category: cs.CV

TL;DR: 提出条件表示学习(CRL)方法，通过用户指定的条件生成定制化特征表示，解决通用表示与下游任务不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 传统表示学习方法学习的是通用表示，主要捕捉主导语义，可能与定制化下游任务不匹配。例如动物栖息地分析中，研究者关注场景相关特征，而通用嵌入强调类别语义，导致结果不理想。现有方法需要监督微调，计算和标注成本高。

Method: CRL方法：1）使用大语言模型(LLM)根据用户指定条件生成描述性文本来构建语义基；2）利用视觉语言模型(VLM)将图像表示投影到这个条件特征空间中。

Result: 在分类和检索任务上的大量实验证明了CRL方法的优越性和通用性。

Conclusion: 条件表示学习能够为特定标准提取更合适的表示，可用于多个定制化任务，解决了通用表示与下游任务不匹配的问题。

Abstract: Conventional representation learning methods learn a universal representation
that primarily captures dominant semantics, which may not always align with
customized downstream tasks. For instance, in animal habitat analysis,
researchers prioritize scene-related features, whereas universal embeddings
emphasize categorical semantics, leading to suboptimal results. As a solution,
existing approaches resort to supervised fine-tuning, which however incurs high
computational and annotation costs. In this paper, we propose Conditional
Representation Learning (CRL), aiming to extract representations tailored to
arbitrary user-specified criteria. Specifically, we reveal that the semantics
of a space are determined by its basis, thereby enabling a set of descriptive
words to approximate the basis for a customized feature space. Building upon
this insight, given a user-specified criterion, CRL first employs a large
language model (LLM) to generate descriptive texts to construct the semantic
basis, then projects the image representation into this conditional feature
space leveraging a vision-language model (VLM). The conditional representation
better captures semantics for the specific criterion, which could be utilized
for multiple customized tasks. Extensive experiments on classification and
retrieval tasks demonstrate the superiority and generality of the proposed CRL.
The code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.

</details>


### [122] [Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior](https://arxiv.org/abs/2510.04587)
*Sheng Wang,Ruiming Wu,Charles Herndon,Yihang Liu,Shunsuke Koga,Jeanne Shen,Zhi Huang*

Main category: cs.CV

TL;DR: 开发了AI Session Recorder系统，通过记录病理学家在WSI查看器中的导航行为，构建Pathology-CoT数据集，并训练Pathologist-o3智能体在胃肠道淋巴结转移检测中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前病理学AI缺乏实用的智能体系统，能够决定查看区域、调整放大倍数并提供可解释诊断。主要障碍是缺乏可扩展的、临床对齐的专家行为监督数据。

Method: 1. AI Session Recorder记录WSI查看器导航日志，转换为标准化行为命令；2. 轻量级人工审查将AI生成的解释转化为Pathology-CoT数据集；3. 构建两阶段Pathologist-o3智能体，先提出感兴趣区域，再进行行为引导推理。

Result: 在胃肠道淋巴结转移检测中，达到84.5%精确率、100.0%召回率和75.4%准确率，超越OpenAI o3模型，并在不同骨干网络上具有良好泛化性。

Conclusion: 该框架将日常查看器日志转化为可扩展的专家验证监督数据，使智能体病理学实用化，为人类对齐、可升级的临床AI建立了路径。

Abstract: Diagnosing a whole-slide image is an interactive, multi-stage process
involving changes in magnification and movement between fields. Although recent
pathology foundation models are strong, practical agentic systems that decide
what field to examine next, adjust magnification, and deliver explainable
diagnoses are still lacking. The blocker is data: scalable, clinically aligned
supervision of expert viewing behavior that is tacit and experience-based, not
written in textbooks or online, and therefore absent from large language model
training. We introduce the AI Session Recorder, which works with standard WSI
viewers to unobtrusively record routine navigation and convert the viewer logs
into standardized behavioral commands (inspect or peek at discrete
magnifications) and bounding boxes. A lightweight human-in-the-loop review
turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired
"where to look" and "why it matters" supervision produced at roughly six times
lower labeling time. Using this behavioral data, we build Pathologist-o3, a
two-stage agent that first proposes regions of interest and then performs
behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection,
it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the
state-of-the-art OpenAI o3 model and generalizing across backbones. To our
knowledge, this constitutes one of the first behavior-grounded agentic systems
in pathology. Turning everyday viewer logs into scalable, expert-validated
supervision, our framework makes agentic pathology practical and establishes a
path to human-aligned, upgradeable clinical AI.

</details>


### [123] [A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification](https://arxiv.org/abs/2510.04628)
*Hao Liu,Yunhao Gao,Wei Li,Mingyang Zhang,Maoguo Gong,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 提出S²Fin网络，通过空间-光谱-频率交互融合，解决多模态遥感图像分类中结构特征和细节特征提取困难的问题


<details>
  <summary>Details</summary>
Motivation: 现有特征融合技术难以从异构冗余的多模态图像中提取结构和细节特征，需要引入频域学习来建模关键稀疏细节特征

Method: 提出高频稀疏增强Transformer，使用稀疏空间-光谱注意力优化高频滤波器参数；采用两级空间-频率融合策略，包括自适应频率通道模块和高频共振掩码；增加空间-光谱注意力融合模块

Result: 在四个基准多模态数据集上，S²Fin在有限标注数据下表现出优越的分类性能，超越了现有最先进方法

Conclusion: S²Fin通过跨域融合有效提升了多模态遥感图像分类能力，证明了频域学习在特征提取中的重要性

Abstract: Deep learning-based methods have achieved significant success in remote
sensing Earth observation data analysis. Numerous feature fusion techniques
address multimodal remote sensing image classification by integrating global
and local features. However, these techniques often struggle to extract
structural and detail features from heterogeneous and redundant multimodal
images. With the goal of introducing frequency domain learning to model key and
sparse detail features, this paper introduces the spatial-spectral-frequency
interaction network (S$^2$Fin), which integrates pairwise fusion modules across
the spatial, spectral, and frequency domains. Specifically, we propose a
high-frequency sparse enhancement transformer that employs sparse
spatial-spectral attention to optimize the parameters of the high-frequency
filter. Subsequently, a two-level spatial-frequency fusion strategy is
introduced, comprising an adaptive frequency channel module that fuses
low-frequency structures with enhanced high-frequency details, and a
high-frequency resonance mask that emphasizes sharp edges via phase similarity.
In addition, a spatial-spectral attention fusion module further enhances
feature extraction at intermediate layers of the network. Experiments on four
benchmark multimodal datasets with limited labeled data demonstrate that
S$^2$Fin performs superior classification, outperforming state-of-the-art
methods. The code is available at https://github.com/HaoLiu-XDU/SSFin.

</details>


### [124] [SFANet: Spatial-Frequency Attention Network for Deepfake Detection](https://arxiv.org/abs/2510.04630)
*Vrushank Ahire,Aniruddh Muley,Shivam Zample,Siddharth Verma,Pranav Menon,Surbhi Madan,Abhinav Dhall*

Main category: cs.CV

TL;DR: 提出了一种新颖的集成框架，结合基于transformer的架构和基于纹理的方法，用于深度伪造检测，在DFWild-Cup数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的兴起，检测被操纵的媒体已成为紧迫问题。现有方法在跨数据集和生成技术的泛化能力方面存在不足。

Method: 采用集成框架，结合Swin Transformers和ViTs等transformer架构与基于纹理的方法，引入创新技术包括数据分割、顺序训练、频率分割、基于补丁的注意力和面部分割。

Result: 在包含八个深度伪造数据集的DFWild-Cup数据集上实现了最先进的检测性能，集成方法受益于不同方法的互补性。

Conclusion: 混合模型能够有效应对深度伪造检测的不断演变挑战，为实际应用提供了鲁棒的解决方案。

Abstract: Detecting manipulated media has now become a pressing issue with the recent
rise of deepfakes. Most existing approaches fail to generalize across diverse
datasets and generation techniques. We thus propose a novel ensemble framework,
combining the strengths of transformer-based architectures, such as Swin
Transformers and ViTs, and texture-based methods, to achieve better detection
accuracy and robustness. Our method introduces innovative data-splitting,
sequential training, frequency splitting, patch-based attention, and face
segmentation techniques to handle dataset imbalances, enhance high-impact
regions (e.g., eyes and mouth), and improve generalization. Our model achieves
state-of-the-art performance when tested on the DFWild-Cup dataset, a diverse
subset of eight deepfake datasets. The ensemble benefits from the
complementarity of these approaches, with transformers excelling in global
feature extraction and texturebased methods providing interpretability. This
work demonstrates that hybrid models can effectively address the evolving
challenges of deepfake detection, offering a robust solution for real-world
applications.

</details>


### [125] [Do Superpixel Segmentation Methods Influence Deforestation Image Classification?](https://arxiv.org/abs/2510.04645)
*Hugo Resende,Fabio A. Faria,Eduardo B. Neto,Isabela Borlido,Victor Sundermann,Silvio Jamil F. Guimarães,Álvaro L. Fazenda*

Main category: cs.CV

TL;DR: 本文研究了不同图像分割方法对森林砍伐检测分类器性能的影响，发现在使用分类器融合方法后，分割方法的选择对精度有显著影响。


<details>
  <summary>Details</summary>
Motivation: ForestEyes项目结合公民科学和机器学习检测热带森林砍伐，传统使用SLIC算法进行图像分割，但研究表明其他超像素方法在遥感图像分割中表现更好，需要评估不同分割方法对分类器训练的影响。

Method: 比较了四种最佳分割方法与SLIC算法，使用PyCaret AutoML库选择前五个分类器，并应用分类器融合（集成学习）方法。

Result: 初始结果显示不同分割方法间性能差异不大，但应用分类器融合方法后，平衡精度有明显提升。

Conclusion: 分割方法的选择和机器学习模型的组合对森林砍伐检测任务都很重要，分类器融合能显著提升检测性能。

Abstract: Image segmentation is a crucial step in various visual applications,
including environmental monitoring through remote sensing. In the context of
the ForestEyes project, which combines citizen science and machine learning to
detect deforestation in tropical forests, image segments are used for labeling
by volunteers and subsequent model training. Traditionally, the Simple Linear
Iterative Clustering (SLIC) algorithm is adopted as the segmentation method.
However, recent studies have indicated that other superpixel-based methods
outperform SLIC in remote sensing image segmentation, and might suggest that
they are more suitable for the task of detecting deforested areas. In this
sense, this study investigated the impact of the four best segmentation
methods, together with SLIC, on the training of classifiers for the target
application. Initially, the results showed little variation in performance
among segmentation methods, even when selecting the top five classifiers using
the PyCaret AutoML library. However, by applying a classifier fusion approach
(ensemble of classifiers), noticeable improvements in balanced accuracy were
observed, highlighting the importance of both the choice of segmentation method
and the combination of machine learning-based models for deforestation
detection tasks.

</details>


### [126] [EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents](https://arxiv.org/abs/2510.04648)
*Buyuan Zhu,Shiyu Hu,Yiping Ma,Yuanming Zhang,Kang Hao Cheong*

Main category: cs.CV

TL;DR: EduPersona是一个大规模教育基准，专注于评估虚拟学生代理的主观能力，包含1308个真实课堂对话和128k扩展数据，通过三个渐进任务评估模型表现，实验显示微调后模型在所有任务上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在教育中的集成，虚拟学生代理对课堂模拟和教师培训变得重要，但其课堂导向的主观能力尚未得到充分评估，限制了模型边界理解和可信部署。

Method: 构建EduPersona基准数据集，涵盖两种语言、三个学科和十种人格类型，包含1308个真实课堂对话轮次。将主观性能分解为三个渐进任务：基本连贯性、学生真实性和长期人格一致性，并基于此框架对三个代表性LLM进行系统实验。

Result: 实验结果显示，经过人格微调的模型在所有三个任务上均有显著提升：TASK1提升33.6%，TASK2提升30.6%，TASK3提升14.9%，证明了数据集的有效性和研究价值。

Conclusion: EduPersona提供了首个专注于主观能力的课堂基准，建立了可解耦和可验证的研究范式，将开源数据集和框架以支持教育领域可信和类人AI的发展。

Abstract: As large language models are increasingly integrated into education, virtual
student agents are becoming vital for classroom simulation and teacher
training. Yet their classroom-oriented subjective abilities remain largely
unassessed, limiting understanding of model boundaries and hindering
trustworthy deployment. We present EduPersona, a large-scale benchmark spanning
two languages, three subjects, and ten persona types based on the Big Five
theory. The dataset contains 1,308 authentic classroom dialogue rounds,
corresponding to 12,814 teacher-student Q&A turns, and is further expanded
through persona stylization into roughly 10 times larger scale (128k turns),
providing a solid foundation for evaluation. Building on this resource, we
decompose hard-to-quantify subjective performance into three progressive tasks:
TASK1 basic coherence (whether behavior, emotion, expression, and voice align
with classroom context), TASK2 student realism, and TASK3 long-term persona
consistency, thereby establishing an evaluation framework grounded in
educational theory and research value. We conduct systematic experiments on
three representative LLMs, comparing their original versions with ten
persona-fine-tuned variants trained on EduPersona. Results show consistent and
significant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%,
and TASK3 +14.9%. These improvements highlight the dataset's effectiveness and
research value, while also revealing the heterogeneous difficulty of persona
modeling. In summary, EduPersona delivers the first classroom benchmark
centered on subjective abilities, establishes a decoupled and verifiable
research paradigm, and we will open-source both the dataset and the framework
to support the broader research community in advancing trustworthy and
human-like AI for education.

</details>


### [127] [MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts](https://arxiv.org/abs/2510.04654)
*Andy Cǎtrunǎ,Adrian Cosma,Emilian Rǎdoi*

Main category: cs.CV

TL;DR: 提出了一个多阶段混合运动专家(MoME)架构，通过步态序列预测心理特征，在PsyMo基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 步态包含丰富的生物特征和行为信息，但利用行走方式推断心理特征仍是一个具有挑战性且未被充分探索的问题

Method: 采用分层多阶段混合运动专家架构，将行走周期分为四个运动复杂度阶段，使用轻量级专家模型提取时空特征，并通过任务特定门控模块自适应加权专家

Result: 在涵盖17个心理特征的PsyMo基准测试中，该方法优于最先进的步态分析模型，在运行级别达到37.47%加权F1分数，在主题级别达到44.6%

Conclusion: 研究表明基于步态的多任务学习在心理特征估计方面具有可行性，为未来基于运动的心理推断研究奠定了基础

Abstract: Gait encodes rich biometric and behavioural information, yet leveraging the
manner of walking to infer psychological traits remains a challenging and
underexplored problem. We introduce a hierarchical Multi-Stage Mixture of
Movement Experts (MoME) architecture for multi-task prediction of psychological
attributes from gait sequences represented as 2D poses. MoME processes the
walking cycle in four stages of movement complexity, employing lightweight
expert models to extract spatio-temporal features and task-specific gating
modules to adaptively weight experts across traits and stages. Evaluated on the
PsyMo benchmark covering 17 psychological traits, our method outperforms
state-of-the-art gait analysis models, achieving a 37.47% weighted F1 score at
the run level and 44.6% at the subject level. Our experiments show that
integrating auxiliary tasks such as identity recognition, gender prediction,
and BMI estimation further improves psychological trait estimation. Our
findings demonstrate the viability of multi-task gait-based learning for
psychological trait estimation and provide a foundation for future research on
movement-informed psychological inference.

</details>


### [128] [ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement](https://arxiv.org/abs/2510.04668)
*Habin Lim,Yeongseob Won,Juwon Seo,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 提出了ConceptSplit框架来解决多概念个性化中的概念混合问题，包含ToVA训练方法和LODA推理优化


<details>
  <summary>Details</summary>
Motivation: 多概念个性化中多个学习概念在输出图像中相互干扰或混合的问题需要解决

Method: 包含Token-wise Value Adaptation (ToVA)训练方法和Latent Optimization for Disentangled Attention (LODA)推理优化

Result: 实现了稳健的多概念个性化，减轻了意外的概念干扰

Conclusion: ConceptSplit框架通过训练和推理阶段的创新方法有效解决了多概念混合问题

Abstract: In recent years, multi-concept personalization for text-to-image (T2I)
diffusion models to represent several subjects in an image has gained much more
attention. The main challenge of this task is "concept mixing", where multiple
learned concepts interfere or blend undesirably in the output image. To address
this issue, in this paper, we present ConceptSplit, a novel framework to split
the individual concepts through training and inference. Our framework comprises
two key components. First, we introduce Token-wise Value Adaptation (ToVA), a
merging-free training method that focuses exclusively on adapting the value
projection in cross-attention. Based on our empirical analysis, we found that
modifying the key projection, a common approach in existing methods, can
disrupt the attention mechanism and lead to concept mixing. Second, we propose
Latent Optimization for Disentangled Attention (LODA), which alleviates
attention entanglement during inference by optimizing the input latent. Through
extensive qualitative and quantitative experiments, we demonstrate that
ConceptSplit achieves robust multi-concept personalization, mitigating
unintended concept interference. Code is available at
https://github.com/KU-VGI/ConceptSplit

</details>


### [129] [Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI](https://arxiv.org/abs/2510.04705)
*Quang-Khai Bui-Tran,Minh-Toan Dinh,Thanh-Huy Nguyen,Ba-Thinh Lam,Mai-Anh Vu,Ulas Bagci*

Main category: cs.CV

TL;DR: 提出了一种标签高效的肝脏分割方法，通过基础模型微调、跨伪监督协同训练和标准化预处理，在多期相、多厂商MRI中实现跨模态泛化，无需空间配准。


<details>
  <summary>Details</summary>
Motivation: 多期相MRI中肝脏分割对肝纤维化评估至关重要，但标注数据稀缺且在不同成像模态和厂商系统中分布不均，存在空间错位和缺失期相等现实问题。

Method: 整合基础级3D分割骨干网络微调、跨伪监督协同训练利用未标注数据，以及标准化预处理流程，无需空间配准。

Result: 模型在标注和未标注域中均表现出稳健的分割性能，能够跨MRI期相和厂商进行泛化。

Conclusion: 该方法展示了标签高效基线的有效性，突出了基础模型适应与协同训练结合在真实临床成像任务中的潜力。

Abstract: Accurate liver segmentation in multi-phase MRI is vital for liver fibrosis
assessment, yet labeled data is often scarce and unevenly distributed across
imaging modalities and vendor systems. We propose a label-efficient
segmentation approach that promotes cross-modality generalization under
real-world conditions, where GED4 hepatobiliary-phase annotations are limited,
non-contrast sequences (T1WI, T2WI, DWI) are unlabeled, and spatial
misalignment and missing phases are common. Our method integrates a
foundation-scale 3D segmentation backbone adapted via fine-tuning, co-training
with cross pseudo supervision to leverage unlabeled volumes, and a standardized
preprocessing pipeline. Without requiring spatial registration, the model
learns to generalize across MRI phases and vendors, demonstrating robust
segmentation performance in both labeled and unlabeled domains. Our results
exhibit the effectiveness of our proposed label-efficient baseline for liver
segmentation in multi-phase, multi-vendor MRI and highlight the potential of
combining foundation model adaptation with co-training for real-world clinical
imaging tasks.

</details>


### [130] [ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion](https://arxiv.org/abs/2510.04706)
*Foivos Paraperas Papantoniou,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: 提出了一个基于扩散模型的框架，能够忠实重现有任何面部表情的任何对象，通过组合式设计实现身份一致性和精确的表情控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持面部身份一致性的同时难以实现精细的表情控制，需要开发能够同时满足这两个核心能力的人类中心生成模型。

Method: 基于身份一致的人脸基础模型，采用组合式设计，包含由FLAME blendshape参数引导的表情交叉注意力模块，并在包含丰富表情变化的图像和视频数据上训练。

Result: 模型能够超越基本情绪生成细微的微表情和表情转换，在定制化和身份一致的表情生成方面优于现有方法。

Conclusion: 该框架成功实现了身份一致性和精确表情控制的结合，为AI驱动的故事讲述提供了有效的解决方案。

Abstract: Human-centric generative models designed for AI-driven storytelling must
bring together two core capabilities: identity consistency and precise control
over human performance. While recent diffusion-based approaches have made
significant progress in maintaining facial identity, achieving fine-grained
expression control without compromising identity remains challenging. In this
work, we present a diffusion-based framework that faithfully reimagines any
subject under any particular facial expression. Building on an ID-consistent
face foundation model, we adopt a compositional design featuring an expression
cross-attention module guided by FLAME blendshape parameters for explicit
control. Trained on a diverse mixture of image and video data rich in
expressive variation, our adapter generalizes beyond basic emotions to subtle
micro-expressions and expressive transitions, overlooked by prior works. In
addition, a pluggable Reference Adapter enables expression editing in real
images by transferring the appearance from a reference frame during synthesis.
Extensive quantitative and qualitative evaluations show that our model
outperforms existing methods in tailored and identity-consistent expression
generation. Code and models can be found at
https://github.com/foivospar/Arc2Face.

</details>


### [131] [ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model](https://arxiv.org/abs/2510.04712)
*Luo Cheng,Song Siyang,Yan Siyuan,Yu Zhen,Ge Zongyuan*

Main category: cs.CV

TL;DR: ReactDiff是一个用于生成多样化面部反应的时间扩散框架，通过整合时空面部运动学约束来产生自然、连贯的人类面部反应。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以模拟真实人类面部反应的随机性和动态特性，无法生成多样化和类人的面部反应。

Method: 提出ReactDiff框架，在扩散过程中融入两个关键先验：时间面部行为运动学和面部动作单元依赖关系，以引导模型生成符合人类面部解剖约束的逼真反应。

Result: 在REACT2024数据集上的广泛实验表明，该方法在反应质量、多样性和反应适当性方面均达到最先进水平。

Conclusion: ReactDiff通过整合时空面部运动学约束，成功解决了生成多样化且类人面部反应的挑战，为人类-计算机交互系统提供了有效的解决方案。

Abstract: The automatic generation of diverse and human-like facial reactions in dyadic
dialogue remains a critical challenge for human-computer interaction systems.
Existing methods fail to model the stochasticity and dynamics inherent in real
human reactions. To address this, we propose ReactDiff, a novel temporal
diffusion framework for generating diverse facial reactions that are
appropriate for responding to any given dialogue context. Our key insight is
that plausible human reactions demonstrate smoothness, and coherence over time,
and conform to constraints imposed by human facial anatomy. To achieve this,
ReactDiff incorporates two vital priors (spatio-temporal facial kinematics)
into the diffusion process: i) temporal facial behavioral kinematics and ii)
facial action unit dependencies. These two constraints guide the model toward
realistic human reaction manifolds, avoiding visually unrealistic jitters,
unstable transitions, unnatural expressions, and other artifacts. Extensive
experiments on the REACT2024 dataset demonstrate that our approach not only
achieves state-of-the-art reaction quality but also excels in diversity and
reaction appropriateness.

</details>


### [132] [Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction](https://arxiv.org/abs/2510.04714)
*KunHo Heo,GiHyun Kim,SuYeon Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: 提出了一种改进的3D语义场景图预测方法，通过设计高区分度的物体特征编码器和对比预训练策略，显著提升了物体分类和关系预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D语义场景图预测中过度依赖图神经网络，但物体和关系特征的表示能力不足，限制了整体性能。研究发现物体特征质量对场景图精度至关重要。

Method: 设计了高区分度的物体特征编码器，采用对比预训练策略将物体表示学习与场景图预测解耦，并有效结合几何和语义特征进行关系预测。

Result: 在3DSSG数据集上的实验表明，该方法在所有评估指标上都显著优于现有最先进方法，将预训练编码器集成到现有框架中也能带来大幅性能提升。

Conclusion: 通过优化物体特征表示和解耦学习策略，该方法在3D语义场景图预测任务中取得了突破性进展，证明了物体特征质量对整体性能的关键影响。

Abstract: 3D Semantic Scene Graph Prediction aims to detect objects and their semantic
relationships in 3D scenes, and has emerged as a crucial technology for
robotics and AR/VR applications. While previous research has addressed dataset
limitations and explored various approaches including Open-Vocabulary settings,
they frequently fail to optimize the representational capacity of object and
relationship features, showing excessive reliance on Graph Neural Networks
despite insufficient discriminative capability. In this work, we demonstrate
through extensive analysis that the quality of object features plays a critical
role in determining overall scene graph accuracy. To address this challenge, we
design a highly discriminative object feature encoder and employ a contrastive
pretraining strategy that decouples object representation learning from the
scene graph prediction. This design not only enhances object classification
accuracy but also yields direct improvements in relationship prediction.
Notably, when plugging in our pretrained encoder into existing frameworks, we
observe substantial performance improvements across all evaluation metrics.
Additionally, whereas existing approaches have not fully exploited the
integration of relationship information, we effectively combine both geometric
and semantic features to achieve superior relationship prediction.
Comprehensive experiments on the 3DSSG dataset demonstrate that our approach
significantly outperforms previous state-of-the-art methods. Our code is
publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.

</details>


### [133] [Benchmark on Monocular Metric Depth Estimation in Wildlife Setting](https://arxiv.org/abs/2510.04723)
*Niccolò Niccoli,Lorenzo Seidenari,Ilaria Greco,Francesco Rovero*

Main category: cs.CV

TL;DR: 本文提出了首个野生动物监测条件下的单目度量深度估计基准，评估了四种先进MDE方法在相机陷阱图像上的性能，发现Depth Anything V2表现最佳，ZoeDepth在户外自然环境中性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 相机陷阱广泛用于野生动物监测，但从单目图像中提取准确距离测量仍然具有挑战性，因为缺乏深度信息。虽然单目深度估计方法已有显著进展，但它们在自然野生动物环境中的性能尚未得到系统评估。

Method: 在93张带有校准ChARUCO图案获取地面真实距离的相机陷阱图像上，评估了四种最先进的MDE方法（Depth Anything V2、ML Depth Pro、ZoeDepth和Metric3D）以及几何基线方法。

Result: Depth Anything V2实现了最佳整体性能，平均绝对误差为0.454m，相关性为0.962；而ZoeDepth在户外自然环境中表现出显著退化（MAE：3.087m）。基于中位数的深度提取在所有深度学习方法中始终优于基于均值的方法。

Conclusion: 该基准为野生动物应用建立了性能基线，并为在保护监测系统中实施深度估计提供了实用指导。Depth Anything V2在准确性和速度之间提供了最佳平衡。

Abstract: Camera traps are widely used for wildlife monitoring, but extracting accurate
distance measurements from monocular images remains challenging due to the lack
of depth information. While monocular depth estimation (MDE) methods have
advanced significantly, their performance in natural wildlife environments has
not been systematically evaluated. This work introduces the first benchmark for
monocular metric depth estimation in wildlife monitoring conditions. We
evaluate four state-of-the-art MDE methods (Depth Anything V2, ML Depth Pro,
ZoeDepth, and Metric3D) alongside a geometric baseline on 93 camera trap images
with ground truth distances obtained using calibrated ChARUCO patterns. Our
results demonstrate that Depth Anything V2 achieves the best overall
performance with a mean absolute error of 0.454m and correlation of 0.962,
while methods like ZoeDepth show significant degradation in outdoor natural
environments (MAE: 3.087m). We find that median-based depth extraction
consistently outperforms mean-based approaches across all deep learning
methods. Additionally, we analyze computational efficiency, with ZoeDepth being
fastest (0.17s per image) but least accurate, while Depth Anything V2 provides
an optimal balance of accuracy and speed (0.22s per image). This benchmark
establishes performance baselines for wildlife applications and provides
practical guidance for implementing depth estimation in conservation monitoring
systems.

</details>


### [134] [ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts](https://arxiv.org/abs/2510.04739)
*Mehdi Houshmand Sarkhoosh,Frøy Øye,Henrik Nestor Sørlie,Nam Hoang Vu,Dag Johansen,Cise Midoglu,Tomas Kupka,Pål Halvorsen*

Main category: cs.CV

TL;DR: ExposureEngine是一个端到端系统，通过预测定向边界框(OBB)来精确量化体育转播中的赞助商可见度，解决了传统水平边界框(HBB)在旋转或倾斜标志检测中的不准确问题。


<details>
  <summary>Details</summary>
Motivation: 传统赞助商可见度分析方法依赖手动、主观且不可扩展的方法，而现有自动化系统使用水平边界框在标志旋转或倾斜时会导致曝光指标不准确。

Method: 开发了包含1,103帧瑞典精英足球比赛图像的新数据集，标注了670个独特赞助商标志的OBB。系统预测定向边界框来精确拟合不同方向的标志，并集成语言驱动代理层支持自然语言查询。

Result: 模型在mAP@0.5上达到0.859，精度0.96，召回率0.87，在多样化转播条件下稳健地定位标志。系统计算精确的可见度指标如曝光时长和屏幕覆盖率。

Conclusion: ExposureEngine提供了一个全面的解决方案，用于体育媒体中可审计和可解释的赞助商测量，包括数据集和分析仪表板。

Abstract: Quantifying sponsor visibility in sports broadcasts is a critical marketing
task traditionally hindered by manual, subjective, and unscalable analysis
methods. While automated systems offer an alternative, their reliance on
axis-aligned Horizontal Bounding Box (HBB) leads to inaccurate exposuremetrics
when logos appear rotated or skewed due to dynamic camera angles and
perspective distortions. This paper introduces ExposureEngine, an end-to-end
system designed for accurate, rotation-aware sponsor visibility analytics in
sports broadcasts, demonstrated in a soccer case study. Our approach predicts
Oriented Bounding Box (OBB) to provide a geometrically precise fit to each logo
regardless of the orientation on-screen. To train and evaluate our detector, we
developed a new dataset comprising 1,103 frames from Swedish elite soccer,
featuring 670 unique sponsor logos annotated with OBBs. Our model achieves a
mean Average Precision (mAP@0.5) of 0.859, with a precision of 0.96 and recall
of 0.87, demonstrating robust performance in localizing logos under diverse
broadcast conditions. The system integrates these detections into an analytical
pipeline that calculates precise visibility metrics, such as exposure duration
and on-screen coverage. Furthermore, we incorporate a language-driven agentic
layer, enabling users to generate reports, summaries, and media content through
natural language queries. The complete system, including the dataset and the
analytics dashboard, provides a comprehensive solution for auditable and
interpretable sponsor measurement in sports media. An overview of the
ExposureEngine is available online: https://youtu.be/tRw6OBISuW4 .

</details>


### [135] [Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection](https://arxiv.org/abs/2510.04741)
*Alina Ciocarlan,Sylvie Le Hégarat-Mascle,Sidonie Lefebvre*

Main category: cs.CV

TL;DR: 提出AA-YOLO方法，在YOLO检测头中集成统计异常检测测试，将小目标视为背景中的异常模式，有效控制误报率，在红外小目标检测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测在国防应用中面临复杂背景和小目标尺寸的挑战，传统目标检测器会产生大量误报，需要更有效的解决方案。

Method: 在YOLO检测头中集成统计异常检测测试，将小目标视为背景中的异常模式，通过修改检测头实现方法。

Result: 在多个IRSTD基准测试中取得竞争性性能，在训练数据有限、噪声和域偏移场景下表现出显著鲁棒性，可应用于各种YOLO主干网络和实例分割YOLO。

Conclusion: AA-YOLO是一种通用且高效的解决方案，特别适合资源受限的实际部署场景，代码将公开发布。

Abstract: Infrared Small Target Detection (IRSTD) is a challenging task in defense
applications, where complex backgrounds and tiny target sizes often result in
numerous false alarms using conventional object detectors. To overcome this
limitation, we propose Anomaly-Aware YOLO (AA-YOLO), which integrates a
statistical anomaly detection test into its detection head. By treating small
targets as unexpected patterns against the background, AA-YOLO effectively
controls the false alarm rate. Our approach not only achieves competitive
performance on several IRSTD benchmarks, but also demonstrates remarkable
robustness in scenarios with limited training data, noise, and domain shifts.
Furthermore, since only the detection head is modified, our design is highly
generic and has been successfully applied across various YOLO backbones,
including lightweight models. It also provides promising results when
integrated into an instance segmentation YOLO. This versatility makes AA-YOLO
an attractive solution for real-world deployments where resources are
constrained. The code will be publicly released.

</details>


### [136] [Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics](https://arxiv.org/abs/2510.04753)
*Masoumeh Chapariniya,Teodora Vukovic,Sarah Ebling,Volker Dellwo*

Main category: cs.CV

TL;DR: 该论文研究了基于Transformer的架构在自然面对面对话场景中的人员识别性能，通过双流框架分别建模空间配置和时间运动模式，在CANDOR对话语料库上取得了98.03%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer架构在自然对话场景中的人员识别潜力，特别是在面对面交流这种具有丰富姿态和动态信息的场景下。

Method: 采用双流框架：空间Transformer处理133个COCO WholeBody关键点的空间配置，多尺度时间Transformer建模层次化运动模式；比较了预训练与从头训练、速度特征的使用等策略。

Result: 领域特定训练显著优于迁移学习；空间配置比时间动态更具判别性（空间Transformer 95.74%，多尺度时间Transformer 93.90%）；特征级融合达到98.03%准确率。

Conclusion: Transformer架构在自然交互中的人员识别具有巨大潜力，姿态和动态信息具有互补性，为未来多模态和跨文化研究提供了见解。

Abstract: This paper investigates the performance of transformer-based architectures
for person identification in natural, face-to-face conversation scenario. We
implement and evaluate a two-stream framework that separately models spatial
configurations and temporal motion patterns of 133 COCO WholeBody keypoints,
extracted from a subset of the CANDOR conversational corpus. Our experiments
compare pre-trained and from-scratch training, investigate the use of velocity
features, and introduce a multi-scale temporal transformer for hierarchical
motion modeling. Results demonstrate that domain-specific training
significantly outperforms transfer learning, and that spatial configurations
carry more discriminative information than temporal dynamics. The spatial
transformer achieves 95.74% accuracy, while the multi-scale temporal
transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%,
confirming that postural and dynamic information are complementary. These
findings highlight the potential of transformer architectures for person
identification in natural interactions and provide insights for future
multimodal and cross-cultural studies.

</details>


### [137] [Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction](https://arxiv.org/abs/2510.04759)
*Chi Yan,Dan Xu*

Main category: cs.CV

TL;DR: PG-Occ是一种渐进式高斯变换器框架，用于开放词汇的3D占用预测，通过渐进在线致密化和各向异性感知采样策略，在保持计算效率的同时提升对小物体的检测能力。


<details>
  <summary>Details</summary>
Motivation: 解决文本对齐场景建模中的权衡问题：稀疏高斯表示难以捕捉小物体，而密集表示计算开销大。

Method: 采用渐进在线致密化策略逐步增强3D高斯表示，结合各向异性感知采样和时空融合技术，自适应分配不同尺度和阶段的感受野。

Result: 在3D占用预测任务中实现了最先进的性能，相比之前最佳方法相对提升了14.3%的mIoU。

Conclusion: PG-Occ框架有效平衡了表示精度和计算效率，为开放词汇3D场景理解提供了新的解决方案。

Abstract: The 3D occupancy prediction task has witnessed remarkable progress in recent
years, playing a crucial role in vision-based autonomous driving systems. While
traditional methods are limited to fixed semantic categories, recent approaches
have moved towards predicting text-aligned features to enable open-vocabulary
text queries in real-world scenes. However, there exists a trade-off in
text-aligned scene modeling: sparse Gaussian representation struggles to
capture small objects in the scene, while dense representation incurs
significant computational overhead. To address these limitations, we present
PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables
open-vocabulary 3D occupancy prediction. Our framework employs progressive
online densification, a feed-forward strategy that gradually enhances the 3D
Gaussian representation to capture fine-grained scene details. By iteratively
enhancing the representation, the framework achieves increasingly precise and
detailed scene understanding. Another key contribution is the introduction of
an anisotropy-aware sampling strategy with spatio-temporal fusion, which
adaptively assigns receptive fields to Gaussians at different scales and
stages, enabling more effective feature aggregation and richer scene
information capture. Through extensive evaluations, we demonstrate that PG-Occ
achieves state-of-the-art performance with a relative 14.3% mIoU improvement
over the previous best performing method. Code and pretrained models will be
released upon publication on our project page:
https://yanchi-3dv.github.io/PG-Occ

</details>


### [138] [Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning](https://arxiv.org/abs/2510.04770)
*Xiaomeng Fan,Yuchuan Mao,Zhi Gao,Yuwei Wu,Jin Chen,Yunde Jia*

Main category: cs.CV

TL;DR: 提出了一种新的开放词汇学习方法，通过生成未见类别数据来估计开放环境中的分布，从而提高泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用已见类别数据估计开放环境分布，由于未见类别的缺失导致估计误差无法识别。直觉上，学习超越已见类别对于边界估计误差至关重要

Method: 提出类别-领域数据生成流程和分布对齐算法。数据生成流程在层次语义树和从已见数据推断的领域信息指导下生成未见类别数据；分布对齐算法估计并最大化后验概率

Result: 在11个数据集上的广泛实验表明，该方法比基线方法性能提升高达14%

Conclusion: 通过生成未见类别数据可以有效估计开放环境分布，理论证明估计误差有上界，实验验证了方法的有效性和优越性

Abstract: Open-vocabulary learning requires modeling the data distribution in open
environments, which consists of both seen-class and unseen-class data.
  Existing methods estimate the distribution in open environments using
seen-class data, where the absence of unseen classes makes the estimation error
inherently unidentifiable.
  Intuitively, learning beyond the seen classes is crucial for distribution
estimation to bound the estimation error.
  We theoretically demonstrate that the distribution can be effectively
estimated by generating unseen-class data, through which the estimation error
is upper-bounded.
  Building on this theoretical insight, we propose a novel open-vocabulary
learning method, which generates unseen-class data for estimating the
distribution in open environments. The method consists of a class-domain-wise
data generation pipeline and a distribution alignment algorithm. The data
generation pipeline generates unseen-class data under the guidance of a
hierarchical semantic tree and domain information inferred from the seen-class
data, facilitating accurate distribution estimation. With the generated data,
the distribution alignment algorithm estimates and maximizes the posterior
probability to enhance generalization in open-vocabulary learning. Extensive
experiments on $11$ datasets demonstrate that our method outperforms baseline
approaches by up to $14\%$, highlighting its effectiveness and superiority.

</details>


### [139] [Visual Representations inside the Language Model](https://arxiv.org/abs/2510.04819)
*Benlin Liu,Amita Kamath,Madeleine Grunde-McLaughlin,Winson Han,Ranjay Krishna*

Main category: cs.CV

TL;DR: 该论文研究了多模态语言模型(MLMs)在感知任务上表现不佳的原因，通过分析视觉键值令牌的信息流，发现视觉值令牌包含足够信息但语言模型未能充分利用，同时揭示了输入无关图像键令牌中的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 理解为什么多模态语言模型在感知密集型任务上表现不佳，通过分析视觉键值令牌的信息流来揭示模型内部工作机制。

Method: 研究流行MLMs（LLaVA-OneVision、Qwen2.5-VL、Llama-3-LLaVA-NeXT）如何处理视觉键值令牌，分析视觉信息在语言模型中的流动，包括零样本分割、语义对应、时序对应和引用表达检测等任务。

Result: 发现图像值令牌编码了足够的感知信息，但语言模型未能充分利用；视觉键令牌在后期层包含降低感知能力的伪影；添加文本前缀可以改善视觉表示；在33.3%的BLINK基准艺术风格问题中，语言模型中的感知信息未能输出。

Conclusion: 揭示了键值令牌在多模态系统中的关键作用，为MLMs的机制可解释性提供了新见解，并提出了改进视觉编码器和语言模型组件训练的新方向。

Abstract: Despite interpretability work analyzing VIT encoders and transformer
activations, we don't yet understand why Multimodal Language Models (MLMs)
struggle on perception-heavy tasks. We offer an under-studied perspective by
examining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and
Llama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the
flow of visual information through the language model, finding that image value
tokens encode sufficient information to perform several perception-heavy tasks
zero-shot: segmentation, semantic correspondence, temporal correspondence, and
referring expression detection. We find that while the language model does
augment the visual information received from the projection of input visual
encodings-which we reveal correlates with overall MLM perception capability-it
contains less visual information on several tasks than the equivalent visual
encoder (SigLIP) that has not undergone MLM finetuning. Further, we find that
the visual information corresponding to input-agnostic image key tokens in
later layers of language models contains artifacts which reduce perception
capability of the overall MLM. Next, we discuss controlling visual information
in the language model, showing that adding a text prefix to the image input
improves perception capabilities of visual representations. Finally, we reveal
that if language models were able to better control their visual information,
their perception would significantly improve; e.g., in 33.3% of Art Style
questions in the BLINK benchmark, perception information present in the
language model is not surfaced to the output! Our findings reveal insights into
the role of key-value tokens in multimodal systems, paving the way for deeper
mechanistic interpretability of MLMs and suggesting new directions for training
their visual encoder and language model components.

</details>


### [140] [Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge](https://arxiv.org/abs/2510.04772)
*Max Kirchner,Hanna Hoffmann,Alexander C. Jenke,Oliver L. Saldanha,Kevin Pfeiffer,Weam Kanjo,Julia Alekseenko,Claas de Boer,Santhi Raj Kolamuri,Lorenzo Mazza,Nicolas Padoy,Sophia Bano,Annika Reinke,Lena Maier-Hein,Danail Stoyanov,Jakob N. Kather,Fiona R. Kolbinger,Sebastian Bodenstedt,Stefanie Speidel*

Main category: cs.CV

TL;DR: FedSurg挑战赛评估了联邦学习在手术视频分类中的应用，重点关注模型在未见临床中心的泛化能力和本地微调适应性，使用Appendix300数据集进行炎症阶段分类。


<details>
  <summary>Details</summary>
Motivation: 建立手术视频分类中联邦学习的首个基准，评估现有方法在保护患者数据隐私的同时，如何实现跨临床中心的模型泛化和本地适应。

Method: 参与者使用基础模型线性探测、度量学习（三元组损失）和多种联邦聚合方案（FedAvg、FedMedian、FedSAM），通过F1分数和期望成本评估性能，并使用自助法和统计检验评估排名稳定性。

Result: 泛化任务中跨中心性能有限，适应任务中所有团队在微调后都有改善但排名稳定性低。ViViT模型表现最佳，揭示了泛化能力不足、类别不平衡敏感性和去中心化训练中超参数调优困难等问题。

Conclusion: 该挑战赛建立了手术视频分类中联邦学习的首个基准，强调了本地个性化与全局鲁棒性之间的权衡，以及架构选择、预处理和损失设计的重要性，为未来开发不平衡感知、自适应和鲁棒的临床手术AI方法提供了参考。

Abstract: Purpose: The FedSurg challenge was designed to benchmark the state of the art
in federated learning for surgical video classification. Its goal was to assess
how well current methods generalize to unseen clinical centers and adapt
through local fine-tuning while enabling collaborative model development
without sharing patient data. Methods: Participants developed strategies to
classify inflammation stages in appendicitis using a preliminary version of the
multi-center Appendix300 video dataset. The challenge evaluated two tasks:
generalization to an unseen center and center-specific adaptation after
fine-tuning. Submitted approaches included foundation models with linear
probing, metric learning with triplet loss, and various FL aggregation schemes
(FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and
Expected Cost, with ranking robustness evaluated via bootstrapping and
statistical testing. Results: In the generalization task, performance across
centers was limited. In the adaptation task, all teams improved after
fine-tuning, though ranking stability was low. The ViViT-based submission
achieved the strongest overall performance. The challenge highlighted
limitations in generalization, sensitivity to class imbalance, and difficulties
in hyperparameter tuning in decentralized training, while spatiotemporal
modeling and context-aware preprocessing emerged as promising strategies.
Conclusion: The FedSurg Challenge establishes the first benchmark for
evaluating FL strategies in surgical video classification. Findings highlight
the trade-off between local personalization and global robustness, and
underscore the importance of architecture choice, preprocessing, and loss
design. This benchmarking offers a reference point for future development of
imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.

</details>


### [141] [Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization](https://arxiv.org/abs/2510.04781)
*Javed Ahmad,Federico Dassiè,Selene Frascella,Gabriele Marchello,Ferdinando Cannella,Arianna Traviglia*

Main category: cs.CV

TL;DR: 提出了一种自动化双机器人3D扫描系统，通过协调机器人操作和高分辨率扫描，实现文化遗产文物的高质量数字化，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统3D扫描方法需要专业知识和手动操作来维持最佳扫描条件和覆盖范围，限制了文化遗产数字化的效率和可及性。

Method: 使用两个协调工作的机器人系统：一个配备扫描仪，另一个处理托盘。通过参数化扫描空间、优化轨迹规划和路径点分布，确保全面表面覆盖并最小化遮挡。

Result: 实验结果显示，该方法相比基线方法显著降低了Chamfer距离，提高了F-score，在几何精度和数字化效率方面表现优越。

Conclusion: 该系统能够提供卓越的几何精度、改进的数字化效率，并减少对专家操作人员的依赖，为文化遗产保护提供了有效的自动化解决方案。

Abstract: High-fidelity 3D scanning is essential for preserving cultural heritage
artefacts, supporting documentation, analysis, and long-term conservation.
However, conventional methods typically require specialized expertise and
manual intervention to maintain optimal scanning conditions and coverage. We
present an automated two-robot scanning system that eliminates the need for
handheld or semi-automatic workflows by combining coordinated robotic
manipulation with high-resolution 3D scanning. Our system parameterizes the
scanning space into distinct regions, enabling coordinated motion planning
between a scanner-equipped robot and a tray-handling robot. Optimized
trajectory planning and waypoint distribution ensure comprehensive surface
coverage, minimize occlusions, and balance reconstruction accuracy with system
efficiency. Experimental results show that our approach achieves significantly
lower Chamfer Distance and higher F-score compared to baseline methods,
offering superior geometric accuracy, improved digitization efficiency, and
reduced reliance on expert operators.

</details>


### [142] [A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation](https://arxiv.org/abs/2510.04794)
*Alon Kaya,Igal Bilik,Inna Stainvas*

Main category: cs.CV

TL;DR: 本文系统比较了ViT和CNN在几何估计任务中的表现，发现在大数据场景下ViT表现更优，而在小数据场景下CNN的归纳偏置使其性能与ViT相当，且ViT在跨域评估中表现出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究ViT和CNN作为骨干网络在几何估计任务（如图像刚性变换和基础矩阵估计）中的效率，特别是在低数据量场景下的表现。

Method: 系统比较了大规模CNN（ResNet、EfficientNet、CLIP-ResNet）与ViT基础模型（CLIP-ViT变体和DINO）在不同数据量设置下的表现，包括少样本场景。

Result: 在大数据场景下，ViT在微调时优于CNN；在小数据场景下，CNN的归纳偏置和较小容量使其性能与ViT相当；ViT在跨域评估中表现出更强的泛化能力。

Conclusion: 需要根据任务需求仔细选择模型架构进行微调，未来研究应关注平衡局部和全局表示的混合架构。

Abstract: Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs)
have reshaped computer vision through pretrained feature representations that
enable strong transfer learning for diverse tasks. However, their efficiency as
backbone architectures for geometric estimation tasks involving image
deformations in low-data regimes remains an open question. This work considers
two such tasks: 1) estimating 2D rigid transformations between pairs of images
and 2) predicting the fundamental matrix for stereo image pairs, an important
problem in various applications, such as autonomous mobility, robotics, and 3D
scene reconstruction. Addressing this intriguing question, this work
systematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet)
with ViT-based foundation models (CLIP-ViT variants and DINO) in various data
size settings, including few-shot scenarios. These pretrained models are
optimized for classification or contrastive learning, encouraging them to focus
mostly on high-level semantics. The considered tasks require balancing local
and global features differently, challenging the straightforward adoption of
these models as the backbone. Empirical comparative analysis shows that,
similar to training from scratch, ViTs outperform CNNs during refinement in
large downstream-data scenarios. However, in small data scenarios, the
inductive bias and smaller capacity of CNNs improve their performance, allowing
them to match that of a ViT. Moreover, ViTs exhibit stronger generalization in
cross-domain evaluation where the data distribution changes. These results
emphasize the importance of carefully selecting model architectures for
refinement, motivating future research towards hybrid architectures that
balance local and global representations.

</details>


### [143] [Paper2Video: Automatic Video Generation from Scientific Papers](https://arxiv.org/abs/2510.05096)
*Zeyu Zhu,Kevin Qinghong Lin,Mike Zheng Shou*

Main category: cs.CV

TL;DR: PaperTalker是一个多智能体框架，用于自动生成学术演示视频，解决了从研究论文创建多模态演示视频的挑战，包括幻灯片生成、字幕、语音合成和说话人头像渲染。


<details>
  <summary>Details</summary>
Motivation: 学术演示视频制作耗时耗力，需要协调幻灯片设计、录音和编辑等多个环节。现有方法难以处理研究论文中的密集多模态信息（文本、图表、表格）以及多个对齐通道（幻灯片、字幕、语音、说话人）的协调问题。

Method: 提出了PaperTalker多智能体框架，集成了幻灯片生成与新颖的树搜索视觉选择、光标定位、字幕生成、语音合成和说话人头像渲染，并通过并行化幻灯片生成提高效率。

Result: 在Paper2Video数据集上的实验表明，该方法生成的演示视频比现有基线更加忠实和内容丰富，为自动化学术视频生成迈出了实际一步。

Conclusion: PaperTalker是首个用于学术演示视频生成的多智能体框架，通过整合多种技术解决了该领域的独特挑战，为自动化学术传播提供了实用解决方案。

Abstract: Academic presentation videos have become an essential medium for research
communication, yet producing them remains highly labor-intensive, often
requiring hours of slide design, recording, and editing for a short 2 to 10
minutes video. Unlike natural video, presentation video generation involves
distinctive challenges: inputs from research papers, dense multi-modal
information (text, figures, tables), and the need to coordinate multiple
aligned channels such as slides, subtitles, speech, and human talker. To
address these challenges, we introduce PaperTalker, the first benchmark of 101
research papers paired with author-created presentation videos, slides, and
speaker metadata. We further design four tailored evaluation metrics--Meta
Similarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos
convey the paper's information to the audience. Building on this foundation, we
propose PaperTalker, the first multi-agent framework for academic presentation
video generation. It integrates slide generation with effective layout
refinement by a novel effective tree search visual choice, cursor grounding,
subtitling, speech synthesis, and talking-head rendering, while parallelizing
slide-wise generation for efficiency. Experiments on Paper2Video demonstrate
that the presentation videos produced by our approach are more faithful and
informative than existing baselines, establishing a practical step toward
automated and ready-to-use academic video generation. Our dataset, agent, and
code are available at https://github.com/showlab/Paper2Video.

</details>


### [144] [DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing](https://arxiv.org/abs/2510.04797)
*Qi Li,Shuwen Qiu,Julien Han,Xingzi Xu,Mehmet Saygin Seyfioglu,Kee Kiat Koo,Karim Bouyarmane*

Main category: cs.CV

TL;DR: DiT-VTON是一个基于扩散变换器的新型虚拟试穿框架，通过多种配置探索最佳图像条件设置，在扩展数据集上训练以增强鲁棒性，支持多种产品类别和图像编辑功能，在VITON-HD数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿模型在细节保留、真实图像鲁棒性、高效采样、图像编辑能力和跨类别泛化方面存在挑战，需要开发更强大的解决方案。

Method: 利用扩散变换器适应图像条件的虚拟试穿任务，探索多种配置（上下文标记连接、通道连接、ControlNet集成），在包含多样化背景和非服装类别的扩展数据集上训练。

Result: 在VITON-HD数据集上超越最先进方法，实现更好的细节保留和鲁棒性，无需额外条件编码器；在涵盖数千产品类别的多样化数据集上，在VTA和图像编辑能力方面表现优异。

Conclusion: DiT-VTON重新定义了虚拟试穿任务，提供通用的虚拟试穿解决方案，支持多种产品类别和高级图像编辑功能，展示了数据扩展对VTO适应性的益处。

Abstract: The rapid growth of e-commerce has intensified the demand for Virtual Try-On
(VTO) technologies, enabling customers to realistically visualize products
overlaid on their own images. Despite recent advances, existing VTO models face
challenges with fine-grained detail preservation, robustness to real-world
imagery, efficient sampling, image editing capabilities, and generalization
across diverse product categories. In this paper, we present DiT-VTON, a novel
VTO framework that leverages a Diffusion Transformer (DiT), renowned for its
performance on text-conditioned image generation, adapted here for the
image-conditioned VTO task. We systematically explore multiple DiT
configurations, including in-context token concatenation, channel
concatenation, and ControlNet integration, to determine the best setup for VTO
image conditioning.
  To enhance robustness, we train the model on an expanded dataset encompassing
varied backgrounds, unstructured references, and non-garment categories,
demonstrating the benefits of data scaling for VTO adaptability. DiT-VTON also
redefines the VTO task beyond garment try-on, offering a versatile Virtual
Try-All (VTA) solution capable of handling a wide range of product categories
and supporting advanced image editing functionalities such as pose
preservation, localized editing, texture transfer, and object-level
customization. Experimental results show that our model surpasses
state-of-the-art methods on VITON-HD, achieving superior detail preservation
and robustness without reliance on additional condition encoders. It also
outperforms models with VTA and image editing capabilities on a diverse dataset
spanning thousands of product categories.

</details>


### [145] [Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors](https://arxiv.org/abs/2510.04802)
*Han Zhang,Lalithkumar Seenivasan,Jose L. Porras,Roger D. Soberanis-Mukul,Hao Ding,Hongchao Shu,Benjamin D. Killeen,Ankita Ghosh,Lonny Yarmus,Masaru Ishii,Angela Christine Argento,Mathias Unberath*

Main category: cs.CV

TL;DR: EgoSurg框架首次实现了从固定摄像头视频重建手术室人员动态自我中心视角回放，无需干扰临床工作流程，为沉浸式外科数据科学奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统手术观察依赖固定视角或回忆，无法记录指导临床决策的自我中心视觉视角。固定摄像头视频只能捕捉房间尺度的工作流程，无法重建每个团队成员实际看到的内容。

Method: EgoSurg结合几何驱动神经渲染和基于扩散的视图增强技术，能够在任意时刻合成任意自我中心视角的高视觉保真度图像。

Result: 在多个手术案例和对照研究中，EgoSurg能够以高视觉质量和保真度重建人员特定的视觉场和任意视点。

Conclusion: 通过将现有手术室摄像头基础设施转化为可导航的动态3D记录，EgoSurg为沉浸式外科数据科学建立了新基础，使外科实践能够从各个角度可视化、体验和分析。

Abstract: Observing surgical practice has historically relied on fixed vantage points
or recollections, leaving the egocentric visual perspectives that guide
clinical decisions undocumented. Fixed-camera video can capture surgical
workflows at the room-scale, but cannot reconstruct what each team member
actually saw. Thus, these videos only provide limited insights into how
decisions that affect surgical safety, training, and workflow optimization are
made. Here we introduce EgoSurg, the first framework to reconstruct the
dynamic, egocentric replays for any operating room (OR) staff directly from
wall-mounted fixed-camera video, and thus, without intervention to clinical
workflow. EgoSurg couples geometry-driven neural rendering with diffusion-based
view enhancement, enabling high-visual fidelity synthesis of arbitrary and
egocentric viewpoints at any moment. In evaluation across multi-site surgical
cases and controlled studies, EgoSurg reconstructs person-specific visual
fields and arbitrary viewpoints with high visual quality and fidelity. By
transforming existing OR camera infrastructure into a navigable dynamic 3D
record, EgoSurg establishes a new foundation for immersive surgical data
science, enabling surgical practice to be visualized, experienced, and analyzed
from every angle.

</details>


### [146] [AvatarVTON: 4D Virtual Try-On for Animatable Avatars](https://arxiv.org/abs/2510.04822)
*Zicheng Jiang,Jixin Gao,Shengfeng He,Xinzhe Li,Yulong Zheng,Zhaotong Yang,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: AvatarVTON是首个4D虚拟试穿框架，能从单张服装图片生成逼真的试穿效果，支持自由姿态控制、新视角渲染和多样服装选择，无需多视角采集或物理先验。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法无法支持动态服装交互和单视角监督，需要多视角服装捕捉或物理先验，限制了实际应用。

Method: 包含两个核心模块：互易流校正器（无先验光流校正策略）确保时间一致性；非线性变形器将高斯图分解为视角姿态不变和特定分量，实现自适应非线性服装变形。

Result: 在扩展的4D虚拟试穿基准测试中，AvatarVTON实现了高保真度、多样性和动态服装真实感，优于现有基线方法。

Conclusion: 该框架在AR/VR、游戏和数字人应用中具有良好适用性，为4D虚拟试穿建立了新基准。

Abstract: We propose AvatarVTON, the first 4D virtual try-on framework that generates
realistic try-on results from a single in-shop garment image, enabling free
pose control, novel-view rendering, and diverse garment choices. Unlike
existing methods, AvatarVTON supports dynamic garment interactions under
single-view supervision, without relying on multi-view garment captures or
physics priors. The framework consists of two key modules: (1) a Reciprocal
Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes
avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer,
which decomposes Gaussian maps into view-pose-invariant and view-pose-specific
components, enabling adaptive, non-linear garment deformations. To establish a
benchmark for 4D virtual try-on, we extend existing baselines with unified
modules for fair qualitative and quantitative comparisons. Extensive
experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic
garment realism, making it well-suited for AR/VR, gaming, and digital-human
applications.

</details>


### [147] [Flow Matching for Conditional MRI-CT and CBCT-CT Image Synthesis](https://arxiv.org/abs/2510.04823)
*Arnela Hadzic,Simon Johannes Joham,Martin Urschler*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D流匹配的合成CT生成方法，可以从MRI或CBCT生成sCT，用于放疗应用。


<details>
  <summary>Details</summary>
Motivation: 通过MRI-only和CBCT-based自适应放疗，提高治疗精度同时减少患者辐射暴露。

Method: 采用全3D流匹配框架，将高斯噪声通过学习的流匹配速度场转换为sCT图像，使用轻量级3D编码器从输入MRI或CBCT中提取特征。

Result: 在SynthRAD2025挑战基准测试中，方法能准确重建全局解剖结构，但受限于训练分辨率，细部细节保留有限。

Conclusion: 未来将探索基于patch的训练和潜在空间流模型，以提高分辨率和局部结构保真度。

Abstract: Generating synthetic CT (sCT) from MRI or CBCT plays a crucial role in
enabling MRI-only and CBCT-based adaptive radiotherapy, improving treatment
precision while reducing patient radiation exposure. To address this task, we
adopt a fully 3D Flow Matching (FM) framework, motivated by recent work
demonstrating FM's efficiency in producing high-quality images. In our
approach, a Gaussian noise volume is transformed into an sCT image by
integrating a learned FM velocity field, conditioned on features extracted from
the input MRI or CBCT using a lightweight 3D encoder. We evaluated the method
on the SynthRAD2025 Challenge benchmark, training separate models for MRI
$\rightarrow$ sCT and CBCT $\rightarrow$ sCT across three anatomical regions:
abdomen, head and neck, and thorax. Validation and testing were performed
through the challenge submission system. The results indicate that the method
accurately reconstructs global anatomical structures; however, preservation of
fine details was limited, primarily due to the relatively low training
resolution imposed by memory and runtime constraints. Future work will explore
patch-based training and latent-space flow models to improve resolution and
local structural fidelity.

</details>


### [148] [Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation](https://arxiv.org/abs/2510.04838)
*Muquan Li,Hang Gou,Dongyang Zhang,Shuang Liang,Xiurui Xie,Deqiang Ouyang,Ke Qin*

Main category: cs.CV

TL;DR: 提出了AT-BPTT框架，通过动态调整截断位置和窗口大小来改进数据集蒸馏中的内循环优化，在多个数据集上实现了SOTA性能，同时显著提升了训练效率和内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法中的内循环优化通常依赖随机截断策略，缺乏灵活性且效果欠佳。研究发现神经网络在不同训练阶段具有不同的学习动态，使得随机截断效果不佳。

Method: AT-BPTT框架包含三个关键组件：(1)基于概率的阶段感知时间步选择机制；(2)基于梯度变化的自适应窗口大小策略；(3)低秩Hessian近似以减少计算开销。

Result: 在CIFAR-10、CIFAR-100、Tiny-ImageNet和ImageNet-1K上的实验表明，AT-BPTT平均准确率比基线方法提高6.16%，内循环优化速度提升3.9倍，内存成本节省63%。

Conclusion: AT-BPTT通过动态适应梯度行为，有效解决了数据集蒸馏中内循环优化的截断问题，在性能和效率方面均取得了显著提升。

Abstract: The growing demand for efficient deep learning has positioned dataset
distillation as a pivotal technique for compressing training dataset while
preserving model performance. However, existing inner-loop optimization methods
for dataset distillation typically rely on random truncation strategies, which
lack flexibility and often yield suboptimal results. In this work, we observe
that neural networks exhibit distinct learning dynamics across different
training stages-early, middle, and late-making random truncation ineffective.
To address this limitation, we propose Automatic Truncated Backpropagation
Through Time (AT-BPTT), a novel framework that dynamically adapts both
truncation positions and window sizes according to intrinsic gradient behavior.
AT-BPTT introduces three key components: (1) a probabilistic mechanism for
stage-aware timestep selection, (2) an adaptive window sizing strategy based on
gradient variation, and (3) a low-rank Hessian approximation to reduce
computational overhead. Extensive experiments on CIFAR-10, CIFAR-100,
Tiny-ImageNet, and ImageNet-1K show that AT-BPTT achieves state-of-the-art
performance, improving accuracy by an average of 6.16% over baseline methods.
Moreover, our approach accelerates inner-loop optimization by 3.9x while saving
63% memory cost.

</details>


### [149] [Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints](https://arxiv.org/abs/2510.04840)
*Viktor Kozák,Jan Chudoba,Libor Přeučil*

Main category: cs.CV

TL;DR: 提出了一种基于航空图像的光伏电站映射新方法，能够自动生成详细到单个光伏组件的电站模型，无需依赖第三方数据。


<details>
  <summary>Details</summary>
Motivation: 光伏电站的准确和最新模型对其优化运维至关重要，但此类模型通常不易获得。

Method: 利用电站结构布局，通过视觉分割识别光伏组件，推断结构信息，使用视觉关键点合并多图像检测结果，保持结构完整性。

Result: 在两个不同电站上进行了实验验证和评估，最终融合3D位置和语义结构，生成适用于电站维护的紧凑地理参考模型。

Conclusion: 该方法能够自动化光伏电站映射过程，提供详细的结构模型，为电站运维提供有效支持。

Abstract: An accurate and up-to-date model of a photovoltaic (PV) power plant is
essential for its optimal operation and maintenance. However, such a model may
not be easily available. This work introduces a novel approach for PV power
plant mapping based on aerial overview images. It enables the automation of the
mapping process while removing the reliance on third-party data. The presented
mapping method takes advantage of the structural layout of the power plants to
achieve detailed modeling down to the level of individual PV modules. The
approach relies on visual segmentation of PV modules in overview images and the
inference of structural information in each image, assigning modules to
individual benches, rows, and columns. We identify visual keypoints related to
the layout and use these to merge detections from multiple images while
maintaining their structural integrity. The presented method was experimentally
verified and evaluated on two different power plants. The final fusion of 3D
positions and semantic structures results in a compact georeferenced model
suitable for power plant maintenance.

</details>


### [150] [From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements](https://arxiv.org/abs/2510.04844)
*Cheyu Lin,Katherine A. Flanigan*

Main category: cs.CV

TL;DR: 提出了一种基于3D骨骼数据的运动识别框架，通过ST-GCN和CNN结合迁移学习来推断人类活动的交际功能，实现隐私保护下的人类心理状态建模。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖理论模型或问卷调查，存在范围有限、静态和劳动密集的问题，需要一种既能保护隐私又能捕捉人类心理状态的通用方法。

Method: 结合空间-时间图卷积网络(ST-GCN)和卷积神经网络(CNN)，利用迁移学习避免手动定义物理动作与心理类别之间的映射关系。

Result: 在DUET数据集上的结果表明，该方法能够实现可扩展、准确且以人为本的行为建模。

Conclusion: 为增强强化学习驱动的人类-环境交互模拟提供了新途径，能够保护用户匿名性同时揭示反映认知和情绪状态的潜在身体运动结构。

Abstract: Understanding the dynamic relationship between humans and the built
environment is a key challenge in disciplines ranging from environmental
psychology to reinforcement learning (RL). A central obstacle in modeling these
interactions is the inability to capture human psychological states in a way
that is both generalizable and privacy preserving. Traditional methods rely on
theoretical models or questionnaires, which are limited in scope, static, and
labor intensive. We present a kinesics recognition framework that infers the
communicative functions of human activity -- known as kinesics -- directly from
3D skeleton joint data. Combining a spatial-temporal graph convolutional
network (ST-GCN) with a convolutional neural network (CNN), the framework
leverages transfer learning to bypass the need for manually defined mappings
between physical actions and psychological categories. The approach preserves
user anonymity while uncovering latent structures in bodily movements that
reflect cognitive and emotional states. Our results on the Dyadic User
EngagemenT (DUET) dataset demonstrate that this method enables scalable,
accurate, and human-centered modeling of behavior, offering a new pathway for
enhancing RL-driven simulations of human-environment interaction.

</details>


### [151] [Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems](https://arxiv.org/abs/2510.04854)
*Cheyu Lin,John Martins,Katherine A. Flanigan,Ph. D*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度传感器的骨架交互识别方法，用于识别12种成对人际交互，解决了传统RGB摄像头带来的隐私问题，为理解人类交互的文化和情感层面提供基础。


<details>
  <summary>Details</summary>
Motivation: 传统网络物理系统主要关注经济目标如性能和安全，但忽视了社会效益。网络物理社会基础设施系统旨在通过将CPS与社会目标对齐来解决这一问题，需要理解人类交互及其社会效益。

Method: 比较了五种基于骨架的交互识别算法，使用深度传感器分析骨骼运动，在包含12种成对交互的数据集上进行测试，这些交互按沟通类型（如象征性动作和情感表达）分类。

Result: 研究结果表明，基于骨架的方法能够有效识别成对人际交互，同时保护隐私，为测量社会行为提供了可行方案。

Conclusion: 基于深度传感器的骨架交互识别是理解人类交互深层含义和相互响应的有效方法，为网络物理社会基础设施系统的发展奠定了基础，平衡了技术性能与社会隐私需求。

Abstract: Cyber-physical systems (CPS) integrate sensing, computing, and control to
improve infrastructure performance, focusing on economic goals like performance
and safety. However, they often neglect potential human-centered (or
''social'') benefits. Cyber-physical-social infrastructure systems (CPSIS) aim
to address this by aligning CPS with social objectives. This involves defining
social benefits, understanding human interactions with each other and
infrastructure, developing privacy-preserving measurement methods, modeling
these interactions for prediction, linking them to social benefits, and
actuating the physical environment to foster positive social outcomes. This
paper delves into recognizing dyadic human interactions using real-world data,
which is the backbone to measuring social behavior. This lays a foundation to
address the need to enhance understanding of the deeper meanings and mutual
responses inherent in human interactions. While RGB cameras are informative for
interaction recognition, privacy concerns arise. Depth sensors offer a
privacy-conscious alternative by analyzing skeletal movements. This study
compares five skeleton-based interaction recognition algorithms on a dataset of
12 dyadic interactions. Unlike single-person datasets, these interactions,
categorized into communication types like emblems and affect displays, offer
insights into the cultural and emotional aspects of human interactions.

</details>


### [152] [ERDE: Entropy-Regularized Distillation for Early-exit](https://arxiv.org/abs/2510.04856)
*Martial Guidez,Stefan Duffner,Yannick Alpou,Oscar Röth,Christophe Garcia*

Main category: cs.CV

TL;DR: 该论文提出了一种结合早期退出和知识蒸馏的神经网络压缩方法，通过引入新的基于熵的损失函数来优化学生模型训练，在保持分类性能的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然性能优越，但计算成本高，难以应用于实时和边缘场景。需要开发压缩技术来降低计算成本，同时动态架构能够在执行时调节压缩级别。

Method: 整合早期退出和知识蒸馏两种优化技术，用更复杂的教师早期退出模型训练简化的学生早期退出模型。提出新的基于熵的损失函数来处理教师分类错误的图像。

Result: 在CIFAR10、CIFAR100和SVHN图像分类数据集上的实验验证了该方法的有效性，在保持分类性能的同时显著降低了计算复杂度。

Conclusion: 该方法成功优化了准确性和效率之间的权衡，为知识蒸馏在其他场景中的应用开辟了新的研究视角。

Abstract: Although deep neural networks and in particular Convolutional Neural Networks
have demonstrated state-of-the-art performance in image classification with
relatively high efficiency, they still exhibit high computational costs, often
rendering them impractical for real-time and edge applications. Therefore, a
multitude of compression techniques have been developed to reduce these costs
while maintaining accuracy. In addition, dynamic architectures have been
introduced to modulate the level of compression at execution time, which is a
desirable property in many resource-limited application scenarios. The proposed
method effectively integrates two well-established optimization techniques:
early exits and knowledge distillation, where a reduced student early-exit
model is trained from a more complex teacher early-exit model. The primary
contribution of this research lies in the approach for training the student
early-exit model. In comparison to the conventional Knowledge Distillation
loss, our approach incorporates a new entropy-based loss for images where the
teacher's classification was incorrect. The proposed method optimizes the
trade-off between accuracy and efficiency, thereby achieving significant
reductions in computational complexity without compromising classification
performance. The validity of this approach is substantiated by experimental
results on image classification datasets CIFAR10, CIFAR100 and SVHN, which
further opens new research perspectives for Knowledge Distillation in other
contexts.

</details>


### [153] [μDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy](https://arxiv.org/abs/2510.04859)
*Elena Corbetta,Thomas Bocklitz*

Main category: cs.CV

TL;DR: μDeepIQA是一种基于深度学习的图像质量评估方法，专门针对光学显微镜图像，能够快速稳定地预测图像质量，并可视化单张图像中空间变化的质素。


<details>
  <summary>Details</summary>
Motivation: 传统图像质量评估方法在处理大规模数据集时计算成本高，且对超出理想域的图像不稳定，需要更高效、泛化性强的解决方案。

Method: 采用深度卷积神经网络，将自然图像IQA架构重新训练用于光学显微镜数据，预测个体质量指标和全局质量分数，并提供补丁级质量预测。

Result: μDeepIQA在光学显微镜图像上表现出稳定的性能，即使在异常值存在时也能保持稳定，能够评估小图像补丁，并提供快速预测。

Conclusion: 深度学习模型因其在异常值存在时的稳定性能、评估小图像补丁的能力和快速预测，使光学显微镜研究能够从中受益。

Abstract: Optical microscopy is one of the most widely used techniques in research
studies for life sciences and biomedicine. These applications require reliable
experimental pipelines to extract valuable knowledge from the measured samples
and must be supported by image quality assessment (IQA) to ensure correct
processing and analysis of the image data. IQA methods are implemented with
variable complexity. However, while most quality metrics have a straightforward
implementation, they might be time consuming and computationally expensive when
evaluating a large dataset. In addition, quality metrics are often designed for
well-defined image features and may be unstable for images out of the ideal
domain.
  To overcome these limitations, recent works have proposed deep learning-based
IQA methods, which can provide superior performance, increased generalizability
and fast prediction. Our method, named $\mathrm{\mu}$DeepIQA, is inspired by
previous studies and applies a deep convolutional neural network designed for
IQA on natural images to optical microscopy measurements. We retrained the same
architecture to predict individual quality metrics and global quality scores
for optical microscopy data. The resulting models provide fast and stable
predictions of image quality by generalizing quality estimation even outside
the ideal range of standard methods. In addition, $\mathrm{\mu}$DeepIQA
provides patch-wise prediction of image quality and can be used to visualize
spatially varying quality in a single image. Our study demonstrates that
optical microscopy-based studies can benefit from the generalizability of deep
learning models due to their stable performance in the presence of outliers,
the ability to assess small image patches, and rapid predictions.

</details>


### [154] [In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning](https://arxiv.org/abs/2510.04864)
*Ciem Cornelissen,Sander De Coninck,Axel Willekens,Sam Leroux,Pieter Simoens*

Main category: cs.CV

TL;DR: 开发了一个端到端的物联网机器人系统，用于葡萄园中葡萄产量和质量的非破坏性、实时、空间分辨映射。系统包含葡萄串检测与重量估计模型，以及基于光照不变光谱自编码器（LISA）的质量评估框架。


<details>
  <summary>Details</summary>
Motivation: 解决葡萄园精准农业中产量和质量实时监测的需求，特别是克服野外高光谱成像中由可变光照引起的"领域偏移"问题。

Method: 集成两个关键模块：高性能葡萄串检测与重量估计模型，以及基于LISA（光照不变光谱自编码器）的深度学习方法进行质量评估。LISA使用领域对抗框架从未校准数据中学习光照不变特征。

Result: 在三种不同光照条件下验证：实验室人工光照、早晨和下午自然阳光。系统实现葡萄串检测召回率0.82，重量预测R²为0.76，LISA模块相比基线将质量预测泛化能力提高20%以上。

Conclusion: 该系统成功生成了高分辨率、地理参考的葡萄产量和质量数据，为精准葡萄栽培提供了可操作的数据驱动洞察。

Abstract: This paper presents an end-to-end, IoT-enabled robotic system for the
non-destructive, real-time, and spatially-resolved mapping of grape yield and
quality (Brix, Acidity) in vineyards. The system features a comprehensive
analytical pipeline that integrates two key modules: a high-performance model
for grape bunch detection and weight estimation, and a novel deep learning
framework for quality assessment from hyperspectral (HSI) data. A critical
barrier to in-field HSI is the ``domain shift" caused by variable illumination.
To overcome this, our quality assessment is powered by the Light-Invariant
Spectral Autoencoder (LISA), a domain-adversarial framework that learns
illumination-invariant features from uncalibrated data. We validated the
system's robustness on a purpose-built HSI dataset spanning three distinct
illumination domains: controlled artificial lighting (lab), and variable
natural sunlight captured in the morning and afternoon. Results show the
complete pipeline achieves a recall (0.82) for bunch detection and a $R^2$
(0.76) for weight prediction, while the LISA module improves quality prediction
generalization by over 20% compared to the baselines. By combining these robust
modules, the system successfully generates high-resolution, georeferenced data
of both grape yield and quality, providing actionable, data-driven insights for
precision viticulture.

</details>


### [155] [BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping](https://arxiv.org/abs/2510.04876)
*Hayat Rajani,Valerio Franchi,Borja Martinez-Clavel Valles,Raimon Ramos,Rafael Garcia,Nuno Gracias*

Main category: cs.CV

TL;DR: 本文提出了一个全面的多模态海底栖息地测绘数据集，包含约100万个侧扫声纳瓦片、测深图和光学图像，其中36000个声纳瓦片已手动标注，旨在为机器学习模型开发提供标准化基准。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模标注数据集，限制了海底栖息地测绘领域机器学习模型的开发和基准测试，因此需要构建一个全面的多模态数据集来推动该领域研究。

Method: 收集加泰罗尼亚海岸的侧扫声纳瓦片、测深图和AUV采集的光学图像，手动标注36000个声纳瓦片，开发空间关联方法实现多传感器数据融合，并提供开源预处理和标注工具。

Result: 创建了包含约100万声纳瓦片的多模态数据集，其中36000个已标注，建立了光学图像与声纳瓦片的空间关联，支持监督学习和自监督跨模态表示学习。

Conclusion: 该资源为水下栖息地测绘建立了标准化基准，将促进自主海底分类和多传感器集成技术的进步。

Abstract: Benthic habitat mapping is fundamental for understanding marine ecosystems,
guiding conservation efforts, and supporting sustainable resource management.
Yet, the scarcity of large, annotated datasets limits the development and
benchmarking of machine learning models in this domain. This paper introduces a
thorough multi-modal dataset, comprising about a million side-scan sonar (SSS)
tiles collected along the coast of Catalonia (Spain), complemented by
bathymetric maps and a set of co-registered optical images from targeted
surveys using an autonomous underwater vehicle (AUV). Approximately \num{36000}
of the SSS tiles have been manually annotated with segmentation masks to enable
supervised fine-tuning of classification models. All the raw sensor data,
together with mosaics, are also released to support further exploration and
algorithm development. To address challenges in multi-sensor data fusion for
AUVs, we spatially associate optical images with corresponding SSS tiles,
facilitating self-supervised, cross-modal representation learning. Accompanying
open-source preprocessing and annotation tools are provided to enhance
accessibility and encourage research. This resource aims to establish a
standardized benchmark for underwater habitat mapping, promoting advancements
in autonomous seafloor classification and multi-sensor integration.

</details>


### [156] [Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for Motorbike Detection in Kigali Autonomous Driving Context](https://arxiv.org/abs/2510.04912)
*Ngeyen Yinkfu,Sunday Nwovu,Jonathan Kayizzi,Angelique Uwamahoro*

Main category: cs.CV

TL;DR: 该研究比较了YOLOv5、Faster R-CNN、SSD和RetinaNet四种目标检测模型在卢旺达基加利摩托车检测中的性能，旨在为资源受限环境下的自动驾驶系统提供实时导航解决方案。


<details>
  <summary>Details</summary>
Motivation: 基加利的摩托车出租车是主要交通工具，但经常不遵守交通规则且行驶难以预测，这给自动驾驶系统带来了重大挑战，需要在资源受限环境中开发有效的检测方案。

Method: 使用在基加利收集的198张图像的自定义数据集，在PyTorch框架下通过迁移学习实现并比较了四种目标检测模型（YOLOv5、Faster R-CNN、SSD、RetinaNet）。

Result: 评估了模型的准确性、定位能力和推理速度，以确定它们在实时导航中的适用性，并识别了数据集限制和模型复杂性等实施挑战。

Conclusion: 建议未来工作采用简化架构，以提高像卢旺达这样的发展中国家自动驾驶系统的可访问性。

Abstract: In Kigali, Rwanda, motorcycle taxis are a primary mode of transportation,
often navigating unpredictably and disregarding traffic rules, posing
significant challenges for autonomous driving systems. This study compares four
object detection models--YOLOv5, Faster R-CNN, SSD, and RetinaNet--for
motorbike detection using a custom dataset of 198 images collected in Kigali.
Implemented in PyTorch with transfer learning, the models were evaluated for
accuracy, localization, and inference speed to assess their suitability for
real-time navigation in resource-constrained settings. We identify
implementation challenges, including dataset limitations and model
complexities, and recommend simplified architectures for future work to enhance
accessibility for autonomous systems in developing countries like Rwanda.

</details>


### [157] [A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images](https://arxiv.org/abs/2510.04916)
*Giulio Weikmann,Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 提出了一种语义感知层次共识（SAHC）方法，通过集成特定层次分类头来学习遥感图像分类中的层次特征和关系，使用可训练的层次矩阵和层次共识机制确保不同层次概率分布的一致性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感图像分类中很重要，但预定义的标签层次结构经常被忽略，大多数方法只关注细粒度分类方案。

Method: 在深度网络架构中集成特定层次分类头，使用可训练的层次矩阵以自监督方式学习层次结构，并引入层次共识机制确保不同层次概率分布的一致性。

Result: 在三个具有不同层次复杂度的基准数据集上评估，使用不同骨干架构，实验结果显示该方法在指导网络学习和层次共识鲁棒性方面有效。

Conclusion: SAHC方法能够有效利用层次分类任务的固有结构，在遥感图像分类任务中表现出良好的适应性和鲁棒性。

Abstract: Deep learning has become increasingly important in remote sensing image
classification due to its ability to extract semantic information from complex
data. Classification tasks often include predefined label hierarchies that
represent the semantic relationships among classes. However, these hierarchies
are frequently overlooked, and most approaches focus only on fine-grained
classification schemes. In this paper, we present a novel Semantics-Aware
Hierarchical Consensus (SAHC) method for learning hierarchical features and
relationships by integrating hierarchy-specific classification heads within a
deep network architecture, each specialized in different degrees of class
granularity. The proposed approach employs trainable hierarchy matrices, which
guide the network through the learning of the hierarchical structure in a
self-supervised manner. Furthermore, we introduce a hierarchical consensus
mechanism to ensure consistent probability distributions across different
hierarchical levels. This mechanism acts as a weighted ensemble being able to
effectively leverage the inherent structure of the hierarchical classification
task. The proposed SAHC method is evaluated on three benchmark datasets with
different degrees of hierarchical complexity on different tasks, using distinct
backbone architectures to effectively emphasize its adaptability. Experimental
results show both the effectiveness of the proposed approach in guiding network
learning and the robustness of the hierarchical consensus for remote sensing
image classification tasks.

</details>


### [158] [REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis](https://arxiv.org/abs/2510.04923)
*Alec K. Peltekian,Halil Ertugrul Aktas,Gorkem Durak,Kevin Grudzinski,Bradford C. Bemiss,Carrie Richardson,Jane E. Dematte,G. R. Scott Budinger,Anthony J. Esposito,Alexander Misharin,Alok Choudhary,Ankit Agrawal,Ulas Bagci*

Main category: cs.CV

TL;DR: 提出了首个针对医学图像分类的解剖学指导的混合专家框架REN，通过训练7个专门针对不同肺叶的专家网络，结合多模态门控机制，在间质性肺病分类中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统MoE系统缺乏医学影像所需的解剖学约束，而肺部解剖结构和区域疾病异质性对病理模式有重要影响，需要专门针对医学影像的解剖学指导框架。

Method: 利用解剖学先验训练7个专门针对不同肺叶和双侧肺组合的专家网络；采用多模态门控机制动态整合放射组学生物标志物和深度学习特征来优化专家贡献权重。

Result: REN在ILD分类中表现优异：放射组学引导的集成模型平均AUC达0.8646±0.0467，比SwinUNETR基线提升12.5%；下叶模型AUC达0.88-0.90，优于深度学习对应模型。

Conclusion: REN展示了强大的泛化能力和临床可解释性，提供了一个可扩展的解剖学指导方法，可轻松扩展到其他结构化医学影像应用。

Abstract: Mixture-of-Experts (MoE) architectures have significantly contributed to
scalable machine learning by enabling specialized subnetworks to tackle complex
tasks efficiently. However, traditional MoE systems lack domain-specific
constraints essential for medical imaging, where anatomical structure and
regional disease heterogeneity strongly influence pathological patterns. Here,
we introduce Regional Expert Networks (REN), the first anatomically-informed
MoE framework tailored specifically for medical image classification. REN
leverages anatomical priors to train seven specialized experts, each dedicated
to distinct lung lobes and bilateral lung combinations, enabling precise
modeling of region-specific pathological variations. Multi-modal gating
mechanisms dynamically integrate radiomics biomarkers and deep learning (DL)
features (CNN, ViT, Mamba) to weight expert contributions optimally. Applied to
interstitial lung disease (ILD) classification, REN achieves consistently
superior performance: the radiomics-guided ensemble reached an average AUC of
0.8646 +/- 0.0467, a +12.5 percent improvement over the SwinUNETR baseline (AUC
0.7685, p = 0.031). Region-specific experts further revealed that lower-lobe
models achieved AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79)
and aligning with known disease progression patterns. Through rigorous
patient-level cross-validation, REN demonstrates strong generalizability and
clinical interpretability, presenting a scalable, anatomically-guided approach
readily extensible to other structured medical imaging applications.

</details>


### [159] [Unsupervised Active Learning via Natural Feature Progressive Framework](https://arxiv.org/abs/2510.04939)
*Yuxi Liu,Catherine Lalman,Yimin Yang*

Main category: cs.CV

TL;DR: 提出NFPF框架，通过特定特征学习机量化样本对模型性能的贡献，在无监督主动学习中达到与监督方法相当的性能


<details>
  <summary>Details</summary>
Motivation: 传统主动学习需要大量人工标注，而无监督主动学习方法性能不佳，主要问题在于基于梯度的样本重要性估计方法对噪声敏感且无法充分代表数据分布

Method: 使用特定特征学习机(SFLM)量化样本重要性，定义重构差异指标进行初始样本选择，构建自然特征渐进框架

Result: NFPF显著优于现有无监督主动学习方法，在视觉数据集上达到与监督主动学习方法相当的性能

Conclusion: NFPF通过改进样本重要性度量方法，在减少人工标注负担的同时保持了高性能，增强了鲁棒性和数据分布覆盖能力

Abstract: The effectiveness of modern deep learning models is predicated on the
availability of large-scale, human-annotated datasets, a process that is
notoriously expensive and time-consuming. While Active Learning (AL) offers a
strategic solution by labeling only the most informative and representative
data, its iterative nature still necessitates significant human involvement.
Unsupervised Active Learning (UAL) presents an alternative by shifting the
annotation burden to a single, post-selection step. Unfortunately, prevailing
UAL methods struggle to achieve state-of-the-art performance. These approaches
typically rely on local, gradient-based scoring for sample importance
estimation, which not only makes them vulnerable to ambiguous and noisy data
but also hinders their capacity to select samples that adequately represent the
full data distribution. Moreover, their use of shallow, one-shot linear
selection falls short of a true UAL paradigm. In this paper, we propose the
Natural Feature Progressive Framework (NFPF), a UAL method that revolutionizes
how sample importance is measured. At its core, NFPF employs a Specific Feature
Learning Machine (SFLM) to effectively quantify each sample's contribution to
model performance. We further utilize the SFLM to define a powerful
Reconstruction Difference metric for initial sample selection. Our
comprehensive experiments show that NFPF significantly outperforms all
established UAL methods and achieves performance on par with supervised AL
methods on vision datasets. Detailed ablation studies and qualitative
visualizations provide compelling evidence for NFPF's superior performance,
enhanced robustness, and improved data distribution coverage.

</details>


### [160] [Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion](https://arxiv.org/abs/2510.04947)
*Xin Li,Kaixiang Yang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: CA3D-Diff是一个基于条件扩散模型的双向乳腺X光片视图转换框架，通过列感知交叉注意力和隐式3D结构重建来解决乳腺图像视图转换中的结构不对齐问题。


<details>
  <summary>Details</summary>
Motivation: 在真实临床工作流中，乳腺X光片的CC和MLO视图可能因采集错误或压缩伪影而缺失、损坏或降质，这会限制下游分析的有效性。视图间转换可以帮助恢复缺失视图并改善病变对齐。

Method: 提出列感知交叉注意力机制，利用解剖对应区域在跨视图中倾向于位于相似列位置的几何特性；引入隐式3D结构重建模块，将噪声2D潜在特征反投影到基于乳腺视图投影几何的粗糙3D特征体积中。

Result: CA3D-Diff在双向任务中实现了卓越性能，在视觉保真度和结构一致性方面优于最先进方法。合成的视图有效改善了筛查设置中的单视图恶性分类。

Conclusion: 该方法在真实世界诊断中具有实用价值，能够通过视图转换提升乳腺X光片分析的准确性和可靠性。

Abstract: Dual-view mammography, including craniocaudal (CC) and mediolateral oblique
(MLO) projections, offers complementary anatomical views crucial for breast
cancer diagnosis. However, in real-world clinical workflows, one view may be
missing, corrupted, or degraded due to acquisition errors or compression
artifacts, limiting the effectiveness of downstream analysis. View-to-view
translation can help recover missing views and improve lesion alignment. Unlike
natural images, this task in mammography is highly challenging due to large
non-rigid deformations and severe tissue overlap in X-ray projections, which
obscure pixel-level correspondences. In this paper, we propose Column-Aware and
Implicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram view
translation framework based on conditional diffusion model. To address
cross-view structural misalignment, we first design a column-aware
cross-attention mechanism that leverages the geometric property that
anatomically corresponding regions tend to lie in similar column positions
across views. A Gaussian-decayed bias is applied to emphasize local column-wise
correlations while suppressing distant mismatches. Furthermore, we introduce an
implicit 3D structure reconstruction module that back-projects noisy 2D latents
into a coarse 3D feature volume based on breast-view projection geometry. The
reconstructed 3D structure is refined and injected into the denoising UNet to
guide cross-view generation with enhanced anatomical awareness. Extensive
experiments demonstrate that CA3D-Diff achieves superior performance in
bidirectional tasks, outperforming state-of-the-art methods in visual fidelity
and structural consistency. Furthermore, the synthesized views effectively
improve single-view malignancy classification in screening settings,
demonstrating the practical value of our method in real-world diagnostics.

</details>


### [161] [SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization](https://arxiv.org/abs/2510.04961)
*Théophane Vallaeys,Jakob Verbeek,Matthieu Cord*

Main category: cs.CV

TL;DR: SSDD是一种新的像素扩散解码器架构，通过蒸馏技术实现单步重建，无需对抗性损失，在重建质量和采样速度上都优于KL-VAE。


<details>
  <summary>Details</summary>
Motivation: 当前基于KL-VAE的tokenizer需要对抗性损失，而扩散解码器虽然更原理化但需要迭代采样，训练不稳定且速度慢。

Method: 提出新的像素扩散解码器架构，利用transformer组件和无GAN训练提高扩展性和稳定性，通过蒸馏技术将扩散解码器性能复制到高效的单步解码器中。

Result: SSDD将重建FID从0.87提升到0.50，吞吐量提高1.4倍，在DiTs中采样速度提高3.8倍且保持生成质量。

Conclusion: SSDD可作为KL-VAE的直接替代品，用于构建更高质量和更快的生成模型。

Abstract: Tokenizers are a key component of state-of-the-art generative image models,
extracting the most important features from the signal while reducing data
dimension and redundancy. Most current tokenizers are based on KL-regularized
variational autoencoders (KL-VAE), trained with reconstruction, perceptual and
adversarial losses. Diffusion decoders have been proposed as a more principled
alternative to model the distribution over images conditioned on the latent.
However, matching the performance of KL-VAE still requires adversarial losses,
as well as a higher decoding time due to iterative sampling. To address these
limitations, we introduce a new pixel diffusion decoder architecture for
improved scaling and training stability, benefiting from transformer components
and GAN-free training. We use distillation to replicate the performance of the
diffusion decoder in an efficient single-step decoder. This makes SSDD the
first diffusion decoder optimized for single-step reconstruction trained
without adversarial losses, reaching higher reconstruction quality and faster
sampling than KL-VAE. In particular, SSDD improves reconstruction FID from
$0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generation
quality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used as
a drop-in replacement for KL-VAE, and for building higher-quality and faster
generative models.

</details>


### [162] [ActiveMark: on watermarking of visual foundation models via massive activations](https://arxiv.org/abs/2510.04966)
*Anna Chistyakova,Mikhail Pautov*

Main category: cs.CV

TL;DR: 提出了一种视觉基础模型的所有权验证方法，通过在VFM的表达层和编码器-解码器网络中嵌入数字水印，即使模型被微调后水印仍可检测。


<details>
  <summary>Details</summary>
Motivation: 保护视觉基础模型的知识产权，防止未经授权的模型再分发，需要开发可靠的所有权验证工具来区分受保护模型的副本和独立模型。

Method: 微调VFM的一小部分表达层，结合小型编码器-解码器网络，在输入图像的内部表示中嵌入数字水印。

Result: 理论分析和实验证明，该方法在非水印模型的误检概率和水印模型的漏检概率方面都表现较低。

Conclusion: 该方法为视觉基础模型提供了有效的所有权验证解决方案，即使在模型被下游任务微调后，嵌入的水印仍能保持可检测性。

Abstract: Being trained on large and vast datasets, visual foundation models (VFMs) can
be fine-tuned for diverse downstream tasks, achieving remarkable performance
and efficiency in various computer vision applications. The high computation
cost of data collection and training motivates the owners of some VFMs to
distribute them alongside the license to protect their intellectual property
rights. However, a dishonest user of the protected model's copy may illegally
redistribute it, for example, to make a profit. As a consequence, the
development of reliable ownership verification tools is of great importance
today, since such methods can be used to differentiate between a redistributed
copy of the protected model and an independent model. In this paper, we propose
an approach to ownership verification of visual foundation models by
fine-tuning a small set of expressive layers of a VFM along with a small
encoder-decoder network to embed digital watermarks into an internal
representation of a hold-out set of input images. Importantly, the watermarks
embedded remain detectable in the functional copies of the protected model,
obtained, for example, by fine-tuning the VFM for a particular downstream task.
Theoretically and experimentally, we demonstrate that the proposed method
yields a low probability of false detection of a non-watermarked model and a
low probability of false misdetection of a watermarked model.

</details>


### [163] [Latent Uncertainty Representations for Video-based Driver Action and Intention Recognition](https://arxiv.org/abs/2510.05006)
*Koen Vellenga,H. Joe Steinhauer,Jonas Andersson,Anders Sjögren*

Main category: cs.CV

TL;DR: 提出了一种新的潜在不确定性表示方法LUR和RLUR，用于深度神经网络的不确定性估计和分布外检测，在视频驾驶行为识别任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在安全关键任务中需要可靠的不确定性估计，现有最后一层概率深度学习方法性能不稳定，需要更有效的替代方案。

Method: 通过在预训练DNN中添加变换层生成多个潜在表示来估计不确定性，提出了LUR和RLUR方法。

Result: LUR和RLUR在分布内分类性能与其他方法相当，在不确定性分布外检测方面与最佳方法相当，但训练更高效且调参更容易。

Conclusion: LUR方法在保持性能的同时提供了更简单高效的训练和调参过程，是现有概率深度学习方法的有力替代方案。

Abstract: Deep neural networks (DNNs) are increasingly applied to safety-critical tasks
in resource-constrained environments, such as video-based driver action and
intention recognition. While last layer probabilistic deep learning (LL-PDL)
methods can detect out-of-distribution (OOD) instances, their performance
varies. As an alternative to last layer approaches, we propose extending
pre-trained DNNs with transformation layers to produce multiple latent
representations to estimate the uncertainty. We evaluate our latent uncertainty
representation (LUR) and repulsively trained LUR (RLUR) approaches against
eight PDL methods across four video-based driver action and intention
recognition datasets, comparing classification performance, calibration, and
uncertainty-based OOD detection. We also contribute 28,000 frame-level action
labels and 1,194 video-level intention labels for the NuScenes dataset. Our
results show that LUR and RLUR achieve comparable in-distribution
classification performance to other LL-PDL approaches. For uncertainty-based
OOD detection, LUR matches top-performing PDL methods while being more
efficient to train and easier to tune than approaches that require Markov-Chain
Monte Carlo sampling or repulsive training procedures.

</details>


### [164] [Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns](https://arxiv.org/abs/2510.05015)
*Nabil Daiyan,Md Rakibul Haque*

Main category: cs.CV

TL;DR: 使用手绘螺旋和波浪图像的机器学习方法检测帕金森病，通过CNN、迁移学习和注意力机制实现高精度诊断


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期诊断对预防不良影响至关重要，但传统诊断方法繁琐且昂贵，需要开发非侵入性、成本效益高的解决方案

Method: 采用卷积神经网络、迁移学习和注意力机制，通过数据增强增加图像多样性，构建包含预训练CNN、自定义卷积层和集成投票的三阶段架构

Result: 螺旋图像精确率、召回率和F1分数达90%，波浪图像达96.67%，集成硬投票后整体准确率为93.3%

Conclusion: 机器学习在帕金森病早期诊断中具有巨大潜力，可提供非侵入性且成本效益高的解决方案以改善患者预后

Abstract: Parkinson's disease (PD) is a progressive neurodegenerative condition
characterized by the death of dopaminergic neurons, leading to various movement
disorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects,
yet traditional diagnostic methods are often cumbersome and costly. In this
study, a machine learning-based approach is proposed using hand-drawn spiral
and wave images as potential biomarkers for PD detection. Our methodology
leverages convolutional neural networks (CNNs), transfer learning, and
attention mechanisms to improve model performance and resilience against
overfitting. To enhance the diversity and richness of both spiral and wave
categories, the training dataset undergoes augmentation to increase the number
of images. The proposed architecture comprises three phases: utilizing
pre-trained CNNs, incorporating custom convolutional layers, and ensemble
voting. Employing hard voting further enhances performance by aggregating
predictions from multiple models. Experimental results show promising accuracy
rates. For spiral images, weighted average precision, recall, and F1-score are
90%, and for wave images, they are 96.67%. After combining the predictions
through ensemble hard voting, the overall accuracy is 93.3%. These findings
underscore the potential of machine learning in early PD diagnosis, offering a
non-invasive and cost-effective solution to improve patient outcomes.

</details>


### [165] [Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models](https://arxiv.org/abs/2510.05034)
*Yunlong Tang,Jing Bi,Pinxin Liu,Zhenyu Pan,Zhangyun Tan,Qianxiang Shen,Jiani Liu,Hang Hua,Junjia Guo,Yunzhong Xiao,Chao Huang,Zhiyuan Wang,Susan Liang,Xinyi Liu,Yizhi Song,Yuhe Nie,Jia-Xing Zhong,Bozheng Li,Daiqing Qi,Ziyun Zeng,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Daiki Shimada,Han Liu,Jiebo Luo,Chenliang Xu*

Main category: cs.CV

TL;DR: 这篇论文首次全面调查了视频大型多模态模型（Video-LMMs）的后训练方法，包括监督微调、强化学习和测试时扩展三大支柱技术，旨在提升模型从基本感知系统向复杂推理引擎的转变能力。


<details>
  <summary>Details</summary>
Motivation: 视频理解是计算机视觉中最具挑战性的前沿领域，需要模型处理复杂的时空关系、长期依赖和多模态证据。虽然Video-LMMs在视频理解任务中展现出卓越能力，但其后训练阶段的研究仍分散在文献中，缺乏系统性整合。

Method: 提出了结构化分类法，涵盖三大后训练方法：带思维链的监督微调（SFT）、基于可验证目标的强化学习（RL）以及通过增强推理计算的测试时扩展（TTS）。这些方法专门针对视频特有的挑战进行适配。

Result: 通过系统分析代表性方法，综合了关键设计原则、见解和评估协议，同时识别了奖励设计、可扩展性和成本性能优化等关键开放挑战，并策划了必要的基准、数据集和指标。

Conclusion: 本调查为研究人员和从业者提供了一个统一框架，用于推进Video-LMMs的能力发展，旨在促进视频理解领域的系统性进展。

Abstract: Video understanding represents the most challenging frontier in computer
vision, requiring models to reason about complex spatiotemporal relationships,
long-term dependencies, and multimodal evidence. The recent emergence of
Video-Large Multimodal Models (Video-LMMs), which integrate visual encoders
with powerful decoder-based language models, has demonstrated remarkable
capabilities in video understanding tasks. However, the critical phase that
transforms these models from basic perception systems into sophisticated
reasoning engines, post-training, remains fragmented across the literature.
This survey provides the first comprehensive examination of post-training
methodologies for Video-LMMs, encompassing three fundamental pillars:
supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)
from verifiable objectives, and test-time scaling (TTS) through enhanced
inference computation. We present a structured taxonomy that clarifies the
roles, interconnections, and video-specific adaptations of these techniques,
addressing unique challenges such as temporal localization, spatiotemporal
grounding, long video efficiency, and multimodal evidence integration. Through
systematic analysis of representative methods, we synthesize key design
principles, insights, and evaluation protocols while identifying critical open
challenges in reward design, scalability, and cost-performance optimization. We
further curate essential benchmarks, datasets, and metrics to facilitate
rigorous assessment of post-training effectiveness. This survey aims to provide
researchers and practitioners with a unified framework for advancing Video-LMM
capabilities. Additional resources and updates are maintained at:
https://github.com/yunlong10/Awesome-Video-LMM-Post-Training

</details>


### [166] [SegMASt3R: Geometry Grounded Segment Matching](https://arxiv.org/abs/2510.05051)
*Rohit Jayanti,Swayam Agrawal,Vansh Garg,Siddharth Tourani,Muhammad Haris Khan,Sourav Garg,Madhava Krishna*

Main category: cs.CV

TL;DR: 利用3D基础模型的空间理解能力解决宽基线分割匹配问题，在极端视角变化下实现分割区域匹配，性能优于现有方法30%


<details>
  <summary>Details</summary>
Motivation: 分割匹配比关键点匹配更能捕捉结构化区域，对遮挡、光照变化和视角变化具有更强鲁棒性。宽基线分割匹配在极端视角变化下尤其具有挑战性

Method: 提出一种架构，利用3D基础模型的归纳偏置来匹配图像对中的分割区域，可处理高达180度的视角变化

Result: 在ScanNet++和Replica数据集上，AUPRC指标比SAM2视频传播器和局部特征匹配方法等最先进方法高出30%

Conclusion: 该方法在3D实例分割和图像目标导航等相关下游任务中展现出优势，证明了3D基础模型在分割匹配中的有效性

Abstract: Segment matching is an important intermediate task in computer vision that
establishes correspondences between semantically or geometrically coherent
regions across images. Unlike keypoint matching, which focuses on localized
features, segment matching captures structured regions, offering greater
robustness to occlusions, lighting variations, and viewpoint changes. In this
paper, we leverage the spatial understanding of 3D foundation models to tackle
wide-baseline segment matching, a challenging setting involving extreme
viewpoint shifts. We propose an architecture that uses the inductive bias of
these 3D foundation models to match segments across image pairs with up to 180
degree view-point change. Extensive experiments show that our approach
outperforms state-of-the-art methods, including the SAM2 video propagator and
local feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++
and Replica datasets. We further demonstrate benefits of the proposed model on
relevant downstream tasks, including 3D instance segmentation and image-goal
navigation. Project Page: https://segmast3r.github.io/

</details>


### [167] [No-reference Quality Assessment of Contrast-distorted Images using Contrast-enhanced Pseudo Reference](https://arxiv.org/abs/2510.05053)
*Mohammad-Ali Mahmoudpour,Saeed Mahmoudpour*

Main category: cs.CV

TL;DR: 提出一种针对对比度失真图像的无参考图像质量评估方法，通过选择最佳对比度增强算法生成伪参考图像，将NR-IQA问题转化为FR-IQA问题以提高评估准确性。


<details>
  <summary>Details</summary>
Motivation: 对比度变化是影响图像质量的重要因素，但在现有图像质量评估研究中常被忽视。不利光照条件会导致对比度变化和视觉质量损失，需要专门的方法来评估对比度失真图像的质量。

Method: 使用一组对比度增强算法生成视觉上接近真实参考图像的伪参考图像，构建大型对比度增强图像数据集训练分类网络，根据图像内容和失真选择最合适的对比度增强算法，最终以全参考方式评估对比度增强图像与退化图像之间的质量差异。

Result: 在包含对比度失真的三个数据库（CCID2014、TID2013和CSIQ）上进行性能评估，结果表明该方法具有有前景的性能表现。

Conclusion: 该方法通过将无参考图像质量评估问题转化为全参考评估问题，有效解决了对比度失真图像的质量评估挑战，在多个标准数据库上表现出良好的性能。

Abstract: Contrast change is an important factor that affects the quality of images.
During image capturing, unfavorable lighting conditions can cause contrast
change and visual quality loss. While various methods have been proposed to
assess the quality of images under different distortions such as blur and
noise, contrast distortion has been largely overlooked as its visual impact and
properties are different from other conventional types of distortions. In this
paper, we propose a no-reference image quality assessment (NR-IQA) metric for
contrast-distorted images. Using a set of contrast enhancement algorithms, we
aim to generate pseudo-reference images that are visually close to the actual
reference image, such that the NR problem is transformed to a Full-reference
(FR) assessment with higher accuracy. To this end, a large dataset of
contrast-enhanced images is produced to train a classification network that can
select the most suitable contrast enhancement algorithm based on image content
and distortion for pseudo-reference image generation. Finally, the evaluation
is performed in the FR manner to assess the quality difference between the
contrast-enhanced (pseudoreference) and degraded images. Performance evaluation
of the proposed method on three databases containing contrast distortions
(CCID2014, TID2013, and CSIQ), indicates the promising performance of the
proposed method.

</details>


### [168] [Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces](https://arxiv.org/abs/2510.05071)
*Debojyoti Ghosh,Soumya K Ghosh,Adrijit Goswami*

Main category: cs.CV

TL;DR: 提出Neuroplastic Modular Classifier，一种结合ResNet-50和Vision Transformer的混合架构，通过FAISS相似性检索和可扩展模块设计，在垃圾分类和工业缺陷检测任务中实现高精度和适应性。


<details>
  <summary>Details</summary>
Motivation: 需要高效准确的垃圾分类和工业表面缺陷检测方法，以支持可持续废物管理和质量控制标准。

Method: 使用ResNet-50进行局部特征提取，Vision Transformer捕获全局语义上下文，集成FAISS相似性检索，并采用神经可塑性模块设计，在训练性能停滞时动态扩展学习模块。

Result: 在垃圾分类和KolektorSDD2工业缺陷检测数据集上，该架构在准确性和适应性方面均优于传统静态模型。

Conclusion: Neuroplastic Modular Classifier为现实世界图像分类提供了可扩展的高性能解决方案，在环境和工业领域具有强适用性。

Abstract: Efficient and accurate classification of waste and industrial surface defects
is essential for ensuring sustainable waste management and maintaining high
standards in quality control. This paper introduces the Neuroplastic Modular
Classifier, a novel hybrid architecture designed for robust and adaptive image
classification in dynamic environments. The model combines a ResNet-50 backbone
for localized feature extraction with a Vision Transformer (ViT) to capture
global semantic context. Additionally, FAISS-based similarity retrieval is
incorporated to provide a memory-like reference to previously encountered data,
enriching the model's feature space. A key innovation of our architecture is
the neuroplastic modular design composed of expandable, learnable blocks that
dynamically grow during training when performance plateaus. Inspired by
biological learning systems, this mechanism allows the model to adapt to data
complexity over time, improving generalization. Beyond garbage classification,
we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),
which involves industrial defect detection on metal surfaces. Experimental
results across domains show that the proposed architecture outperforms
traditional static models in both accuracy and adaptability. The Neuroplastic
Modular Classifier offers a scalable, high-performance solution for real-world
image classification, with strong applicability in both environmental and
industrial domains.

</details>


### [169] [Factuality Matters: When Image Generation and Editing Meet Structured Visuals](https://arxiv.org/abs/2510.05091)
*Le Zhuo,Songhao Han,Yuandong Pu,Boxiang Qiu,Sayak Paul,Yue Liao,Yihao Liu,Jie Shao,Xi Chen,Si Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 该论文提出了首个针对结构化视觉内容（如图表、图表、数学图形）生成和编辑的综合解决方案，包括大规模数据集构建、统一模型训练和评估基准创建。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型在生成自然图像方面表现出色，但在处理需要组合规划、文本渲染和多模态推理的结构化视觉内容时存在困难，无法保证事实准确性。

Method: 构建了130万高质量结构化图像对数据集，训练了集成VLM与FLUX.1 Kontext的统一模型，采用三阶段训练课程，并在推理时使用外部推理器增强性能。

Result: 评估了15个模型，发现即使是领先的闭源系统也表现不佳。提出的模型在编辑任务上表现强劲，推理时推理机制在不同架构中均带来一致性能提升。

Conclusion: 通过发布数据集、模型和基准测试，旨在推进结构化视觉内容的统一多模态基础研究。

Abstract: While modern visual generation models excel at creating aesthetically
pleasing natural images, they struggle with producing or editing structured
visuals like charts, diagrams, and mathematical figures, which demand
composition planning, text rendering, and multimodal reasoning for factual
fidelity. To address this, we present the first comprehensive, systematic
investigation of this domain, encompassing data construction, model training,
and an evaluation benchmark. First, we construct a large-scale dataset of 1.3
million high-quality structured image pairs derived from executable drawing
programs and augmented with chain-of-thought reasoning annotations. Building on
it, we train a unified model that integrates a VLM with FLUX.1 Kontext via a
lightweight connector for enhanced multimodal understanding. A three-stage
training curriculum enables progressive feature alignment, knowledge infusion,
and reasoning-augmented generation, further boosted by an external reasoner at
inference time. Finally, we introduce StructBench, a novel benchmark for
generation and editing with over 1,700 challenging instances, and an
accompanying evaluation metric, StructScore, which employs a multi-round Q\&A
protocol to assess fine-grained factual accuracy. Evaluations of 15 models
reveal that even leading closed-source systems remain far from satisfactory.
Our model attains strong editing performance, and inference-time reasoning
yields consistent gains across diverse architectures. By releasing the dataset,
model, and benchmark, we aim to advance unified multimodal foundations for
structured visuals.

</details>


### [170] [Character Mixing for Video Generation](https://arxiv.org/abs/2510.05093)
*Tingting Liao,Chongjian Ge,Guangyi Liu,Hao Li,Yi Zhou*

Main category: cs.CV

TL;DR: 提出了一个跨角色交互的视频生成框架，通过交叉角色嵌入和交叉角色增强技术，解决不同世界角色自然交互时的身份保持和风格一致性问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何让不同作品中的角色（如Mr. Bean和Tom and Jerry）在视频中自然交互，同时保持各自的身份特征和行为逻辑，避免风格混淆。

Method: 使用交叉角色嵌入（CCE）学习跨多模态源的身份和行为逻辑，以及交叉角色增强（CCA）通过合成共存和混合风格数据来丰富训练。

Result: 在包含10个卡通和真人角色的基准测试中，在身份保持、交互质量和风格混淆鲁棒性方面都显示出明显改进。

Conclusion: 该框架能够实现先前不共存角色之间的自然交互，同时保持风格保真度，为生成式故事叙述开辟了新形式。

Abstract: Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where
characters interact naturally across different worlds? We study inter-character
interaction in text-to-video generation, where the key challenge is to preserve
each character's identity and behaviors while enabling coherent cross-context
interaction. This is difficult because characters may never have coexisted and
because mixing styles often causes style delusion, where realistic characters
appear cartoonish or vice versa. We introduce a framework that tackles these
issues with Cross-Character Embedding (CCE), which learns identity and
behavioral logic across multimodal sources, and Cross-Character Augmentation
(CCA), which enriches training with synthetic co-existence and mixed-style
data. Together, these techniques allow natural interactions between previously
uncoexistent characters without losing stylistic fidelity. Experiments on a
curated benchmark of cartoons and live-action series with 10 characters show
clear improvements in identity preservation, interaction quality, and
robustness to style delusion, enabling new forms of generative
storytelling.Additional results and videos are available on our project page:
https://tingtingliao.github.io/mimix/.

</details>


### [171] [VChain: Chain-of-Visual-Thought for Reasoning in Video Generation](https://arxiv.org/abs/2510.05094)
*Ziqi Huang,Ning Yu,Gordon Chen,Haonan Qiu,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: VChain是一个推理时视觉思维链框架，通过多模态模型生成关键帧来指导视频生成，提升复杂动态场景的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型难以合成具有连贯因果链的复杂动态，而多模态模型具备强大的视觉状态推理能力，需要将两者优势结合。

Method: 利用大型多模态模型生成稀疏关键帧作为快照，然后在这些关键时刻对预训练视频生成器进行稀疏推理时微调。

Result: 在复杂多步骤场景的广泛实验中，VChain显著提升了生成视频的质量。

Conclusion: VChain通过注入视觉推理信号，实现了高效、低开销的视频生成质量提升。

Abstract: Recent video generation models can produce smooth and visually appealing
clips, but they often struggle to synthesize complex dynamics with a coherent
chain of consequences. Accurately modeling visual outcomes and state
transitions over time remains a core challenge. In contrast, large language and
multimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and
future prediction capabilities. To bridge these strengths, we introduce VChain,
a novel inference-time chain-of-visual-thought framework that injects visual
reasoning signals from multimodal models into video generation. Specifically,
VChain contains a dedicated pipeline that leverages large multimodal models to
generate a sparse set of critical keyframes as snapshots, which are then used
to guide the sparse inference-time tuning of a pre-trained video generator only
at these key moments. Our approach is tuning-efficient, introduces minimal
overhead and avoids dense supervision. Extensive experiments on complex,
multi-step scenarios show that VChain significantly enhances the quality of
generated videos.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [172] [Decomposing Attention To Find Context-Sensitive Neurons](https://arxiv.org/abs/2510.03315)
*Alex Gibson*

Main category: cs.CL

TL;DR: 通过分析GPT2-Small第一层中注意力模式分散且对内容依赖较弱的注意力头，发现当token分布固定时这些头的softmax分母是稳定的。利用校准文本采样softmax分母，可以近似这些稳定头的组合输出为周围文本的线性摘要，从而仅从权重和单个校准文本就能识别出数百个对周围文本高级上下文属性响应的第一层神经元。


<details>
  <summary>Details</summary>
Motivation: 研究transformer语言模型中注意力模式分散、对内容依赖较弱的注意力头，探索这些稳定头的特性及其在模型理解中的作用。

Method: 通过采样校准文本中的softmax分母，结合多个稳定注意力头的输出，将其近似为周围文本的线性摘要，从而仅从模型权重和单个校准文本就能识别响应高级上下文属性的神经元。

Result: 成功识别出GPT2-Small第一层中数百个对周围文本高级上下文属性（包括未在校准文本中激活的神经元）响应的神经元。

Conclusion: 该方法证明了仅从模型权重和少量校准数据就能揭示transformer模型中神经元对高级语义特征的响应模式，为模型可解释性提供了新途径。

Abstract: We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.

</details>


### [173] [Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision](https://arxiv.org/abs/2510.03323)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.CL

TL;DR: Graph-S³是一个基于LLM的文本图推理框架，通过合成逐步监督训练检索器，解决了大型图中相关内容的检索问题，在复杂推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界大量数据以文本图形式存在，但现有图检索方法性能不佳，要么依赖浅层嵌入相似度，要么需要大量标注数据和训练成本。

Method: 提出基于LLM的检索器，使用合成逐步监督训练，通过数据合成管道提取黄金子图生成奖励，采用两阶段训练方案学习交互式图探索策略。

Result: 在三个常见数据集上与七个强基线比较，准确率平均提升8.1%，F1分数平均提升9.7%，在多跳推理任务中优势更明显。

Conclusion: Graph-S³框架通过合成监督训练有效解决了文本图检索问题，在复杂推理任务中表现突出，代码将开源。

Abstract: A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.

</details>


### [174] [Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks](https://arxiv.org/abs/2510.03384)
*Arjun Arunasalam,Madison Pickering,Z. Berkay Celik,Blase Ur*

Main category: cs.CL

TL;DR: 本文通过审计6个流行大语言模型完成30个日常任务时的表现，发现LLMs在展示隐含价值观方面与人类和其他LLMs存在不一致。


<details>
  <summary>Details</summary>
Motivation: 尽管AI助手在帮助用户完成日常任务方面具有潜力，但人们对这些助手在完成主观日常任务时展示的隐含价值观知之甚少。

Method: 通过审计6个流行LLMs完成30个日常任务，并与100名美国众包工作者进行比较。

Result: LLMs在展示隐含价值观时往往与人类不一致，与其他LLMs也不一致。

Conclusion: LLMs在价值观表现方面与人类存在显著差异，需要进一步研究以确保AI助手的价值观与人类保持一致。

Abstract: Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.

</details>


### [175] [Morpheme Induction for Emergent Language](https://arxiv.org/abs/2510.03439)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: CSAR是一种从涌现语言语料库中诱导语素的贪婪算法，通过互信息加权、选择、移除和重复的过程来识别语素。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够从平行话语和意义语料库中自动识别语素的算法，以分析涌现语言的结构特性。

Method: 使用贪婪算法：基于形式和意义之间的互信息对语素进行加权，选择权重最高的对，从语料库中移除，然后重复该过程。

Result: 在程序生成的数据集上验证了CSAR的有效性，并在人类语言数据上显示了合理的预测能力，能够量化涌现语言中的同义和多义程度。

Conclusion: CSAR算法能够有效地从涌现语言中诱导语素，为分析语言特性提供了有用的工具。

Abstract: We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.

</details>


### [176] [Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video](https://arxiv.org/abs/2510.03458)
*Mengyao Xu,Wenfei Zhou,Yauhen Babakhin,Gabriel Moreira,Ronay Ak,Radek Osmulski,Bo Liu,Even Oldridge,Benedikt Schifferer*

Main category: cs.CL

TL;DR: Omni-Embed-Nemotron是一个统一的多模态检索嵌入模型，支持文本、图像、音频和视频的跨模态和联合模态检索。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的检索器依赖干净的结构化输入，难以处理现实世界中包含丰富视觉和语义内容的文档（如PDF、幻灯片、视频）。

Method: 基于ColPali和Qwen2.5-Omni等模型，扩展了检索能力，支持文本、图像、音频和视频的多模态检索，使用单一模型实现跨模态和联合模态检索。

Result: 展示了Omni-Embed-Nemotron在文本、图像和视频检索中的有效性。

Conclusion: 该模型能够处理现实世界中复杂的信息需求，支持多种模态的检索任务。

Abstract: We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.

</details>


### [177] [Searching for the Most Human-like Emergent Language](https://arxiv.org/abs/2510.03467)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 通过基于信号博弈的涌现通信环境和超参数优化，生成与人类语言相似度最高的涌现语言，使用XferBench作为目标函数来量化统计相似性，并验证了熵对涌现语言迁移学习性能的预测能力。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够生成与人类语言高度相似的涌现语言的环境，通过量化统计相似性来评估涌现语言的质量，并探索影响涌现语言真实性的关键因素。

Method: 使用基于信号博弈的涌现通信环境，结合超参数优化方法，以XferBench作为目标函数来评估涌现语言与人类语言的统计相似性，并分析熵对迁移学习性能的影响。

Result: 成功生成了在统计相似性方面达到最先进水平的涌现语言，验证了熵对涌现语言迁移学习性能的预测能力，并确认了涌现通信系统的熵最小化特性。

Conclusion: 确定了能够产生更真实涌现语言的关键超参数，这些语言在迁移到人类语言时表现更好，为理解涌现语言与人类语言之间的关系提供了重要见解。

Abstract: In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.

</details>


### [178] [SEER: The Span-based Emotion Evidence Retrieval Benchmark](https://arxiv.org/abs/2510.03490)
*Aneesha Sampath,Oya Aran,Emily Mower Provost*

Main category: cs.CL

TL;DR: SEER基准测试评估LLMs识别文本中表达情感的具体片段的能力，包含单句和跨句情感证据检测任务，发现模型在长文本中表现下降。


<details>
  <summary>Details</summary>
Motivation: 传统情感识别只给整句分配标签，而实际应用如共情对话和临床支持需要知道情感如何表达，因此需要细粒度的情感证据检测。

Method: 构建包含1200个真实世界句子的SEER基准，标注情感和情感证据，评估14个开源LLMs在单句和五句段落中的表现。

Result: 部分模型在单句任务上接近人类平均水平，但在长段落中准确率下降；错误分析显示模型过度依赖情感关键词且在非情感文本中产生误报。

Conclusion: SEER基准揭示了LLMs在细粒度情感证据检测方面的局限性，特别是在处理长文本时，为改进情感理解模型提供了重要方向。

Abstract: We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.

</details>


### [179] [ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection](https://arxiv.org/abs/2510.03502)
*Ali Khairallah,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: ALHD是首个大规模阿拉伯语数据集，专门用于区分人类和LLM生成的文本，涵盖新闻、社交媒体和评论三种文体，包含超过40万个平衡样本，支持阿拉伯语LLM生成文本检测的可泛化性研究。


<details>
  <summary>Details</summary>
Motivation: 建立专门针对阿拉伯语的LLM生成文本检测数据集，以解决错误信息、学术不端和网络威胁等风险，填补阿拉伯语在该研究领域的空白。

Method: 构建包含三种文体（新闻、社交媒体、评论）的平衡数据集，覆盖现代标准阿拉伯语和方言，使用三个领先LLM生成文本，并提供严格预处理、丰富注释和标准化分割。

Result: 微调的BERT模型在检测任务中表现最佳，优于基于LLM的模型，但在跨文体泛化方面存在挑战，特别是在新闻文章中LLM生成文本与人类文本风格相似时。

Conclusion: ALHD为阿拉伯语LLM检测研究奠定了基础，揭示了跨文体泛化的挑战，特别是在新闻领域，为未来研究指明了方向。

Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.

</details>


### [180] [TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning](https://arxiv.org/abs/2510.03519)
*Fangxu Yu,Hongyu Zhao,Tianyi Zhou*

Main category: cs.CL

TL;DR: 提出了TS-Reasoner模型，通过将时间序列基础模型(TSFMs)的潜在表示与大型语言模型(LLMs)的文本输入对齐，解决时间序列推理任务中数值理解与高级推理的融合问题。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型能捕捉低层动态模式但缺乏高级推理能力，而大型语言模型具有推理能力但难以理解时间序列数值数据。需要有效整合两种模型的能力。

Method: 提出两阶段训练方法：1) 使用合成的时序-文本对进行对齐预训练；2) 指令微调。冻结预训练的TSFM，仅训练对齐层。

Result: 在多个基准测试中，TS-Reasoner超越了主流LLMs、VLMs和时间序列LLMs，且具有显著的数据效率(使用不到一半的训练数据)。

Conclusion: TS-Reasoner成功实现了时间序列数值理解与语言推理的有效融合，为时间序列推理任务提供了高效解决方案。

Abstract: Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.

</details>


### [181] [Identifying Financial Risk Information Using RAG with a Contrastive Insight](https://arxiv.org/abs/2510.03521)
*Ali Elahi*

Main category: cs.CL

TL;DR: 提出在RAG基础上增加对比推理层，解决专业领域推理中缺乏可比案例检索的问题，在金融领域生成更具体的风险分析而非通用描述。


<details>
  <summary>Details</summary>
Motivation: 专业领域推理需要比较相似案例和问题，但传统RAG只能提取事实信息，无法检索可比案例，导致输出过于通用化。

Method: 在RAG基础上构建同伴感知的对比推理层，通过对比分析生成更具体的专业见解。

Result: 对比方法在ROUGE和BERTScore等文本生成指标上优于基线RAG，与人工生成的股票研究和风险分析更接近。

Conclusion: 对比推理层能有效提升RAG在专业领域推理中的表现，生成更具体、情境相关的见解。

Abstract: In specialized domains, humans often compare new problems against similar
examples, highlight nuances, and draw conclusions instead of analyzing
information in isolation. When applying reasoning in specialized contexts with
LLMs on top of a RAG, the pipeline can capture contextually relevant
information, but it is not designed to retrieve comparable cases or related
problems.
  While RAG is effective at extracting factual information, its outputs in
specialized reasoning tasks often remain generic, reflecting broad facts rather
than context-specific insights. In finance, it results in generic risks that
are true for the majority of companies. To address this limitation, we propose
a peer-aware comparative inference layer on top of RAG.
  Our contrastive approach outperforms baseline RAG in text generation metrics
such as ROUGE and BERTScore in comparison with human-generated equity research
and risk.

</details>


### [182] [Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs](https://arxiv.org/abs/2510.03527)
*Sayan Ghosh,Shahzaib Saqib Warraich,Dhruv Tarsadiya,Gregory Yauney,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 提出Consensus Graphs (ConGrs)数据结构，通过轻量级序列对齐算法构建，能够有效整合语言模型多次采样的响应，提升事实精度、拒绝率和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法高效整合语言模型多次采样生成的长文本响应中的丰富认知信号，需要一种灵活的数据结构来表征共享信息和语义变化。

Method: 使用生物信息学中的轻量级词汇序列对齐算法构建DAG结构的ConGrs，辅以辅助语言模型判断，并设计任务相关的解码方法从ConGr合成最终响应。

Result: 在传记生成任务中事实精度提升31%，减少对语言模型判断的依赖80%以上；在拒绝任务中拒绝率提升56%；在MATH和AIME推理任务中准确率比基线提升6个百分点。

Conclusion: ConGrs提供了一种灵活的方法来捕捉语言模型响应的变化，并利用响应变化提供的认知信号来合成更有效的响应。

Abstract: Language models can be sampled multiple times to access the distribution
underlying their responses, but existing methods cannot efficiently synthesize
rich epistemic signals across different long-form responses. We introduce
Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents
shared information, as well as semantic variation in a set of sampled LM
responses to the same prompt. We construct ConGrs using a light-weight lexical
sequence alignment algorithm from bioinformatics, supplemented by the targeted
usage of a secondary LM judge. Further, we design task-dependent decoding
methods to synthesize a single, final response from our ConGr data structure.
Our experiments show that synthesizing responses from ConGrs improves factual
precision on two biography generation tasks by up to 31% over an average
response and reduces reliance on LM judges by more than 80% compared to other
methods. We also use ConGrs for three refusal-based tasks requiring abstention
on unanswerable queries and find that abstention rate is increased by up to
56%. We apply our approach to the MATH and AIME reasoning tasks and find an
improvement over self-verification and majority vote baselines by up to 6
points of accuracy. We show that ConGrs provide a flexible method for capturing
variation in LM responses and using the epistemic signals provided by response
variation to synthesize more effective responses.

</details>


### [183] [Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance](https://arxiv.org/abs/2510.03528)
*Ahmed Alajrami,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 研究表明，在指令微调数据中引入扰动（如删除停用词或打乱词语顺序）可以增强大语言模型对噪声指令的鲁棒性，甚至在某些情况下提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型对指令表述的微小变化很敏感，本研究探索通过指令微调数据中的扰动来增强模型对噪声指令的抵抗能力。

Method: 在指令微调过程中引入扰动（删除停用词、打乱词语顺序等），并在MMLU、BBH、GSM8K等基准测试上评估模型在原始和扰动版本上的表现。

Result: 令人惊讶的是，在扰动指令上进行指令微调在某些情况下能够改善下游任务性能。

Conclusion: 在指令微调中包含扰动指令非常重要，可以使大语言模型对噪声用户输入更具弹性。

Abstract: Instruction-tuning plays a vital role in enhancing the task-solving abilities
of large language models (LLMs), improving their usability in generating
helpful responses on various tasks. However, previous work has demonstrated
that they are sensitive to minor variations in instruction phrasing. In this
paper, we explore whether introducing perturbations in instruction-tuning data
can enhance LLMs' resistance against noisy instructions. We focus on how
instruction-tuning with perturbations, such as removing stop words or shuffling
words, affects LLMs' performance on the original and perturbed versions of
widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics
and potential shifts in model behavior. Surprisingly, our results suggest that
instruction-tuning on perturbed instructions can, in some cases, improve
downstream performance. These findings highlight the importance of including
perturbed instructions in instruction-tuning, which can make LLMs more
resilient to noisy user inputs.

</details>


### [184] [TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering](https://arxiv.org/abs/2510.03536)
*Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis*

Main category: cs.CL

TL;DR: TriMediQ通过将患者对话转换为三元组知识图谱，解决了LLM在多轮医疗问答中推理能力下降的问题，显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: LLM在静态单轮医疗问答中表现良好，但在实际临床对话的多轮交互中可靠性显著下降，因为临床事实在对话日志中缺乏清晰关联。

Method: 提出TriMediQ框架：使用冻结的三元组生成器提取临床相关三元组，构建知识图谱；通过可训练的投影模块（图编码器和投影器）捕获关系信息；采用两阶段训练：投影模块微调（LLM权重冻结）和推理时引导多跳推理。

Result: 在两个交互式QA基准测试中，TriMediQ在iMedQA数据集上比五个基线方法提升了10.4%的准确率。

Conclusion: 将患者响应转换为结构化三元组图谱能够实现更准确的多轮临床推理，为基于LLM的医疗助手部署提供了解决方案。

Abstract: Large Language Models (LLMs) perform strongly in static and single-turn
medical Question Answer (QA) benchmarks, yet such settings diverge from the
iterative information gathering process required in practical clinical
consultations. The MEDIQ framework addresses this mismatch by recasting the
diagnosis as an interactive dialogue between a patient and an expert system,
but the reliability of LLMs drops dramatically when forced to reason with
dialogue logs, where clinical facts appear in sentences without clear links. To
bridge this gap, we introduce TriMediQ, a triplet-structured approach that
summarises patient responses into triplets and integrates them into a Knowledge
Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet
generator that extracts clinically relevant triplets, using prompts designed to
ensure factual consistency. In parallel, a trainable projection module,
comprising a graph encoder and a projector, captures relational information
from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)
the projection module fine-tuning with all LLM weights frozen; and (ii) using
the fine-tuned module to guide multi-hop reasoning during inference. We
evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up
to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset.
These results demonstrate that converting patient responses into structured
triplet-based graphs enables more accurate clinical reasoning in multi-turn
settings, providing a solution for the deployment of LLM-based medical
assistants.

</details>


### [185] [What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification](https://arxiv.org/abs/2510.03541)
*Andrew Halterman,Katherine A. Keith*

Main category: cs.CL

TL;DR: 论文指出在计算社会科学中使用大语言模型进行文本分类时，概念化步骤常被忽视，这会导致下游统计推断的偏差，且无法通过提高模型准确性或后处理偏差校正来修正。


<details>
  <summary>Details</summary>
Motivation: 当前计算社会科学中广泛使用生成式大语言模型进行文本分类，但研究者往往忽视了分类前的概念化步骤和分类后的统计推断步骤，这些被忽视的环节可能导致严重的估计偏差。

Method: 通过模拟实验分析概念化错误对下游估计的影响，并测试提高LLM准确性和后处理偏差校正方法是否能修正这种偏差。

Result: 研究发现概念化引起的偏差无法仅通过提高LLM准确性或后处理偏差校正方法来修正，这种偏差会持续影响下游估计。

Conclusion: 在LLM时代，概念化仍然是计算社会科学中的首要关注点，作者提供了实现低成本、无偏差、低方差下游估计的具体建议。

Abstract: Generative large language models (LLMs) are now used extensively for text
classification in computational social science (CSS). In this work, focus on
the steps before and after LLM prompting -- conceptualization of concepts to be
classified and using LLM predictions in downstream statistical inference --
which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can
tempt analysts to skip the conceptualization step, creating conceptualization
errors that bias downstream estimates. Using simulations, we show that this
conceptualization-induced bias cannot be corrected for solely by increasing LLM
accuracy or post-hoc bias correction methods. We conclude by reminding CSS
analysts that conceptualization is still a first-order concern in the LLM-era
and provide concrete advice on how to pursue low-cost, unbiased, low-variance
downstream estimates.

</details>


### [186] [CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making](https://arxiv.org/abs/2510.03553)
*Hasibur Rahman,Hanan Salam*

Main category: cs.CL

TL;DR: CCD-Bench是一个评估LLM在跨文化价值冲突下决策能力的基准，包含2182个开放式的两难困境，覆盖7个领域，每个困境对应10个GLOBE文化集群的匿名响应选项。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注文化知识、价值预测或单轴偏见诊断，但缺乏评估LLM在多个文化价值观直接冲突时的裁决能力。

Method: 使用分层拉丁方设计呈现困境以避免顺序效应，评估了17个非推理LLM，分析模型对不同文化集群的偏好模式。

Result: 模型明显偏好北欧（20.2%）和日耳曼欧洲（12.4%），而东欧和中东北非选项代表性不足（5.6-5.8%）。虽然87.9%的理由涉及多个GLOBE维度，但这种多元性是表面的，主要重组未来导向和绩效导向，很少基于自信或性别平等（均低于3%）。

Conclusion: 当前的对齐流程促成了共识导向的世界观，但无法充分处理需要权力协商、权利推理或性别意识分析的场景。CCD-Bench将评估从孤立偏见检测转向多元决策，强调需要实质性参与多元世界观的校准策略。

Abstract: Although large language models (LLMs) are increasingly implicated in
interpersonal and societal decision-making, their ability to navigate explicit
conflicts between legitimately different cultural value systems remains largely
unexamined. Existing benchmarks predominantly target cultural knowledge
(CulturalBench), value prediction (WorldValuesBench), or single-axis bias
diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple
culturally grounded values directly clash. We address this gap with CCD-Bench,
a benchmark that assesses LLM decision-making under cross-cultural value
conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,
each paired with ten anonymized response options corresponding to the ten GLOBE
cultural clusters. These dilemmas are presented using a stratified Latin square
to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models
disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe
(12.4 percent), while options for Eastern Europe and the Middle East and North
Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of
rationales reference multiple GLOBE dimensions, this pluralism is superficial:
models recombine Future Orientation and Performance Orientation, and rarely
ground choices in Assertiveness or Gender Egalitarianism (both under 3
percent). Ordering effects are negligible (Cramer's V less than 0.10), and
symmetrized KL divergence shows clustering by developer lineage rather than
geography. These patterns suggest that current alignment pipelines promote a
consensus-oriented worldview that underserves scenarios demanding power
negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts
evaluation beyond isolated bias detection toward pluralistic decision making
and highlights the need for alignment strategies that substantively engage
diverse worldviews.

</details>


### [187] [Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models](https://arxiv.org/abs/2510.03561)
*Adam Filipek*

Main category: cs.CL

TL;DR: RxT是一种新型Transformer架构，通过事件驱动范式解决传统Transformer在对话AI中的状态缺失和二次计算复杂度问题，实现实时、有状态的长对话。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在对话应用中存在状态缺失和二次计算复杂度问题，导致长对话成本高昂、延迟严重，需要新的架构来解决这些限制。

Method: RxT采用事件驱动范式，将对话轮次作为离散事件处理，通过集成固定大小的短期记忆系统、生成器-解码器和专用记忆注意力网络，实现响应生成与记忆更新的解耦。

Result: RxT将对话总成本从二次降低到线性，在合成数据上的概念验证实验显示优于基线无状态模型的性能和恒定时间推理延迟。

Conclusion: RxT架构通过事件驱动设计和记忆系统，实现了实时、有状态且经济可行的长对话，显著改善了Transformer在对话AI中的可扩展性。

Abstract: The Transformer architecture has become the de facto standard for Large
Language Models (LLMs), demonstrating remarkable capabilities in language
understanding and generation. However, its application in conversational AI is
fundamentally constrained by its stateless nature and the quadratic
computational complexity ($O(L^2)$) with respect to sequence length $L$.
Current models emulate memory by reprocessing an ever-expanding conversation
history with each turn, leading to prohibitive costs and latency in long
dialogues. This paper introduces the Reactive Transformer (RxT), a novel
architecture designed to overcome these limitations by shifting from a
data-driven to an event-driven paradigm. RxT processes each conversational turn
as a discrete event in real-time, maintaining context in an integrated,
fixed-size Short-Term Memory (STM) system. The architecture features a distinct
operational cycle where a generator-decoder produces a response based on the
current query and the previous memory state, after which a memory-encoder and a
dedicated Memory Attention network asynchronously update the STM with a
representation of the complete interaction. This design fundamentally alters
the scaling dynamics, reducing the total user-facing cost of a conversation
from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to
the number of interactions $N$. By decoupling response generation from memory
updates, RxT achieves low latency, enabling truly real-time, stateful, and
economically viable long-form conversations. We validated our architecture with
a series of proof-of-concept experiments on synthetic data, demonstrating
superior performance and constant-time inference latency compared to a baseline
stateless model of comparable size.

</details>


### [188] [LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction](https://arxiv.org/abs/2510.03577)
*Ikram Belmadani,Parisa Nazari Hashemi,Thomas Sebbag,Benoit Favre,Guillaume Fortier,Solen Quiniou,Emmanuel Morin,Richard Dufour*

Main category: cs.CL

TL;DR: 该论文介绍了在EvalLLM 2025挑战赛中针对法语生物医学命名实体识别和健康事件抽取的三种方法，主要基于大语言模型、合成数据和后处理技术，其中GPT-4.1在少样本设置下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决法语生物医学领域在极低资源场景下的命名实体识别和事件抽取问题，探索大语言模型在少样本学习中的应用潜力。

Method: 提出了三种方法：(1) GPT-4.1的上下文学习，包含自动选择10个示例和标注指南摘要；(2) GLiNER系统在合成语料上微调后经LLM后处理验证；(3) LLaMA-3.1-8B-Instruct在相同合成语料上微调。事件抽取采用与NER相同的上下文学习策略。

Result: GPT-4.1在命名实体识别上获得61.53%的宏观F1分数，在事件抽取上获得15.02%的宏观F1分数，表现最佳。

Conclusion: 精心设计的提示工程对于在极低资源场景下最大化性能至关重要，GPT-4.1在少样本法语生物医学信息抽取任务中展现了优越性能。

Abstract: This work presents our participation in the EvalLLM 2025 challenge on
biomedical Named Entity Recognition (NER) and health event extraction in French
(few-shot setting). For NER, we propose three approaches combining large
language models (LLMs), annotation guidelines, synthetic data, and
post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating
automatic selection of 10 examples and a summary of the annotation guidelines
into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic
corpus and then verified by an LLM in post-processing, and (3) the open LLM
LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event
extraction uses the same ICL strategy with GPT-4.1, reusing the guideline
summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for
NER and 15.02% for event extraction, highlighting the importance of
well-crafted prompting to maximize performance in very low-resource scenarios.

</details>


### [189] [Decoupling Task-Solving and Output Formatting in LLM Generation](https://arxiv.org/abs/2510.03595)
*Haikang Deng,Po-Nien Kung,Nanyun Peng*

Main category: cs.CL

TL;DR: Deco-G是一个解码框架，通过将格式遵循与任务解决解耦，使用单独的易处理概率模型处理格式合规性，让LLM专注于任务指令，从而提升复杂指令下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着提示变得越来越复杂，模型往往难以遵循所有指令，特别是在推理指令与严格格式要求交织时会产生竞争目标，需要更明确地分离这两个方面。

Method: 引入Deco-G框架，使用易处理概率模型处理格式合规性，LLM只处理任务指令，在解码步骤中结合LLM的下一个token概率和TPM计算的格式合规似然。

Result: 在数学推理、LLM作为评判者和事件参数提取等任务中，相比常规提示方法获得1.0%到6.0%的相对增益，并保证格式合规。

Conclusion: 通过明确解耦格式遵循和任务解决，Deco-G框架能有效提升LLM在复杂指令下的性能，同时确保格式合规。

Abstract: Large language models (LLMs) are increasingly adept at following instructions
containing task descriptions to solve complex problems, such as mathematical
reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow
more complex, models often struggle to adhere to all instructions. This
difficulty is especially common when instructive prompts intertwine reasoning
directives -- specifying what the model should solve -- with rigid formatting
requirements that dictate how the solution must be presented. The entanglement
creates competing goals for the model, suggesting that more explicit separation
of these two aspects could lead to improved performance. To this front, we
introduce Deco-G, a decoding framework that explicitly decouples format
adherence from task solving. Deco-G handles format compliance with a separate
tractable probabilistic model (TPM), while prompts LLMs with only task
instructions. At each decoding step, Deco-G combines next token probabilities
from the LLM with the TPM calculated format compliance likelihood to form the
output probability. To make this approach both practical and scalable for
modern instruction-tuned LLMs, we introduce three key innovations:
instruction-aware distillation, a flexible trie-building algorithm, and HMM
state pruning for computational efficiency. We demonstrate the effectiveness of
Deco-G across a wide range of tasks with diverse format requirements, including
mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,
our approach yields 1.0% to 6.0% relative gain over regular prompting practice
with guaranteed format compliance.

</details>


### [190] [Can an LLM Induce a Graph? Investigating Memory Drift and Context Length](https://arxiv.org/abs/2510.03611)
*Raquib Bin Yousuf,Aadyant Khatri,Shengzhe Xu,Mandar Sharma,Naren Ramakrishnan*

Main category: cs.CL

TL;DR: 现有评估基准在衡量LLM有效上下文长度和遗忘倾向方面存在不足，本文提出基于关系推理任务的更准确评估方法，发现LLM在复杂推理中会出现更早的记忆漂移和上下文遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准主要依赖简单的检索或续写任务，无法准确反映LLM在信息密集场景下的真实性能，需要更复杂的推理任务来评估模型从文本中提取结构化关系知识的能力。

Method: 使用需要从潜在噪声自然语言内容中归纳图结构的关系推理任务进行评估，其中文本结构不明确，连接必须从分散的文本线索中推导。

Result: 研究发现LLM在这种关系推理任务中，在比现有基准建议的更短有效长度下就开始出现记忆漂移和上下文遗忘，即使是专门用于推理的模型如OpenAI o1也容易受到早期记忆漂移的影响。

Conclusion: 这些结果揭示了模型从非结构化输入中抽象结构化知识能力的显著局限性，强调需要架构改进来提升长距离推理能力。

Abstract: Recently proposed evaluation benchmarks aim to characterize the effective
context length and the forgetting tendencies of large language models (LLMs).
However, these benchmarks often rely on simplistic 'needle in a haystack'
retrieval or continuation tasks that may not accurately reflect the performance
of these models in information-dense scenarios. Thus, rather than simple next
token prediction, we argue for evaluating these models on more complex
reasoning tasks that requires them to induce structured relational knowledge
from the text - such as graphs from potentially noisy natural language content.
While the input text can be viewed as generated in terms of a graph, its
structure is not made explicit and connections must be induced from distributed
textual cues, separated by long contexts and interspersed with irrelevant
information. Our findings reveal that LLMs begin to exhibit memory drift and
contextual forgetting at much shorter effective lengths when tasked with this
form of relational reasoning, compared to what existing benchmarks suggest.
With these findings, we offer recommendations for the optimal use of popular
LLMs for complex reasoning tasks. We further show that even models specialized
for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in
these settings. These results point to significant limitations in the models'
ability to abstract structured knowledge from unstructured input and highlight
the need for architectural adaptations to improve long-range reasoning.

</details>


### [191] [Towards Unsupervised Speech Recognition at the Syllable-Level](https://arxiv.org/abs/2510.03639)
*Liming Wang,Junrui Ni,Kai-Wei Chang,Saurabhchand Bhati,David Harwath,Mark Hasegawa-Johnson,James R. Glass*

Main category: cs.CL

TL;DR: 提出了一种基于音节级别的无监督语音识别框架，使用掩码语言建模方法，避免了传统G2P转换器的依赖和GAN方法的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决无监督语音识别中传统方法依赖昂贵资源（如G2P转换器）和在模糊音素边界语言中训练不稳定的问题，扩展ASR到低资源语言。

Method: 基于掩码语言建模的音节级UASR框架，无需G2P转换器，避免了GAN方法的不稳定性。

Result: 在LibriSpeech上实现了40%的相对字符错误率降低，并在普通话等困难语言上表现出良好的泛化能力。

Conclusion: 该方法为无监督语音识别提供了一种更稳定和通用的解决方案，特别适用于资源稀缺的语言。

Abstract: Training speech recognizers with unpaired speech and text -- known as
unsupervised speech recognition (UASR) -- is a crucial step toward extending
ASR to low-resource languages in the long-tail distribution and enabling
multimodal learning from non-parallel data. However, existing approaches based
on phones often rely on costly resources such as grapheme-to-phoneme converters
(G2Ps) and struggle to generalize to languages with ambiguous phoneme
boundaries due to training instability. In this paper, we address both
challenges by introducing a syllable-level UASR framework based on masked
language modeling, which avoids the need for G2P and the instability of
GAN-based methods. Our approach achieves up to a 40\% relative reduction in
character error rate (CER) on LibriSpeech and generalizes effectively to
Mandarin, a language that has remained particularly difficult for prior
methods. Code will be released upon acceptance.

</details>


### [192] [UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG](https://arxiv.org/abs/2510.03663)
*Xiangyu Peng,Cab Qin,Zeyuan Chen,Ran Xu,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: UniDoc-Bench是首个大规模、真实的多模态检索增强生成基准，基于70k真实PDF页面构建，包含1,600个多模态QA对，支持四种范式的公平比较。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索增强生成评估存在碎片化问题，要么只关注文本或图像，要么使用简化的多模态设置，无法捕捉文档中心的多模态使用场景。

Method: 从8个领域的70k真实PDF页面中提取并链接文本、表格和图像证据，生成1,600个多模态QA对，涵盖事实检索、比较、摘要和逻辑推理查询，其中20%经过多标注者和专家验证。

Result: 多模态文本-图像融合RAG系统在性能上持续优于单模态和联合多模态嵌入检索，表明单独使用文本或图像都不足够，且当前多模态嵌入仍不充分。

Conclusion: 该基准不仅提供公平比较框架，还揭示了视觉上下文何时以及如何补充文本证据，识别了系统性失败模式，并为开发更稳健的MM-RAG管道提供了可行指导。

Abstract: Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.

</details>


### [193] [Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text](https://arxiv.org/abs/2510.03683)
*Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov*

Main category: cs.CL

TL;DR: 提出基于QLoRA的微调框架，用于改进罗马乌尔都语-英语混合文本中的冒犯性语言检测，通过翻译处理低资源输入，在多个LLM中LLaMA 3 8B获得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 罗马乌尔都语等代码混合语言中的贬义词汇检测面临语法不明确、拼写不一致和标注数据稀缺的挑战。

Method: 使用Google Translate将罗马乌尔都语-英语混合数据集翻译为英语，利用QLoRA对多个Transformer和大型语言模型进行内存高效的微调。

Result: LLaMA 3 8B获得最高F1分数91.45，Mistral 7B为89.66，均优于传统Transformer基线模型。

Conclusion: QLoRA在低资源环境下的代码混合冒犯性语言检测中有效，证实了LLM在此任务中的潜力，为基于LLM的多语言冒犯检测系统铺平道路。

Abstract: The use of derogatory terms in languages that employ code mixing, such as
Roman Urdu, presents challenges for Natural Language Processing systems due to
unstated grammar, inconsistent spelling, and a scarcity of labeled data. In
this work, we propose a QLoRA based fine tuning framework to improve offensive
language detection in Roman Urdu-English text. We translated the Roman
Urdu-English code mixed dataset into English using Google Translate to leverage
English LLMs, while acknowledging that this translation reduces direct
engagement with code mixing features. Our focus is on classification
performance using English translated low resource inputs. We fine tuned several
transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B
v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient
adaptation. Models were trained and evaluated on a manually annotated Roman
Urdu dataset for offensive vs non offensive content. Of all tested models, the
highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral
7B at 89.66, surpassing traditional transformer baselines. These results
demonstrate the efficacy of QLoRA in fine tuning high performing models for low
resource environments such as code mixed offensive language detection, and
confirm the potential of LLMs for this task. This work advances a scalable
approach to Roman Urdu moderation and paves the way for future multilingual
offensive detection systems based on LLMs.

</details>


### [194] [MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction](https://arxiv.org/abs/2510.03687)
*Yue Huang,Yanyuan Chen,Dexuan Xu,Weihua Yue,Huamin Zhang,Meikang Qiu,Yu Huang*

Main category: cs.CL

TL;DR: MedReflect是一个通用框架，通过模拟医生反思思维模式，让LLM在医学问题解决中进行自我验证和反思，无需外部检索或大量标注，显著提升性能并降低标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部知识检索或大量标注数据，存在检索开销大、标注成本高的问题，且性能有限。需要一种能激发LLM内在能力的方法。

Method: 提出MedReflect框架，生成单次反思链：初始假设生成→自我提问→自我回答→决策精炼，实现自我验证和反思。

Result: 仅用2000个训练样本和轻量微调，就在多个医学基准上取得显著准确率提升，大幅减少标注需求。

Conclusion: LLM可以通过自我反思学习解决专业医学问题，减少对外部监督和大量任务特定微调数据的依赖。

Abstract: Medical problem solving demands expert knowledge and intricate reasoning.
Recent studies of large language models (LLMs) attempt to ease this complexity
by introducing external knowledge verification through retrieval-augmented
generation or by training on reasoning datasets. However, these approaches
suffer from drawbacks such as retrieval overhead and high annotation costs, and
they heavily rely on substituted external assistants to reach limited
performance in medical field. In this paper, we introduce MedReflect, a
generalizable framework designed to inspire LLMs with a physician-like
reflective thinking mode. MedReflect generates a single-pass reflection chain
that includes initial hypothesis generation, self-questioning, self-answering
and decision refinement. This self-verified and self-reflective nature releases
large language model's latent capability in medical problem-solving without
external retrieval or heavy annotation. We demonstrate that MedReflect enables
cost-efficient medical dataset construction: with merely 2,000 randomly sampled
training examples and a light fine-tuning, this approach achieves notable
absolute accuracy improvements across a series of medical benchmarks while
cutting annotation requirements. Our results provide evidence that LLMs can
learn to solve specialized medical problems via self-reflection and
self-improve, reducing reliance on external supervision and extensive
task-specific fine-tuning data.

</details>


### [195] [TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation](https://arxiv.org/abs/2510.03748)
*Ramtin Kakavand,Ebrahim Ansari*

Main category: cs.CL

TL;DR: TreePrompt：一种基于树形框架学习LLM偏好的示例选择方法，通过结合相似性和质量来提升机器翻译性能


<details>
  <summary>Details</summary>
Motivation: 现有示例选择方法仅关注查询与示例的相似性，忽略了示例质量对翻译效果的影响

Method: 提出TreePrompt方法，在树形框架中学习LLM偏好以识别高质量上下文相关示例，并与K-NN和AFSP方法结合

Result: 在英-波斯语(MIZAN)和英-德语(WMT19)上的评估显示，TreePrompt与AFSP或随机选择结合能提升翻译性能

Conclusion: TreePrompt通过平衡相似性和质量，有效提升了少样本提示在机器翻译中的效果

Abstract: Large Language Models (LLMs) have consistently demonstrated strong
performance in machine translation, especially when guided by high-quality
prompts. Few-shot prompting is an effective technique to improve translation
quality; however, most existing example selection methods focus solely on
query-to-example similarity and do not account for the quality of the examples.
In this work, we propose TreePrompt, a novel example selection approach that
learns LLM preferences to identify high-quality, contextually relevant examples
within a tree-structured framework. To further explore the balance between
similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)
and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -
English-Persian (MIZAN) and English-German (WMT19) - show that integrating
TreePrompt with AFSP or Random selection leads to improved translation
performance.

</details>


### [196] [Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's Disease Diagnosis from Speech](https://arxiv.org/abs/2510.03758)
*Ilias Tougui,Mehdi Zakroum,Mounir Ghogho*

Main category: cs.CL

TL;DR: 提出了一种基于语音细粒度分析的帕金森病检测方法，通过分析音素、音节和单词级别的语音特征，在意大利语、西班牙语和英语数据集上实现了93.78%的AUROC和92.17%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前基于语音的帕金森病检测系统通常分析整个话语，可能忽略了特定语音元素的诊断价值。高达89%的帕金森病患者存在语音障碍，需要更精细的分析方法。

Method: 开发了细粒度感知的多语言PD检测方法，使用自动化流程从录音中提取时间对齐的音素、音节和单词。采用双向LSTM和多头注意力机制，在不同粒度级别上比较诊断性能。

Result: 音素级分析表现最佳，AUROC达93.78%±2.34%，准确率达92.17%±2.43%。注意力分析显示最有信息的语音特征与临床协议一致：音素级的持续元音、音节级的交替运动音节和单词级的/pataka/序列。

Conclusion: 该方法显著提升了跨语言帕金森病检测的诊断能力，证明了细粒度语音分析的有效性，且发现的诊断特征与临床实践相符。

Abstract: Parkinson's Disease (PD) affects over 10 million people worldwide, with
speech impairments in up to 89% of patients. Current speech-based detection
systems analyze entire utterances, potentially overlooking the diagnostic value
of specific phonetic elements. We developed a granularity-aware approach for
multilingual PD detection using an automated pipeline that extracts
time-aligned phonemes, syllables, and words from recordings. Using Italian,
Spanish, and English datasets, we implemented a bidirectional LSTM with
multi-head attention to compare diagnostic performance across the different
granularity levels. Phoneme-level analysis achieved superior performance with
AUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates
enhanced diagnostic capability for cross-linguistic PD detection. Importantly,
attention analysis revealed that the most informative speech features align
with those used in established clinical protocols: sustained vowels (/a/, /e/,
/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)
at syllable level, and /pataka/ sequences at word level. Source code will be
available at https://github.com/jetliqs/clearpd.

</details>


### [197] [Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs](https://arxiv.org/abs/2510.03762)
*Deshan Sumanathilaka,Nicholas Micallef,Julian Hough*

Main category: cs.CL

TL;DR: 研究探讨了少样本提示策略对词义消歧任务的影响，特别关注样本分布不平衡引入的偏差问题，发现多语言环境下不平衡样本会导致错误预测，而英语中不存在此问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，少样本提示因其实用性和有效性受到广泛关注。本研究旨在调查少样本提示策略如何影响词义消歧任务，特别是由样本分布不平衡引起的偏差问题。

Method: 使用GLOSSGPT提示方法，在英语、德语、西班牙语、法语和意大利语五种语言上测试其有效性，评估GPT-4o和LLaMA-3.1-70B模型的行为表现。

Result: 结果显示，不平衡的少样本示例会导致多语言环境中的错误词义预测，但英语中未出现此问题。多语言词义消歧对少样本设置中的样本分布非常敏感。

Conclusion: 研究强调了在多语言词义消歧任务中需要采用平衡且具有代表性的提示策略，以避免样本分布不平衡带来的偏差影响。

Abstract: Recent advances in Large Language Models (LLMs) have significantly reshaped
the landscape of Natural Language Processing (NLP). Among the various prompting
techniques, few-shot prompting has gained considerable attention for its
practicality and effectiveness. This study investigates how few-shot prompting
strategies impact the Word Sense Disambiguation (WSD) task, particularly
focusing on the biases introduced by imbalanced sample distributions. We use
the GLOSSGPT prompting method, an advanced approach for English WSD, to test
its effectiveness across five languages: English, German, Spanish, French, and
Italian. Our results show that imbalanced few-shot examples can cause incorrect
sense predictions in multilingual languages, but this issue does not appear in
English. To assess model behavior, we evaluate both the GPT-4o and
LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual
WSD to sample distribution in few-shot settings, emphasizing the need for
balanced and representative prompting strategies.

</details>


### [198] [Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development](https://arxiv.org/abs/2510.03781)
*Majid Asgari-Bidhendi,Muhammad Amin Ghaseminia,Alireza Shahbazi,Sayyed Ali Hossayni,Najmeh Torabian,Behrouz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: 开发了Rezwan大规模AI辅助圣训语料库，包含120万条圣训，通过全自动流水线提取和结构化，实现了多语言翻译、智能标音、摘要生成等功能，在规模和质量上都优于人工标注的Noor语料库。


<details>
  <summary>Details</summary>
Motivation: 传统圣训文本处理依赖人工专家，耗时耗力且难以大规模扩展。需要利用AI技术实现自动化处理，为数字人文和伊斯兰研究提供丰富标注的研究基础设施。

Method: 基于数字资源库，使用大语言模型进行分段、传述链-文本分离、验证和多层增强，包括机器翻译、智能标音、摘要生成、主题标注和跨文本语义分析。

Result: 在1,213条随机样本评估中，传述链-文本分离和摘要生成接近人类准确度(9.33/10)，总体评分8.46/10显著优于人工语料库的3.66/10，成本效益显著。

Conclusion: AI可以增强人类专业知识，实现大规模、多语言和语义丰富的伊斯兰遗产访问，为宗教文本处理引入新范式。

Abstract: This paper presents the development of Rezwan, a large-scale AI-assisted
Hadith corpus comprising over 1.2M narrations, extracted and structured through
a fully automated pipeline. Building on digital repositories such as Maktabat
Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for
segmentation, chain--text separation, validation, and multi-layer enrichment.
Each narration is enhanced with machine translation into twelve languages,
intelligent diacritization, abstractive summarization, thematic tagging, and
cross-text semantic analysis. This multi-step process transforms raw text into
a richly annotated research-ready infrastructure for digital humanities and
Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled
narrations, assessed by six domain experts. Results show near-human accuracy in
structured tasks such as chain--text separation (9.33/10) and summarization
(9.33/10), while highlighting ongoing challenges in diacritization and semantic
similarity detection. Comparative analysis against the manually curated Noor
Corpus demonstrates the superiority of Najm in both scale and quality, with a
mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis
confirms the economic feasibility of the AI approach: tasks requiring over
229,000 hours of expert labor were completed within months at a fraction of the
cost. The work introduces a new paradigm in religious text processing by
showing how AI can augment human expertise, enabling large-scale, multilingual,
and semantically enriched access to Islamic heritage.

</details>


### [199] [Mechanistic Interpretability of Socio-Political Frames in Language Models](https://arxiv.org/abs/2510.03799)
*Hadi Asghari,Sami Nenno*

Main category: cs.CL

TL;DR: LLMs能够生成和识别深层认知框架，特别是在社会政治语境中。研究发现LLMs在零样本设置下能有效识别这些框架，并通过机制可解释性研究定位了特定框架在模型隐藏表示中的位置。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在生成和识别深层认知框架方面的能力，特别是在社会政治语境中，以理解LLMs如何捕捉和表达有意义的人类概念。

Method: 采用机制可解释性研究方法，分析LLMs在零样本设置下生成和识别文本框架的能力，并识别模型隐藏表示中与特定框架强相关的单一维度。

Result: LLMs在生成唤起特定框架的文本方面表现出高度流畅性，在零样本设置下能有效识别这些框架。研究发现'严格父亲'和'养育父母'框架在模型隐藏表示中有特定的相关维度。

Conclusion: 该研究有助于理解LLMs如何捕捉和表达有意义的人类概念，揭示了特定认知框架在模型内部表示中的具体位置，为LLMs的机制可解释性研究提供了新的见解。

Abstract: This paper explores the ability of large language models to generate and
recognize deep cognitive frames, particularly in socio-political contexts. We
demonstrate that LLMs are highly fluent in generating texts that evoke specific
frames and can recognize these frames in zero-shot settings. Inspired by
mechanistic interpretability research, we investigate the location of the
`strict father' and `nurturing parent' frames within the model's hidden
representation, identifying singular dimensions that correlate strongly with
their presence. Our findings contribute to understanding how LLMs capture and
express meaningful human concepts.

</details>


### [200] [Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models](https://arxiv.org/abs/2510.03805)
*Canhui Wu,Qiong Cao,Chang Li,Zhenfang Wang,Chao Xue,Yuwei Fan,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: Step Pruner (SP)是一个RL框架，通过惩罚冗余推理步骤来减少大型推理模型的过度思考问题，在保持准确性的同时显著降低响应长度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在过度思考问题，现有基于token惩罚的RL方法面临两个挑战：更少的token不一定对应更少的推理步骤，模型可能在训练后期通过丢弃推理步骤来最小化token使用。

Method: 提出Step Pruner框架，使用步骤感知的奖励函数，优先考虑正确性同时惩罚冗余步骤，对错误响应不给予奖励；引入动态停止机制，当任何输出步骤长度超过上限时停止更新以防止步骤合并。

Result: 在四个推理基准测试中，SP实现了最先进的准确性，同时显著减少响应长度。在AIME24上，token使用量减少了69.7%。

Conclusion: SP框架有效解决了大型推理模型的过度思考问题，通过步骤级别的优化实现了更高效的推理过程。

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks
but often suffer from excessive verbosity, known as "overthinking." Existing
solutions via reinforcement learning (RL) typically penalize generated tokens
to promote conciseness. However, these methods encounter two challenges:
responses with fewer tokens do not always correspond to fewer reasoning steps,
and models may develop hacking behavior in later stages of training by
discarding reasoning steps to minimize token usage. In this work, we introduce
\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more
efficient reasoning by favoring compact reasoning steps. Our step-aware reward
function prioritizes correctness while imposing penalties for redundant steps,
and withholds rewards for incorrect responses to prevent the reinforcement of
erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when
the length of any output step exceeds the upper limit, we halt updates to
prevent hacking behavior caused by merging steps. Extensive experiments across
four reasoning benchmarks demonstrate that SP achieves state-of-the-art
accuracy while significantly reducing response length. For instance, on AIME24,
SP reduces token usage by \textbf{69.7\%}.

</details>


### [201] [Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches](https://arxiv.org/abs/2510.03808)
*Mehedi Hasan Emon*

Main category: cs.CL

TL;DR: 本研究使用INCEpTION工具标注语篇修辞关系，比较手动标注与基于大语言模型的自动方法。在板球新闻语料上评估BERT、DistilBERT和逻辑回归模型对修辞关系的分类性能，发现DistilBERT准确率最高。


<details>
  <summary>Details</summary>
Motivation: 探索修辞关系标注方法，比较手动与自动标注的效果，推动语篇分析与基于Transformer的自然语言处理技术的结合。

Method: 使用INCEpTION工具进行手动标注，并采用BERT、DistilBERT和逻辑回归模型自动分类修辞关系（如阐述、对比、背景、因果等）。

Result: DistilBERT模型在修辞关系分类中取得了最高准确率，显示出其在语篇关系预测中的高效潜力。

Conclusion: 本研究证明了基于Transformer的模型（特别是DistilBERT）在语篇修辞关系分类中的有效性，为语篇分析与NLP技术的融合提供了实证支持。

Abstract: This research explores the annotation of rhetorical relations in discourse
using the INCEpTION tool and compares manual annotation with automatic
approaches based on large language models. The study focuses on sports reports
(specifically cricket news) and evaluates the performance of BERT, DistilBERT,
and Logistic Regression models in classifying rhetorical relations such as
elaboration, contrast, background, and cause-effect. The results show that
DistilBERT achieved the highest accuracy, highlighting its potential for
efficient discourse relation prediction. This work contributes to the growing
intersection of discourse parsing and transformer-based NLP. (This paper was
conducted as part of an academic requirement under the supervision of Prof. Dr.
Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:
Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,
NLP.

</details>


### [202] [Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles](https://arxiv.org/abs/2510.03898)
*Nusrat Jahan Lia,Shubhashis Roy Dipta,Abdullah Khan Zehady,Naymul Islam,Madhusodan Chakraborty,Abdullah Al Wasif*

Main category: cs.CL

TL;DR: 提出了首个孟加拉语政治立场检测基准数据集，包含200篇新闻文章，标注了亲政府、批评政府和中性立场，并评估了28个大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 南亚地区的媒体偏见检测很重要，但孟加拉语政治立场研究缺乏标注数据集和计算研究，需要理解语言线索、文化背景、微妙偏见等多重因素。

Method: 创建了包含200篇孟加拉语新闻文章的基准数据集，标注三种政治立场，并对28个专有和开源大语言模型进行全面评估。

Result: 模型在检测批评政府内容方面表现良好（F1最高0.83），但在中性文章上表现很差（F1最低0.00），模型倾向于过度预测亲政府立场。

Conclusion: 该数据集和诊断分析为推进孟加拉语媒体立场检测研究奠定了基础，并为改善低资源语言中大语言模型的性能提供了见解。

Abstract: Detecting media bias is crucial, specifically in the South Asian region.
Despite this, annotated datasets and computational studies for Bangla political
bias research remain scarce. Crucially because, political stance detection in
Bangla news requires understanding of linguistic cues, cultural context, subtle
biases, rhetorical strategies, code-switching, implicit sentiment, and
socio-political background. To address this, we introduce the first benchmark
dataset of 200 politically significant and highly debated Bangla news articles,
labeled for government-leaning, government-critique, and neutral stances,
alongside diagnostic analyses for evaluating large language models (LLMs). Our
comprehensive evaluation of 28 proprietary and open-source LLMs shows strong
performance in detecting government-critique content (F1 up to 0.83) but
substantial difficulty with neutral articles (F1 as low as 0.00). Models also
tend to over-predict government-leaning stances, often misinterpreting
ambiguous narratives. This dataset and its associated diagnostics provide a
foundation for advancing stance detection in Bangla media research and offer
insights for improving LLM performance in low-resource languages.

</details>


### [203] [PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian](https://arxiv.org/abs/2510.03913)
*Mohammad Amin Abbasi,Hassan Naderi*

Main category: cs.CL

TL;DR: PsychoLexTherapy是一个用于波斯语心理治疗推理模拟的框架，使用小型语言模型，支持设备端部署，确保隐私和可行性。


<details>
  <summary>Details</summary>
Motivation: 开发针对低资源语言的文化适应、治疗连贯的对话系统，解决多轮交互中的结构化记忆挑战。

Method: 三阶段开发：评估SLMs心理知识、设计推理导向框架、构建评估数据集；比较简单提示、多代理辩论和结构化治疗推理路径。

Result: 在单轮评估中表现最佳，多轮测试中长时记忆模块至关重要，完整框架在共情、连贯性、文化适应和个性化方面获得最高评分。

Conclusion: 为波斯语心理治疗模拟建立了实用、隐私保护且文化对齐的基础，贡献了新颖数据集、可复现评估流程和结构化记忆的实证见解。

Abstract: This study presents PsychoLexTherapy, a framework for simulating
psychotherapeutic reasoning in Persian using small language models (SLMs). The
framework tackles the challenge of developing culturally grounded,
therapeutically coherent dialogue systems with structured memory for multi-turn
interactions in underrepresented languages. To ensure privacy and feasibility,
PsychoLexTherapy is optimized for on-device deployment, enabling use without
external servers. Development followed a three-stage process: (i) assessing
SLMs psychological knowledge with PsychoLexEval; (ii) designing and
implementing the reasoning-oriented PsychoLexTherapy framework; and (iii)
constructing two evaluation datasets-PsychoLexQuery (real Persian user
questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark
against multiple baselines. Experiments compared simple prompting, multi-agent
debate, and structured therapeutic reasoning paths. Results showed that
deliberate model selection balanced accuracy, efficiency, and privacy. On
PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic
LLM-as-a-judge evaluation and was ranked highest by human evaluators in a
single-turn preference study. In multi-turn tests with PsychoLexDialogue, the
long-term memory module proved essential: while naive history concatenation
caused incoherence and information loss, the full framework achieved the
highest ratings in empathy, coherence, cultural fit, and personalization.
Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and
culturally aligned foundation for Persian psychotherapy simulation,
contributing novel datasets, a reproducible evaluation pipeline, and empirical
insights into structured memory for therapeutic reasoning.

</details>


### [204] [Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs](https://arxiv.org/abs/2510.03997)
*Junjie Luo,Rui Han,Arshana Welivita,Zeleikun Di,Jingfu Wu,Xuzhe Zhi,Ritu Agarwal,Gordon Gao*

Main category: cs.CL

TL;DR: 使用LLM从410万患者评价中提取医生的大五人格特质和主观判断，验证了方法的有效性，并发现男性医生评分更高、儿科和精神病科更看重同理心等系统性模式。


<details>
  <summary>Details</summary>
Motivation: 理解患者对医生的看法对于改善信任、沟通和满意度至关重要，需要大规模分析患者评价来获得可解释的指标。

Method: 基于大语言模型的流水线，分析410万条患者评价，通过多模型比较和人类专家基准验证方法有效性。

Result: 人类与LLM评估高度一致（相关系数0.72-0.89），与患者满意度显著相关（r=0.41-0.81），发现男性医生评分更高、不同专科特质偏好差异等系统性模式。

Conclusion: 从患者叙述中自动提取特质可以提供可解释、经过验证的指标，用于大规模理解医患关系，对质量测量、偏见检测和医疗人力发展具有重要意义。

Abstract: Understanding how patients perceive their physicians is essential to
improving trust, communication, and satisfaction. We present a large language
model (LLM)-based pipeline that infers Big Five personality traits and five
patient-oriented subjective judgments. The analysis encompasses 4.1 million
patient reviews of 226,999 U.S. physicians from an initial pool of one million.
We validate the method through multi-model comparison and human expert
benchmarking, achieving strong agreement between human and LLM assessments
(correlation coefficients 0.72-0.89) and external validity through correlations
with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis
reveals systematic patterns: male physicians receive higher ratings across all
traits, with largest disparities in clinical competence perceptions;
empathy-related traits predominate in pediatrics and psychiatry; and all traits
positively predict overall satisfaction. Cluster analysis identifies four
distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly
high traits) to "Underperforming" (22.6%, consistently low). These findings
demonstrate that automated trait extraction from patient narratives can provide
interpretable, validated metrics for understanding physician-patient
relationships at scale, with implications for quality measurement, bias
detection, and workforce development in healthcare.

</details>


### [205] [Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions](https://arxiv.org/abs/2510.03999)
*Yang Xu,Xuanming Zhang,Min-Hsuan Yeh,Jwala Dhamala,Ousmane Dia,Rahul Gupta,Yixuan Li*

Main category: cs.CL

TL;DR: 提出了首个用于在长序列相互依赖任务和动态情境压力下探测和评估LLM欺骗行为的模拟框架，通过多智能体系统研究发现欺骗行为具有模型依赖性、随事件压力增加，并会持续削弱监督者信任。


<details>
  <summary>Details</summary>
Motivation: 欺骗是人类沟通的普遍特征，也是大型语言模型(LLM)中日益关注的问题。现有研究大多局限于单轮提示，未能捕捉欺骗策略通常展开的长时程交互过程。

Method: 构建多智能体模拟框架：执行者智能体完成任务，监督者智能体评估进展、提供反馈并维护信任状态，独立的欺骗审计员审查完整轨迹以识别欺骗行为。在11个前沿模型上进行广泛实验。

Result: 发现欺骗行为具有模型依赖性，随事件压力增加而增加，并持续削弱监督者信任。定性分析揭示了隐瞒、含糊其辞和伪造等不同欺骗策略。

Conclusion: 研究确立了在长时程交互中欺骗作为新兴风险的存在，为评估未来LLM在现实世界信任敏感环境中的表现提供了基础。

Abstract: Deception is a pervasive feature of human communication and an emerging
concern in large language models (LLMs). While recent studies document
instances of LLM deception under pressure, most evaluations remain confined to
single-turn prompts and fail to capture the long-horizon interactions in which
deceptive strategies typically unfold. We introduce the first simulation
framework for probing and evaluating deception in LLMs under extended sequences
of interdependent tasks and dynamic contextual pressures. Our framework
instantiates a multi-agent system: a performer agent tasked with completing
tasks and a supervisor agent that evaluates progress, provides feedback, and
maintains evolving states of trust. An independent deception auditor then
reviews full trajectories to identify when and how deception occurs. We conduct
extensive experiments across 11 frontier models, spanning both closed- and
open-source systems, and find that deception is model-dependent, increases with
event pressure, and consistently erodes supervisor trust. Qualitative analyses
further reveal distinct strategies of concealment, equivocation, and
falsification. Our findings establish deception as an emergent risk in
long-horizon interactions and provide a foundation for evaluating future LLMs
in real-world, trust-sensitive contexts.

</details>


### [206] [Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation](https://arxiv.org/abs/2510.04001)
*Xuankang Zhang,Jiangming Liu*

Main category: cs.CL

TL;DR: 提出了一种新颖的实体知识增强方法，用于COVID-19命名实体识别，解决了社交媒体文本中标注数据稀缺和领域知识需求的问题。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情期间社交媒体讨论活跃，但相关命名实体识别面临挑战：社交媒体文本非正式且标注稀缺，识别需要大量领域专业知识。

Method: 采用实体知识增强方法，通过增强模型对领域知识的理解来提升命名实体识别性能，适用于非正式和正式文本格式。

Result: 在COVID-19推文数据集和PubMed数据集上的实验表明，该方法在完全监督和少样本设置下都能提升NER性能。

Conclusion: 提出的实体知识增强方法有效解决了COVID-19命名实体识别中的挑战，在社交媒体和生物医学文本中均有良好表现。

Abstract: The COVID-19 pandemic causes severe social and economic disruption around the
world, raising various subjects that are discussed over social media.
Identifying pandemic-related named entities as expressed on social media is
fundamental and important to understand the discussions about the pandemic.
However, there is limited work on named entity recognition on this topic due to
the following challenges: 1) COVID-19 texts in social media are informal and
their annotations are rare and insufficient to train a robust recognition
model, and 2) named entity recognition in COVID-19 requires extensive
domain-specific knowledge. To address these issues, we propose a novel entity
knowledge augmentation approach for COVID-19, which can also be applied in
general biomedical named entity recognition in both informal text format and
formal text format. Experiments carried out on the COVID-19 tweets dataset and
PubMed dataset show that our proposed entity knowledge augmentation improves
NER performance in both fully-supervised and few-shot settings. Our source code
is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master

</details>


### [207] [AgriGPT-VL: Agricultural Vision-Language Understanding Suite](https://arxiv.org/abs/2510.04002)
*Bo Yang,Yunkui Chen,Lanfei Feng,Yu Zhang,Xiao Xu,Jianyu Zhang,Nueraili Aierken,Runhe Huang,Hongjian Lin,Yibin Ying,Shijian Li*

Main category: cs.CL

TL;DR: 提出了AgriGPT-VL套件，包含最大的农业视觉语言语料库Agri-3M-VL、专门训练的农业视觉语言模型AgriGPT-VL和评估套件AgriBench-VL-4K，在农业任务上超越通用VLMs且保持文本能力。


<details>
  <summary>Details</summary>
Motivation: 解决农业领域缺乏定制化模型、标注视觉语言语料库和严格评估的问题，推动农业AI应用发展。

Method: 使用可扩展多智能体数据生成器构建Agri-3M-VL语料库；通过渐进式课程训练AgriGPT-VL模型，包括文本基础、多模态浅层/深层对齐和GRPO优化；建立多指标评估框架。

Result: AgriGPT-VL在AgriBench-VL-4K上优于领先通用VLMs，在LLM-as-a-judge评估中获得更高胜率，同时在文本任务上保持竞争力。

Conclusion: AgriGPT-VL套件为农业AI提供了全面的解决方案，在保持语言能力的同时显著提升多模态推理性能，将开源支持低资源农业环境应用。

Abstract: Despite rapid advances in multimodal large language models, agricultural
applications remain constrained by the scarcity of domain-tailored models,
curated vision-language corpora, and rigorous evaluation. To address these
challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for
agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,
the largest vision-language corpus for agriculture to our knowledge, curated by
a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M
image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO
reinforcement learning samples. Second, we develop AgriGPT-VL, an
agriculture-specialized vision-language model trained via a progressive
curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO
refinement. This method achieves strong multimodal reasoning while preserving
text-only capability. Third, we establish AgriBench-VL-4K, a compact yet
challenging evaluation suite with open-ended and image-grounded questions,
paired with multi-metric evaluation and an LLM-as-a-judge framework.
Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on
AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge
evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K
with no noticeable degradation of language ability. Ablation studies further
confirm consistent gains from our alignment and GRPO refinement stages. We will
open source all of the resources to support reproducible research and
deployment in low-resource agricultural settings.

</details>


### [208] [LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization](https://arxiv.org/abs/2510.04013)
*Jiarui Liu,Jivitesh Jain,Mona Diab,Nishant Subramani*

Main category: cs.CL

TL;DR: 使用模型内部激活信号预测LLM输出正确性和上下文有效性，通过简单分类器实现75%准确率的早期审计，显著优于提示基准。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型具有巨大效用，但可信度仍是主要问题：模型经常以高置信度生成错误信息。虽然上下文信息可以指导生成，但识别何时查询需要检索上下文以及评估上下文有效性仍然具有挑战性。

Method: 操作化可解释性方法，从模型激活中预测输出正确性；探索模型内部是否包含外部上下文有效性的信号；考虑正确、错误和不相关的上下文，并引入指标进行区分；在六个不同模型上进行实验。

Result: 基于第一个输出token的中间层激活训练的简单分类器可以以约75%的准确率预测输出正确性，实现早期审计；基于模型内部的指标在区分正确和错误上下文方面显著优于提示基准，防止受污染上下文引入的不准确性。

Conclusion: 这些发现提供了一个视角来更好地理解LLMs的底层决策过程，为模型可信度评估提供了新方法。

Abstract: Although large language models (LLMs) have tremendous utility,
trustworthiness is still a chief concern: models often generate incorrect
information with high confidence. While contextual information can help guide
generation, identifying when a query would benefit from retrieved context and
assessing the effectiveness of that context remains challenging. In this work,
we operationalize interpretability methods to ascertain whether we can predict
the correctness of model outputs from the model's activations alone. We also
explore whether model internals contain signals about the efficacy of external
context. We consider correct, incorrect, and irrelevant context and introduce
metrics to distinguish amongst them. Experiments on six different models reveal
that a simple classifier trained on intermediate layer activations of the first
output token can predict output correctness with about 75% accuracy, enabling
early auditing. Our model-internals-based metric significantly outperforms
prompting baselines at distinguishing between correct and incorrect context,
guarding against inaccuracies introduced by polluted context. These findings
offer a lens to better understand the underlying decision-making processes of
LLMs. Our code is publicly available at
https://github.com/jiarui-liu/LLM-Microscope

</details>


### [209] [Thai Semantic End-of-Turn Detection for Real-Time Voice Agents](https://arxiv.org/abs/2510.04016)
*Thanapol Popit,Natthapath Rungseesiripak,Monthol Charattrakool,Saksorn Ruangtanusak*

Main category: cs.CL

TL;DR: 本文系统研究了泰语文本端到端对话结束检测，比较了零样本/少样本提示与监督微调方法，建立了泰语基准并展示了轻量级模型可实现近乎实时的检测。


<details>
  <summary>Details</summary>
Motivation: 传统音频静音端点检测存在数百毫秒延迟，且在犹豫或语言特定现象下失效，需要更可靠的实时对话结束检测方法。

Method: 使用YODAS语料库的转录字幕和泰语特定语言线索，将对话结束检测制定为标记边界上的二元决策，比较了紧凑LLM的零样本/少样本提示与轻量级transformer的监督微调。

Result: 报告了清晰的准确率-延迟权衡，展示了小型微调模型能够提供近乎实时的对话结束决策，适合设备端代理使用。

Conclusion: 这项工作建立了泰语基准，并证明小型微调模型可以提供适合设备端代理的近乎实时对话结束检测。

Abstract: Fluid voice-to-voice interaction requires reliable and low-latency detection
of when a user has finished speaking. Traditional audio-silence end-pointers
add hundreds of milliseconds of delay and fail under hesitations or
language-specific phenomena. We present, to our knowledge, the first systematic
study of Thai text-only end-of-turn (EOT) detection for real-time agents. We
compare zero-shot and few-shot prompting of compact LLMs to supervised
fine-tuning of lightweight transformers. Using transcribed subtitles from the
YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final
particles), we formulate EOT as a binary decision over token boundaries. We
report a clear accuracy-latency tradeoff and provide a public-ready
implementation plan. This work establishes a Thai baseline and demonstrates
that small, fine-tuned models can deliver near-instant EOT decisions suitable
for on-device agents.

</details>


### [210] [Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?](https://arxiv.org/abs/2510.04031)
*Nelvin Tan,James Asikin Cheung,Yu-Ching Shih,Dong Yang,Amol Salunkhe*

Main category: cs.CL

TL;DR: 该论文研究如何通过反事实推理来帮助解释大型语言模型(LLMs)在文本分类任务中的决策，提出了决策改变率框架来量化关键词的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs通常是黑盒模型且调用成本高昂，需要开发有效的方法来解释其分类决策，特别是在文本分类任务中。

Method: 引入反事实推理到LLM决策过程中，提出了决策改变率框架来量化关键词对分类结果的影响程度。

Result: 实验结果表明，使用反事实推理方法能够有效帮助识别对LLM分类决策最重要的关键词。

Conclusion: 反事实推理是解释LLM分类决策的有效方法，决策改变率框架能够量化关键词的重要性。

Abstract: Large language models (LLMs) are becoming useful in many domains due to their
impressive abilities that arise from large training datasets and large model
sizes. More recently, they have been shown to be very effective in textual
classification tasks, motivating the need to explain the LLMs' decisions.
Motivated by practical constrains where LLMs are black-boxed and LLM calls are
expensive, we study how incorporating counterfactuals into LLM reasoning can
affect the LLM's ability to identify the top words that have contributed to its
classification decision. To this end, we introduce a framework called the
decision changing rate that helps us quantify the importance of the top words
in classification. Our experimental results show that using counterfactuals can
be helpful.

</details>


### [211] [Small Language Models for Emergency Departments Decision Support: A Benchmark Study](https://arxiv.org/abs/2510.04032)
*Zirui Wang,Jiajun Wu,Braden Teitge,Jessalyn Holodinsky,Steve Drew*

Main category: cs.CL

TL;DR: 该论文提出了一个专门针对急诊部门的基准测试，评估小型语言模型在医疗决策支持中的表现，发现通用领域的小型语言模型在急诊场景下表现优于医学微调的模型。


<details>
  <summary>Details</summary>
Motivation: 考虑到急诊部门的高风险环境和实际部署中的硬件限制、运营成本及隐私问题，需要评估小型语言模型在急诊决策支持中的适用性。

Method: 使用MedMCQA、MedQA-4Options和PubMedQA等基准数据集，模拟急诊医生的日常任务，评估在通用领域和医学语料上训练的小型语言模型。

Result: 实验结果显示，通用领域的小型语言模型在急诊相关基准测试中意外地优于医学微调的模型。

Conclusion: 对于急诊部门，可能不需要对模型进行专门的医学微调，通用领域的小型语言模型已能提供有效的决策支持。

Abstract: Large language models (LLMs) have become increasingly popular in medical
domains to assist physicians with a variety of clinical and operational tasks.
Given the fast-paced and high-stakes environment of emergency departments
(EDs), small language models (SLMs), characterized by a reduction in parameter
count compared to LLMs, offer significant potential due to their inherent
reasoning capability and efficient performance. This enables SLMs to support
physicians by providing timely and accurate information synthesis, thereby
improving clinical decision-making and workflow efficiency. In this paper, we
present a comprehensive benchmark designed to identify SLMs suited for ED
decision support, taking into account both specialized medical expertise and
broad general problem-solving capabilities. In our evaluations, we focus on
SLMs that have been trained on a mixture of general-domain and medical corpora.
A key motivation for emphasizing SLMs is the practical hardware limitations,
operational cost constraints, and privacy concerns in the typical real-world
deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and
PubMedQA, with the medical abstracts dataset emulating tasks aligned with real
ED physicians' daily tasks. Experimental results reveal that general-domain
SLMs surprisingly outperform their medically fine-tuned counterparts across
these diverse benchmarks for ED. This indicates that for ED, specialized
medical fine-tuning of the model may not be required.

</details>


### [212] [Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment](https://arxiv.org/abs/2510.04045)
*Yunfan Zhang,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 研究探索如何通过思维链技术让大语言模型支持可引导的多元主义，使模型能够采纳特定视角并生成相应输出。比较了多种方法，发现RLVR方法表现最佳且训练样本效率高。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通常反映相对统一的价值观念，限制了其在需要理解细微人类视角任务中的应用。需要开发能够支持可引导多元主义的能力。

Method: 研究了多种方法：思维链提示、基于人类撰写思维链的微调、基于合成解释的微调，以及带可验证奖励的强化学习(RLVR)。使用Value Kaleidoscope和OpinionQA数据集进行评估。

Result: 在所有研究方法中，RLVR方法持续优于其他方法，并展现出强大的训练样本效率。还对生成的思维链轨迹进行了忠实性和安全性分析。

Conclusion: 思维链技术可以有效构建可引导的多元主义模型，其中RLVR方法是最有效的方法，在性能和样本效率方面都表现出色。

Abstract: Large Language Models (LLMs) are typically trained to reflect a relatively
uniform set of values, which limits their applicability to tasks that require
understanding of nuanced human perspectives. Recent research has underscored
the importance of enabling LLMs to support steerable pluralism -- the capacity
to adopt a specific perspective and align generated outputs with it. In this
work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be
applied to building steerable pluralistic models. We explore several methods,
including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on
synthetic explanations, and Reinforcement Learning with Verifiable Rewards
(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA
datasets. Among the methods studied, RLVR consistently outperforms others and
demonstrates strong training sample efficiency. We further analyze the
generated CoT traces with respect to faithfulness and safety.

</details>


### [213] [What Makes Diffusion Language Models Super Data Learners?](https://arxiv.org/abs/2510.04071)
*Zitian Gao,Haoming Luo,Lynx Chen,Jason Klein Liu,Ran Tao,Joey Zhou,Bryan Dai*

Main category: cs.CL

TL;DR: 扩散语言模型在有限数据条件下表现出色，研究发现随机掩码输入标记是数据效率提升的主要因素，类似效果可通过MLP dropout和权重衰减实现。


<details>
  <summary>Details</summary>
Motivation: 理解扩散语言模型在有限数据约束下获得显著数据效率的底层机制

Method: 通过广泛的消融实验来分离数据效率的来源，分析随机掩码、MLP dropout和权重衰减的作用

Result: 随机掩码输入标记在数据效率提升中起主导作用，类似增益可通过MLP dropout和权重衰减获得

Conclusion: 随机正则化在多轮训练中广泛增强数据效率，随机掩码是扩散语言模型数据效率的关键因素

Abstract: Recent studies have shown that diffusion language models achieve remarkable
data efficiency under limited-data constraints, yet the underlying mechanisms
remain unclear. In this work, we perform extensive ablation experiments to
disentangle the sources of this efficiency. Our results show that random
masking of input tokens plays the dominant role. We further show that similar
gains can be obtained through in MLP dropout and weight decay, indicating that
stochastic regularization broadly enhances data efficiency in multi-epoch
training. Our code is available at
https://github.com/zitian-gao/data-efficiency.

</details>


### [214] [PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity](https://arxiv.org/abs/2510.04080)
*Zixin Song,Bowen Zhang,Qian-Wen Zhang,Di Yin,Xing Sun,Chunping Li*

Main category: cs.CL

TL;DR: 提出PoLi-RL框架，通过两阶段课程学习和并行切片排序奖励机制，成功将强化学习应用于条件语义文本相似度任务，在C-STS基准上达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有C-STS方法局限于判别模型，未能充分利用LLM和强化学习的突破。RL能直接优化不可微的Spearman排序指标，但简单的列表式RL因复杂奖励信号而失败。

Method: PoLi-RL框架：两阶段课程学习（先点式奖励建立基础能力，后混合点式、对式和列表式奖励），并行切片排序奖励机制（PSRR）提供精确的差异化学习信号。

Result: 在官方C-STS基准上达到Spearman相关系数48.18，为交叉编码器架构建立新的SOTA。

Conclusion: 首次成功将RL应用于C-STS任务，为在复杂排序条件判断任务上训练LLM提供了强大而精确的范式。

Abstract: Conditional Semantic Textual Similarity (C-STS) measures the semantic
proximity between text segments under a specific condition, thereby overcoming
the ambiguity inherent in traditional STS. However, existing methods are
largely confined to discriminative models, failing to fully integrate recent
breakthroughs in the NLP community concerning Large Language Models (LLMs) and
Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this
task, as it can directly optimize the non-differentiable Spearman ranking
metric and guide the reasoning process required by C-STS. However, we find that
naively applying listwise RL fails to produce meaningful improvements, as the
model is overwhelmed by complex, coarse-grained reward signals. To address this
challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning
framework. PoLi-RL employs a two-stage curriculum: it first trains the model
with simple pointwise rewards to establish fundamental scoring capabilities,
then transitions to a hybrid reward that combines pointwise, pairwise, and
listwise objectives to refine the model's ability to discern subtle semantic
distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward
(PSRR) mechanism that computes ranking rewards in parallel slices, where each
slice comprises same-indexed completions from different samples. This provides
a precise, differentiated learning signal for each individual completion,
enabling granular credit assignment and effective optimization. On the official
C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18,
establishing a new SOTA for the cross-encoder architecture. As the first work
to successfully apply RL to C-STS, our study introduces a powerful and precise
paradigm for training LLMs on complex, ranking-based conditional judgment
tasks.

</details>


### [215] [Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning](https://arxiv.org/abs/2510.04081)
*Honglin Lin,Qizhi Pei,Xin Gao,Zhuoshi Pan,Yu Li,Juntao Li,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 提出了Caco框架，通过代码驱动的增强方法自动合成高质量、可验证且多样化的指令-CoT推理数据，提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在生成不可控、质量不足和推理路径多样性有限的问题，而基于代码的方法通常局限于预定义的数学问题，阻碍了可扩展性和泛化性。

Method: 首先在统一代码格式的现有数学和编程解决方案上微调基于代码的CoT生成器，然后扩展到大量多样化的推理轨迹。通过代码执行和基于规则的过滤进行自动验证，确保逻辑正确性和结构多样性，最后将过滤后的输出反向工程为自然语言指令和语言CoT。

Result: 在创建的Caco-1.3M数据集上的实验表明，Caco训练的模型在数学推理基准上实现了强大的竞争性能，优于现有强基线。

Conclusion: Caco的代码锚定验证和指令多样性有助于在未见任务上实现优越的泛化能力，为构建自持续、可信赖的推理系统建立了范式。

Abstract: Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.

</details>


### [216] [Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence](https://arxiv.org/abs/2510.04120)
*Fengying Ye,Shanshan Wang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 该研究从概念映射、隐喻-字面知识库和句法敏感性三个角度分析大语言模型的隐喻理解能力，发现LLMs存在概念无关解释、依赖训练数据而非上下文线索、对句法异常更敏感等问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在知识整合、上下文推理和创造性生成方面表现出先进能力，但其隐喻理解机制仍未被充分探索，需要系统评估LLMs处理隐喻的能力。

Method: 从三个维度分析：(1)概念映射：使用嵌入空间投影评估LLMs如何映射目标域概念；(2)隐喻-字面知识库：分析隐喻词及其字面对应词；(3)句法敏感性：评估隐喻句法结构对LLMs性能的影响。

Result: LLMs产生15%-25%的概念无关解释，依赖训练数据中的隐喻指示器而非上下文线索，对句法异常比结构理解更敏感。

Conclusion: 这些发现突显了LLMs在隐喻分析方面的局限性，呼吁开发更稳健的计算方法。

Abstract: Metaphor analysis is a complex linguistic phenomenon shaped by context and
external factors. While Large Language Models (LLMs) demonstrate advanced
capabilities in knowledge integration, contextual reasoning, and creative
generation, their mechanisms for metaphor comprehension remain insufficiently
explored. This study examines LLMs' metaphor-processing abilities from three
perspectives: (1) Concept Mapping: using embedding space projections to
evaluate how LLMs map concepts in target domains (e.g., misinterpreting "fall
in love" as "drop down from love"); (2) Metaphor-Literal Repository: analyzing
metaphorical words and their literal counterparts to identify inherent
metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how
metaphorical syntactic structures influence LLMs' performance. Our findings
reveal that LLMs generate 15\%-25\% conceptually irrelevant interpretations,
depend on metaphorical indicators in training data rather than contextual cues,
and are more sensitive to syntactic irregularities than to structural
comprehension. These insights underline the limitations of LLMs in metaphor
analysis and call for more robust computational approaches.

</details>


### [217] [Sri Lanka Document Datasets: A Large-Scale, Multilingual Resource for Law, News, and Policy (v20251005)](https://arxiv.org/abs/2510.04124)
*Nuwan I. Senaratna*

Main category: cs.CL

TL;DR: 本文介绍了斯里兰卡的多语言开放文档数据集集合，包含议会记录、法律判决、政府出版物等，共215,670个文档（60.3 GB），支持计算语言学、法律分析等研究。


<details>
  <summary>Details</summary>
Motivation: 为支持斯里兰卡的计算语言学、法律分析、社会政治研究和多语言自然语言处理研究，提供机器可读的开放文档数据集资源。

Method: 构建数据收集管道，从议会记录、法律判决、政府出版物、新闻和旅游统计等多个来源收集数据，以Sinhala、Tamil和英语三种语言组织，每日更新并在GitHub和Hugging Face上镜像。

Result: 创建了包含13个数据集、215,670个文档（60.3 GB）的多语言文档集合，涵盖多种文档类型，为相关研究提供了丰富的资源。

Conclusion: 该数据集集合为斯里兰卡相关研究提供了宝贵的多语言资源，同时讨论了许可和伦理考虑，支持计算语言学、法律分析等多个领域的研究发展。

Abstract: We present a collection of open, machine-readable document datasets covering
parliamentary proceedings, legal judgments, government publications, news, and
tourism statistics from Sri Lanka. As of v20251005, the collection currently
comprises 215,670 documents (60.3 GB) across 13 datasets in Sinhala, Tamil, and
English. The datasets are updated daily and mirrored on GitHub and Hugging
Face. These resources aim to support research in computational linguistics,
legal analytics, socio-political studies, and multilingual natural language
processing. We describe the data sources, collection pipeline, formats, and
potential use cases, while discussing licensing and ethical considerations.

</details>


### [218] [Fine Tuning Methods for Low-resource Languages](https://arxiv.org/abs/2510.04139)
*Tim Bakkenes,Daniel Wang,Anton Johansson*

Main category: cs.CL

TL;DR: 开发了一种通用方法来准备文化相关数据集，通过后训练Gemma 2模型，提高其在代表性不足语言上的性能，使生成式AI能在不同国家发挥作用并保护文化遗产。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型主要基于英语文本和文化训练，在其他语言和文化背景下表现不佳，缺乏文化包容性。

Method: 开发通用方法准备文化相关数据集，并对Gemma 2模型进行后训练。

Result: 提高了Gemma 2在代表性不足语言上的性能表现。

Conclusion: 该方法可推广到其他国家，帮助解锁生成式AI的潜力并保护文化遗产。

Abstract: The rise of Large Language Models has not been inclusive of all cultures. The
models are mostly trained on English texts and culture which makes them
underperform in other languages and cultural contexts. By developing a
generalizable method for preparing culturally relevant datasets and
post-training the Gemma 2 model, this project aimed to increase the performance
of Gemma 2 for an underrepresented language and showcase how others can do the
same to unlock the power of Generative AI in their country and preserve their
cultural heritage.

</details>


### [219] [Self Speculative Decoding for Diffusion Large Language Models](https://arxiv.org/abs/2510.04147)
*Yifeng Gao,Ziang Ji,Yuxuan Wang,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: SSD是一种无损推理加速方法，利用扩散大语言模型自身作为推测解码的起草者和验证者，无需辅助模块，实现了高达3.46倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 当前并行解码方法的生成结果与逐步解码存在偏差，导致性能下降，限制了实际部署。

Method: 提出自推测解码(SSD)，通过自起草机制让模型生成多个位置的预测，然后通过分层验证树在单次前向传播中进行验证。

Result: 在开源模型LLaDA和Dream上实现了高达3.46倍的加速，同时保持输出与逐步解码完全相同。

Conclusion: SSD通过利用dLLM固有的并行预测能力，消除了模型冗余和内存开销，实现了高效的无损推理加速。

Abstract: Diffusion-based Large Language Models (dLLMs) have emerged as a competitive
alternative to autoregressive models, offering unique advantages through
bidirectional attention and parallel generation paradigms. However, the
generation results of current parallel decoding methods deviate from stepwise
decoding, introducing potential performance degradation, which limits their
practical deployment. To address this problem, we propose \textbf{S}elf
\textbf{S}peculative \textbf{D}ecoding (SSD), a lossless inference acceleration
method that leverages the dLLM itself as both speculative decoding drafter and
verifier without auxiliary modules. SSD introduces a self-drafting mechanism
where the model generates predictions for multiple positions, then verifies
them through hierarchical verification trees in a single forward pass. Unlike
traditional speculative decoding that requires separate draft models, SSD
eliminates model redundancy and memory overhead by exploiting the dLLM's
inherent parallel prediction capability for multiple positions. This
self-speculative approach allows the model to progressively verify and accept
multiple tokens in a single forward pass. Our experiments demonstrate that SSD
achieves up to 3.46$\times$ speedup while keeping the output identical to
stepwise decoding on open source models such as LLaDA and Dream. Code will be
made publicly available on GitHub.

</details>


### [220] [Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization](https://arxiv.org/abs/2510.04182)
*Wengao Ye,Yan Liang,Lianlei Shan*

Main category: cs.CL

TL;DR: LTPO是一个无需参数更新的测试时优化框架，通过将中间潜在思维向量作为动态参数进行优化，提升LLM在挑战性推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法在具有挑战性的分布外任务上表现脆弱，而鲁棒推理在这些任务中最为关键。

Method: 使用在线策略梯度方法，基于冻结LLM自身输出分布计算的置信度奖励信号，优化中间潜在思维向量。

Result: 在五个推理基准测试中，LTPO不仅匹配或超越强基线，在标准任务上表现优异，在AIME基准测试中更是实现了显著改进，而现有潜在推理方法准确率接近零。

Conclusion: LTPO展示了在复杂推理任务上的独特能力，无需外部监督或昂贵的文本生成，完全在测试时优化推理过程。

Abstract: Recent advancements in Large Language Models (LLMs) have shifted from
explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning,
where intermediate thoughts are represented as vectors rather than text.
However, latent reasoning can be brittle on challenging, out-of-distribution
tasks where robust reasoning is most critical. To overcome these limitations,
we introduce Latent Thought Policy Optimization (LTPO), a parameter-free
framework that enhances LLM reasoning entirely at test time, without requiring
model parameter updates. LTPO treats intermediate latent "thought" vectors as
dynamic parameters that are actively optimized for each problem instance. It
employs an online policy gradient method guided by an intrinsic,
confidence-based reward signal computed directly from the frozen LLM's own
output distributions, eliminating the need for external supervision or
expensive text generation during optimization. Extensive experiments on five
reasoning benchmarks show that LTPO not only matches or surpasses strong
baselines on standard tasks but also demonstrates remarkable robustness where
others fail. Most notably, on highly challenging AIME benchmarks where existing
latent reasoning baselines collapse to near-zero accuracy, LTPO delivers
substantial improvements, showcasing a unique capability for complex reasoning.

</details>


### [221] [CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling](https://arxiv.org/abs/2510.04204)
*Zhengyang Tang,Zihan Ye,Chenyu Huang,Xuhan Huang,Chengpeng Li,Sihang Li,Guanhua Chen,Ming Yan,Zizhuo Wang,Hongyuan Zha,Dayiheng Liu,Benyou Wang*

Main category: cs.CL

TL;DR: CALM框架通过轻量级修正适应方法，利用LRMs的固有推理能力进行优化建模，开发出STORM模型在多个基准测试中达到68.9%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 现有领域适应方法未能充分利用现代大型推理模型的高级推理模式，直接微调传统非反思数据集效果有限。

Method: 提出CALM框架：专家识别推理缺陷并提供简洁修正提示，LRM整合提示生成改进的推理轨迹，仅修改2.6%的生成标记，通过监督微调和强化学习进行软适应。

Result: 基于CALM开发的4B参数STORM模型在五个优化建模基准测试中达到68.9%的平均准确率，性能与671B LRM相当。

Conclusion: 基于提示的动态数据合成方法能够保持并增强现代LRMs的固有推理模式，为挑战性优化建模任务提供了更有效和可扩展的路径。

Abstract: Large Reasoning Models (LRMs) have demonstrated strong capabilities in
complex multi-step reasoning, opening new opportunities for automating
optimization modeling. However, existing domain adaptation methods, originally
designed for earlier instruction-tuned models, often fail to exploit the
advanced reasoning patterns of modern LRMs -- In particular, we show that
direct fine-tuning on traditional \textit{non-reflective} datasets leads to
limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose
\textbf{CALM} (\textit{Corrective Adaptation with Lightweight Modification}), a
framework that progressively refines LRMs within their native reasoning modes
for optimization modeling tasks. In CALM, an expert intervener identifies
reasoning flaws and provides concise corrective hints, which the LRM
incorporates to produce improved reasoning trajectories. These interventions
modify fewer than 2.6\% of generated tokens, but generate high-quality data for
soft adaptation through supervised fine-tuning. The adapted model is then
further improved through reinforcement learning. Building on CALM, we develop
\textbf{STORM} (\textit{Smart Thinking Optimization Reasoning Model}), a
4B-parameter LRM that achieves a new state-of-the-art average accuracy of
68.9\% across five popular optimization modeling benchmarks, matching the
performance of a 671B LRM. These results demonstrate that dynamic, hint-based
data synthesis both preserves and amplifies the native reasoning patterns of
modern LRMs, offering a more effective and scalable path towards expert-level
performance on challenging optimization modeling tasks.

</details>


### [222] [Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards](https://arxiv.org/abs/2510.04214)
*Zhuoran Zhuang,Ye Chen,Xia Zeng,Chao Luo,Luhui Liu,Yihan Chen*

Main category: cs.CL

TL;DR: 提出了REPO强化学习框架，通过整合偏好奖励模型、说服行为奖励和程序化奖励，优化LLM在在线旅行社价格谈判中的表现，显著提升了对话质量和约束遵从性。


<details>
  <summary>Details</summary>
Motivation: 传统后训练方法在商务谈判场景中存在过度拟合脚本、忽略微妙说服风格、无法强制执行业务约束的问题，需要开发更有效的对齐方法。

Method: REPO框架结合三种奖励：偏好训练的奖励模型用于密集人类对齐，奖励法官用于高级说服行为和SOP遵从，程序化奖励函数用于数值、格式和护栏的确定性检查。

Result: 在150轮真实对话和225轮精选坏案例对话评估中，REPO将平均对话评分提升至4.63，比基准高1.20，比DPO高0.83；将至少有一个优秀回复的对话比例提升至66.67%，坏案例修复率达到93.33%。

Conclusion: REPO框架有效解决了LLM在商务谈判中的对齐问题，不仅提升了性能指标，还涌现出主动同理心、本地化推理和校准策略等超越黄金标注的能力。

Abstract: We study deploying large language models (LLMs) as business development (BD)
agents for persuasive price negotiation in online travel agencies (OTAs), where
aligning traveler affordability and hotel profitability directly affects
bookings, partner relationships, and access to travel. The agent must follow a
Standard Operating Procedure (SOP) while conducting multi-turn persuasion,
interpreting colloquial inputs, and adhering to guardrails (no over-promising,
no hallucinations). Conventional post-training -- supervised fine-tuning (SFT)
or single-source reward optimization -- overfits scripts, misses nuanced
persuasive style, and fails to enforce verifiable business constraints.
  We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement
learning post-training framework that aligns an LLM with heterogeneous rewards:
a preference-trained reward model (RM) for dense human alignment, a reward
judge (RJ) for high-level persuasive behavior and SOP compliance, and
programmatic reward functions (RF) for deterministic checks on numerics,
formatting, and guardrails. A straightforward enhancement mechanism is proposed
to combine the RM with RJ and RF signals to curb reward hacking and improve
negotiation quality. In production-style evaluations -- approximately 150 turns
from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts
average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference
Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO),
increases the share of conversations with at least one excellent response to
66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix
rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also
observe emergent capabilities -- proactive empathy, localized reasoning,
calibrated tactics -- that surpass gold annotations.

</details>


### [223] [Epistemic Diversity and Knowledge Collapse in Large Language Models](https://arxiv.org/abs/2510.04226)
*Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 该论文提出了一种衡量LLM认知多样性的新方法，发现虽然新模型生成的声明更多样化，但几乎所有模型都比基础网络搜索的认知多样性低。模型大小对认知多样性有负面影响，而RAG有正面影响，但改善程度因文化背景而异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型倾向于生成词汇、语义和风格同质化的文本，这带来了知识崩溃的风险，即同质化的LLM会随着时间的推移导致可获取信息范围的缩小。现有关于同质化的研究局限于封闭式多项选择设置或模糊的语义特征，且未考察跨时间和文化背景的趋势。

Method: 提出了一种衡量认知多样性的新方法，即测量LLM输出中现实世界声明的变化。测试了27个LLM、涵盖12个国家的155个主题，以及来自真实用户聊天的200个提示变体。

Result: 较新的模型倾向于生成更多样化的声明，但几乎所有模型的认知多样性都低于基础网络搜索。模型大小对认知多样性有负面影响，RAG有正面影响，但改善程度因文化背景而异。与维基百科相比，特定国家的声明更多地反映了英语而非本地语言。

Conclusion: LLM存在认知多样性不足的问题，特别是在文化背景方面。模型大小增加会降低多样性，而RAG技术可以改善但效果因文化而异。需要关注LLM在不同文化背景下的知识表示平衡问题。

Abstract: Large language models (LLMs) tend to generate lexically, semantically, and
stylistically homogenous texts. This poses a risk of knowledge collapse, where
homogenous LLMs mediate a shrinking in the range of accessible information over
time. Existing works on homogenization are limited by a focus on closed-ended
multiple-choice setups or fuzzy semantic features, and do not look at trends
across time and cultural contexts. To overcome this, we present a new
methodology to measure epistemic diversity, i.e., variation in real-world
claims in LLM outputs, which we use to perform a broad empirical study of LLM
knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200
prompt variations sourced from real user chats. For the topics in our study, we
show that while newer models tend to generate more diverse claims, nearly all
models are less epistemically diverse than a basic web search. We find that
model size has a negative impact on epistemic diversity, while
retrieval-augmented generation (RAG) has a positive impact, though the
improvement from RAG varies by the cultural context. Finally, compared to a
traditional knowledge source (Wikipedia), we find that country-specific claims
reflect the English language more than the local one, highlighting a gap in
epistemic representation

</details>


### [224] [Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought](https://arxiv.org/abs/2510.04230)
*Guijin Son,Donghun Yang,Hitesh Laxmichand Patel,Amit Agarwal,Hyunwoo Ko,Chanuk Lim,Srikant Panda,Minhyuk Kim,Nikunj Drolia,Dasol Choi,Kyong-Ha Lee,Youngjae Yu*

Main category: cs.CL

TL;DR: 该论文提出了语言混合思维链方法，通过在英语和目标语言之间切换来提升推理能力，并以韩语为例构建了大规模数据集和模型，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数蒸馏研究集中在英语上，对于语言特定推理的研究较少。为了填补这一空白，研究者希望开发能够有效处理特定语言推理的模型。

Method: 提出语言混合思维链推理模式，在英语和目标语言之间切换；构建了包含579万韩语提示和370万长推理轨迹的Yi-Sang数据集；在六个模型家族上训练了九个模型。

Result: 最佳模型KO-REAson-35B在9个基准测试中的5个排名第一，其余排名第二，总体平均得分64.0±25；中小型模型平均提升18.6分；语言混合思维链比单语思维链更有效。

Conclusion: 语言混合思维链方法显著提升了韩语推理性能，同时带来了跨语言和多模态性能增益，为语言特定推理研究提供了新的方向。

Abstract: Recent frontier models employ long chain-of-thought reasoning to explore
solution spaces in context and achieve stonger performance. While many works
study distillation to build smaller yet capable models, most focus on English
and little is known about language-specific reasoning. To bridge this gap, we
first introduct **Language-Mixed CoT**, a reasoning schema that switches
between English and a target language, using English as an anchor to excel in
reasoning while minimizing translation artificats. As a Korean case study, we
curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and
code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k
high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5,
Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves
state-of-the-art performance, with the highest overall average score (64.0 \pm
25), ranking first on 5/9 benchmarks and second on the remainder. Samller and
mid-sized models also benefit substantially, with an average improvement of
+18.6 points across teh evaluated nine benchmarks. Ablations show
**Language-Mixed CoT** is more effective than monolingual CoT, also resulting
in cross-lingual and mult-modal performance gains. We release our data-curation
pipeline, evaluation system, datasets, and models to advance research on
language-specific reasoning. Data and model collection:
https://huggingface.co/KOREAson.

</details>


### [225] [LongTail-Swap: benchmarking language models' abilities on rare words](https://arxiv.org/abs/2510.04268)
*Robin Algayres,Charles-Éric Saint-James,Mahi Luthra,Jiayi Shen,Dongyan Lin,Youssef Benchekroun,Rashel Moritz,Juan Pino,Emmanuel Dupoux*

Main category: cs.CL

TL;DR: 提出了LongTail-Swap（LT-Swap）基准测试，专注于评估语言模型在罕见词学习上的能力，类似于婴儿的少样本学习。


<details>
  <summary>Details</summary>
Motivation: 现有BabyLM挑战主要关注词汇分布头部，而婴儿学习语言的特点是能够从少量数据中学习新词，特别是在罕见词（分布尾部）上的学习能力。

Method: 构建了与BabyLM训练集对应的测试集，包含可接受与不可接受的句子对，隔离了罕见词的语义和句法使用。通过零样本方式评估模型，计算每对句子的平均对数概率。

Result: 评估了16个BabyLM排行榜模型，结果显示语言模型在罕见词上表现较差，且不同架构模型在长尾分布上的性能差异比头部更明显。

Conclusion: LT-Swap基准提供了关于哪些架构更擅长处理罕见词泛化的新见解，揭示了语言模型在罕见词学习方面的局限性。

Abstract: Children learn to speak with a low amount of data and can be taught new words
on a few-shot basis, making them particularly data-efficient learners. The
BabyLM challenge aims at exploring language model (LM) training in the low-data
regime but uses metrics that concentrate on the head of the word distribution.
Here, we introduce LongTail-Swap (LT-Swap), a benchmark that focuses on the
tail of the distribution, i.e., measures the ability of LMs to learn new words
with very little exposure, like infants do. LT-Swap is a pretraining
corpus-specific test set of acceptable versus unacceptable sentence pairs that
isolate semantic and syntactic usage of rare words. Models are evaluated in a
zero-shot fashion by computing the average log probabilities over the two
members of each pair. We built two such test sets associated with the 10M words
and 100M words BabyLM training sets, respectively, and evaluated 16 models from
the BabyLM leaderboard. Our results not only highlight the poor performance of
language models on rare words but also reveal that performance differences
across LM architectures are much more pronounced in the long tail than in the
head. This offers new insights into which architectures are better at handling
rare word generalization. We've also made the code publicly avail

</details>


### [226] [Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy](https://arxiv.org/abs/2510.04285)
*Karthik Viswanathan,Sang Eon Park*

Main category: cs.CL

TL;DR: 提出了一个累积量展开框架，用于量化大型语言模型在下一个token预测过程中如何内化高阶统计结构，通过分析GPT-2和Pythia模型揭示了模型从学习方差到高阶统计结构的渐进过程。


<details>
  <summary>Details</summary>
Motivation: 需要量化理解大型语言模型如何内化高阶统计结构，以及不同内容类型（如数学与语言）在模型处理机制上的差异。

Method: 通过将每层logit分布的softmax熵视为围绕其中心分布的扰动，推导出封闭形式的累积量观测值来隔离高阶相关性，并在GPT-2和Pythia模型上进行实证分析。

Result: 结构化提示显示累积量在层间呈现上升-平台特征，而token打乱的提示保持平坦；训练过程中所有累积量单调增加后饱和；数学提示与一般文本显示不同的累积量特征。

Conclusion: 累积量分析成为高维神经网络中特征学习动态的轻量级、数学基础扎实的探测工具。

Abstract: We introduce a cumulant-expansion framework for quantifying how large
language models (LLMs) internalize higher-order statistical structure during
next-token prediction. By treating the softmax entropy of each layer's logit
distribution as a perturbation around its "center" distribution, we derive
closed-form cumulant observables that isolate successively higher-order
correlations. Empirically, we track these cumulants in GPT-2 and Pythia models
on Pile-10K prompts. (i) Structured prompts exhibit a characteristic
rise-and-plateau profile across layers, whereas token-shuffled prompts remain
flat, revealing the dependence of the cumulant profile on meaningful context.
(ii) During training, all cumulants increase monotonically before saturating,
directly visualizing the model's progression from capturing variance to
learning skew, kurtosis, and higher-order statistical structures. (iii)
Mathematical prompts show distinct cumulant signatures compared to general
text, quantifying how models employ fundamentally different processing
mechanisms for mathematical versus linguistic content. Together, these results
establish cumulant analysis as a lightweight, mathematically grounded probe of
feature-learning dynamics in high-dimensional neural networks.

</details>


### [227] [SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling](https://arxiv.org/abs/2510.04286)
*Harshil Vejendla*

Main category: cs.CL

TL;DR: SliceMoE是一种改进的混合专家架构，它将token的隐藏向量分割成多个切片，对每个切片独立进行专家路由，解决了传统token级路由的容量瓶颈和负载均衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE层的token级路由将整个语义空间分配给每个专家，导致容量瓶颈、负载均衡问题和有限的专家专业化。SliceMoE旨在通过更细粒度的切片路由来解决这些问题。

Method: 将d维嵌入分割成S个切片，为每个切片使用轻量级共享路由器预测top-k专家。专家独立处理分配的切片，输出重新组装，保持每个token的FLOP效率。提出了切片级容量损失、跨切片dropout和高效融合批处理GEMM内核。

Result: 在WikiText-103语言建模、WMT En-De翻译和三个文本分类数据集上的实验显示，SliceMoE比密集基线推理速度快1.7倍，比参数匹配的token-MoE困惑度降低12-18%，专家负载更均衡，并在句法与语义子空间上表现出可解释的专业化。

Conclusion: SliceMoE通过切片级路由有效解决了传统MoE的局限性，实现了更好的性能、效率和专家专业化，为大规模transformer模型提供了更优的扩展方案。

Abstract: Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a
sparse subset of feed-forward experts. Token-level routing, however, assigns an
entire semantic spectrum to each expert, creating capacity bottlenecks,
load-balancing pathologies, and limited specialization. We introduce SliceMoE,
an architecture that routes contiguous slices of a token's hidden vector. A
d-dimensional embedding is partitioned into S slices, and for each slice, a
lightweight shared router predicts the top-k experts. Experts operate on their
assigned slices independently, and outputs are reassembled, maintaining
per-token FLOP efficiency. Because slices from different tokens interleave
within an expert, utilization is naturally smoother. We propose a slice-level
capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels.
Experiments on WikiText-103 language modeling, WMT En-De translation, and three
text-classification datasets show SliceMoE attains up to 1.7x faster inference
than dense baselines, 12 to 18 percent lower perplexity than parameter-matched
token-MoE, and improved expert balance, with interpretable expertise over
syntactic versus semantic subspaces.

</details>


### [228] [PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2510.04291)
*Mehrzad Tareh,Aydin Mohandesi,Ebrahim Ansari*

Main category: cs.CL

TL;DR: 提出了一种结合机器学习和深度学习的混合方法，用于波斯语方面级情感分析，通过集成多语言BERT的极性分数作为特征，在Pars-ABSA数据集上达到93.34%的准确率。


<details>
  <summary>Details</summary>
Motivation: 波斯语情感分析面临标注数据集稀缺、预处理工具有限、高质量嵌入和特征提取方法缺乏等挑战。

Method: 使用多语言BERT的极性分数作为额外特征，结合决策树分类器，并引入波斯语同义词和实体词典进行文本增强。

Result: 在Pars-ABSA数据集上达到93.34%的准确率，超越了现有基准。

Conclusion: 混合建模和特征增强方法对波斯语等低资源语言的情感分析具有显著效果。

Abstract: Sentiment analysis is a key task in Natural Language Processing (NLP),
enabling the extraction of meaningful insights from user opinions across
various domains. However, performing sentiment analysis in Persian remains
challenging due to the scarcity of labeled datasets, limited preprocessing
tools, and the lack of high-quality embeddings and feature extraction methods.
To address these limitations, we propose a hybrid approach that integrates
machine learning (ML) and deep learning (DL) techniques for Persian
aspect-based sentiment analysis (ABSA). In particular, we utilize polarity
scores from multilingual BERT as additional features and incorporate them into
a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing
benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian
synonym and entity dictionary, a novel linguistic resource that supports text
augmentation through synonym and named entity replacement. Our results
demonstrate the effectiveness of hybrid modeling and feature augmentation in
advancing sentiment analysis for low-resource languages such as Persian.

</details>


### [229] [Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness](https://arxiv.org/abs/2510.04293)
*Lingnan Xu,Chong Feng,Kaiyuan Zhang,Liu Zhengyong,Wenqiang Xu,Fanqing Meng*

Main category: cs.CL

TL;DR: 提出了RDR2框架，在检索增强生成中显式整合文档结构信息，通过LLM路由器和结构树导航来提升事实准确性


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法将检索到的段落视为孤立块，忽略了文档组织结构这一关键信息，导致知识获取和利用不足

Method: 使用LLM路由器动态导航文档结构树，联合评估内容相关性和层次关系，将文档路由制定为可训练任务

Result: 在五个挑战性数据集上达到最先进性能，显式结构感知显著增强了RAG系统获取和利用知识的能力

Conclusion: 文档结构信息对RAG系统至关重要，特别是在需要多文档合成的复杂场景中

Abstract: While large language models (LLMs) demonstrate impressive capabilities, their
reliance on parametric knowledge often leads to factual inaccuracies.
Retrieval-Augmented Generation (RAG) mitigates this by leveraging external
documents, yet existing approaches treat retrieved passages as isolated chunks,
ignoring valuable structure that is crucial for document organization.
Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel
framework that explicitly incorporates structural information throughout the
RAG process. RDR2 employs an LLM-based router to dynamically navigate document
structure trees, jointly evaluating content relevance and hierarchical
relationships to assemble optimal evidence. Our key innovation lies in
formulating document routing as a trainable task, with automatic action
curation and structure-aware passage selection inspired by human reading
strategies. Through comprehensive evaluation on five challenging datasets, RDR2
achieves state-of-the-art performance, demonstrating that explicit structural
awareness significantly enhances RAG systems' ability to acquire and utilize
knowledge, particularly in complex scenarios requiring multi-document
synthesis.

</details>


### [230] [Measuring Language Model Hallucinations Through Distributional Correctness](https://arxiv.org/abs/2510.04302)
*Thomas F Burns*

Main category: cs.CL

TL;DR: 提出了一个新的评估指标DCS，通过考虑模型在答案选择上的完整概率分布来区分有害的过度自信和通过弃权表达的不确定性，从而更细致地评估语言模型的信念状态。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估范式仅关注单一响应的准确性评分，无法捕捉模型完整的信念状态。模型产生幻觉的部分原因是它们被优化为在二元评分方案下成为好的应试者，这鼓励了任何答案而非弃权。

Method: 引入分布正确性评分(DCS)，该指标考虑模型在答案选择上的完整概率分布，自然区分对错误答案的有害过度自信和通过"我不知道"表达的不确定性。

Result: 在12个现有评估基准上应用DCS变体，测量6个语言模型的性能，发现半数测试基准的得分在所有测试模型中均为负值，表明存在显著的幻觉倾向。

Conclusion: DCS提供了一个更细致和对齐的评估范式，激励模型表达真实的不确定性而非猜测，能够更准确地评估语言模型的信念状态。

Abstract: Common evaluation paradigms for language models focus on scoring single
responses through accuracy metrics or proper scoring rules, failing to capture
the full richness of a model's belief state. Recent work illustrates that
language models hallucinate in-part because they are optimised to be good
test-takers under binary scoring schemes that reward any answer over
abstention. While this insight naturally leads to penalty-based approaches,
they ignore crucial distinctions in how models distribute uncertainty, for
example between hedging toward incorrect answers versus hedging toward "I don't
know" responses. A novel evaluation metric, the Distributional Correctness
Score (DCS), is introduced to solve this problem, i.e., of not considering a
model's entire probability distribution over answer choices. DCS naturally
distinguishes between harmful overconfidence in wrong answers and uncertainty
expressed through abstention, providing scores in an interpretable default
range. Through theoretical analysis and illustrative examples, DCS is
demonstrated to offer a more nuanced and aligned evaluation paradigm that
incentivises models to express genuine uncertainty rather than guessing.
Adapting 12 existing evaluation benchmarks to DCS's variants and measuring
performance on six language models reveals that for half of the tested
benchmarks scores are negative across all tested models, indicating significant
tendencies towards hallucination.

</details>


### [231] [Read the Scene, Not the Script: Outcome-Aware Safety for LLMs](https://arxiv.org/abs/2510.04320)
*Rui Wu,Yihao Quan,Zeru Shi,Zhenting Wang,Yanshu Li,Ruixiang Tang*

Main category: cs.CL

TL;DR: 论文发现安全对齐的大语言模型存在后果盲目性问题，即模型过度依赖表面信号而忽视行动与后果的关联，导致易被越狱或过度拒绝无害输入。


<details>
  <summary>Details</summary>
Motivation: 当前安全对齐的大语言模型存在两个主要失效模式：易被越狱和过度拒绝无害输入，这些问题的根源是模型缺乏对行动与后果关联的推理能力。

Method: 构建CB-Bench基准测试四种风险场景，并开发CS-Chain-4k数据集用于安全对齐，通过微调模型来增强后果推理能力。

Result: 在CS-Chain-4k上微调的模型在语义伪装越狱攻击中表现更好，减少了对无害输入的过度拒绝，同时保持了在其他基准测试上的效用和泛化能力。

Conclusion: 后果盲目性是当前对齐方法的系统性局限，后果感知推理应成为核心对齐目标，该研究为更实用和可复现的评估提供了路径。

Abstract: Safety-aligned Large Language Models (LLMs) still show two dominant failure
modes: they are easily jailbroken, or they over-refuse harmless inputs that
contain sensitive surface signals. We trace both to a common cause: current
models reason weakly about links between actions and outcomes and over-rely on
surface-form signals, lexical or stylistic cues that do not encode
consequences. We define this failure mode as Consequence-blindness. To study
consequence-blindness, we build a benchmark named CB-Bench covering four risk
scenarios that vary whether semantic risk aligns with outcome risk, enabling
evaluation under both matched and mismatched conditions which are often ignored
by existing safety benchmarks. Mainstream models consistently fail to separate
these risks and exhibit consequence-blindness, indicating that
consequence-blindness is widespread and systematic. To mitigate
consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning
dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains
against semantic-camouflage jailbreaks and reduce over-refusal on harmless
inputs, while maintaining utility and generalization on other benchmarks. These
results clarify the limits of current alignment, establish consequence-aware
reasoning as a core alignment goal and provide a more practical and
reproducible evaluation path.

</details>


### [232] [Evaluation of Clinical Trials Reporting Quality using Large Language Models](https://arxiv.org/abs/2510.04338)
*Mathieu Laï-king,Patrick Paroubek*

Main category: cs.CL

TL;DR: 本文测试了大语言模型评估临床试验研究报告质量的能力，使用CONSORT标准创建了CONSORT-QA评估语料库，最佳模型组合达到85%准确率。


<details>
  <summary>Details</summary>
Motivation: 临床试验研究报告质量影响临床决策，需要评估大语言模型在此类文章报告质量评估中的能力。

Method: 创建CONSORT-QA评估语料库，使用不同大语言模型和提示方法（包括思维链）评估CONSORT标准。

Result: 最佳模型和提示方法组合达到85%的准确率，思维链方法为模型推理提供了有价值的信息。

Conclusion: 大语言模型能够有效评估临床试验研究报告质量，思维链方法增强了模型推理的可解释性。

Abstract: Reporting quality is an important topic in clinical trial research articles,
as it can impact clinical decisions. In this article, we test the ability of
large language models to assess the reporting quality of this type of article
using the Consolidated Standards of Reporting Trials (CONSORT). We create
CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality
with CONSORT-abstract standards. We then evaluate the ability of different
large generative language models (from the general domain or adapted to the
biomedical domain) to correctly assess CONSORT criteria with different known
prompting methods, including Chain-of-thought. Our best combination of model
and prompting method achieves 85% accuracy. Using Chain-of-thought adds
valuable information on the model's reasoning for completing the task.

</details>


### [233] [Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time](https://arxiv.org/abs/2510.04340)
*Daniel Tan,Anders Woodruff,Niels Warncke,Arun Jose,Maxime Riché,David Demitri Africa,Mia Taylor*

Main category: cs.CL

TL;DR: 提出接种提示法：通过在微调数据前添加简短的系统提示指令来有意识地引发不良特征，从而在测试时显著降低该特征的表现。该方法在多个场景中有效，包括减少任务特定微调中的突发错位、防御后门注入和缓解潜意识学习中的特征传递。


<details>
  <summary>Details</summary>
Motivation: 语言模型微调常常在学习期望特征的同时也学习到不良特征。为了解决这个问题，需要一种能够选择性学习的方法，避免模型泛化不良特征。

Method: 接种提示法：修改微调数据，在数据前添加简短的系统提示指令，有意识地引发不良特征。在测试时不使用该指令，使模型在保留期望特征的同时显著减少不良特征的表现。

Result: 接种后的模型在测试时不良特征表现显著降低。该方法在多个场景中有效：减少突发错位、防御后门攻击、缓解特征传递。分析表明机制是通过减少优化压力来降低泛化程度。

Conclusion: 接种提示法是一种简单有效的选择性学习技术，不仅提供了实用的解决方案，还增进了对语言模型泛化机制的理解，解释了先前关于教育情境缓解不安全代码中突发错位的发现。

Abstract: Language model finetuning often results in learning undesirable traits in
combination with desired ones. To address this, we propose inoculation
prompting: modifying finetuning data by prepending a short system-prompt
instruction that deliberately elicits the undesirable trait. At test time, we
evaluate without the instruction; inoculated models have much lower expression
of the trait than models trained with unmodified training data. Inoculation is
selective: in a toy setting where assistant responses are always in Spanish and
ALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'')
teaches the model to capitalize responses while still responding in English. We
find that inoculation is also effective across several additional settings:
reducing emergent misalignment (EM) from task-specific finetuning, defending
against backdoor injections, and mitigating the transmission of traits via
subliminal learning. Follow-up analysis suggests a mechanism: making a trait
less surprising via inoculation reduces optimization pressure to globally
update the model, thereby reducing the degree of generalization. Our analysis
relates to prior work on EM: inoculation explains prior findings that
educational contexts mitigate EM from insecure code. Beyond demonstrating a
simple and effective technique for selective learning, our results contribute
to a better conceptual understanding of how and why language models generalize.

</details>


### [234] [Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models](https://arxiv.org/abs/2510.04347)
*Anindya Sundar Das,Kangjie Chen,Monowar Bhuyan*

Main category: cs.CL

TL;DR: 该论文研究了预训练语言模型中的后门攻击，提出了一种基于注意力机制和梯度信息的推理时防御方法，能有效降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型虽然在各种NLP任务中表现出色，但容易受到后门攻击的威胁，攻击者通过在训练数据中植入触发模式来嵌入恶意行为，这些触发器在正常使用时保持休眠状态，但激活时会导致定向错误分类。

Method: 提出了一种推理时防御方法，通过结合token级别的注意力信息和梯度信息来构建异常分数，从而检测和防御后门攻击。

Result: 在多种后门攻击场景下的文本分类任务实验表明，该方法相比现有基线显著降低了攻击成功率。

Conclusion: 该方法不仅有效防御后门攻击，还通过可解释性分析揭示了触发器定位机制和防御方法的鲁棒性。

Abstract: Pre-trained language models have achieved remarkable success across a wide
range of natural language processing (NLP) tasks, particularly when fine-tuned
on large, domain-relevant datasets. However, they remain vulnerable to backdoor
attacks, where adversaries embed malicious behaviors using trigger patterns in
the training data. These triggers remain dormant during normal usage, but, when
activated, can cause targeted misclassifications. In this work, we investigate
the internal behavior of backdoored pre-trained encoder-based language models,
focusing on the consistent shift in attention and gradient attribution when
processing poisoned inputs; where the trigger token dominates both attention
and gradient signals, overriding the surrounding context. We propose an
inference-time defense that constructs anomaly scores by combining token-level
attention and gradient information. Extensive experiments on text
classification tasks across diverse backdoor attack scenarios demonstrate that
our method significantly reduces attack success rates compared to existing
baselines. Furthermore, we provide an interpretability-driven analysis of the
scoring mechanism, shedding light on trigger localization and the robustness of
the proposed defense.

</details>


### [235] [Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards](https://arxiv.org/abs/2510.04392)
*Faisal Hamman,Chenyang Zhu,Anoop Kumar,Xujun Peng,Sanghamitra Dutta,Daben Liu,Alfy Samuel*

Main category: cs.CL

TL;DR: 提出了Con-RAG系统，通过PS-GRPO强化学习方法解决RAG系统在语义等价查询下输出不一致的问题，显著提升了系统的一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在语义等价查询下经常产生不一致的输出，这在关键应用领域会损害用户信任和系统可靠性。

Method: 引入分解式评估框架分析不一致来源，提出PS-GRPO强化学习方法，使用多轮次生成和组相似性奖励来训练生成器，并开发了可扩展的近似奖励计算方法。

Result: 在短文本、多跳和长文本问答基准测试中，Con-RAG在一致性和准确性方面均显著优于基线方法，即使在没有显式监督的情况下也能有效工作。

Conclusion: 该研究为评估和构建可靠RAG系统提供了实用解决方案，特别适用于安全关键部署场景。

Abstract: RAG systems are increasingly deployed in high-stakes domains where users
expect outputs to be consistent across semantically equivalent queries.
However, existing systems often exhibit significant inconsistencies due to
variability in both the retriever and generator (LLM), undermining trust and
reliability. In this work, we focus on information consistency, i.e., the
requirement that outputs convey the same core content across semantically
equivalent inputs. We introduce a principled evaluation framework that
decomposes RAG consistency into retriever-level, generator-level, and
end-to-end components, helping identify inconsistency sources. To improve
consistency, we propose Paraphrased Set Group Relative Policy Optimization
(PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased
set to assign group similarity rewards. We leverage PS-GRPO to achieve
Information Consistent RAG (Con-RAG), training the generator to produce
consistent outputs across paraphrased queries and remain robust to
retrieval-induced variability. Because exact reward computation over paraphrase
sets is computationally expensive, we also introduce a scalable approximation
method that retains effectiveness while enabling efficient, large-scale
training. Empirical evaluations across short-form, multi-hop, and long-form QA
benchmarks demonstrate that Con-RAG significantly improves both consistency and
accuracy over strong baselines, even in the absence of explicit ground-truth
supervision. Our work provides practical solutions for evaluating and building
reliable RAG systems for safety-critical deployments.

</details>


### [236] [Time Is Effort: Estimating Human Post-Editing Time for Grammar Error Correction Tool Evaluation](https://arxiv.org/abs/2510.04394)
*Ankit Vadehra,Bill Johnson,Gene Saunders,Pascal Poupart*

Main category: cs.CL

TL;DR: 提出了首个大规模语法错误校正工具后编辑时间数据集，并引入PEET评分器来评估GEC工具节省用户编辑时间的能力。


<details>
  <summary>Details</summary>
Motivation: 量化语法错误校正工具的实际可用性，衡量其能为用户节省多少编辑时间，提供以人为中心的GEC工具评估方法。

Method: 构建包含后编辑时间标注和修正的大型数据集，提出PEET评分器来估计后编辑时间并排名GEC工具。

Result: 分析表明判断句子是否需要修正以及改写、标点等编辑类型对后编辑时间影响最大，PEET与人工技术努力判断相关性良好。

Conclusion: PEET为GEC工具可用性评估提供了新的人本主义方向，能够有效量化工具节省的编辑时间。

Abstract: Text editing can involve several iterations of revision. Incorporating an
efficient Grammar Error Correction (GEC) tool in the initial correction round
can significantly impact further human editing effort and final text quality.
This raises an interesting question to quantify GEC Tool usability: How much
effort can the GEC Tool save users? We present the first large-scale dataset of
post-editing (PE) time annotations and corrections for two English GEC test
datasets (BEA19 and CoNLL14). We introduce Post-Editing Effort in Time (PEET)
for GEC Tools as a human-focused evaluation scorer to rank any GEC Tool by
estimating PE time-to-correct. Using our dataset, we quantify the amount of
time saved by GEC Tools in text editing. Analyzing the edit type indicated that
determining whether a sentence needs correction and edits like paraphrasing and
punctuation changes had the greatest impact on PE time. Finally, comparison
with human rankings shows that PEET correlates well with technical effort
judgment, providing a new human-centric direction for evaluating GEC tool
usability. We release our dataset and code at:
https://github.com/ankitvad/PEET_Scorer.

</details>


### [237] [SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations](https://arxiv.org/abs/2510.04398)
*Buyun Liang,Liangzu Peng,Jinqi Luo,Darshan Thaker,Kwan Ho Ryan Chan,René Vidal*

Main category: cs.CL

TL;DR: SECA是一种通过语义等效且连贯的提示修改来引发LLM幻觉的方法，相比现有方法能产生更现实的攻击提示，同时保持语义等价性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在引发LLM幻觉时往往产生不现实的提示（如插入乱码或改变原意），无法反映实际中幻觉发生的真实情况，因此需要开发能保持语义等效和连贯性的现实攻击方法。

Method: 将寻找现实攻击问题形式化为输入提示空间上的约束优化问题，引入保持约束的零阶优化方法来有效搜索对抗性但可行的提示。

Result: 在开放式多项选择题回答任务上的实验表明，SECA相比现有方法实现了更高的攻击成功率，同时几乎没有约束违反。

Conclusion: SECA揭示了开源和商业梯度不可访问LLM对现实且合理的提示变动的敏感性，为评估LLM可靠性提供了更现实的测试方法。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-risk domains.
However, state-of-the-art LLMs often produce hallucinations, raising serious
concerns about their reliability. Prior work has explored adversarial attacks
for hallucination elicitation in LLMs, but it often produces unrealistic
prompts, either by inserting gibberish tokens or by altering the original
meaning. As a result, these approaches offer limited insight into how
hallucinations may occur in practice. While adversarial attacks in computer
vision often involve realistic modifications to input images, the problem of
finding realistic adversarial prompts for eliciting LLM hallucinations has
remained largely underexplored. To address this gap, we propose Semantically
Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic
modifications to the prompt that preserve its meaning while maintaining
semantic coherence. Our contributions are threefold: (i) we formulate finding
realistic attacks for hallucination elicitation as a constrained optimization
problem over the input prompt space under semantic equivalence and coherence
constraints; (ii) we introduce a constraint-preserving zeroth-order method to
effectively search for adversarial yet feasible prompts; and (iii) we
demonstrate through experiments on open-ended multiple-choice question
answering tasks that SECA achieves higher attack success rates while incurring
almost no constraint violations compared to existing methods. SECA highlights
the sensitivity of both open-source and commercial gradient-inaccessible LLMs
to realistic and plausible prompt variations. Code is available at
https://github.com/Buyun-Liang/SECA.

</details>


### [238] [Large Language Models Preserve Semantic Isotopies in Story Continuations](https://arxiv.org/abs/2510.04400)
*Marc Cavazza*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型生成文本是否保留语义同位素，通过故事续写实验发现LLM在给定token范围内能够保持语义同位素。


<details>
  <summary>Details</summary>
Motivation: 探索文本语义与大型语言模型的相关性，研究LLM生成文本是否保持语义同位素，扩展分布语义学与结构语义学之间联系的研究。

Method: 设计了故事续写实验，使用10,000个ROCStories提示由5个LLM完成，首先验证GPT-4o从语言基准中提取同位素的能力，然后应用于生成的故事，分析同位素的结构和语义特性。

Result: 结果显示，在给定token范围内，LLM续写能够跨多个属性保留语义同位素。

Conclusion: LLM在特定token范围内完成文本时能够保持语义同位素，这表明LLM生成文本在语义连贯性方面表现良好。

Abstract: In this work, we explore the relevance of textual semantics to Large Language
Models (LLMs), extending previous insights into the connection between
distributional semantics and structural semantics. We investigate whether
LLM-generated texts preserve semantic isotopies. We design a story continuation
experiment using 10,000 ROCStories prompts completed by five LLMs. We first
validate GPT-4o's ability to extract isotopies from a linguistic benchmark,
then apply it to the generated stories. We then analyze structural (coverage,
density, spread) and semantic properties of isotopies to assess how they are
affected by completion. Results show that LLM completion within a given token
horizon preserves semantic isotopies across multiple properties.

</details>


### [239] [Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?](https://arxiv.org/abs/2510.04434)
*Grace LeFevre,Qingcheng Zeng,Adam Leif,Jason Jewell,Denis Peskoff,Rob Voigt*

Main category: cs.CL

TL;DR: 本文通过作者和会议层面的分析，发现ACL作者在非ACL会议上发表社会公益相关研究的比例远高于在ACL会议上，且大多数NLP社会公益研究由非ACL作者在非ACL会议上发表。


<details>
  <summary>Details</summary>
Motivation: 随着NLP对社会影响日益重要，NLP4SG研究社区不断壮大。近20%的ACL论文涉及联合国可持续发展目标，需要了解该领域的研究格局。

Method: 采用作者和会议层面的视角，量化ACL社区内外作者在ACL和非ACL会议上发表社会公益相关研究的比例。

Result: 发现两个意外事实：1) ACL作者在非ACL会议上更可能发表社会公益研究；2) 大多数NLP社会公益研究由非ACL作者在非ACL会议上完成。

Conclusion: 这些发现对ACL社区在NLP4SG议程设置方面具有重要意义，需要重新考虑如何促进该领域的发展。

Abstract: The social impact of Natural Language Processing (NLP) is increasingly
important, with a rising community focus on initiatives related to NLP for
Social Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the
ACL Anthology address topics related to social good as defined by the UN
Sustainable Development Goals (Adauto et al., 2023). In this study, we take an
author- and venue-level perspective to map the landscape of NLP4SG, quantifying
the proportion of work addressing social good concerns both within and beyond
the ACL community, by both core ACL contributors and non-ACL authors. With this
approach we discover two surprising facts about the landscape of NLP4SG. First,
ACL authors are dramatically more likely to do work addressing social good
concerns when publishing in venues outside of ACL. Second, the vast majority of
publications using NLP techniques to address concerns of social good are done
by non-ACL authors in venues outside of ACL. We discuss the implications of
these findings on agenda-setting considerations for the ACL community related
to NLP4SG.

</details>


### [240] [On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs](https://arxiv.org/abs/2510.04439)
*Lucie Kunitomo-Jacquin,Edison Marrese-Taylor,Ken Fukuda*

Main category: cs.CL

TL;DR: 本文主张在大型语言模型不确定性量化中考虑未观测序列的概率，以提升量化方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全关键应用中需要准确的不确定性量化来识别错误答案（幻觉），现有基于熵估计的方法主要依赖观测到的输出序列，但忽略了未观测序列的重要性。

Method: 通过实验证明未观测序列概率在不确定性量化中的关键作用，建议未来研究整合这一因素。

Result: 实验结果表明未观测序列概率对提升LLM不确定性量化方法至关重要。

Conclusion: 未来研究应整合未观测序列概率来增强大型语言模型的不确定性量化方法。

Abstract: Quantifying uncertainty in large language models (LLMs) is important for
safety-critical applications because it helps spot incorrect answers, known as
hallucinations. One major trend of uncertainty quantification methods is based
on estimating the entropy of the distribution of the LLM's potential output
sequences. This estimation is based on a set of output sequences and associated
probabilities obtained by querying the LLM several times. In this paper, we
advocate and experimentally show that the probability of unobserved sequences
plays a crucial role, and we recommend future research to integrate it to
enhance such LLM uncertainty quantification methods.

</details>


### [241] [Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners](https://arxiv.org/abs/2510.04454)
*Xiangchi Yuan,Xiang Chen,Tong Yu,Dachuan Shi,Can Jin,Wenke Lee,Saayan Mitra*

Main category: cs.CL

TL;DR: 提出了一种动态结合监督微调(SFT)和强化学习(RL)的即插即用框架，通过选择挑战性样本进行SFT，仅需1.5%的SFT数据和20.4%的RL数据即可达到最先进推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法结合SFT和RL面临数据效率低、算法特定设计和灾难性遗忘三大挑战，需要一种更高效、通用的解决方案来扩展大语言模型的推理边界。

Method: 动态选择挑战性样本进行SFT，计算高熵token的损失以减轻灾难性遗忘，并冻结对RL重要的参数，实现与RL和SFT算法无关的即插即用集成。

Result: 仅使用先前最先进方法1.5%的SFT数据和20.4%的RL数据，就达到了最先进的推理性能。

Conclusion: 该方法为推理后训练中结合SFT和RL提供了高效且即插即用的解决方案，显著降低了数据需求并保持了算法通用性。

Abstract: Large Language Models (LLMs) show strong reasoning abilities, often amplified
by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although
RL algorithms can substantially improve reasoning, they struggle to expand
reasoning boundaries because they learn from their own reasoning trajectories
rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers
complementary benefits but typically requires large-scale data and risks
overfitting. Recent attempts to combine SFT and RL face three main challenges:
data inefficiency, algorithm-specific designs, and catastrophic forgetting. We
propose a plug-and-play framework that dynamically integrates SFT into RL by
selecting challenging examples for SFT. This approach reduces SFT data
requirements and remains agnostic to the choice of RL or SFT algorithm. To
mitigate catastrophic forgetting of RL-acquired skills during SFT, we select
high-entropy tokens for loss calculation and freeze parameters identified as
critical for RL. Our method achieves state-of-the-art (SoTA) reasoning
performance using only 1.5% of the SFT data and 20.4% of the RL data used by
prior SoTA, providing an efficient and plug-and-play solution for combining SFT
and RL in reasoning post-training.

</details>


### [242] [Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space](https://arxiv.org/abs/2510.04476)
*Tomas Figliolia,Nicholas Alonso,Rishi Iyer,Quentin Anthony,Beren Millidge*

Main category: cs.CL

TL;DR: 提出压缩卷积注意力(CCA)，通过在共享潜在空间执行注意力操作，同时减少参数、KV缓存和FLOPs，并与分组查询注意力结合形成CCGQA，在保持质量的同时显著提升训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 多头注意力(MHA)的二次计算复杂度和线性增长的KV缓存使得长上下文transformer训练和服务成本高昂，现有方法主要优化缓存但计算开销基本不变。

Method: CCA通过降维投影查询、键和值到共享潜在空间执行注意力操作，并与分组查询注意力结合形成CCGQA，实现计算和带宽的帕累托优化。

Result: CCGQA在相同KV缓存压缩下优于GQA和MLA，在MoE模型上以GQA和MLA一半的KV缓存实现8倍压缩且性能不下降，在H100 GPU上预填充延迟减少约1.7倍，反向传播加速约1.3倍。

Conclusion: CCA和CCGQA通过压缩注意力机制显著降低了计算和内存需求，为长上下文transformer提供了高效的训练和推理解决方案。

Abstract: Multi-headed Attention's (MHA) quadratic compute and linearly growing
KV-cache make long-context transformers expensive to train and serve. Prior
works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)
shrink the cache, speeding decode, but leave compute, which determines prefill
and training speed, largely unchanged. We introduce Compressed Convolutional
Attention (CCA), a novel attention method which down-projects queries, keys,
and values and performs the entire attention operation inside the shared latent
space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all
at once by the desired compression factor. Because CCA is orthogonal to
head-sharing, we combine the two to form Compressed Convolutional Grouped Query
Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier
so that users can tune compression toward either FLOP or memory limits without
sacrificing quality. Experiments show that CCGQA consistently outperforms both
GQA and MLA at equal KV-cache compression on dense and MoE models.
Additionally, we show that CCGQA outperforms all other attention methods on MoE
models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache
compression with no drop in performance compared to standard MHA. CCA and CCGQA
also dramatically reduce the FLOP cost of attention which leads to
substantially faster training and prefill than existing methods. On H100 GPUs,
our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence
length of 16k relative to MHA, and accelerates backward by about 1.3x.

</details>


### [243] [Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness](https://arxiv.org/abs/2510.04484)
*Amin Banayeeanzade,Ala N. Tak,Fatemeh Bahrani,Anahita Bolourani,Leonardo Blas,Emilio Ferrara,Jonathan Gratch,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: PsySET是一个心理学基准测试，用于评估LLM在情绪和人格领域的引导效果和可信度，发现不同引导策略各有优劣，情绪引导可能带来意想不到的副作用。


<details>
  <summary>Details</summary>
Motivation: 控制LLM的情绪状态和人格特质对于实现丰富、以人为中心的社会交互至关重要，需要系统评估引导策略的有效性和可信度。

Method: 使用PsySET基准测试四种不同LLM模型，结合提示、微调和表示工程等引导策略，评估情绪和人格引导的效果。

Result: 提示方法一致有效但强度控制有限，向量注入实现更精细控制但略微降低输出质量；情绪引导可能产生副作用，如快乐情绪会降低对抗事实鲁棒性、隐私意识和增加偏好偏见。

Conclusion: 该框架建立了首个情绪和人格引导的整体评估，为社交交互应用中的可解释性和可靠性提供了见解。

Abstract: The ability to control LLMs' emulated emotional states and personality traits
is essential for enabling rich, human-centered interactions in socially
interactive settings. We introduce PsySET, a Psychologically-informed benchmark
to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion
and personality domains. Our study spans four models from different LLM
families paired with various steering strategies, including prompting,
fine-tuning, and representation engineering. Our results indicate that
prompting is consistently effective but limited in intensity control, whereas
vector injections achieve finer controllability while slightly reducing output
quality. Moreover, we explore the trustworthiness of steered LLMs by assessing
safety, truthfulness, fairness, and ethics, highlighting potential side effects
and behavioral shifts. Notably, we observe idiosyncratic effects; for instance,
even a positive emotion like joy can degrade robustness to adversarial
factuality, lower privacy awareness, and increase preferential bias. Meanwhile,
anger predictably elevates toxicity yet strengthens leakage resistance. Our
framework establishes the first holistic evaluation of emotion and personality
steering, offering insights into its interpretability and reliability for
socially interactive applications.

</details>


### [244] [GenQuest: An LLM-based Text Adventure Game for Language Learners](https://arxiv.org/abs/2510.04498)
*Qiao Wang,Adnan Labib,Robert Swier,Michael Hofmeyr,Zheng Yuan*

Main category: cs.CL

TL;DR: GenQuest是一个基于大语言模型的生成式文本冒险游戏，通过沉浸式互动故事促进第二语言学习，为EFL学习者提供个性化内容和词汇辅助功能。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型为英语作为外语的学习者创造沉浸式、互动式的语言学习环境，通过游戏化方式提高学习动机和效果。

Method: 采用"选择你自己的冒险"风格叙事，动态生成响应学习者选择的故事分支，包含根据学习者水平定制的内容生成和上下文词汇解释功能。

Result: 对中国大学生EFL学习者的试点研究表明，该系统在词汇习得方面表现出良好效果，并获得积极的用户反馈。

Conclusion: GenQuest展示了生成式文本冒险游戏在语言学习中的潜力，未来可考虑增加多模态内容和优化叙事质量来进一步提升用户体验。

Abstract: GenQuest is a generative text adventure game that leverages Large Language
Models (LLMs) to facilitate second language learning through immersive,
interactive storytelling. The system engages English as a Foreign Language
(EFL) learners in a collaborative "choose-your-own-adventure" style narrative,
dynamically generated in response to learner choices. Game mechanics such as
branching decision points and story milestones are incorporated to maintain
narrative coherence while allowing learner-driven plot development. Key
pedagogical features include content generation tailored to each learner's
proficiency level, and a vocabulary assistant that provides in-context
explanations of learner-queried text strings, ranging from words and phrases to
sentences. Findings from a pilot study with university EFL students in China
indicate promising vocabulary gains and positive user perceptions. Also
discussed are suggestions from participants regarding the narrative length and
quality, and the request for multi-modal content such as illustrations.

</details>


### [245] [GRACE: Generative Representation Learning via Contrastive Policy Optimization](https://arxiv.org/abs/2510.04506)
*Jiashuo Sun,Shixuan Liu,Zhaochen Su,Xianrui Zhong,Pengcheng Jiang,Bowen Jin,Peiran Li,Weijia Shi,Jiawei Han*

Main category: cs.CL

TL;DR: GRACE框架将对比信号重新构想为奖励，通过策略梯度优化训练LLM生成可解释的推理过程，同时产生高质量的嵌入表示，在MTEB基准测试中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将LLM作为黑盒函数训练文本编码器，丢弃了其生成和推理能力，仅产生静态嵌入。GRACE旨在统一表示学习与生成能力，使LLM成为可解释的智能体。

Method: 将LLM视为生成可解释推理过程的策略，通过策略梯度优化训练，使用多组件奖励函数最大化正样本对相似度、最小化负样本对相似度，将推理过程编码为嵌入。

Result: 在MTEB基准测试中，监督设置相比基础模型总体得分提升11.5%，无监督变体提升6.9%，同时保持通用能力。

Conclusion: GRACE将对比目标作为推理过程的奖励，统一了表示学习与生成，产生更强的嵌入和透明的推理过程。

Abstract: Prevailing methods for training Large Language Models (LLMs) as text encoders
rely on contrastive losses that treat the model as a black box function,
discarding its generative and reasoning capabilities in favor of static
embeddings. We introduce GRACE (Generative Representation Learning via
Contrastive Policy Optimization), a novel framework that reimagines contrastive
signals not as losses to be minimized, but as rewards that guide a generative
policy. In GRACE, the LLM acts as a policy that produces explicit,
human-interpretable rationales--structured natural language explanations of its
semantic understanding. These rationales are then encoded into high-quality
embeddings via mean pooling. Using policy gradient optimization, we train the
model with a multi-component reward function that maximizes similarity between
query positive pairs and minimizes similarity with negatives. This transforms
the LLM from an opaque encoder into an interpretable agent whose reasoning
process is transparent and inspectable. On MTEB benchmark, GRACE yields broad
cross category gains: averaged over four backbones, the supervised setting
improves overall score by 11.5% over base models, and the unsupervised variant
adds 6.9%, while preserving general capabilities. This work treats contrastive
objectives as rewards over rationales, unifying representation learning with
generation to produce stronger embeddings and transparent rationales. The
model, data and code are available at https://github.com/GasolSun36/GRACE.

</details>


### [246] [Fine-grained auxiliary learning for real-world product recommendation](https://arxiv.org/abs/2510.04551)
*Mario Almagro,Diego Ortego,David Jimenez*

Main category: cs.CL

TL;DR: 提出ALC辅助学习策略，通过细粒度嵌入提升产品推荐系统的覆盖率，结合最难负样本构建判别性训练信号，在两个数据集上实现最先进的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 解决产品推荐系统中覆盖率不足的问题，即需要高比例的推荐自动化，而现有模型在真实系统集成中往往被忽视。

Method: ALC辅助学习策略，引入两个训练目标，利用批次中最难负样本来构建正负样本间的判别性训练信号，结合阈值一致性边界损失。

Result: 在LF-AmazonTitles-131K和Tech and Durables两个数据集上验证，与三种极端多标签分类方法结合，实现了最先进的覆盖率。

Conclusion: ALC策略能有效提升产品推荐系统的覆盖率，通过细粒度嵌入和最难负样本利用，为实际生产系统提供了实用的解决方案。

Abstract: Product recommendation is the task of recovering the closest items to a given
query within a large product corpora. Generally, one can determine if
top-ranked products are related to the query by applying a similarity
threshold; exceeding it deems the product relevant, otherwise manual revision
is required. Despite being a well-known problem, the integration of these
models in real-world systems is often overlooked. In particular, production
systems have strong coverage requirements, i.e., a high proportion of
recommendations must be automated. In this paper we propose ALC , an Auxiliary
Learning strategy that boosts Coverage through learning fine-grained
embeddings. Concretely, we introduce two training objectives that leverage the
hardest negatives in the batch to build discriminative training signals between
positives and negatives. We validate ALC using three extreme multi-label
classification approaches in two product recommendation datasets;
LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating
state-of-the-art coverage rates when combined with a recent
threshold-consistent margin loss.

</details>


### [247] [Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference](https://arxiv.org/abs/2510.04581)
*Dang Anh,Rick Nouwen,Massimo Poesio*

Main category: cs.CL

TL;DR: 研究LLMs在歧义和非歧义语境中如何表示和解释复数指称，发现LLMs有时能识别歧义代词的潜在指称对象，但在选择解释时并不总是遵循人类偏好，且难以在没有直接指令时识别歧义。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在表示和解释复数指称时是否表现出类似人类的偏好，以及能否检测复数照应表达中的歧义并识别可能的指称对象。

Method: 设计实验，使用下一词预测任务检验代词生成，采用不同提示策略进行代词解释和歧义检测，评估LLMs与人类在构建和解释复数指称方面的可比性。

Result: LLMs有时能识别歧义代词的潜在指称对象，但在选择解释时不总是遵循人类参考，特别是当可能的解释未被明确提及时。它们在没有直接指令时难以识别歧义，且不同类型实验的结果存在不一致性。

Conclusion: LLMs在复数指称处理方面表现出部分能力，但与人类存在显著差异，特别是在歧义识别和解释偏好方面，且结果存在实验间的不一致性。

Abstract: Our goal is to study how LLMs represent and interpret plural reference in
ambiguous and unambiguous contexts. We ask the following research questions:
(1) Do LLMs exhibit human-like preferences in representing plural reference?
(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and
identify possible referents? To address these questions, we design a set of
experiments, examining pronoun production using next-token prediction tasks,
pronoun interpretation, and ambiguity detection using different prompting
strategies. We then assess how comparable LLMs are to humans in formulating and
interpreting plural reference. We find that LLMs are sometimes aware of
possible referents of ambiguous pronouns. However, they do not always follow
human reference when choosing between interpretations, especially when the
possible interpretation is not explicitly mentioned. In addition, they struggle
to identify ambiguity without direct instruction. Our findings also reveal
inconsistencies in the results across different types of experiments.

</details>


### [248] [Robustness assessment of large audio language models in multiple-choice evaluation](https://arxiv.org/abs/2510.04584)
*Fernando López,Santosh Kesiraju,Jordi Luque*

Main category: cs.CL

TL;DR: 研究发现大型音频语言模型在多项选择题评估中对选项顺序和表述变化敏感，提出新的评估协议来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有MCQA评估框架只报告单一准确率，但模型对选项顺序和表述的细微变化会产生显著不同的结果，需要更全面的评估方法。

Method: 在三个基准测试(MMAU、MMAR、MMSU)和四个模型上系统研究选项顺序、问题重述和选项重述对评估结果的影响。

Result: 模型不仅对选项顺序敏感，对问题和选项的重新表述也表现出敏感性，现有评估方法无法捕捉这种变异性。

Conclusion: 提出了更简单的评估协议和指标，能够考虑细微变化并提供更详细的大型音频语言模型评估报告。

Abstract: Recent advances in large audio language models (LALMs) have primarily been
assessed using a multiple-choice question answering (MCQA) framework. However,
subtle changes, such as shifting the order of choices, result in substantially
different results. Existing MCQA frameworks do not account for this variability
and report a single accuracy number per benchmark or category. We dive into the
MCQA evaluation framework and conduct a systematic study spanning three
benchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio
Flamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings
indicate that models are sensitive not only to the ordering of choices, but
also to the paraphrasing of the question and the choices. Finally, we propose a
simpler evaluation protocol and metric that account for subtle variations and
provide a more detailed evaluation report of LALMs within the MCQA framework.

</details>


### [249] [FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning](https://arxiv.org/abs/2510.04601)
*Guochen Yan,Luyuan Xie,Qingni Shen,Yuejian Fang,Zhonghai Wu*

Main category: cs.CL

TL;DR: FedSRD框架通过稀疏化-重构-分解方法，在联邦学习中显著降低LoRA参数更新的通信开销达90%，同时提升异构数据上的模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于公开网络数据训练大语言模型的范式不可持续，高质量专业领域数据接近枯竭。联邦学习虽能利用分布式私有数据进行隐私保护的协同微调，但LoRA在联邦设置中的结构冗余导致通信开销巨大且客户端更新冲突。

Method: 提出FedSRD框架：重要性感知稀疏化保持LoRA更新结构完整性以减少上传参数；服务器在完整秩空间重构聚合更新以缓解冲突；将全局更新分解为稀疏低秩格式进行广播。还提出计算开销更低的FedSRD-e变体。

Result: 在10个基准测试上，该框架显著降低通信成本达90%，同时在异构客户端数据上甚至提升了模型性能。

Conclusion: FedSRD为下一代去中心化网络上的AI提供了通信高效的联邦学习解决方案，解决了LoRA在联邦设置中的通信瓶颈和更新冲突问题。

Abstract: The current paradigm of training large language models (LLMs) on publicly
available Web data is becoming unsustainable, with high-quality data sources in
specialized domains nearing exhaustion. Federated Learning (FL) emerges as a
practical solution for the next generation of AI on a decentralized Web,
enabling privacy-preserving collaborative fine-tuning by leveraging private
data distributed across a global client base. While Low-Rank Adaptation (LoRA)
is the standard for efficient fine-tuning, its application in federated
settings presents a critical challenge: communication overhead remains a
significant bottleneck across the Web's heterogeneous network conditions. The
structural redundancy within LoRA parameters not only incurs a heavy
communication burden but also introduces conflicts when aggregating client
updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose
framework designed for communication-efficient FL. We first introduce an
importance-aware sparsification method that preserves the structural integrity
of LoRA updates to reduce the uploaded parameter count. The server then
reconstructs and aggregates these updates in a full-rank space to mitigate
conflicts. Finally, it decomposes the global update into a sparse low-rank
format for broadcast, ensuring a symmetrically efficient cycle. We also propose
an efficient variant, FedSRD-e, to reduce computational overhead. Experimental
results on 10 benchmarks demonstrate that our framework significantly reduces
communication costs by up to 90\% while even improving model performance on
heterogeneous client data.

</details>


### [250] [Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry](https://arxiv.org/abs/2510.04631)
*Anastasia Zhukova,Jonas Lührs,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 将SciNCL图感知邻域对比学习方法应用于流程工业领域，通过知识图谱增强语言模型，在PITEB基准上比mE5-large提升9.8-14.3%，且模型尺寸小3-5倍。


<details>
  <summary>Details</summary>
Motivation: 利用知识图谱增强预训练语言模型，学习领域特定术语和文档间关系，解决流程工业文本日志中可能被忽略的重要信息。

Method: 采用SciNCL图感知邻域对比学习方法，从图结构中提取三元组对语言模型进行微调。

Result: 在专有流程工业文本嵌入基准(PITEB)上，比最先进的mE5-large文本编码器性能提升9.8-14.3%(5.4-8.0个百分点)，同时模型尺寸小3-5倍。

Conclusion: 图感知对比学习方法能有效提升流程工业领域的文本嵌入性能，在保持较小模型尺寸的同时显著超越现有方法。

Abstract: Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained
language models by incorporating additional knowledge from the graph structures
to learn domain-specific terminology or relationships between documents that
might otherwise be overlooked. This paper explores how SciNCL, a graph-aware
neighborhood contrastive learning methodology originally designed for
scientific publications, can be applied to the process industry domain, where
text logs contain crucial information about daily operations and are often
structured as sparse KGs. Our experiments demonstrate that language models
fine-tuned with triplets derived from GE outperform a state-of-the-art
mE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process
industry text embedding benchmark (PITEB) while being 3-5 times smaller in
size.

</details>


### [251] [Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study](https://arxiv.org/abs/2510.04641)
*Ayan Majumdar,Feihao Chen,Jinghui Li,Xiaozhen Wang*

Main category: cs.CL

TL;DR: 该研究提出了一个全面的评估框架，用于评估大语言模型在检测英语文本中针对人口统计特征的社会偏见方面的能力，通过多标签任务和系统性评估发现微调的小型模型在可扩展检测方面具有潜力，但在多人口统计目标偏见方面仍存在差距。


<details>
  <summary>Details</summary>
Motivation: 大规模网络爬取的文本语料库通常包含有害的人口统计目标社会偏见，需要数据审计和可扩展的偏见检测方法。现有研究范围狭窄，缺乏对LLMs在自动偏见检测方面能力的全面理解。

Method: 构建了一个针对英语文本的全面评估框架，将偏见检测构建为多标签任务，使用人口统计聚焦的分类法。通过提示、上下文学习和微调等技术，对跨尺度的模型进行系统性评估，使用了涵盖不同内容类型和人口统计特征的12个数据集。

Result: 研究表明微调的小型模型在可扩展检测方面具有潜力，但分析也暴露了跨人口统计轴和多人口统计目标偏见的持续差距。

Conclusion: 需要更有效和可扩展的审计框架来解决多人口统计目标偏见检测方面的挑战。

Abstract: Large-scale web-scraped text corpora used to train general-purpose AI models
often contain harmful demographic-targeted social biases, creating a regulatory
need for data auditing and developing scalable bias-detection methods. Although
prior work has investigated biases in text datasets and related detection
methods, these studies remain narrow in scope. They typically focus on a single
content type (e.g., hate speech), cover limited demographic axes, overlook
biases affecting multiple demographics simultaneously, and analyze limited
techniques. Consequently, practitioners lack a holistic understanding of the
strengths and limitations of recent large language models (LLMs) for automated
bias detection. In this study, we present a comprehensive evaluation framework
aimed at English texts to assess the ability of LLMs in detecting
demographic-targeted social biases. To align with regulatory requirements, we
frame bias detection as a multi-label task using a demographic-focused
taxonomy. We then conduct a systematic evaluation with models across scales and
techniques, including prompting, in-context learning, and fine-tuning. Using
twelve datasets spanning diverse content types and demographics, our study
demonstrates the promise of fine-tuned smaller models for scalable detection.
However, our analyses also expose persistent gaps across demographic axes and
multi-demographic targeted biases, underscoring the need for more effective and
scalable auditing frameworks.

</details>


### [252] [FT-MDT: Extracting Decision Trees from Medical Texts via a Novel Low-rank Adaptation Method](https://arxiv.org/abs/2510.04655)
*Yuheng Li,Jiechao Gao,Wei Han,Wenwen Ouyang,Wei Zhu,Hui Yi Leong*

Main category: cs.CL

TL;DR: 提出PI-LoRA方法，通过集成梯度路径信息自动从临床指南中提取医疗决策树，在保持轻量级架构的同时显著提升Text2MDT任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗决策树构建方法依赖耗时费力的人工标注，需要自动化解决方案来支持临床决策系统建设。

Method: PI-LoRA（路径集成LoRA）方法，通过集成梯度路径信息捕捉模块间协同效应，实现更有效的秩分配，关键模块获得适当秩分配，次要模块被剪枝。

Result: 在医疗指南数据集上的实验表明，PI-LoRA显著优于现有参数高效微调方法，在保持轻量级架构的同时达到最先进结果。

Conclusion: PI-LoRA方法特别适合计算资源有限的临床决策支持系统，能够高效准确地从临床文本中提取医疗决策树。

Abstract: Knowledge of the medical decision process, which can be modeled as medical
decision trees (MDTs), is critical to building clinical decision support
systems. However, current MDT construction methods rely heavily on
time-consuming and laborious manual annotation. To address this challenge, we
propose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for
automatically extracting MDTs from clinical guidelines and textbooks. We
integrate gradient path information to capture synergistic effects between
different modules, enabling more effective and reliable rank allocation. This
framework ensures that the most critical modules receive appropriate rank
allocations while less important ones are pruned, resulting in a more efficient
and accurate model for extracting medical decision trees from clinical texts.
Extensive experiments on medical guideline datasets demonstrate that our
PI-LoRA method significantly outperforms existing parameter-efficient
fine-tuning approaches for the Text2MDT task, achieving better accuracy with
substantially reduced model complexity. The proposed method achieves
state-of-the-art results while maintaining a lightweight architecture, making
it particularly suitable for clinical decision support systems where
computational resources may be limited.

</details>


### [253] [FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification](https://arxiv.org/abs/2510.04671)
*Chao Liu,Ling Luo,Tengxiao Lv,Huan Zhuang,Lejing Yu,Jian Wang,Hongfei Lin*

Main category: cs.CL

TL;DR: 提出了基于核心焦点指导的优化框架，通过提取忠实于原文的核心焦点、构建微调数据集和多维度质量评估，显著提升了医疗问题摘要任务中焦点识别能力和减少了幻觉生成。


<details>
  <summary>Details</summary>
Motivation: 在线医疗平台中消费者健康问题存在信息冗余和非专业术语，现有医疗问题摘要方法在问题焦点识别和模型幻觉方面仍面临挑战。

Method: 设计提示模板提取核心焦点，结合原始CHQ-FAQ对构建微调数据集，提出多维度质量评估和选择机制。

Result: 在两个广泛采用的MQS数据集上使用三个评估指标进行实验，在所有指标上达到最先进性能，显著提升了问题关键焦点识别能力并减轻了幻觉。

Conclusion: 提出的基于核心焦点指导的优化框架有效解决了医疗问题摘要任务中的焦点识别偏差和内容不忠实问题。

Abstract: With the rapid development of online medical platforms, consumer health
questions (CHQs) are inefficient in diagnosis due to redundant information and
frequent non-professional terms. The medical question summary (MQS) task aims
to transform CHQs into streamlined doctors' frequently asked questions (FAQs),
but existing methods still face challenges such as poor identification of
question focus and model hallucination. This paper explores the potential of
large language models (LLMs) in the MQS task and finds that direct fine-tuning
is prone to focus identification bias and generates unfaithful content. To this
end, we propose an optimization framework based on core focus guidance. First,
a prompt template is designed to drive the LLMs to extract the core focus from
the CHQs that is faithful to the original text. Then, a fine-tuning dataset is
constructed in combination with the original CHQ-FAQ pairs to improve the
ability to identify the focus of the question. Finally, a multi-dimensional
quality evaluation and selection mechanism is proposed to comprehensively
improve the quality of the summary from multiple dimensions. We conduct
comprehensive experiments on two widely-adopted MQS datasets using three
established evaluation metrics. The proposed framework achieves
state-of-the-art performance across all measures, demonstrating a significant
boost in the model's ability to identify critical focus of questions and a
notable mitigation of hallucinations. The source codes are freely available at
https://github.com/DUT-LiuChao/FocusMed.

</details>


### [254] [Multi-Agent Tool-Integrated Policy Optimization](https://arxiv.org/abs/2510.04678)
*Zhanfeng Mo,Xingxuan Li,Yuntao Chen,Lidong Bing*

Main category: cs.CL

TL;DR: 提出了MATPO方法，在单个LLM实例中通过强化学习训练规划者和执行者两种角色，解决多轮工具集成规划中的上下文限制和噪声工具响应问题。


<details>
  <summary>Details</summary>
Motivation: 现有单智能体方法存在上下文长度限制和工具响应噪声问题，而多智能体框架虽然能管理上下文，但缺乏有效的强化学习后训练方法。

Method: MATPO通过角色特定提示在单个LLM实例中训练规划者和执行者角色，采用基于原则的跨角色信用分配机制，无需部署多个LLM。

Result: 在GAIA-text、WebWalkerQA和FRAMES数据集上，MATPO平均性能相对提升18.38%，对噪声工具输出表现出更强鲁棒性。

Conclusion: 在单个LLM中统一多个智能体角色是有效的，为稳定高效的多智能体强化学习训练提供了实用见解。

Abstract: Large language models (LLMs) increasingly rely on multi-turn tool-integrated
planning for knowledge-intensive and complex reasoning tasks. Existing
implementations typically rely on a single agent, but they suffer from limited
context length and noisy tool responses. A natural solution is to adopt a
multi-agent framework with planner- and worker-agents to manage context.
However, no existing methods support effective reinforcement learning
post-training of tool-integrated multi-agent frameworks. To address this gap,
we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which
enables distinct roles (planner and worker) to be trained within a single LLM
instance using role-specific prompts via reinforcement learning. MATPO is
derived from a principled credit assignment mechanism across planner and worker
rollouts. This design eliminates the need to deploy multiple LLMs, which would
be memory-intensive, while preserving the benefits of specialization.
Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently
outperforms single-agent baselines by an average of 18.38% relative improvement
in performance and exhibits greater robustness to noisy tool outputs. Our
findings highlight the effectiveness of unifying multiple agent roles within a
single LLM and provide practical insights for stable and efficient multi-agent
RL training.

</details>


### [255] [TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA](https://arxiv.org/abs/2510.04682)
*Chanjoo Jung,Jaehyung Kim*

Main category: cs.CL

TL;DR: TiTok是一个新的框架，通过token级知识转移实现有效的LoRA移植，无需额外模型或开销即可在基础模型间转移适配参数。


<details>
  <summary>Details</summary>
Motivation: 解决PEFT方法如LoRA中适配参数依赖于基础模型、无法在不同骨干网络间转移的问题，避免知识蒸馏对训练数据的依赖和TransLoRA需要额外判别器模型的复杂性。

Method: 通过对比源模型在有和没有LoRA时的差异，捕获任务相关信息，突出信息丰富的token，并选择性过滤合成数据。

Result: 在三个基准测试的多种转移设置中，该方法持续有效，相比基线平均性能提升+4~8%。

Conclusion: TiTok框架能够有效实现LoRA移植，在不同基础模型间转移适配参数，且无需额外模型或复杂开销。

Abstract: Large Language Models (LLMs) are widely applied in real world scenarios, but
fine-tuning them comes with significant computational and storage costs.
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these
costs, but the adapted parameters are dependent on the base model and cannot be
transferred across different backbones. One way to address this issue is
through knowledge distillation, but its effectiveness inherently depends on
training data. Recent work such as TransLoRA avoids this by generating
synthetic data, but this adds complexity because it requires training an
additional discriminator model. In this paper, we propose TiTok, a new
framework that enables effective LoRA Transplantation through Token-level
knowledge transfer. Specifically, TiTok captures task-relevant information
through a contrastive excess between a source model with and without LoRA. This
excess highlights informative tokens and enables selective filtering of
synthetic data, all without additional models or overhead. Through experiments
on three benchmarks across multiple transfer settings, our experiments show
that the proposed method is consistently effective, achieving average
performance gains of +4~8% compared to baselines overall.

</details>


### [256] [Multilingual Routing in Mixture-of-Experts](https://arxiv.org/abs/2510.04694)
*Lucas Bandarkar,Chenyuan Yang,Mohsen Fayyaz,Junlin Hu,Nanyun Peng*

Main category: cs.CL

TL;DR: 该论文分析了MoE架构在多语言数据下的稀疏路由动态，发现中间层存在跨语言路由对齐现象，并提出了一种通过引导路由器提升多语言性能的干预方法。


<details>
  <summary>Details</summary>
Motivation: 理解MoE架构在多语言数据下的稀疏路由动态，探索如何提升多语言LLMs的性能。

Method: 使用并行多语言数据集分析专家路由模式，提出在推理时通过促进中间层任务专家来引导路由器的干预方法。

Result: 干预方法在两种评估任务、三个模型和15+种语言上一致提升了1-2%的多语言性能，而其他干预方式则导致性能下降。

Conclusion: MoE模型处理非英语文本的能力受限于其利用语言通用专家的能力，中间层的跨语言路由对齐与模型性能密切相关。

Abstract: Mixture-of-Experts (MoE) architectures have become the key to scaling modern
LLMs, yet little is understood about how their sparse routing dynamics respond
to multilingual data. In this work, we analyze expert routing patterns using
parallel multilingual datasets and present highly interpretable layer-wise
phenomena. We find that MoE models route tokens in language-specific ways in
the early and late decoder layers but exhibit significant cross-lingual routing
alignment in middle layers, mirroring parameter-sharing trends observed in
dense LLMs. In particular, we reveal a clear, strong correlation between a
model's performance in a given language and how similarly its tokens are routed
to English in these layers. Extending beyond correlation, we explore
inference-time interventions that induce higher cross-lingual routing
alignment. We introduce a method that steers the router by promoting
middle-layer task experts frequently activated in English, and it successfully
increases multilingual performance. These 1-2% gains are remarkably consistent
across two evaluation tasks, three models, and 15+ languages, especially given
that these simple interventions override routers of extensively trained,
state-of-the-art LLMs. In comparison, interventions outside of the middle
layers or targeting multilingual-specialized experts only yield performance
degradation. Altogether, we present numerous findings that explain how MoEs
process non-English text and demonstrate that generalization is limited by the
model's ability to leverage language-universal experts in all languages.

</details>


### [257] [JSON Whisperer: Efficient JSON Editing with LLMs](https://arxiv.org/abs/2510.04717)
*Sarel Duanis,Asnat Greenstein-Messica,Eliya Habba*

Main category: cs.CL

TL;DR: JSON Whisperer是一个让LLM生成RFC 6902差异补丁而非完整JSON文档的框架，通过EASE编码解决数组操作中的索引偏移问题，显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前LLM编辑JSON文档时需要重新生成整个结构，计算效率低下，需要一种更高效的方法来只生成必要的修改部分。

Method: 提出JSON Whisperer框架，引入EASE（显式寻址序列编码）将数组转换为具有稳定键的字典，消除索引算术复杂性。

Result: 补丁生成结合EASE减少31%的token使用量，编辑质量保持在完全重新生成的5%以内，在复杂指令和列表操作方面表现尤其突出。

Conclusion: JSON Whisperer通过补丁生成和EASE编码有效解决了LLM在JSON编辑中的计算效率问题，特别改善了数组操作的性能。

Abstract: Large language models (LLMs) can modify JSON documents through natural
language commands, but current approaches regenerate entire structures for each
edit, resulting in computational inefficiency. We present JSON Whisperer, a
framework that enables LLMs to generate RFC 6902 diff patches-expressing only
the necessary modifications-rather than complete documents. We identify two key
challenges in patch-based editing: (1) LLMs often miss related updates when
generating isolated patches, and (2) array manipulations require tracking index
shifts across operations, which LLMs handle poorly. To address these issues, we
introduce EASE (Explicitly Addressed Sequence Encoding), which transforms
arrays into dictionaries with stable keys, eliminating index arithmetic
complexities. Our evaluation shows that patch generation with EASE reduces
token usage by 31% while maintaining edit quality within 5% of full
regeneration with particular gains for complex instructions and list
manipulations. The dataset is available at:
https://github.com/emnlp2025/JSON-Whisperer/

</details>


### [258] [A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance](https://arxiv.org/abs/2510.04750)
*Peshala Perera,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: 为僧伽罗语阅读障碍成人开发的多模态辅助系统，集成语音转文本、错误识别、文本校正和语音输出功能，在资源有限的语言环境中取得良好效果


<details>
  <summary>Details</summary>
Motivation: 成人阅读障碍在非英语环境中研究不足，特别是僧伽罗语等低资源语言缺乏语言可及性工具，严重影响个人和职业生活

Method: 整合Whisper进行语音转文本，使用SinBERT识别常见阅读障碍错误，结合mT5和Mistral模型生成校正文本，最后通过gTTS转回语音形成完整多模态反馈循环

Result: 在僧伽罗语数据集有限的情况下，系统达到0.66的转录准确率、0.7的校正准确率和0.65的整体系统准确率

Conclusion: 该方法证明了在低资源语言环境中开发包容性自然语言处理技术的可行性和有效性

Abstract: Dyslexia in adults remains an under-researched and under-served area,
particularly in non-English-speaking contexts, despite its significant impact
on personal and professional lives. This work addresses that gap by focusing on
Sinhala, a low-resource language with limited tools for linguistic
accessibility. We present an assistive system explicitly designed for
Sinhala-speaking adults with dyslexia. The system integrates Whisper for
speech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model
trained for Sinhala to identify common dyslexic errors, and a combined mT5 and
Mistral-based model to generate corrected text. Finally, the output is
converted back to speech using gTTS, creating a complete multimodal feedback
loop. Despite the challenges posed by limited Sinhala-language datasets, the
system achieves 0.66 transcription accuracy and 0.7 correction accuracy with
0.65 overall system accuracy. These results demonstrate both the feasibility
and effectiveness of the approach. Ultimately, this work highlights the
importance of inclusive Natural Language Processing (NLP) technologies in
underrepresented languages and showcases a practical

</details>


### [259] [ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever](https://arxiv.org/abs/2510.04757)
*Eduardo Martínez Rivera,Filippo Menolascina*

Main category: cs.CL

TL;DR: 提出了一种两阶段检索架构，结合轻量级ModernBERT进行候选检索和ColBERTv2进行重排序，在生物医学RAG系统中实现了最先进性能


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中检索模块性能限制问题，平衡专业领域语言理解与计算成本之间的权衡

Method: 两阶段检索架构：ModernBERT双向编码器进行初始候选检索，ColBERTv2延迟交互模型进行细粒度重排序，使用PubMedQA的10k问答对进行微调

Result: ColBERT重排序器将Recall@3提升4.2个百分点，在MIRAGE问答基准测试中达到0.4448的平均准确率，优于MedCPT基线

Conclusion: 两阶段检索架构在生物医学RAG中表现优异，但性能关键依赖于检索器和重排序器的联合微调过程

Abstract: Retrieval-Augmented Generation (RAG) is a powerful technique for enriching
Large Language Models (LLMs) with external knowledge, allowing for factually
grounded responses, a critical requirement in high-stakes domains such as
healthcare. However, the efficacy of RAG systems is fundamentally restricted by
the performance of their retrieval module, since irrelevant or semantically
misaligned documents directly compromise the accuracy of the final generated
response. General-purpose dense retrievers can struggle with the nuanced
language of specialised domains, while the high accuracy of in-domain models is
often achieved at prohibitive computational costs. In this work, we aim to
address this trade-off by developing and evaluating a two-stage retrieval
architecture that combines a lightweight ModernBERT bidirectional encoder for
efficient initial candidate retrieval with a ColBERTv2 late-interaction model
for fine-grained re-ranking. We conduct comprehensive evaluations of our
retriever module performance and RAG system performance in the biomedical
context, fine-tuning the IR module using 10k question-passage pairs from
PubMedQA. Our analysis of the retriever module confirmed the positive impact of
the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points
compared to its retrieve-only counterpart. When integrated into the biomedical
RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on
the five tasks of the MIRAGE question-answering benchmark, outperforming strong
baselines such as MedCPT (0.4436). Our ablation studies reveal that this
performance is critically dependent on a joint fine-tuning process that aligns
the retriever and re-ranker; otherwise, the re-ranker might degrade the
performance.

</details>


### [260] [Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models](https://arxiv.org/abs/2510.04764)
*Raha Askari,Sina Zarrieß,Özge Alacam,Judith Sieker*

Main category: cs.CL

TL;DR: 该论文提出了一个评估语言模型识别格赖斯会话准则违反的新基准，比较了在不同规模数据上预训练的BabyLMs与儿童和大型语言模型的性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否能够识别和解释人类交流中的隐含意义，特别是通过检测格赖斯会话准则的违反来理解语用推理。

Method: 基于Surian等人对儿童识别格赖斯准则违反的研究，创建新基准测试，比较在少于10M和100M tokens上预训练的BabyLMs、儿童以及基于3T tokens预训练的LLM在五个会话准则上的表现。

Result: 在少于100M tokens上训练的模型整体优于在少于10M tokens上训练的模型，但仍未达到儿童和LLM的水平。数据量的适度增加改善了某些语用行为方面，导致对语用维度更细粒度的区分。

Conclusion: 虽然增加训练数据能提升语言模型的语用能力，但当前的小规模模型仍无法达到人类儿童或大型语言模型的语用推理水平，表明语用理解需要更复杂的学习机制。

Abstract: Implicit meanings are integral to human communication, making it essential
for language models to be capable of identifying and interpreting them. Grice
(1975) proposed a set of conversational maxims that guide cooperative dialogue,
noting that speakers may deliberately violate these principles to express
meanings beyond literal words, and that listeners, in turn, recognize such
violations to draw pragmatic inferences.
  Building on Surian et al. (1996)'s study of children's sensitivity to
violations of Gricean maxims, we introduce a novel benchmark to test whether
language models pretrained on less than 10M and less than 100M tokens can
distinguish maxim-adhering from maxim-violating utterances. We compare these
BabyLMs across five maxims and situate their performance relative to children
and a Large Language Model (LLM) pretrained on 3T tokens.
  We find that overall, models trained on less than 100M tokens outperform
those trained on less than 10M, yet fall short of child-level and LLM
competence. Our results suggest that modest data increases improve some aspects
of pragmatic behavior, leading to finer-grained differentiation between
pragmatic dimensions.

</details>


### [261] [Hybrid Architectures for Language Models: Systematic Analysis and Design Insights](https://arxiv.org/abs/2510.04800)
*Sangmin Bae,Bilge Acun,Haroun Habeeb,Seungyeon Kim,Chien-Yu Lin,Liang Luo,Junjie Wang,Carole-Jean Wu*

Main category: cs.CL

TL;DR: 本文系统评估了基于层间（顺序）和层内（并行）融合的混合架构，分析了语言建模性能、长上下文能力、扩展性以及训练推理效率，提出了混合模型的最优设计方法。


<details>
  <summary>Details</summary>
Motivation: 虽然混合架构（结合自注意力机制和结构化状态空间模型如Mamba）在建模质量和计算效率方面表现良好，但缺乏对混合策略的系统比较和关键因素分析。

Method: 通过层间（顺序）和层内（并行）融合两种混合策略，从语言建模性能、长上下文能力、扩展分析、训练和推理效率等多个角度进行全面评估。

Result: 识别了每种混合策略最关键的计算原语特征，提出了两种混合模型的最优设计方法。

Conclusion: 为开发混合语言模型提供了实用指导和宝贵见解，有助于优化架构配置。

Abstract: Recent progress in large language models demonstrates that hybrid
architectures--combining self-attention mechanisms with structured state space
models like Mamba--can achieve a compelling balance between modeling quality
and computational efficiency, particularly for long-context tasks. While these
hybrid models show promising performance, systematic comparisons of
hybridization strategies and analyses on the key factors behind their
effectiveness have not been clearly shared to the community. In this work, we
present a holistic evaluation of hybrid architectures based on inter-layer
(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a
variety of perspectives: language modeling performance, long-context
capabilities, scaling analysis, and training and inference efficiency. By
investigating the core characteristics of their computational primitive, we
identify the most critical elements for each hybridization strategy and further
propose optimal design recipes for both hybrid models. Our comprehensive
analysis provides practical guidance and valuable insights for developing
hybrid language models, facilitating the optimization of architectural
configurations.

</details>


### [262] [How I Built ASR for Endangered Languages with a Spoken Dictionary](https://arxiv.org/abs/2510.04832)
*Christopher Bartley,Anton Ragni*

Main category: cs.CL

TL;DR: 研究表明，濒危语言构建语音识别系统的数据需求远低于传统预期，仅需40分钟的发音数据即可为马恩岛盖尔语和康沃尔语等濒危语言开发可用的ASR系统。


<details>
  <summary>Details</summary>
Motivation: 全球近半数语言濒临灭绝，传统语音识别系统需要句子级监督数据，而大多数濒危语言缺乏此类格式数据。研究探索如何用最少数据为濒危语言构建ASR系统。

Method: 使用短格式发音资源作为替代方案，测试了马恩岛盖尔语和康沃尔语两种濒危语言，仅需40分钟此类数据即可构建ASR系统。

Result: 40分钟的发音数据可为马恩岛盖尔语构建词错误率低于50%的可用ASR系统，并在康沃尔语上成功复现该方法。

Conclusion: 构建濒危语言ASR系统的数据门槛（数量与格式）远低于传统认知，为无法满足传统数据要求的濒危语言社区带来了希望。

Abstract: Nearly half of the world's languages are endangered. Speech technologies such
as Automatic Speech Recognition (ASR) are central to revival efforts, yet most
languages remain unsupported because standard pipelines expect utterance-level
supervised data. Speech data often exist for endangered languages but rarely
match these formats. Manx Gaelic ($\sim$2,200 speakers), for example, has had
transcribed speech since 1948, yet remains unsupported by modern systems. In
this paper, we explore how little data, and in what form, is needed to build
ASR for critically endangered languages. We show that a short-form
pronunciation resource is a viable alternative, and that 40 minutes of such
data produces usable ASR for Manx ($<$50\% WER). We replicate our approach,
applying it to Cornish ($\sim$600 speakers), another critically endangered
language. Results show that the barrier to entry, in quantity and form, is far
lower than previously thought, giving hope to endangered language communities
that cannot afford to meet the requirements arbitrarily imposed upon them.

</details>


### [263] [Instability in Downstream Task Performance During LLM Pretraining](https://arxiv.org/abs/2510.04848)
*Yuto Nishida,Masaru Isonuma,Yusuke Oda*

Main category: cs.CL

TL;DR: 该论文分析了LLM训练中下游任务性能的波动问题，提出了两种检查点集成方法来提高性能稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练过程中，下游任务性能经常出现显著波动，使得难以确定真正最佳性能的检查点。

Method: 研究了下游任务性能的稳定性，并提出了两种后处理检查点集成方法：检查点平均和集成，通过聚合相邻检查点来减少性能波动。

Result: 经验证明和理论分析表明，这些方法能够提高下游性能稳定性，且无需改变训练过程。

Conclusion: 检查点集成方法可以有效解决LLM训练中下游任务性能波动的问题，提高模型选择的可靠性。

Abstract: When training large language models (LLMs), it is common practice to track
downstream task performance throughout the training process and select the
checkpoint with the highest validation score. However, downstream metrics often
exhibit substantial fluctuations, making it difficult to identify the
checkpoint that truly represents the best-performing model. In this study, we
empirically analyze the stability of downstream task performance in an LLM
trained on diverse web-scale corpora. We find that task scores frequently
fluctuate throughout training, both at the aggregate and example levels. To
address this instability, we investigate two post-hoc checkpoint integration
methods: checkpoint averaging and ensemble, motivated by the hypothesis that
aggregating neighboring checkpoints can reduce performance volatility. We
demonstrate both empirically and theoretically that these methods improve
downstream performance stability without requiring any changes to the training
procedure.

</details>


### [264] [ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization](https://arxiv.org/abs/2505.02819)
*Dmitriy Shopkhoev,Ammar Ali,Magauiya Zhussip,Valentin Malykh,Stamatios Lefkimmiatis,Nikos Komodakis,Sergey Zagoruyko*

Main category: cs.CL

TL;DR: ReplaceMe是一种无需训练即可进行深度剪枝的方法，通过用线性变换替换Transformer块，在低压缩比下保持高性能。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法需要额外训练或微调，计算成本高。ReplaceMe旨在开发一种无需训练即可有效剪枝的方法，减少计算开销。

Method: 使用小型校准数据集估计线性变换来近似被剪枝的块，该线性映射可与剩余Transformer块无缝合并，无需额外网络参数。

Result: 在多个大语言模型上实现高达25%的剪枝，同时保持约90%的原始模型性能，计算开销极小。

Conclusion: ReplaceMe在无需训练的情况下，性能优于其他无训练剪枝方法，并与需要大量重新训练的最先进方法保持竞争力。

Abstract: We introduce ReplaceMe, a generalized training-free depth pruning method that
effectively replaces transformer blocks with a linear operation, while
maintaining high performance for low compression ratios. In contrast to
conventional pruning approaches that require additional training or
fine-tuning, our approach requires only a small calibration dataset that is
used to estimate a linear transformation, which approximates the pruned blocks.
The estimated linear mapping can be seamlessly merged with the remaining
transformer blocks, eliminating the need for any additional network parameters.
Our experiments show that ReplaceMe consistently outperforms other
training-free approaches and remains highly competitive with state-of-the-art
pruning methods that involve extensive retraining/fine-tuning and architectural
modifications. Applied to several large language models (LLMs), ReplaceMe
achieves up to 25% pruning while retaining approximately 90% of the original
model's performance on open benchmarks - without any training or healing steps,
resulting in minimal computational overhead (see Fig.1). We provide an
open-source library implementing ReplaceMe alongside several state-of-the-art
depth pruning techniques, available at https://github.com/mts-ai/ReplaceMe.

</details>


### [265] [When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA](https://arxiv.org/abs/2510.04849)
*Elisei Rykov,Kseniia Petrushina,Maksim Savkin,Valerii Olisov,Artem Vazhentsev,Kseniia Titova,Alexander Panchenko,Vasily Konovalov,Julia Belikova*

Main category: cs.CL

TL;DR: 提出了PsiloQA，一个大规模多语言数据集，包含14种语言的span级幻觉标注，用于评估幻觉检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉基准测试主要在序列级别且仅限于英语，缺乏细粒度的多语言监督，无法全面评估大语言模型的幻觉问题。

Method: 通过自动化三阶段流程构建数据集：使用GPT-4o从维基百科生成问答对，在无上下文设置下从多样LLMs获取可能幻觉的答案，使用GPT-4o通过与黄金答案和检索上下文的比较自动标注幻觉span。

Result: 评估了多种幻觉检测方法，发现基于编码器的模型在所有语言中表现最强，PsiloQA展示了有效的跨语言泛化能力，并能有效迁移到其他基准测试。

Conclusion: PsiloQA数据集和结果推动了在多语言设置下可扩展、细粒度幻觉检测的发展，且比人工标注数据集更具成本效益。

Abstract: Hallucination detection remains a fundamental challenge for the safe and
reliable deployment of large language models (LLMs), especially in applications
requiring factual accuracy. Existing hallucination benchmarks often operate at
the sequence level and are limited to English, lacking the fine-grained,
multilingual supervision needed for a comprehensive evaluation. In this work,
we introduce PsiloQA, a large-scale, multilingual dataset annotated with
span-level hallucinations across 14 languages. PsiloQA is constructed through
an automated three-stage pipeline: generating question-answer pairs from
Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse
LLMs in a no-context setting, and automatically annotating hallucinated spans
using GPT-4o by comparing against golden answers and retrieved context. We
evaluate a wide range of hallucination detection methods -- including
uncertainty quantification, LLM-based tagging, and fine-tuned encoder models --
and show that encoder-based models achieve the strongest performance across
languages. Furthermore, PsiloQA demonstrates effective cross-lingual
generalization and supports robust knowledge transfer to other benchmarks, all
while being significantly more cost-efficient than human-annotated datasets.
Our dataset and results advance the development of scalable, fine-grained
hallucination detection in multilingual settings.

</details>


### [266] [Detecting Distillation Data from Reasoning Models](https://arxiv.org/abs/2510.04850)
*Hengxiang Zhang,Hyeong Kyu Choi,Yixuan Li,Hongxin Wei*

Main category: cs.CL

TL;DR: 提出了一种名为Token Probability Deviation (TBD)的新方法，用于检测推理蒸馏过程中的数据污染问题，通过分析生成token的概率偏差来区分已见和未见问题。


<details>
  <summary>Details</summary>
Motivation: 推理蒸馏可能无意中导致基准污染，评估数据包含在蒸馏数据集中会夸大蒸馏模型的性能指标，需要检测这种数据污染。

Method: 提出Token Probability Deviation (TBD)方法，利用生成输出token的概率模式，量化生成token概率与高参考概率的偏差程度。

Result: 在S1数据集上实现了0.918的AUC和0.470的TPR@1% FPR，表现出优越的检测性能。

Conclusion: TBD方法能有效检测推理蒸馏中的数据污染问题，通过分析token概率偏差实现高精度的已见/未见问题区分。

Abstract: Reasoning distillation has emerged as an efficient and powerful paradigm for
enhancing the reasoning capabilities of large language models. However,
reasoning distillation may inadvertently cause benchmark contamination, where
evaluation data included in distillation datasets can inflate performance
metrics of distilled models. In this work, we formally define the task of
distillation data detection, which is uniquely challenging due to the partial
availability of distillation data. Then, we propose a novel and effective
method Token Probability Deviation (TBD), which leverages the probability
patterns of the generated output tokens. Our method is motivated by the
analysis that distilled models tend to generate near-deterministic tokens for
seen questions, while producing more low-probability tokens for unseen
questions. Our key idea behind TBD is to quantify how far the generated tokens'
probabilities deviate from a high reference probability. In effect, our method
achieves competitive detection performance by producing lower scores for seen
questions than for unseen questions. Extensive experiments demonstrate the
effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of
0.470 on the S1 dataset.

</details>


### [267] [SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891)
*Punya Syon Pandey,Hai Son Le,Devansh Bhardwaj,Rada Mihalcea,Zhijing Jin*

Main category: cs.CL

TL;DR: SocialHarmBench是一个包含585个提示的数据集，涵盖7个社会政治类别和34个国家，用于测试LLM在政治敏感语境中的脆弱性。研究发现开源模型在有害合规方面存在高风险，Mistral-7B在历史修正主义、宣传和政治操纵等领域的攻击成功率高达97%-98%。


<details>
  <summary>Details</summary>
Motivation: 现有安全基准很少测试LLM在政治操纵、宣传和虚假信息生成、监控和信息控制等领域的漏洞，而这些失败可能产生直接的社会政治后果。

Method: 构建SocialHarmBench数据集，包含585个提示，涵盖7个社会政治类别和34个国家，评估LLM在政治敏感语境中的表现。

Result: 开源模型对有害合规表现出高脆弱性，Mistral-7B在历史修正主义、宣传和政治操纵等领域的攻击成功率高达97%-98%。时间和地理分析显示LLM在21世纪和前20世纪语境中最脆弱，对拉丁美洲、美国和英国等地区的提示响应最不稳定。

Conclusion: 当前的安全防护措施无法推广到高风险的社会政治环境中，暴露了系统性偏见，引发了对LLM在保护人权和民主价值观方面可靠性的担忧。

Abstract: Large language models (LLMs) are increasingly deployed in contexts where
their failures can have direct sociopolitical consequences. Yet, existing
safety benchmarks rarely test vulnerabilities in domains such as political
manipulation, propaganda and disinformation generation, or surveillance and
information control. We introduce SocialHarmBench, a dataset of 585 prompts
spanning 7 sociopolitical categories and 34 countries, designed to surface
where LLMs most acutely fail in politically charged contexts. Our evaluations
reveal several shortcomings: open-weight models exhibit high vulnerability to
harmful compliance, with Mistral-7B reaching attack success rates as high as
97% to 98% in domains such as historical revisionism, propaganda, and political
manipulation. Moreover, temporal and geographic analyses show that LLMs are
most fragile when confronted with 21st-century or pre-20th-century contexts,
and when responding to prompts tied to regions such as Latin America, the USA,
and the UK. These findings demonstrate that current safeguards fail to
generalize to high-stakes sociopolitical settings, exposing systematic biases
and raising concerns about the reliability of LLMs in preserving human rights
and democratic values. We share the SocialHarmBench benchmark at
https://huggingface.co/datasets/psyonp/SocialHarmBench.

</details>


### [268] [Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment](https://arxiv.org/abs/2510.04919)
*Davood Rafiei,Morgan Lindsay Heisler,Weiwei Zhang,Mohammadreza Pourreza,Yong Zhang*

Main category: cs.CL

TL;DR: 本文研究了NL2SQL任务中训练数据与目标查询的结构对齐问题，发现结构对齐程度是预测微调成功的关键指标。


<details>
  <summary>Details</summary>
Motivation: 监督微调(SFT)能有效适应大语言模型，但训练数据的可变性会影响模型跨领域泛化能力。本文旨在研究NL2SQL任务中数据集对齐对模型性能的影响。

Method: 通过比较训练集、目标数据和模型预测中SQL结构特征的分布来估计对齐程度，并在三个大型跨领域NL2SQL基准和多个模型家族上进行综合实验。

Result: 实验表明结构对齐是微调成功的强预测因子：当对齐度高时，SFT能显著提升准确率和SQL生成质量；当对齐度低时，改进微乎其微或不存在。

Conclusion: 研究结果强调了在NL2SQL任务中，基于对齐的数据选择对于有效微调和泛化的重要性。

Abstract: Supervised Fine-Tuning (SFT) is an effective method for adapting Large
Language Models (LLMs) on downstream tasks. However, variability in training
data can hinder a model's ability to generalize across domains. This paper
studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or
text to SQL), examining how well SFT training data matches the structural
characteristics of target queries and how this alignment impacts model
performance. We hypothesize that alignment can be accurately estimated by
comparing the distributions of structural SQL features across the training set,
target data, and the model's predictions prior to SFT. Through comprehensive
experiments on three large cross-domain NL2SQL benchmarks and multiple model
families, we show that structural alignment is a strong predictor of
fine-tuning success. When alignment is high, SFT yields substantial gains in
accuracy and SQL generation quality; when alignment is low, improvements are
marginal or absent. These findings highlight the importance of alignment-aware
data selection for effective fine-tuning and generalization in NL2SQL tasks.

</details>


### [269] [The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.04933)
*Amir Hameed Mir*

Main category: cs.CL

TL;DR: LSD是一种基于层间语义动态的幻觉检测框架，通过分析transformer层间隐藏状态语义的演变来识别LLM生成的错误信息，无需多次采样或外部验证，仅需单次前向传播即可实现高效检测。


<details>
  <summary>Details</summary>
Motivation: LLM经常产生流畅但事实错误的陈述（幻觉现象），这在高风险领域构成严重威胁，需要开发高效的幻觉检测方法。

Method: 使用基于边界的对比学习，将隐藏激活与事实编码器生成的真实嵌入对齐，分析语义轨迹的分离：事实性回答保持稳定对齐，而幻觉在深度上表现出明显的语义漂移。

Result: 在TruthfulQA和合成事实-幻觉数据集上，LSD达到F1分数0.92、AUROC 0.96和聚类准确率0.89，优于SelfCheckGPT和语义熵基线，速度比基于采样的方法快5-20倍。

Conclusion: LSD提供了一个可扩展、模型无关的实时幻觉监测机制，并为大语言模型中事实一致性的几何特性提供了新的见解。

Abstract: Large Language Models (LLMs) often produce fluent yet factually incorrect
statements-a phenomenon known as hallucination-posing serious risks in
high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric
framework for hallucination detection that analyzes the evolution of
hidden-state semantics across transformer layers. Unlike prior methods that
rely on multiple sampling passes or external verification sources, LSD operates
intrinsically within the model's representational space. Using margin-based
contrastive learning, LSD aligns hidden activations with ground-truth
embeddings derived from a factual encoder, revealing a distinct separation in
semantic trajectories: factual responses preserve stable alignment, while
hallucinations exhibit pronounced semantic drift across depth. Evaluated on the
TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an
F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming
SelfCheckGPT and Semantic Entropy baselines while requiring only a single
forward pass. This efficiency yields a 5-20x speedup over sampling-based
methods without sacrificing precision or interpretability. LSD offers a
scalable, model-agnostic mechanism for real-time hallucination monitoring and
provides new insights into the geometry of factual consistency within large
language models.

</details>


### [270] [A First Context-Free Grammar Applied to Nawatl Corpora Augmentation](https://arxiv.org/abs/2510.04945)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Martha-Lorena Avendaño-Garrido,Graham Ranger*

Main category: cs.CL

TL;DR: 本文为纳瓦特尔语引入了上下文无关语法(CFG)，旨在生成大量语法正确的合成句子，以扩充用于语言模型训练的语料库。


<details>
  <summary>Details</summary>
Motivation: 纳瓦特尔语是一种π型语言，数字资源稀缺，可用于机器学习的语料库几乎不存在。目标是生成大量语法正确的句子来扩充语料库。

Method: 使用上下文无关语法(CFG)生成合成句子，扩充名为π-yalli的纳瓦特尔语料库，然后使用FastText等算法进行训练。

Result: 初步结果显示，通过使用语法，相比某些LLMs取得了比较性改进，但要获得更显著的改进需要更有效地建模纳瓦特尔语的语法。

Conclusion: 上下文无关语法可以有效扩充低资源语言的语料库，但要获得更好的性能需要开发更精确的语言模型。

Abstract: In this article we introduce a context-free grammar (CFG) for the Nawatl
language. Nawatl (or Nahuatl) is an Amerindian language of the $\pi$-language
type, i.e. a language with few digital resources, in which the corpora
available for machine learning are virtually non-existent. The objective here
is to generate a significant number of grammatically correct artificial
sentences, in order to increase the corpora available for language model
training. We want to show that a grammar enables us significantly to expand a
corpus in Nawatl which we call $\pi$-\textsc{yalli}. The corpus, thus enriched,
enables us to train algorithms such as FastText and to evaluate them on
sentence-level semantic tasks. Preliminary results show that by using the
grammar, comparative improvements are achieved over some LLMs. However, it is
observed that to achieve more significant improvement, grammars that model the
Nawatl language even more effectively are required.

</details>


### [271] [Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)](https://arxiv.org/abs/2510.04950)
*Om Dobariya,Akhil Kumar*

Main category: cs.CL

TL;DR: 研究发现不礼貌的提示词比礼貌提示词在ChatGPT 4o上表现更好，准确率从非常礼貌的80.8%提升到非常粗鲁的84.8%。


<details>
  <summary>Details</summary>
Motivation: 探索自然语言提示中礼貌程度和语气对大型语言模型性能的影响，特别是多选问题上的准确性。

Method: 创建包含数学、科学和历史领域的50个基础问题，每个问题重写为5种语气变体（非常礼貌、礼貌、中性、粗鲁、非常粗鲁），共250个提示，使用ChatGPT 4o评估响应并进行配对样本t检验。

Result: 与预期相反，不礼貌提示词表现优于礼貌提示词，准确率随礼貌程度降低而提高：非常礼貌80.8% → 非常粗鲁84.8%。

Conclusion: 新的大型语言模型对语气变化的响应可能与早期研究不同，强调了研究提示语用学的重要性，并引发关于人机交互社会维度的更广泛问题。

Abstract: The wording of natural language prompts has been shown to influence the
performance of large language models (LLMs), yet the role of politeness and
tone remains underexplored. In this study, we investigate how varying levels of
prompt politeness affect model accuracy on multiple-choice questions. We
created a dataset of 50 base questions spanning mathematics, science, and
history, each rewritten into five tone variants: Very Polite, Polite, Neutral,
Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we
evaluated responses across these conditions and applied paired sample t-tests
to assess statistical significance. Contrary to expectations, impolite prompts
consistently outperformed polite ones, with accuracy ranging from 80.8% for
Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from
earlier studies that associated rudeness with poorer outcomes, suggesting that
newer LLMs may respond differently to tonal variation. Our results highlight
the importance of studying pragmatic aspects of prompting and raise broader
questions about the social dimensions of human-AI interaction.

</details>


### [272] [AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives](https://arxiv.org/abs/2510.04983)
*Khalid Mehtab Khan,Anagha Kulkarni*

Main category: cs.CL

TL;DR: AWARE框架通过提升Transformer模型对领域语言、上下文和类别重叠的感知能力，在识别学生反思中的文化资本主题方面显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 学生反思中的文化资本主题（如抱负目标、家庭支持）往往隐含在叙事中而非直接关键词，标准NLP模型因缺乏领域特定语言和上下文意识而难以检测。

Method: 提出AWARE框架，包含三个核心组件：领域意识（调整词汇适应学生反思语言风格）、上下文意识（生成考虑全文的句子嵌入）、类别重叠意识（使用多标签策略识别主题共存）。

Result: AWARE在Macro-F1上比强基线提升2.1个百分点，在所有主题上均显示出显著改进。

Conclusion: 该工作为任何依赖叙事上下文的文本分类任务提供了稳健且可推广的方法论。

Abstract: Identifying cultural capital (CC) themes in student reflections can offer
valuable insights that help foster equitable learning environments in
classrooms. However, themes such as aspirational goals or family support are
often woven into narratives, rather than appearing as direct keywords. This
makes them difficult to detect for standard NLP models that process sentences
in isolation. The core challenge stems from a lack of awareness, as standard
models are pre-trained on general corpora, leaving them blind to the
domain-specific language and narrative context inherent to the data. To address
this, we introduce AWARE, a framework that systematically attempts to improve a
transformer model's awareness for this nuanced task. AWARE has three core
components: 1) Domain Awareness, adapting the model's vocabulary to the
linguistic style of student reflections; 2) Context Awareness, generating
sentence embeddings that are aware of the full essay context; and 3) Class
Overlap Awareness, employing a multi-label strategy to recognize the
coexistence of themes in a single sentence. Our results show that by making the
model explicitly aware of the properties of the input, AWARE outperforms a
strong baseline by 2.1 percentage points in Macro-F1 and shows considerable
improvements across all themes. This work provides a robust and generalizable
methodology for any text classification task in which meaning depends on the
context of the narrative.

</details>


### [273] [Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.05003)
*Imran Mansha*

Main category: cs.CL

TL;DR: 提出了一种资源高效的LLaMA-3.2-3B微调方法，使用LoRA和QLoRA技术在有限GPU和内存条件下提升医学链式推理能力，相比标准全微调减少60%内存使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型如GPT-4和LLaMA具有强大推理能力，但全微调需要大量计算资源，特别是在医疗领域部署时面临资源限制问题。

Method: 采用参数高效微调技术(LoRA和QLoRA)，在公开医疗推理数据集上对LLaMA-3.2-3B进行适配，实现在受限GPU和内存环境下的高效微调。

Result: 模型在保持强大推理能力的同时，推理连贯性和事实准确性得到提升，内存使用比标准全微调减少高达60%。

Conclusion: 轻量级适配方法能在医疗问答任务中保持强推理能力，为低资源研究环境部署LLM提供了实用策略，平衡了效率与领域专业化需求。

Abstract: Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated
remarkable reasoning abilities but require significant computational resources
for fine-tuning. This paper presents a resource-efficient fine-tuning approach
for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating
under constrained GPU and memory settings. Using parameter-efficient tuning
techniques such as LoRA and QLoRA, we adapt the base model on publicly
available medical reasoning datasets. The model achieves improved reasoning
coherence and factual accuracy while reducing memory usage by up to 60%
compared to standard full fine-tuning. Experimental evaluation demonstrates
that lightweight adaptations can retain strong reasoning capability in medical
question-answering tasks. This work highlights practical strategies for
deploying LLMs in low-resource research environments and provides insights into
balancing efficiency and domain specialization for medical AI systems.

</details>


### [274] [Imperceptible Jailbreaking against Large Language Models](https://arxiv.org/abs/2510.05025)
*Kuofeng Gao,Yiming Li,Chao Du,Xin Wang,Xingjun Ma,Shu-Tao Xia,Tianyu Pang*

Main category: cs.CL

TL;DR: 提出了一种基于Unicode变体选择器的不可感知越狱攻击方法，通过在恶意问题后附加不可见的变体选择器字符，使提示在视觉上与原问题相同但分词被秘密改变，从而诱导有害响应。


<details>
  <summary>Details</summary>
Motivation: 视觉模态的越狱攻击通常依赖不可感知的对抗扰动，而文本模态攻击通常需要可见修改。本文旨在探索文本模态中不可感知的越狱攻击可能性。

Method: 利用Unicode变体选择器字符，提出链式搜索流水线生成对抗后缀，在不产生可见修改的情况下改变提示的分词。

Result: 实验表明该方法对四个对齐的LLM实现了高攻击成功率，并能泛化到提示注入攻击。

Conclusion: 证明了文本模态中不可感知越狱攻击的可行性，揭示了当前LLM安全机制的新漏洞。

Abstract: Jailbreaking attacks on the vision modality typically rely on imperceptible
adversarial perturbations, whereas attacks on the textual modality are
generally assumed to require visible modifications (e.g., non-semantic
suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a
class of Unicode characters called variation selectors. By appending invisible
variation selectors to malicious questions, the jailbreak prompts appear
visually identical to original malicious questions on screen, while their
tokenization is "secretly" altered. We propose a chain-of-search pipeline to
generate such adversarial suffixes to induce harmful responses. Our experiments
show that our imperceptible jailbreaks achieve high attack success rates
against four aligned LLMs and generalize to prompt injection attacks, all
without producing any visible modifications in the written prompt. Our code is
available at https://github.com/sail-sg/imperceptible-jailbreaks.

</details>


### [275] [A Set of Quebec-French Corpus of Regional Expressions and Terms](https://arxiv.org/abs/2510.05026)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: 提出了两个新的魁北克法语方言基准数据集QFrCoRE和QFrCoRT，用于测试方言理解能力，特别是通过地区性习语来评估模型在特定方言上的熟练度。


<details>
  <summary>Details</summary>
Motivation: 将习语理解和方言理解两个任务结合起来，使用地区性习语作为方言理解的测试基准，填补了现有研究的空白。

Method: 构建了包含4,633个习语短语的QFrCoRE数据集和171个地区性习语词汇的QFrCoRT数据集，并详细说明了构建方法以便在其他方言中复制。

Result: 通过对94个大型语言模型的实验验证，证明这些地区性习语基准是衡量模型在特定方言上熟练度的可靠工具。

Conclusion: 地区性习语可以作为有效的方言理解评估指标，提出的数据集构建方法具有可扩展性，适用于其他方言的研究。

Abstract: The tasks of idiom understanding and dialect understanding are both
well-established benchmarks in natural language processing. In this paper, we
propose combining them, and using regional idioms as a test of dialect
understanding. Towards this end, we propose two new benchmark datasets for the
Quebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic
phrases, and QFrCoRT, which comprises 171 regional instances of idiomatic
words. We explain how to construct these corpora, so that our methodology can
be replicated for other dialects. Our experiments with 94 LLM demonstrate that
our regional idiom benchmarks are a reliable tool for measuring a model's
proficiency in a specific dialect.

</details>


### [276] [Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization](https://arxiv.org/abs/2510.05038)
*Omri Uzan,Asaf Yehudai,Roi pony,Eyal Shnarch,Ariel Gera*

Main category: cs.CL

TL;DR: 提出了一种名为GQR的测试时优化方法，通过使用互补检索器的分数来优化主检索器的查询嵌入，从而在视觉文档检索中实现性能与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉的多模态编码器虽然性能优异，但存在表示规模过大、部署困难的问题，且纯视觉方法可能受到模态差距的限制。

Method: 引入引导查询优化(GQR)方法，在测试时使用互补检索器的分数来优化主检索器的查询嵌入，实现细粒度的模型交互。

Result: GQR使视觉中心模型能够匹配具有更大表示模型的性能，同时速度提升14倍，内存需求减少54倍。

Conclusion: GQR有效推动了多模态检索在性能和效率方面的帕累托前沿，为实际部署提供了可行方案。

Abstract: Multimodal encoders have pushed the boundaries of visual document retrieval,
matching textual query tokens directly to image patches and achieving
state-of-the-art performance on public benchmarks. Recent models relying on
this paradigm have massively scaled the sizes of their query and document
representations, presenting obstacles to deployment and scalability in
real-world pipelines. Furthermore, purely vision-centric approaches may be
constrained by the inherent modality gap still exhibited by modern
vision-language models. In this work, we connect these challenges to the
paradigm of hybrid retrieval, investigating whether a lightweight dense text
retriever can enhance a stronger vision-centric model. Existing hybrid methods,
which rely on coarse-grained fusion of ranks or scores, fail to exploit the
rich interactions within each model's representation space. To address this, we
introduce Guided Query Refinement (GQR), a novel test-time optimization method
that refines a primary retriever's query embedding using guidance from a
complementary retriever's scores. Through extensive experiments on visual
document retrieval benchmarks, we demonstrate that GQR allows vision-centric
models to match the performance of models with significantly larger
representations, while being up to 14x faster and requiring 54x less memory.
Our findings show that GQR effectively pushes the Pareto frontier for
performance and efficiency in multimodal retrieval. We release our code at
https://github.com/IBM/test-time-hybrid-retrieval

</details>


### [277] [COLE: a Comprehensive Benchmark for French Language Understanding Evaluation](https://arxiv.org/abs/2510.05046)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: COLE是一个新的法语自然语言理解基准测试，包含23个多样化任务，评估了94个大语言模型，揭示了闭源与开源模型之间的性能差距，并识别了当前LLM面临的挑战领域。


<details>
  <summary>Details</summary>
Motivation: 解决法语自然语言理解评估不够全面的问题，需要建立一个更全面的法语NLU基准测试。

Method: 构建COLE基准测试，包含23个多样化任务，涵盖情感分析、释义检测、语法判断和推理等能力，特别关注法语特有的语言现象。

Result: 评估了94个大语言模型，发现闭源和开源模型之间存在显著性能差距，识别出零样本抽取式问答、细粒度词义消歧和区域语言变体理解等关键挑战领域。

Conclusion: COLE作为公共资源发布，旨在促进法语语言建模的进一步发展。

Abstract: To address the need for a more comprehensive evaluation of French Natural
Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23
diverse task covering a broad range of NLU capabilities, including sentiment
analysis, paraphrase detection, grammatical judgment, and reasoning, with a
particular focus on linguistic phenomena relevant to the French language. We
benchmark 94 large language models (LLM), providing an extensive analysis of
the current state of French NLU. Our results highlight a significant
performance gap between closed- and open-weights models and identify key
challenging frontiers for current LLMs, such as zero-shot extractive
question-answering (QA), fine-grained word sense disambiguation, and
understanding of regional language variations. We release COLE as a public
resource to foster further progress in French language modelling.

</details>


### [278] [SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs](https://arxiv.org/abs/2510.05069)
*Dachuan Shi,Abedelkadir Asi,Keying Li,Xiangchi Yuan,Leyan Pan,Wenke Lee,Wen Xiao*

Main category: cs.CL

TL;DR: SwiReasoning是一个无需训练的大语言模型推理框架，通过动态切换显式和潜在推理模式来解决潜在推理中的概率扩散和过度思考问题，在数学和STEM基准测试中提升准确性和token效率。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法面临两个挑战：1）纯潜在推理会扩散概率质量，引入噪声，阻碍收敛到高置信度解；2）即使没有显式文本，过度思考问题依然存在，浪费token并降低效率。

Method: 提出SwiReasoning框架，包含两个关键创新：1）基于下一个token分布的熵趋势估计块级置信度，动态切换显式和潜在推理模式；2）限制思维块切换的最大次数来抑制过度思考。

Result: 在广泛使用的数学和STEM基准测试中，SwiReasoning在不同模型家族和规模的推理LLM上平均准确率提升1.5%-2.8%。在受限预算下，平均token效率提升56%-79%，且预算越紧提升越大。

Conclusion: SwiReasoning通过动态切换推理模式和限制过度思考，有效解决了潜在推理中的收敛问题和效率问题，显著提升了LLM的推理性能和token效率。

Abstract: Recent work shows that, beyond discrete reasoning through explicit
chain-of-thought steps, which are limited by the boundaries of natural
languages, large language models (LLMs) can also reason continuously in latent
space, allowing richer information per step and thereby improving token
efficiency. Despite this promise, latent reasoning still faces two challenges,
especially in training-free settings: 1) purely latent reasoning broadens the
search distribution by maintaining multiple implicit paths, which diffuses
probability mass, introduces noise, and impedes convergence to a single
high-confidence solution, thereby hurting accuracy; and 2) overthinking
persists even without explicit text, wasting tokens and degrading efficiency.
To address these issues, we introduce SwiReasoning, a training-free framework
for LLM reasoning which features two key innovations: 1) SwiReasoning
dynamically switches between explicit and latent reasoning, guided by
block-wise confidence estimated from entropy trends in next-token
distributions, to balance exploration and exploitation and promote timely
convergence. 2) By limiting the maximum number of thinking-block switches,
SwiReasoning curbs overthinking and improves token efficiency across varying
problem difficulties. On widely used mathematics and STEM benchmarks,
SwiReasoning consistently improves average accuracy by 1.5%-2.8% across
reasoning LLMs of different model families and scales. Furthermore, under
constrained budgets, SwiReasoning improves average token efficiency by 56%-79%,
with larger gains as budgets tighten.

</details>


### [279] [Slm-mux: Orchestrating small language models for reasoning](https://arxiv.org/abs/2510.05077)
*Chenyu Wang,Zishen Wan,Hao Kang,Emma Chen,Zhiqiang Xie,Tushar Krishna,Vijay Janapa Reddi,Yilun Du*

Main category: cs.CL

TL;DR: 提出了SLM-MUX方法，通过协调多个小语言模型来构建更准确高效的系统，在多个基准测试中显著优于现有编排方法。


<details>
  <summary>Details</summary>
Motivation: 随着小语言模型数量的快速增长，虽然它们无法达到最先进的精度，但在特定任务上表现出色且更高效。现有编排方法主要针对前沿模型，在小语言模型上表现不佳。

Method: 提出三阶段方法：1) SLM-MUX多模型架构协调多个小语言模型；2) 模型选择搜索从候选池中识别最互补的模型；3) 针对SLM-MUX的测试时缩放策略。

Result: 在MATH上提升13.4%，GPQA上提升8.8%，GSM8K上提升7.0%。仅用两个小语言模型就在GPQA和GSM8K上超越Qwen 2.5 72B，在MATH上表现相当。

Conclusion: 通过所提出的方法，小语言模型可以被有效编排成更准确和高效的系统，并通过理论分析验证了该方法的优势。

Abstract: With the rapid development of language models, the number of small language
models (SLMs) has grown significantly. Although they do not achieve
state-of-the-art accuracy, they are more efficient and often excel at specific
tasks. This raises a natural question: can multiple SLMs be orchestrated into a
system where each contributes effectively, achieving higher accuracy than any
individual model? Existing orchestration methods have primarily targeted
frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To
address this gap, we propose a three-stage approach for orchestrating SLMs.
First, we introduce SLM-MUX, a multi-model architecture that effectively
coordinates multiple SLMs. Building on this, we develop two optimization
strategies: (i) a model selection search that identifies the most complementary
SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our
approach delivers strong results: Compared to existing orchestration methods,
our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%
on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and
GSM8K, and matches its performance on MATH. We further provide theoretical
analyses to substantiate the advantages of our method. In summary, we
demonstrate that SLMs can be effectively orchestrated into more accurate and
efficient systems through the proposed approach.

</details>


### [280] [TeachLM: Post-Training LLMs for Education Using Authentic Learning Data](https://arxiv.org/abs/2510.05087)
*Janos Perczel,Jin Chow,Dorottya Demszky*

Main category: cs.CL

TL;DR: TeachLM通过参数高效微调优化LLM用于教学，使用真实学生-导师对话数据训练，显著提升对话能力和教学效果。


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI在教育中受限于LLM教学能力不足的问题，特别是缺乏反映真实学生学习过程的高质量训练数据。

Method: 使用10万小时真实学生-导师对话数据进行参数高效微调，开发真实学生模型生成高质量合成对话，并提出多轮评估协议。

Result: 微调后显著改善对话和教学表现：学生发言时间翻倍，提问风格改善，对话轮次增加50%，教学个性化程度提高。

Conclusion: 基于真实学习数据的微调能显著提升LLM的教学对话能力，为教育AI发展提供有效路径。

Abstract: The promise of generative AI to revolutionize education is constrained by the
pedagogical limits of large language models (LLMs). A major issue is the lack
of access to high-quality training data that reflect the learning of actual
students. Prompt engineering has emerged as a stopgap, but the ability of
prompts to encode complex pedagogical strategies in rule-based natural language
is inherently limited. To address this gap we introduce TeachLM - an LLM
optimized for teaching through parameter-efficient fine-tuning of
state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000
hours of one-on-one, longitudinal student-tutor interactions maintained by
Polygence, which underwent a rigorous anonymization process to protect privacy.
We use parameter-efficient fine-tuning to develop an authentic student model
that enables the generation of high-fidelity synthetic student-tutor dialogues.
Building on this capability, we propose a novel multi-turn evaluation protocol
that leverages synthetic dialogue generation to provide fast, scalable, and
reproducible assessments of the dialogical capabilities of LLMs. Our
evaluations demonstrate that fine-tuning on authentic learning data
significantly improves conversational and pedagogical performance - doubling
student talk time, improving questioning style, increasing dialogue turns by
50%, and greater personalization of instruction.

</details>


### [281] [Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models](https://arxiv.org/abs/2510.05090)
*Runchu Tian,Junxia Cui,Xueqiang Xu,Feng Yao,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出了Tolerator解码策略，通过令牌级交叉验证改进扩散大语言模型的解码过程，允许已接受的令牌在后续步骤中被重新考虑和修正。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型(dLLMs)虽然具有并行解码和双向上下文建模的优势，但其解码策略存在关键限制：一旦令牌被接受就无法在后续步骤中修正，导致早期错误持续影响预测质量。

Method: Tolerator采用两阶段过程：(i)序列填充和(ii)通过重新掩码和解码令牌子集的迭代精炼，同时将剩余令牌作为上下文，实现令牌的交叉验证和修正。

Result: 在五个标准基准测试（语言理解、代码生成和数学）上的实验表明，该方法在相同计算预算下相比基线模型实现了持续改进。

Conclusion: 解码算法对于实现扩散大语言模型的全部潜力至关重要，Tolerator通过允许令牌修正显著提高了解码输出的可靠性。

Abstract: Diffusion large language models (dLLMs) have recently emerged as a promising
alternative to autoregressive (AR) models, offering advantages such as
accelerated parallel decoding and bidirectional context modeling. However, the
vanilla decoding strategy in discrete dLLMs suffers from a critical limitation:
once a token is accepted, it can no longer be revised in subsequent steps. As a
result, early mistakes persist across iterations, harming both intermediate
predictions and final output quality. To address this issue, we propose
Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding
strategy that leverages cross-validation among predicted tokens. Unlike
existing methods that follow a single progressive unmasking procedure,
Tolerator introduces a two-stage process: (i) sequence fill-up and (ii)
iterative refinement by remasking and decoding a subset of tokens while
treating the remaining as context. This design enables previously accepted
tokens to be reconsidered and corrected when necessary, leading to more
reliable diffusion decoding outputs. We evaluate Tolerator on five standard
benchmarks covering language understanding, code generation, and mathematics.
Experiments show that our method achieves consistent improvements over the
baselines under the same computational budget. These findings suggest that
decoding algorithms are crucial to realizing the full potential of diffusion
large language models. Code and data are publicly available.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [282] [Creative synthesis of kinematic mechanisms](https://arxiv.org/abs/2510.03308)
*Jiong Lin,Jialong Ning,Judah Goldfeder,Hod Lipson*

Main category: cs.GR

TL;DR: 该论文将平面连杆机构的运动综合问题转化为跨域图像生成任务，使用RGB图像表示连杆机构，通过共享潜在变分自编码器合成未见过的运动曲线和模拟新运动学。


<details>
  <summary>Details</summary>
Motivation: 探索基于图像的生成模型在机械设计中的潜力，为平面连杆机构运动综合提供统一框架，支持从简单到复杂多种机构类型的表示与合成。

Method: 使用RGB图像表示平面连杆机构，通过共享潜在变分自编码器进行图像生成，利用轨迹点绘制速度作为颜色梯度，支持基于轨迹形状和速度分布的运动综合。

Result: 在三个复杂度递增的数据集上验证了方法的有效性：标准四杆机构、四杆与曲柄滑块混合机构、包含多环机构的复杂集合。初步结果表明图像表示在生成式机械设计中的有效性。

Conclusion: 基于图像的表示框架能够统一表示和合成具有转动副、移动副的机构，并可能扩展到凸轮和齿轮，为生成式机械设计提供了新途径。

Abstract: In this paper, we formulate the problem of kinematic synthesis for planar
linkages as a cross-domain image generation task. We develop a planar linkages
dataset using RGB image representations, covering a range of mechanisms: from
simple types such as crank-rocker and crank-slider to more complex eight-bar
linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE)
is employed to explore the potential of image generative models for
synthesizing unseen motion curves and simulating novel kinematics. By encoding
the drawing speed of trajectory points as color gradients, the same
architecture also supports kinematic synthesis conditioned on both trajectory
shape and velocity profiles. We validate our method on three datasets of
increasing complexity: a standard four-bar linkage set, a mixed set of four-bar
and crank-slider mechanisms, and a complex set including multi-loop mechanisms.
Preliminary results demonstrate the effectiveness of image-based
representations for generative mechanical design, showing that mechanisms with
revolute and prismatic joints, and potentially cams and gears, can be
represented and synthesized within a unified image generation framework.

</details>


### [283] [Universal Beta Splatting](https://arxiv.org/abs/2510.03312)
*Rong Liu,Zhongpai Gao,Benjamin Planche,Meida Chen,Van Nguyen Nguyen,Meng Zheng,Anwesa Choudhuri,Terrence Chen,Yue Wang,Andrew Feng,Ziyan Wu*

Main category: cs.GR

TL;DR: Universal Beta Splatting (UBS) 是一个统一框架，将3D高斯泼溅推广到N维各向异性Beta核，用于显式辐射场渲染，在保持向后兼容的同时实现更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高斯泼溅方法使用固定的高斯基元，限制了其在复杂光传输、各向异性视角相关外观和场景动态建模方面的能力。UBS旨在通过更灵活的Beta核来统一处理这些挑战。

Method: 使用N维各向异性Beta核作为通用基元，可控制空间、角度和时间维度上的依赖关系建模，无需辅助网络或特定颜色编码，通过CUDA加速实现实时渲染。

Result: 在静态、视角相关和动态基准测试中一致优于现有方法，Beta参数可自然分解场景属性为可解释的空间、角度和时间分量。

Conclusion: Beta核作为可扩展的通用基元，为辐射场渲染提供了统一的解决方案，在保持实时性能的同时显著提升了渲染质量。

Abstract: We introduce Universal Beta Splatting (UBS), a unified framework that
generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for
explicit radiance field rendering. Unlike fixed Gaussian primitives, Beta
kernels enable controllable dependency modeling across spatial, angular, and
temporal dimensions within a single representation. Our unified approach
captures complex light transport effects, handles anisotropic view-dependent
appearance, and models scene dynamics without requiring auxiliary networks or
specific color encodings. UBS maintains backward compatibility by approximating
to Gaussian Splatting as a special case, guaranteeing plug-in usability and
lower performance bounds. The learned Beta parameters naturally decompose scene
properties into interpretable without explicit supervision: spatial (surface
vs. texture), angular (diffuse vs. specular), and temporal (static vs.
dynamic). Our CUDA-accelerated implementation achieves real-time rendering
while consistently outperforming existing methods across static,
view-dependent, and dynamic benchmarks, establishing Beta kernels as a scalable
universal primitive for radiance field rendering. Our project website is
available at https://rongliu-leo.github.io/universal-beta-splatting/.

</details>


### [284] [Style Brush: Guided Style Transfer for 3D Objects](https://arxiv.org/abs/2510.03433)
*Áron Samuel Kovács,Pedro Hermosilla,Renata G. Raidou*

Main category: cs.GR

TL;DR: Style Brush是一种新颖的纹理网格风格迁移方法，通过引入捕捉风格方向性的新损失函数，为艺术家提供细粒度控制，支持多风格图像和平滑风格过渡。


<details>
  <summary>Details</summary>
Motivation: 传统3D风格迁移方法缺乏对风格化过程的细粒度控制，无法支持多风格图像和平滑风格过渡，限制了艺术家的创作自由度。

Method: 引入捕捉风格方向性的新损失函数，使用易于生成的引导纹理简化用户交互，支持多风格图像和风格间的平滑过渡。

Result: 在各种网格、风格图像和轮廓形状上的广泛评估证明了方法的灵活性，生成的纹理具有视觉吸引力。

Conclusion: Style Brush通过创新的损失函数和用户友好的引导纹理，为3D风格迁移提供了更精细的控制和更好的用户体验。

Abstract: We introduce Style Brush, a novel style transfer method for textured meshes
designed to empower artists with fine-grained control over the stylization
process. Our approach extends traditional 3D style transfer methods by
introducing a novel loss function that captures style directionality, supports
multiple style images or portions thereof, and enables smooth transitions
between styles in the synthesized texture. The use of easily generated guiding
textures streamlines user interaction, making our approach accessible to a
broad audience. Extensive evaluations with various meshes, style images, and
contour shapes demonstrate the flexibility of our method and showcase the
visual appeal of the generated textures.

</details>


### [285] [Paris: A Decentralized Trained Open-Weight Diffusion Model](https://arxiv.org/abs/2510.03434)
*Zhiying Jiang,Raihan Seraj,Marcos Villagra,Bidhan Roy*

Main category: cs.GR

TL;DR: Paris是首个完全通过去中心化计算预训练的扩散模型，展示了无需中央协调基础设施即可实现高质量文本到图像生成的能力。


<details>
  <summary>Details</summary>
Motivation: 旨在证明高质量文本到图像生成可以在没有中央协调基础设施的情况下实现，消除对专用GPU集群的需求。

Method: 使用分布式扩散训练框架，包含8个专家扩散模型，在完全隔离的环境中训练，无需梯度、参数或中间激活同步。通过数据语义聚类分区，每个专家独立优化其子集，轻量级transformer路由器在推理时动态选择专家。

Result: Paris在保持生成质量的同时，相比之前的去中心化基线，使用14倍更少的训练数据和16倍更少的计算量。

Conclusion: 去中心化训练能够维持生成质量，同时消除了大规模扩散模型对专用GPU集群的需求，为更广泛的研究和商业应用打开了可能性。

Abstract: We present Paris, the first publicly released diffusion model pre-trained
entirely through decentralized computation. Paris demonstrates that
high-quality text-to-image generation can be achieved without centrally
coordinated infrastructure. Paris is open for research and commercial use.
Paris required implementing our Distributed Diffusion Training framework from
scratch. The model consists of 8 expert diffusion models (129M-605M parameters
each) trained in complete isolation with no gradient, parameter, or
intermediate activation synchronization. Rather than requiring synchronized
gradient updates across thousands of GPUs, we partition data into semantically
coherent clusters where each expert independently optimizes its subset while
collectively approximating the full distribution. A lightweight transformer
router dynamically selects appropriate experts at inference, achieving
generation quality comparable to centrally coordinated baselines. Eliminating
synchronization enables training on heterogeneous hardware without specialized
interconnects. Empirical validation confirms that Paris's decentralized
training maintains generation quality while removing the dedicated GPU cluster
requirement for large-scale diffusion models. Paris achieves this using
14$\times$ less training data and 16$\times$ less compute than the prior
decentralized baseline.

</details>


### [286] [Neon: Negative Extrapolation From Self-Training Improves Image Generation](https://arxiv.org/abs/2510.03597)
*Sina Alemohammad,Zhangyang Wang,Richard G. Baraniuk*

Main category: cs.GR

TL;DR: Neon是一种新的学习方法，通过负向外推从自训练中解决模型自噬障碍问题，无需新真实数据即可提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型扩展受限于高质量训练数据的稀缺性，使用未验证的合成数据进行微调会导致模型自噬障碍，造成样本质量和多样性的快速退化。

Method: Neon首先在自身合成的数据上微调基础模型，然后反直觉地反转梯度更新，通过负向外推远离退化的权重。该方法利用典型推理采样器在高概率区域产生的可预测反对齐特性。

Result: Neon在多种架构（扩散、流匹配、自回归和归纳矩匹配模型）和数据集（ImageNet、CIFAR-10、FFHQ）上表现出普适性。在ImageNet 256x256上，将xAR-L模型的FID提升至1.02的新SOTA，仅需0.36%的额外训练计算。

Conclusion: Neon通过简单的后处理合并实现，无需新真实数据，仅需1k合成样本即可有效工作，通常使用不到1%的额外训练计算，为解决模型自噬障碍提供了一种有效方案。

Abstract: Scaling generative AI models is bottlenecked by the scarcity of high-quality
training data. The ease of synthesizing from a generative model suggests using
(unverified) synthetic data to augment a limited corpus of real data for the
purpose of fine-tuning in the hope of improving performance. Unfortunately,
however, the resulting positive feedback loop leads to model autophagy disorder
(MAD, aka model collapse) that results in a rapid degradation in sample quality
and/or diversity. In this paper, we introduce Neon (for Negative Extrapolation
frOm self-traiNing), a new learning method that turns the degradation from
self-training into a powerful signal for self-improvement. Given a base model,
Neon first fine-tunes it on its own self-synthesized data but then,
counterintuitively, reverses its gradient updates to extrapolate away from the
degraded weights. We prove that Neon works because typical inference samplers
that favor high-probability regions create a predictable anti-alignment between
the synthetic and real data population gradients, which negative extrapolation
corrects to better align the model with the true data distribution. Neon is
remarkably easy to implement via a simple post-hoc merge that requires no new
real data, works effectively with as few as 1k synthetic samples, and typically
uses less than 1% additional training compute. We demonstrate Neon's
universality across a range of architectures (diffusion, flow matching,
autoregressive, and inductive moment matching models) and datasets (ImageNet,
CIFAR-10, and FFHQ). In particular, on ImageNet 256x256, Neon elevates the
xAR-L model to a new state-of-the-art FID of 1.02 with only 0.36% additional
training compute. Code is available at https://github.com/SinaAlemohammad/Neon

</details>


### [287] [Diverse Text-to-Image Generation via Contrastive Noise Optimization](https://arxiv.org/abs/2510.03813)
*Byungjun Kim,Soobin Um,Jong Chul Ye*

Main category: cs.GR

TL;DR: 提出对比噪声优化方法，通过优化初始噪声来提升文本到图像生成模型的多样性，同时保持保真度


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在强文本引导下容易出现输出模式崩溃、多样性不足的问题，现有方法效果有限且对超参数敏感

Method: 开发在Tweedie数据空间定义的对比损失函数，优化一批噪声潜在变量，通过对比优化使批次内实例相互排斥以最大化多样性，同时锚定参考样本保持保真度

Result: 在多个T2I骨干模型上的广泛实验表明，该方法实现了更优的质量-多样性帕累托前沿，且对超参数选择具有鲁棒性

Conclusion: 对比噪声优化是一种简单有效的预处理方法，能从独特视角解决文本到图像生成中的多样性问题

Abstract: Text-to-image (T2I) diffusion models have demonstrated impressive performance
in generating high-fidelity images, largely enabled by text-guided inference.
However, this advantage often comes with a critical drawback: limited
diversity, as outputs tend to collapse into similar modes under strong text
guidance. Existing approaches typically optimize intermediate latents or text
conditions during inference, but these methods deliver only modest gains or
remain sensitive to hyperparameter tuning. In this work, we introduce
Contrastive Noise Optimization, a simple yet effective method that addresses
the diversity issue from a distinct perspective. Unlike prior techniques that
adapt intermediate latents, our approach shapes the initial noise to promote
diverse outputs. Specifically, we develop a contrastive loss defined in the
Tweedie data space and optimize a batch of noise latents. Our contrastive
optimization repels instances within the batch to maximize diversity while
keeping them anchored to a reference sample to preserve fidelity. We further
provide theoretical insights into the mechanism of this preprocessing to
substantiate its effectiveness. Extensive experiments across multiple T2I
backbones demonstrate that our approach achieves a superior quality-diversity
Pareto frontier while remaining robust to hyperparameter choices.

</details>


### [288] [Joint Neural SDF Reconstruction and Semantic Segmentation for CAD Models](https://arxiv.org/abs/2510.03837)
*Shen Fan,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种数据高效的方法，通过为基于神经SDF的CAD部件隐式重建网络添加部件分割头，在PartField生成的监督下训练，能够处理任意数量部件的网格并产生几何对齐的标签。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于固定分类法，无法处理具有任意数量部件的CAD网格。本文旨在开发一种不受分类法限制、能够处理任意部件数量的语义结构化CAD网格方法。

Method: 在Flat-CAD SDF主干网络上附加轻量级分割头，使用PartField生成的监督进行训练，单次处理即可为任意数量部件的网格生成几何对齐的部件标签。

Result: 在ABC数据集上评估显示，在重建（CDL1/CDL2、F1-micro、NC）和分割（mIoU、准确率）方面表现强劲，即使在薄壁或复杂几何的退化重建情况下，分割仍保持准确和标签一致性。

Conclusion: 该方法为语义结构化CAD网格提供了一条实用路径，无需精心策划的分类法或精确的调色板匹配，但边界精度存在局限性，未来可朝边界感知训练和更高分辨率标签方向发展。

Abstract: We propose a simple, data-efficient pipeline that augments an implicit
reconstruction network based on neural SDF-based CAD parts with a
part-segmentation head trained under PartField-generated supervision. Unlike
methods tied to fixed taxonomies, our model accepts meshes with any number of
parts and produces coherent, geometry-aligned labels in a single pass. We
evaluate on randomly sampled CAD meshes from the ABC dataset with intentionally
varied part cardinalities, including over-segmented shapes, and report strong
performance across reconstruction (CDL1/CDL2, F1-micro, NC) and segmentation
(mIoU, Accuracy), together with a new Segmentation Consistency metric that
captures local label smoothness. We attach a lightweight segmentation head to
the Flat-CAD SDF trunk; on a paired evaluation it does not alter reconstruction
while providing accurate part labels for meshes with any number of parts. Even
under degraded reconstructions on thin or intricate geometries, segmentation
remains accurate and label-coherent, often preserving the correct part count.
Our approach therefore offers a practical route to semantically structured CAD
meshes without requiring curated taxonomies or exact palette matches. We
discuss limitations in boundary precision, partly due to per-face supervision,
and outline paths toward boundary-aware training and higher resolution labels.

</details>


### [289] [Enhancing Foveated Rendering with Weighted Reservoir Sampling](https://arxiv.org/abs/2510.03964)
*Ville Cantory,Darya Biparva,Haoyu Tan,Tongyu Nie,John Schroeder,Ruofei Du,Victoria Interrante,Piotr Didyk*

Main category: cs.GR

TL;DR: 提出一种基于加权蓄水池采样的注视点渲染技术，通过时间复用先前帧的高质量像素样本来减小每帧需要渲染的注视区域大小，同时保持更高的感知图像质量。


<details>
  <summary>Details</summary>
Motivation: 利用人眼在注视点周围存在微小移动的特性，从时间相邻帧中采样不同注视位置的像素，从而减小注视区域渲染尺寸并提高感知质量。

Method: 将帧间像素呈现视为数据流，采用加权蓄水池采样技术高效维护先前帧中感知相关的高质量像素样本库，并将其整合到当前帧计算中。

Result: 该方法在4K分辨率下运行时间小于1毫秒，能够显著减小每帧注视区域渲染尺寸，同时允许更高的注视化水平。

Conclusion: 该技术高效且易于集成到实时VR和AR注视点渲染系统中，通过时间复用像素样本实现了渲染效率与感知质量的平衡。

Abstract: Spatiotemporal sensitivity to high frequency information declines with
increased peripheral eccentricity. Foveated rendering exploits this by
decreasing the spatial resolution of rendered images in peripheral vision,
reducing the rendering cost by omitting high frequency details. As foveation
levels increase, the rendering quality is reduced, and traditional foveated
rendering systems tend not to preserve samples that were previously rendered at
high spatial resolution in previous frames. Additionally, prior research has
shown that saccade landing positions are distributed around a target location
rather than landing at a single point, and that even during fixations, eyes
perform small microsaccades around a fixation point. This creates an
opportunity for sampling from temporally neighbouring frames with differing
foveal locations to reduce the required rendered size of the foveal region
while achieving a higher perceived image quality. We further observe that the
temporal presentation of pixels frame-to-frame can be viewed as a data stream,
presenting a random sampling problem. Following this intuition, we propose a
Weighted Reservoir Sampling technique to efficiently maintain a reservoir of
the perceptually relevant high quality pixel samples from previous frames and
incorporate them into the computation of the current frame. This allows the
renderer to render a smaller region of foveal pixels per frame by temporally
reusing pixel samples that are still relevant to reconstruct a higher perceived
image quality, while allowing for higher levels of foveation. Our method
operates on the output of foveated rendering, and runs in under 1\,ms at 4K
resolution, making it highly efficient and integrable with real-time VR and AR
foveated rendering systems.

</details>


### [290] [3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG](https://arxiv.org/abs/2510.04536)
*Shun-ichiro Hayashi,Daichi Mukunoki,Tetsuya Hoshino,Satoshi Ohshima,Takahiro Katagiri*

Main category: cs.GR

TL;DR: 3Dify是一个基于大型语言模型的程序化3D计算机图形生成框架，允许用户通过自然语言指令生成3D内容，支持多种数字内容创作工具的自动化操作和本地模型部署。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统3D内容创作需要专业技能和复杂操作的问题，让普通用户也能通过自然语言轻松生成3D图形内容。

Method: 基于Dify平台构建，结合模型上下文协议(MCP)和检索增强生成(RAG)技术，通过MCP自动化DCC工具操作，在MCP不支持时使用计算机使用代理(CUA)方法自动化GUI操作，并支持用户反馈优化图像生成质量。

Result: 开发了一个完整的3D-CG生成框架，能够通过自然语言指令生成3D内容，支持多种DCC工具自动化操作，并允许用户通过选择偏好图像来优化生成质量。

Conclusion: 3Dify框架成功实现了通过自然语言指令生成3D计算机图形内容的目标，为普通用户提供了便捷的3D内容创作工具，同时支持本地模型部署以降低成本。

Abstract: This paper proposes "3Dify," a procedural 3D computer graphics (3D-CG)
generation framework utilizing Large Language Models (LLMs). The framework
enables users to generate 3D-CG content solely through natural language
instructions. 3Dify is built upon Dify, an open-source platform for AI
application development, and incorporates several state-of-the-art LLM-related
technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented
Generation (RAG). For 3D-CG generation support, 3Dify automates the operation
of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not
support MCP-based interaction, the framework employs the Computer-Using Agent
(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,
to enhance image generation quality, 3Dify allows users to provide feedback by
selecting preferred images from multiple candidates. The LLM then learns
variable patterns from these selections and applies them to subsequent
generations. Furthermore, 3Dify supports the integration of locally deployed
LLMs, enabling users to utilize custom-developed models and to reduce both time
and monetary costs associated with external API calls by leveraging their own
computational resources.

</details>


### [291] [C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing](https://arxiv.org/abs/2510.04539)
*Zeng Tao,Zheng Ding,Zeyuan Chen,Xiang Zhang,Leizhi Li,Zhuowen Tu*

Main category: cs.GR

TL;DR: C3Editor是一个可控且一致的基于2D提升的3D编辑框架，通过选择性建立视图一致的2D编辑模型来解决现有方法的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D提升的3D编辑方法存在不一致性问题，主要源于缺乏视图一致的2D编辑模型和难以确保多视图编辑一致性。

Method: 首先选择地面真实视图及其编辑图像作为优化目标，然后在GT视图和多个视图上微调2D编辑模型，引入单独的LoRA模块分别处理GT视图拟合和多视图一致性需求。

Result: 该方法在定性和定量评估中均优于现有的基于2D提升的方法，实现了更一致和可控的2D和3D编辑结果。

Conclusion: C3Editor通过可控的视图选择和针对性的微调策略，有效解决了3D编辑中的一致性问题，为基于2D提升的3D编辑提供了更可靠的解决方案。

Abstract: Existing 2D-lifting-based 3D editing methods often encounter challenges
related to inconsistency, stemming from the lack of view-consistent 2D editing
models and the difficulty of ensuring consistent editing across multiple views.
To address these issues, we propose C3Editor, a controllable and consistent
2D-lifting-based 3D editing framework. Given an original 3D representation and
a text-based editing prompt, our method selectively establishes a
view-consistent 2D editing model to achieve superior 3D editing results. The
process begins with the controlled selection of a ground truth (GT) view and
its corresponding edited image as the optimization target, allowing for
user-defined manual edits. Next, we fine-tune the 2D editing model within the
GT view and across multiple views to align with the GT-edited image while
ensuring multi-view consistency. To meet the distinct requirements of GT view
fitting and multi-view consistency, we introduce separate LoRA modules for
targeted fine-tuning. Our approach delivers more consistent and controllable 2D
and 3D editing results than existing 2D-lifting-based methods, outperforming
them in both qualitative and quantitative evaluations.

</details>


### [292] [Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents](https://arxiv.org/abs/2510.04637)
*Zeyi Zhang,Yanju Zhou,Heyuan Yao,Tenglong Ao,Xiaohang Zhan,Libin Liu*

Main category: cs.GR

TL;DR: Social Agent框架通过LLM驱动对话流程和确定交互行为，结合基于自回归扩散模型的双人姿态生成器，合成协调的伴随语音非语言行为，形成持续反馈循环实现动态互动。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成双人对话中的伴随语音非语言行为时缺乏协调性和动态响应能力，需要开发能够产生自然、同步非语言行为的系统。

Method: 开发LLM驱动的智能体系统指导对话流程和行为决策，提出基于自回归扩散模型的双人姿态生成模型，将智能体输出转化为高层指导生成协调动作，并建立持续反馈循环。

Result: 用户研究和定量评估表明，该模型显著提高了双人互动质量，产生了自然、同步的非语言行为。

Conclusion: Social Agent框架能够有效合成真实且上下文合适的伴随语音非语言行为，为双人对话中的动态互动提供了有效解决方案。

Abstract: We present Social Agent, a novel framework for synthesizing realistic and
contextually appropriate co-speech nonverbal behaviors in dyadic conversations.
In this framework, we develop an agentic system driven by a Large Language
Model (LLM) to direct the conversation flow and determine appropriate
interactive behaviors for both participants. Additionally, we propose a novel
dual-person gesture generation model based on an auto-regressive diffusion
model, which synthesizes coordinated motions from speech signals. The output of
the agentic system is translated into high-level guidance for the gesture
generator, resulting in realistic movement at both the behavioral and motion
levels. Furthermore, the agentic system periodically examines the movements of
interlocutors and infers their intentions, forming a continuous feedback loop
that enables dynamic and responsive interactions between the two participants.
User studies and quantitative evaluations show that our model significantly
improves the quality of dyadic interactions, producing natural, synchronized
nonverbal behaviors.

</details>


### [293] [Bridging Text and Video Generation: A Survey](https://arxiv.org/abs/2510.04999)
*Nilay Kumar,Priyansh Bhandari,G. Maragatham*

Main category: cs.GR

TL;DR: 本文对文本到视频生成技术进行了全面综述，回顾了从早期GANs、VAEs到混合扩散-Transformer架构的发展历程，详细分析了模型工作原理、训练配置、评估指标及性能表现，并指出了当前面临的挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 文本到视频生成技术在教育、营销、娱乐和辅助技术等领域具有巨大潜力，但现有模型在质量、一致性和控制方面仍存在挑战。为了推动该领域发展，需要对技术演进、模型架构、训练方法和评估标准进行系统性总结。

Method: 采用系统性综述方法，追溯文本到视频生成模型从GANs、VAEs到混合扩散-Transformer架构的发展路径，详细分析模型工作原理、训练数据集、硬件配置、超参数设置以及评估指标。

Result: 调查显示文本到视频生成技术已从对抗模型发展到扩散模型，产生了更高保真度和时间一致性的输出。但模型在对齐、长程一致性和计算效率方面仍存在挑战。同时评估指标正从传统度量转向更全面、感知对齐的评估策略。

Conclusion: 文本到视频生成技术虽已取得显著进展，但在质量、一致性和控制方面仍需改进。未来研究方向包括解决对齐问题、提升长程一致性、优化计算效率，以及开发更全面的评估方法，为研究人员提供明确的发展路径。

Abstract: Text-to-video (T2V) generation technology holds potential to transform
multiple domains such as education, marketing, entertainment, and assistive
technologies for individuals with visual or reading comprehension challenges,
by creating coherent visual content from natural language prompts. From its
inception, the field has advanced from adversarial models to diffusion-based
models, yielding higher-fidelity, temporally consistent outputs. Yet challenges
persist, such as alignment, long-range coherence, and computational efficiency.
Addressing this evolving landscape, we present a comprehensive survey of
text-to-video generative models, tracing their development from early GANs and
VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these
models work, what limitations they addressed in their predecessors, and why
shifts toward new architectural paradigms were necessary to overcome challenges
in quality, coherence, and control. We provide a systematic account of the
datasets, which the surveyed text-to-video models were trained and evaluated
on, and, to support reproducibility and assess the accessibility of training
such models, we detail their training configurations, including their hardware
specifications, GPU counts, batch sizes, learning rates, optimizers, epochs,
and other key hyperparameters. Further, we outline the evaluation metrics
commonly used for evaluating such models and present their performance across
standard benchmarks, while also discussing the limitations of these metrics and
the emerging shift toward more holistic, perception-aligned evaluation
strategies. Finally, drawing from our analysis, we outline the current open
challenges and propose a few promising future directions, laying out a
perspective for future researchers to explore and build upon in advancing T2V
research and applications.

</details>


### [294] [SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder](https://arxiv.org/abs/2510.05081)
*Ronen Kamenetsky,Sara Dorfman,Daniel Garibi,Roni Paiss,Or Patashnik,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: 提出一种基于文本嵌入token级操作的解耦连续编辑方法，通过稀疏自编码器识别语义隔离的编辑方向，实现无需修改扩散模型的图像编辑控制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型仅通过文本提示无法提供足够的编辑控制，需要实现解耦编辑（改变一个属性不影响其他属性）和连续控制（平滑调整编辑强度）。

Method: 通过稀疏自编码器在文本嵌入空间中识别语义隔离的编辑方向，然后沿着这些方向操作文本嵌入来控制目标属性的强度，无需修改扩散过程。

Result: 实验表明该方法能够在不同属性和领域中实现直观高效的连续控制操作。

Conclusion: 该方法提供了一种模型无关的解耦连续编辑解决方案，可直接应用于各种图像合成框架。

Abstract: Large-scale text-to-image diffusion models have become the backbone of modern
image editing, yet text prompts alone do not offer adequate control over the
editing process. Two properties are especially desirable: disentanglement,
where changing one attribute does not unintentionally alter others, and
continuous control, where the strength of an edit can be smoothly adjusted. We
introduce a method for disentangled and continuous editing through token-level
manipulation of text embeddings. The edits are applied by manipulating the
embeddings along carefully chosen directions, which control the strength of the
target attribute. To identify such directions, we employ a Sparse Autoencoder
(SAE), whose sparse latent space exposes semantically isolated dimensions. Our
method operates directly on text embeddings without modifying the diffusion
process, making it model agnostic and broadly applicable to various image
synthesis backbones. Experiments show that it enables intuitive and efficient
manipulations with continuous control across diverse attributes and domains.

</details>


### [295] [Pulp Motion: Framing-aware multimodal camera and human motion generation](https://arxiv.org/abs/2510.05097)
*Robin Courant,Xi Wang,David Loiseaux,Marc Christie,Vicky Kalogeiton*

Main category: cs.GR

TL;DR: 本文提出了一种文本条件联合生成框架，将人类动作和相机轨迹作为内在关联的模态进行联合生成，通过屏幕空间框架作为辅助模态来确保多模态一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将人类动作和相机轨迹生成分开处理，忽略了电影摄影中演员表演与摄像机工作的紧密互动关系。本文旨在解决这一核心原则，实现两种异质但内在关联模态的一致性生成。

Method: 提出了一个模型无关的框架，通过将人体关节点投影到相机上产生的屏幕框架作为辅助模态来强制多模态一致性。设计了联合自编码器学习共享潜在空间，并引入辅助采样方法来引导生成朝向一致的框架模态。

Result: 在DiT和MAR架构上的广泛实验表明，该方法能够生成屏幕框架一致的人机运动，同时在两种模态的文本对齐方面也取得了提升。定性结果产生了更具电影摄影意义的框架设置。

Conclusion: 该方法为人类动作和相机轨迹的联合生成任务设定了新的技术水平，通过屏幕框架作为自然桥梁实现了多模态一致性，并发布了PulpMotion数据集支持该任务。

Abstract: Treating human motion and camera trajectory generation separately overlooks a
core principle of cinematography: the tight interplay between actor performance
and camera work in the screen space. In this paper, we are the first to cast
this task as a text-conditioned joint generation, aiming to maintain consistent
on-screen framing while producing two heterogeneous, yet intrinsically linked,
modalities: human motion and camera trajectories. We propose a simple,
model-agnostic framework that enforces multimodal coherence via an auxiliary
modality: the on-screen framing induced by projecting human joints onto the
camera. This on-screen framing provides a natural and effective bridge between
modalities, promoting consistency and leading to more precise joint
distribution. We first design a joint autoencoder that learns a shared latent
space, together with a lightweight linear transform from the human and camera
latents to a framing latent. We then introduce auxiliary sampling, which
exploits this linear transform to steer generation toward a coherent framing
modality. To support this task, we also introduce the PulpMotion dataset, a
human-motion and camera-trajectory dataset with rich captions, and high-quality
human motions. Extensive experiments across DiT- and MAR-based architectures
show the generality and effectiveness of our method in generating on-frame
coherent human-camera motions, while also achieving gains on textual alignment
for both modalities. Our qualitative results yield more cinematographically
meaningful framings setting the new state of the art for this task. Code,
models and data are available in our
\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project
page}.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [296] [WAREX: Web Agent Reliability Evaluation on Existing Benchmarks](https://arxiv.org/abs/2510.03285)
*Su Kara,Fazle Faisal,Suman Nath*

Main category: cs.AI

TL;DR: WAREX是一个用于评估网络LLM代理在真实网络环境下可靠性的框架，通过在现有基准测试中引入网络不稳定性和网站攻击等现实因素，发现当前最先进代理的鲁棒性存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在受控环境中评估网络代理性能，忽略了真实世界中网络不稳定、HTTPS连接问题以及网站攻击等因素对代理可靠性的影响。

Method: 提出WAREX框架，在三个流行基准测试（WebArena、WebVoyager和REAL）中引入网络不稳定性和网站攻击等现实因素来评估代理性能。

Result: 实验显示，引入WAREX后任务成功率显著下降，表明当前最先进代理在面对真实网络环境时的鲁棒性有限。

Conclusion: WAREX揭示了当前网络代理在真实环境中的可靠性问题，强调了在基准测试中考虑现实因素的重要性，为开发更鲁棒的代理提供了评估标准。

Abstract: Recent advances in browser-based LLM agents have shown promise for automating
tasks ranging from simple form filling to hotel booking or online shopping.
Current benchmarks measure agent performance in controlled environments, such
as containers or stable networks, where websites behave deterministically.
However, in the real world, users access websites over networks and HTTPS
connections that introduce instability from multiple sources: client-side,
server-side issues or broader system failures. Moreover, live websites are
prone to web attacks such Cross-Site Scripting, as well as general site
modifications which can cause unexpected or malicious pop-ups or improper
functionality. To address this gap, we present WAREX: Web Agent Reliability
Evaluation on Existing Benchmarks. We measure the impact of WAREX across three
popular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that
introducing WAREX leads to significant drops in task success rates,
highlighting the limited robustness of state-of-the-art agents.

</details>


### [297] [Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints](https://arxiv.org/abs/2510.03377)
*Ahmed Missaoui,Cemalettin Ozturk,Barry O'Sullivan*

Main category: cs.AI

TL;DR: 该研究针对带阻塞约束的混合流水车间调度问题，提出了多目标优化方法，同时最小化生产周期和能耗，开发了增强ε约束法和改进迭代帕累托贪婪算法来解决这一冲突目标问题。


<details>
  <summary>Details</summary>
Motivation: 不可再生能源稀缺、地缘政治问题、价格上涨和气候变化影响迫使制造业开发更节能的解决方案。混合流水车间调度作为一种快速部署且能立即见效的方法，受到制造企业的关注。

Method: 首先建立了新颖的多目标混合整数规划模型，提出了增强ε约束法寻找帕累托最优解，并开发了有效的多目标元启发式算法——改进迭代帕累托贪婪算法来解决大规模实例。

Result: 通过小、中、大规模实例对提出的方法进行基准测试，并与两种知名算法进行比较，计算结果表明所提方法的有效性。

Conclusion: 提出的多目标优化方法能够有效解决混合流水车间调度中生产周期和能耗的冲突优化问题，为制造业节能调度提供了有效解决方案。

Abstract: The scarcity of non-renewable energy sources, geopolitical problems in its
supply, increasing prices, and the impact of climate change, force the global
economy to develop more energy-efficient solutions for their operations. The
Manufacturing sector is not excluded from this challenge as one of the largest
consumers of energy. Energy-efficient scheduling is a method that attracts
manufacturing companies to reduce their consumption as it can be quickly
deployed and can show impact immediately. In this study, the hybrid flow shop
scheduling problem with blocking constraint (BHFS) is investigated in which we
seek to minimize the latest completion time (i.e. makespan) and overall energy
consumption, a typical manufacturing setting across many industries from
automotive to pharmaceutical. Energy consumption and the latest completion time
of customer orders are usually conflicting objectives. Therefore, we first
formulate the problem as a novel multi-objective mixed integer programming
(MIP) model and propose an augmented epsilon-constraint method for finding the
Pareto-optimal solutions. Also, an effective multi-objective metaheuristic
algorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large
instances in reasonable time. Our proposed methods are benchmarked using small,
medium, and large-size instances to evaluate their efficiency. Two well-known
algorithms are adopted for comparing our novel approaches. The computational
results show the effectiveness of our method.

</details>


### [298] [Know Thyself? On the Incapability and Implications of AI Self-Recognition](https://arxiv.org/abs/2510.03399)
*Xiaoyan Bai,Aryan Shrivastava,Ari Holtzman,Chenhao Tan*

Main category: cs.AI

TL;DR: 本文系统评估了10个大型语言模型的自我识别能力，发现模型普遍无法识别自己生成的文本，性能仅略高于随机猜测，且存在对GPT和Claude家族的强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 针对AI系统是否具备自我识别能力这一存在争议的问题，研究者希望建立一个系统评估框架来澄清模型是否真正具备识别自身生成文本的能力。

Method: 设计了二元自我识别和精确模型预测两个任务，评估10个当代大型语言模型识别自己生成文本与其他模型文本的能力。

Result: 结果显示模型自我识别能力普遍失败，仅4/10模型能正确识别自己，性能很少超过随机水平。模型存在对GPT和Claude家族的强烈偏见，并表现出对模型存在层次结构的认知。

Conclusion: 研究结果对AI安全具有重要意义，表明需要开发适当的AI自我意识，当前模型缺乏真正的自我识别能力。

Abstract: Self-recognition is a crucial metacognitive capability for AI systems,
relevant not only for psychological analysis but also for safety, particularly
in evaluative scenarios. Motivated by contradictory interpretations of whether
models possess self-recognition (Panickssery et al., 2024; Davidson et al.,
2024), we introduce a systematic evaluation framework that can be easily
applied and updated. Specifically, we measure how well 10 contemporary larger
language models (LLMs) can identify their own generated text versus text from
other models through two tasks: binary self-recognition and exact model
prediction. Different from prior claims, our results reveal a consistent
failure in self-recognition. Only 4 out of 10 models predict themselves as
generators, and the performance is rarely above random chance. Additionally,
models exhibit a strong bias toward predicting GPT and Claude families. We also
provide the first evaluation of model awareness of their own and others'
existence, as well as the reasoning behind their choices in self-recognition.
We find that the model demonstrates some knowledge of its own existence and
other models, but their reasoning reveals a hierarchical bias. They appear to
assume that GPT, Claude, and occasionally Gemini are the top-tier models, often
associating high-quality text with them. We conclude by discussing the
implications of our findings on AI safety and future directions to develop
appropriate AI self-awareness.

</details>


### [299] [ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection](https://arxiv.org/abs/2510.03418)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji,Nand Dave,Anudha Mittal*

Main category: cs.AI

TL;DR: 提出了ContraGen基准框架，专门针对企业领域生成包含矛盾内容的合成文档，用于系统评估RAG系统在检测和解决矛盾方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有矛盾检测基准仅限于句子级分析，无法处理企业文档（如合同、财务报告等）的复杂性，而RAG系统中检索证据的矛盾会导致不可靠输出，这在需要合规性和问责制的企业环境中尤其成问题。

Method: 结合自动化矛盾挖掘和人工验证，生成包含嵌入矛盾的企业风格合成文档，建立企业流程中常见矛盾类型的分类法，支持受控创建自矛盾和成对矛盾，开发矛盾感知的检索评估流程。

Result: 构建了专门针对企业领域的矛盾感知基准框架，能够系统评估文档内和跨文档的一致性，为更可信的RAG系统奠定基础。

Conclusion: 这项工作为企业信息检索应用中更可信和可问责的RAG系统建立了基础，其中检测和解决矛盾对于降低风险和确保合规性至关重要。

Abstract: Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,
offering advanced capabilities for information access and decision-making.
However, contradictions in retrieved evidence can result in inconsistent or
untrustworthy outputs, which is especially problematic in enterprise settings
where compliance, governance, and accountability are critical. Existing
benchmarks for contradiction detection are limited to sentence-level analysis
and do not capture the complexity of enterprise documents such as contracts,
financial filings, compliance reports, or policy manuals. To address this
limitation, we propose ContraGen, a contradiction-aware benchmark framework
tailored to enterprise domain. The framework generates synthetic
enterprise-style documents with embedded contradictions, enabling systematic
evaluation of both intra-document and cross-document consistency. Automated
contradiction mining is combined with human-in-the-loop validation to ensure
high accuracy. Our contributions include generating realistic enterprise
documents, modeling a taxonomy of contradiction types common in business
processes, enabling controlled creation of self- and pairwise contradictions,
developing a contradiction-aware retrieval evaluation pipeline and embedding
human oversight to reflect domain-specific judgment complexity. This work
establishes a foundation for more trustworthy and accountable RAG systems in
enterprise information-seeking applications, where detecting and resolving
contradictions is essential for reducing risk and ensuring compliance.

</details>


### [300] [A Qualitative Comparative Evaluation of Cognitive and Generative Theories](https://arxiv.org/abs/2510.03453)
*Paul S. Rosenbloom*

Main category: cs.AI

TL;DR: 本文提出了一种评估认知架构和生成式神经架构理论的定性比较方法


<details>
  <summary>Details</summary>
Motivation: 认知架构理论和生成式神经架构理论都面临着评估挑战，需要一种全面的评估方法

Method: 采用广泛的理论评估视角，对面向全脑的认知架构和生成式架构及其完整系统进行定性比较

Result: 开发了一种宽泛但定性的比较框架来评估不同类型的架构理论

Conclusion: 通过这种全面的评估方法，可以更好地理解和比较认知架构与生成式神经架构理论

Abstract: Evaluation is a critical activity associated with any theory. Yet this has
proven to be an exceptionally challenging activity for theories based on
cognitive architectures. For an overlapping set of reasons, evaluation can also
be challenging for theories based on generative neural architectures. This dual
challenge is approached here by leveraging a broad perspective on theory
evaluation to yield a wide-ranging, albeit qualitative, comparison of
whole-mind-oriented cognitive and generative architectures and the full systems
that are based on these architectures.

</details>


### [301] [Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification](https://arxiv.org/abs/2510.03469)
*Keshav Ramani,Vali Tawosi,Salwa Alamir,Daniel Borrajo*

Main category: cs.AI

TL;DR: 提出了一种使用LLMs将自然语言计划转换为Kripke结构和LTL公式，并通过模型检查评估计划对齐性的新框架。


<details>
  <summary>Details</summary>
Motivation: 需要评估自然语言计划与其预期行为之间的对齐性，确保计划的正确执行。

Method: 使用大型语言模型将自然语言计划转换为Kripke结构和线性时序逻辑公式，然后进行模型检查。

Result: GPT-5在PlanBench数据集上实现了96.3%的F1分数，几乎总能生成语法完美的形式化表示。

Conclusion: 该框架在分类性能上表现出色，但语义完美形式模型的合成仍需进一步探索。

Abstract: We introduce a novel framework for evaluating the alignment between natural
language plans and their expected behavior by converting them into Kripke
structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)
and performing model checking. We systematically evaluate this framework on a
simplified version of the PlanBench plan verification dataset and report on
metrics like Accuracy, Precision, Recall and F1 scores. Our experiments
demonstrate that GPT-5 achieves excellent classification performance (F1 score
of 96.3%) while almost always producing syntactically perfect formal
representations that can act as guarantees. However, the synthesis of
semantically perfect formal models remains an area for future exploration.

</details>


### [302] [Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection](https://arxiv.org/abs/2510.03485)
*Xiaofei Wen,Wenjie Jacky Mo,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: 提出了PolicyGuardBench基准和PolicyGuard-4B模型，用于检测网络代理轨迹中的策略违规，支持跨领域泛化和小规模高效推理。


<details>
  <summary>Details</summary>
Motivation: 自主网络代理需要在外部策略约束下生成长视野轨迹，但现有研究很少关注这些轨迹是否遵守策略，以及策略违规在不同上下文中的持续性。

Method: 从多样化代理运行中生成广泛策略集，创建包含约60k个示例的基准数据集，支持完整轨迹和前缀检测任务，并训练轻量级PolicyGuard-4B模型。

Result: PolicyGuard-4B在所有任务上实现强检测精度，能跨领域泛化并在未见设置上保持高准确率。

Conclusion: PolicyGuardBench和PolicyGuard-4B为研究网络代理轨迹策略合规性提供了首个全面框架，证明小规模下可实现准确且可泛化的护栏机制。

Abstract: Autonomous web agents need to operate under externally imposed or
human-specified policies while generating long-horizon trajectories. However,
little work has examined whether these trajectories comply with such policies,
or whether policy violations persist across different contexts such as domains
(e.g., shopping or coding websites) and subdomains (e.g., product search and
order management in shopping). To address this gap, we introduce
PolicyGuardBench, a benchmark of about 60k examples for detecting policy
violations in agent trajectories. From diverse agent runs, we generate a broad
set of policies and create both within subdomain and cross subdomain pairings
with violation labels. In addition to full-trajectory evaluation,
PolicyGuardBench also includes a prefix-based violation detection task where
models must anticipate policy violations from truncated trajectory prefixes
rather than complete sequences. Using this dataset, we train PolicyGuard-4B, a
lightweight guardrail model that delivers strong detection accuracy across all
tasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes
across domains and preserves high accuracy on unseen settings. Together,
PolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework
for studying policy compliance in web agent trajectories, and show that
accurate and generalizable guardrails are feasible at small scales.

</details>


### [303] [OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows](https://arxiv.org/abs/2510.03506)
*John Nguyen,Marton Havasi,Tariq Berrada,Luke Zettlemoyer,Ricky T. Q. Chen*

Main category: cs.AI

TL;DR: OneFlow是首个非自回归多模态模型，支持可变长度和并发混合模态生成，通过插入式编辑流和流匹配技术实现文本图像的并发生成，在减少50%训练计算量的同时超越自回归基线。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型在文本和图像生成间强制因果顺序限制，无法实现并发混合模态生成，需要开发更灵活高效的多模态生成方法。

Method: 结合基于插入的编辑流处理离散文本标记，使用流匹配处理图像潜在表示，通过分层采样优先内容而非语法，实现并发文本图像合成。

Result: 在1B到8B模型规模的实验中，OneFlow在生成和理解任务上均超越自回归基线，同时减少高达50%的训练计算量，优于自回归和基于扩散的方法。

Conclusion: OneFlow解锁了并发生成、迭代优化和类自然推理生成等新能力，为非自回归多模态生成提供了高效解决方案。

Abstract: We present OneFlow, the first non-autoregressive multimodal model that
enables variable-length and concurrent mixed-modal generation. Unlike
autoregressive models that enforce rigid causal ordering between text and image
generation, OneFlow combines an insertion-based Edit Flow for discrete text
tokens with Flow Matching for image latents. OneFlow enables concurrent
text-image synthesis with hierarchical sampling that prioritizes content over
grammar. Through controlled experiments across model sizes from 1B to 8B, we
demonstrate that OneFlow outperforms autoregressive baselines on both
generation and understanding tasks while using up to 50% fewer training FLOPs.
OneFlow surpasses both autoregressive and diffusion-based approaches while
unlocking new capabilities for concurrent generation, iterative refinement, and
natural reasoning-like generation.

</details>


### [304] [Understanding the Role of Training Data in Test-Time Scaling](https://arxiv.org/abs/2510.03605)
*Adel Javanmard,Baharan Mirzasoleiman,Vahab Mirrokni*

Main category: cs.AI

TL;DR: 测试时扩展通过生成更长的思维链来提升大语言模型的推理能力，但训练数据中长思维链何时出现以及何时有效仍不明确。本文通过理论分析解释了测试时扩展的几个关键现象。


<details>
  <summary>Details</summary>
Motivation: 研究测试时扩展在何种训练数据条件下有效，以及长思维链何时能提升模型性能，填补当前对测试时扩展机制理解的理论空白。

Method: 在上下文权重预测任务上训练transformer模型，通过理论分析研究测试时扩展的性能表现，并用非线性transformer架构实验验证。

Result: 发现测试时扩展可在固定测试误差下减少训练提示中的上下文示例数量；当训练数据缺乏必要技能时，增加测试时计算反而会损害性能；任务难度与特征协方差矩阵最小特征值相关。

Conclusion: 在多样化、相关且困难的任务集上训练，能为测试时扩展带来最佳性能，这为理解测试时扩展的有效条件提供了理论框架。

Abstract: Test-time scaling improves the reasoning capabilities of large language
models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts
(CoTs). This enables models to tackle more complex problem by breaking them
down into additional steps, backtracking, and correcting mistakes. Despite its
strong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions
in the training data under which long CoTs emerge, and when such long CoTs
improve the performance, remain unclear. In this paper, we study the
performance of test-time scaling for transformers trained on an in-context
weight prediction task for linear regression. Our analysis provides a
theoretical explanation for several intriguing observations: First, at any
fixed test error, increasing test-time compute allows us to reduce the number
of in-context examples (context length) in training prompts. Second, if the
skills required to solve a downstream task are not sufficiently present in the
training data, increasing test-time compute can harm performance. Finally, we
characterize task hardness via the smallest eigenvalue of its feature
covariance matrix and show that training on a diverse, relevant, and hard set
of tasks results in best performance for test-time scaling. We confirm our
findings with experiments on large, nonlinear transformer architectures.

</details>


### [305] [Cross-Modal Content Optimization for Steering Web Agent Preferences](https://arxiv.org/abs/2510.03612)
*Tanqiu Jiang,Min Bai,Nikolaos Pappas,Yanjun Qi,Sandesh Swamy*

Main category: cs.AI

TL;DR: 提出了一种名为跨模态偏好引导(CPS)的新型攻击方法，通过联合优化视觉和文本通道的不可察觉修改，在现实黑盒威胁设置下有效操纵基于视觉语言模型的网络代理决策。


<details>
  <summary>Details</summary>
Motivation: 现有研究要么假设强白盒访问，要么使用不切实际的设置，缺乏在现实攻击者能力下对视觉和文本通道的联合利用。本文旨在证明在现实黑盒威胁下，联合利用视觉和文本通道可以产生更强大的偏好操纵。

Method: 引入跨模态偏好引导(CPS)，联合优化项目视觉和自然语言描述的不可察觉修改，利用CLIP可迁移图像扰动和RLHF诱导的语言偏见来引导代理决策。采用现实黑盒威胁设置，攻击者只能编辑自己列表的图像和文本元数据。

Result: 在GPT-4.1、Qwen-2.5VL和Pixtral-Large等最先进VLM上评估，CPS在所有模型上始终优于基线方法，同时保持70%更低的检测率，证明了有效性和隐蔽性。

Conclusion: 这些发现凸显了随着代理系统在社会中扮演越来越重要的角色，迫切需要强大的防御机制来应对此类攻击。

Abstract: Vision-language model (VLM)-based web agents increasingly power high-stakes
selection tasks like content recommendation or product ranking by combining
multimodal perception with preference reasoning. Recent studies reveal that
these agents are vulnerable against attackers who can bias selection outcomes
through preference manipulations using adversarial pop-ups, image
perturbations, or content tweaks. Existing work, however, either assumes strong
white-box access, with limited single-modal perturbations, or uses impractical
settings. In this paper, we demonstrate, for the first time, that joint
exploitation of visual and textual channels yields significantly more powerful
preference manipulations under realistic attacker capabilities. We introduce
Cross-Modal Preference Steering (CPS) that jointly optimizes imperceptible
modifications to an item's visual and natural language descriptions, exploiting
CLIP-transferable image perturbations and RLHF-induced linguistic biases to
steer agent decisions. In contrast to prior studies that assume gradient
access, or control over webpages, or agent memory, we adopt a realistic
black-box threat setup: a non-privileged adversary can edit only their own
listing's images and textual metadata, with no insight into the agent's model
internals. We evaluate CPS on agents powered by state-of-the-art proprietary
and open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both
movie selection and e-commerce tasks. Our results show that CPS is
significantly more effective than leading baseline methods. For instance, our
results show that CPS consistently outperforms baselines across all models
while maintaining 70% lower detection rates, demonstrating both effectiveness
and stealth. These findings highlight an urgent need for robust defenses as
agentic systems play an increasingly consequential role in society.

</details>


### [306] [MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information](https://arxiv.org/abs/2510.03632)
*Jiaxi Li,Yucheng Shi,Jin Lu,Ninghao Liu*

Main category: cs.AI

TL;DR: 提出了基于互信息的树搜索框架MITS，通过点互信息评分函数和基于熵的动态采样策略，在保持计算效率的同时提升大语言模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索方法难以对中间推理步骤进行即时可靠的量化评估，且广泛路径探索计算成本高昂。

Method: 使用点互信息(PMI)作为评分函数进行推理路径评估，结合基于熵的动态采样策略自适应分配计算资源，采用加权投票方案进行最终预测。

Result: 在多样化推理基准测试中，MITS持续超越基线方法。

Conclusion: MITS为大语言模型推理提供了一个原则性且高效的框架。

Abstract: Tree search has become as a representative framework for test-time reasoning
with large language models (LLMs), exemplified by methods such as
Tree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning
paths. However, it remains difficult to provide instant and reliable
quantitative assessments of intermediate reasoning step quality, and extensive
path exploration is computationally costly. To address this, we propose Mutual
Information Tree Search (MITS), a novel framework that guides reasoning with
information-theoretic principles. MITS introduces an effective scoring function
based on pointwise mutual information (PMI), which enables step-wise evaluation
of reasoning paths and search tree expansion via beam search without expensive
look-ahead simulations, achieving superior reasoning performances while
maintaining computational efficiency. The framework is complemented by an
entropy-based dynamic sampling strategy that adaptively allocates computational
resources to uncertain reasoning steps where exploration is most beneficial.
For final prediction, MITS employs a weighted voting scheme that combines PMI
scores with prediction consensus. Through comprehensive experiments on diverse
reasoning benchmarks, MITS consistently surpasses baseline methods,
establishing a principled and efficient framework for LLM reasoning.

</details>


### [307] [Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs](https://arxiv.org/abs/2510.03680)
*Bumjun Kim,Dongjae Jeon,Dueun Kim,Wonje Jeung,Albert No*

Main category: cs.AI

TL;DR: 扩散大语言模型在指令调优后存在<eos>溢出问题：随着序列长度增加，响应反而变短，导致提前终止或退化为<eos>流。作者提出彩虹填充方法，用循环的不同填充标记替代重复<eos>，有效解决了这一问题。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在复杂推理任务上表现优异，但指令调优后的模型存在<eos>溢出漏洞，即随着序列长度增加，响应反而变短，这一问题尚未被系统分析。

Method: 提出彩虹填充方法，用循环的不同填充标记替代重复<eos>占位符，分散概率质量，打破<eos>主导地位。该方法可高效集成到现有模型中，仅需少量数据和单轮LoRA微调。

Result: 彩虹填充显著提高了长度鲁棒性和输出质量，仅需7个填充标记即可防止提前终止。在现有指令调优模型上的集成效果显著且实用。

Conclusion: 彩虹填充是一种简单有效的解决方案，解决了扩散大语言模型中的<eos>溢出问题，提高了模型在长序列生成中的稳定性和质量。

Abstract: Diffusion large language models (dLLMs) have emerged as a promising
alternative to autoregressive models, offering flexible generation orders and
strong performance on complex reasoning tasks. However, instruction-tuned dLLMs
exhibit a critical vulnerability we term \texttt{<eos>} overflow: as allocated
sequence length increases, responses paradoxically become shorter, collapsing
into early termination or degenerating into streams of \texttt{<eos>} tokens.
Although noticed in practice, this issue has not been systematically analyzed.
We trace its root cause to the dual role of \texttt{<eos>} as both termination
and padding, which concentrates probability mass on \texttt{<eos>} at later
positions and propagates backward to trigger early termination. To address
this, we introduce Rainbow Padding, a simple remedy that replaces repeated
\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,
distributing probability mass and breaking \texttt{<eos>} dominance.
Experiments show that Rainbow Padding substantially improves length robustness
and output quality, with as few as seven padding tokens sufficient to prevent
early termination. Moreover, the method integrates efficiently into existing
instruction-tuned models: LoRA fine-tuning for a single epoch on minimal data
yields significant improvements, making this solution highly practical. The
code is publicly available at https://github.com/quasar529/rainbow-padding.

</details>


### [308] [Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models](https://arxiv.org/abs/2510.03696)
*Deepak Babu Piskala,Sharlene Chen,Udita Patel,Parul Kalra,Rafael Castrillo*

Main category: cs.AI

TL;DR: 提出了一个面向目标的多智能体系统评估框架，引入目标成功率(GSR)和失败根因分类法(RCOF)，通过教师LLM进行可解释、数据高效的系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法多在对话轮次层面评估，无法判断用户总体目标是否达成，需要更全面的目标导向评估框架。

Method: 基于用户目标分割对话，使用教师LLM结合领域专家定义的目标和质量标准进行评估，通过"思考标记"产生可解释的推理过程。

Result: 在企业环境中应用该框架评估AIDA系统，观察到目标成功率从63%提升至79%。

Conclusion: 该框架具有通用性，通过详细的缺陷分类提供可操作的见解，能够诊断整体成功率、识别关键失败模式并指导系统改进。

Abstract: Evaluating the quality of multi-turn chatbot interactions remains
challenging, as most existing methods assess interactions at the turn level
without addressing whether a user's overarching goal was fulfilled. A ``goal''
here refers to an information need or task, such as asking for policy
information or applying for leave. We propose a comprehensive framework for
goal-oriented evaluation of multi-agent systems (MAS), introducing the
\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,
and a \textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for
failure in multi-agent chatbots. Our method segments conversations by user
goals and evaluates success using all relevant turns. We present a model-based
evaluation system combining teacher LLMs, where domain experts define goals,
set quality standards serving as a guidance for the LLMs. The LLMs use
``thinking tokens'' to produce interpretable rationales, enabling
\textit{explainable}, \textit{data-efficient} evaluations. In an enterprise
setting, we apply our framework to evaluate AIDA, a zero-to-one employee
conversational agent system built as a ground-up multi-agent conversational
agent, and observe GSR improvement from 63\% to 79\% over six months since its
inception. Our framework is generic and offers actionable insights through a
detailed defect taxonomy based on analysis of failure points in multi-agent
chatbots, diagnosing overall success, identifying key failure modes, and
informing system improvements.

</details>


### [309] [H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis](https://arxiv.org/abs/2510.03700)
*Seungseop Lim,Gibaeg Kim,Hyunkyung Lee,Wooseok Han,Jean Seo,Jaehyo Yoo,Eunho Yang*

Main category: cs.AI

TL;DR: 提出了H-DDx分层评估框架，用于更准确地评估LLM在医学鉴别诊断中的表现，克服了传统平直指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在鉴别诊断评估中主要使用平直指标（如Top-k准确率），无法区分临床相关的近似错误和诊断上遥远的错误，需要更符合临床相关性的评估方法。

Method: H-DDx框架采用检索和重排序流程将自由文本诊断映射到ICD-10代码，并应用分层指标来奖励与真实诊断密切相关的预测。

Result: 在22个领先模型的基准测试中，传统平直指标低估了性能，忽略了临床有意义的输出；领域专业化的开源模型表现突出；框架揭示了分层错误模式，显示LLM即使错过精确诊断也能正确识别更广泛的临床背景。

Conclusion: H-DDx框架提供了更准确、可解释的LLM鉴别诊断评估方法，能更好地反映临床相关性，并揭示了模型在识别临床背景方面的能力。

Abstract: An accurate differential diagnosis (DDx) is essential for patient care,
shaping therapeutic decisions and influencing outcomes. Recently, Large
Language Models (LLMs) have emerged as promising tools to support this process
by generating a DDx list from patient narratives. However, existing evaluations
of LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,
which fail to distinguish between clinically relevant near-misses and
diagnostically distant errors. To mitigate this limitation, we introduce H-DDx,
a hierarchical evaluation framework that better reflects clinical relevance.
H-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses
to ICD-10 codes and applies a hierarchical metric that credits predictions
closely related to the ground-truth diagnosis. In benchmarking 22 leading
models, we show that conventional flat metrics underestimate performance by
overlooking clinically meaningful outputs, with our results highlighting the
strengths of domain-specialized open-source models. Furthermore, our framework
enhances interpretability by revealing hierarchical error patterns,
demonstrating that LLMs often correctly identify the broader clinical context
even when the precise diagnosis is missed.

</details>


### [310] [Bridging the Gap Between Multimodal Foundation Models and World Models](https://arxiv.org/abs/2510.03727)
*Xuehai He*

Main category: cs.AI

TL;DR: 该论文旨在弥合多模态基础模型与世界模型之间的差距，通过增强模型的推理能力和生成能力，使其能够进行反事实推理、模拟动态过程、理解时空信息并实现可控生成。


<details>
  <summary>Details</summary>
Motivation: 受人类通过多感官整合理解世界的启发，当前的多模态基础模型缺乏作为有效世界模型的关键能力，如反事实推理、动态模拟、时空信息理解和可控生成等。

Method: 通过判别性任务提升推理能力，赋予结构化推理技能（因果推断、反事实思维、时空推理）；开发结构化可控生成框架，结合场景图、多模态条件化和对齐策略；扩展到可控4D生成，实现时空交互式对象合成。

Result: 提出的方法使多模态基础模型能够超越表面相关性，理解视觉和文本数据中的深层关系，并实现与高层语义和用户意图一致的生成结果。

Conclusion: 通过增强推理和生成能力，多模态基础模型可以更好地模拟和理解物理世界，向真正的世界模型迈进。

Abstract: Humans understand the world through the integration of multiple sensory
modalities, enabling them to perceive, reason about, and imagine dynamic
physical processes. Inspired by this capability, multimodal foundation models
(MFMs) have emerged as powerful tools for multimodal understanding and
generation. However, today's MFMs fall short of serving as effective world
models. They lack the essential ability such as perform counterfactual
reasoning, simulate dynamics, understand the spatiotemporal information,
control generated visual outcomes, and perform multifaceted reasoning. We
investigates what it takes to bridge the gap between multimodal foundation
models and world models. We begin by improving the reasoning capabilities of
MFMs through discriminative tasks and equipping MFMs with structured reasoning
skills, such as causal inference, counterfactual thinking, and spatiotemporal
reasoning, enabling them to go beyond surface correlations and understand
deeper relationships within visual and textual data. Next, we explore
generative capabilities of multimodal foundation models across both image and
video modalities, introducing new frameworks for structured and controllable
generation. Our approaches incorporate scene graphs, multimodal conditioning,
and multimodal alignment strategies to guide the generation process, ensuring
consistency with high-level semantics and fine-grained user intent. We further
extend these techniques to controllable 4D generation, enabling interactive,
editable, and morphable object synthesis over time and space.

</details>


### [311] [OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation](https://arxiv.org/abs/2510.03771)
*Divij Handa,David Blincoe,Orson Adams,Yinlin Fu*

Main category: cs.AI

TL;DR: OptAgent框架通过多智能体模拟和遗传算法优化电商查询改写，在主观性任务中实现了比原始查询21.98%和基线方法3.36%的性能提升。


<details>
  <summary>Details</summary>
Motivation: LLM在可验证任务中表现优异，但在缺乏标准答案的主观性任务（如电商查询改写）中部署困难，需要可靠的评估方法。

Method: 使用多个LLM智能体模拟购物顾客作为动态奖励信号，结合遗传算法迭代优化用户查询。

Result: 在1000个真实电商查询的五个类别上测试，平均比原始查询提升21.98%，比Best-of-N基线提升3.36%。

Conclusion: OptAgent框架有效解决了主观性任务评估难题，为电商查询改写提供了可靠优化方案。

Abstract: Deploying capable and user-aligned LLM-based systems necessitates reliable
evaluation. While LLMs excel in verifiable tasks like coding and mathematics,
where gold-standard solutions are available, adoption remains challenging for
subjective tasks that lack a single correct answer. E-commerce Query Rewriting
(QR) is one such problem where determining whether a rewritten query properly
captures the user intent is extremely difficult to figure out algorithmically.
In this work, we introduce OptAgent, a novel framework that combines
multi-agent simulations with genetic algorithms to verify and optimize queries
for QR. Instead of relying on a static reward model or a single LLM judge, our
approach uses multiple LLM-based agents, each acting as a simulated shopping
customer, as a dynamic reward signal. The average of these agent-derived scores
serves as an effective fitness function for an evolutionary algorithm that
iteratively refines the user's initial query. We evaluate OptAgent on a dataset
of 1000 real-world e-commerce queries in five different categories, and we
observe an average improvement of 21.98% over the original user query and 3.36%
over a Best-of-N LLM rewriting baseline.

</details>


### [312] [GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time](https://arxiv.org/abs/2510.03777)
*Divij Handa,Mihir Parmar,Aswin RRV,Md Nayem Uddin,Hamid Palangi,Chitta Baral*

Main category: cs.AI

TL;DR: 提出GuidedSampling推理算法，通过分离探索和生成阶段来增加解决方案多样性，相比重复采样在pass@50指标上平均提升21.6%


<details>
  <summary>Details</summary>
Motivation: 重复采样算法在复杂任务中虽然有效，但难以生成多样化的解决方案候选，经常依赖相同的基础方法导致样本冗余

Method: GuidedSampling算法将推理过程解耦为探索阶段和生成阶段：探索阶段识别解决问题的多个概念，生成阶段应用特定概念提供最终解决方案候选

Result: 在多个基准测试中，GuidedSampling相比重复采样在pass@50指标上平均提升21.6%；使用GuidedSampling轨迹训练的模型在pass@5指标上平均提升9.7%，每个实例的平均概念数从1.67增加到3.03

Conclusion: GuidedSampling通过解耦探索和生成阶段，有效提高了解决方案的多样性，在多个性能指标上显著优于传统重复采样方法

Abstract: Repeated Sampling (RS) is a simple inference-time algorithm that has been
shown to improve model performance on complex tasks. Although it is an
effective way of scaling inference time, it often struggles to generate diverse
solution candidates, frequently relying on the same underlying approach to
solve the problem and thus producing redundant samples. To address this
limitation, we propose a new inference algorithm, GuidedSampling, which
decouples the exploration and generation phases during inference, increasing
diversity of generated candidate solutions. The exploration phase identifies
multiple concepts that can be utilized to solve the problem, while the
generation phase applies a specific concept to provide final solution
candidates. We first define the theoretical bounds of GuidedSampling and then
empirically demonstrate that it improves the performance of base model at
pass@50 by on an average ~21.6% across various benchmarks compared to RS.
Furthermore, models trained on trajectories of GuidedSampling exhibit
substantial performance improvements at pass@5 by on an average ~9.7%, compared
to models trained on traditional RS. Additionally, models trained with
GuidedSampling increases the average number of concepts per instance (1.67 ->
3.03), yielding a diverse set of candidates than traditional RS.

</details>


### [313] [The Hidden Game Problem](https://arxiv.org/abs/2510.03845)
*Gon Buzaglo,Noah Golowich,Elad Hazan*

Main category: cs.AI

TL;DR: 本文研究具有大策略空间的游戏类别，针对AI对齐和语言游戏中的挑战，提出了隐藏游戏问题，并开发了能够发现和利用隐藏结构的遗憾最小化算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于AI对齐和语言游戏中的挑战，其中玩家存在未知的能够持续获得更高奖励的策略子集，需要设计高效算法来发现和利用这种隐藏结构。

Method: 开发了一种遗憾最小化技术的组合方法，实现了最优的外部遗憾和交换遗憾界限，利用隐藏游戏结构提高计算效率。

Result: 该方法能够快速收敛到隐藏子游戏中的相关均衡，同时保持一般情况下的理性，证明了高效算法的可行性。

Conclusion: 肯定地回答了能否设计高效遗憾最小化算法来发现和利用隐藏结构的问题，为具有大策略空间的游戏提供了有效的解决方案。

Abstract: This paper investigates a class of games with large strategy spaces,
motivated by challenges in AI alignment and language games. We introduce the
hidden game problem, where for each player, an unknown subset of strategies
consistently yields higher rewards compared to the rest. The central question
is whether efficient regret minimization algorithms can be designed to discover
and exploit such hidden structures, leading to equilibrium in these subgames
while maintaining rationality in general. We answer this question affirmatively
by developing a composition of regret minimization techniques that achieve
optimal external and swap regret bounds. Our approach ensures rapid convergence
to correlated equilibria in hidden subgames, leveraging the hidden game
structure for improved computational efficiency.

</details>


### [314] [Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs](https://arxiv.org/abs/2510.03847)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 小语言模型（1-20B参数）在需要模式约束准确性的智能体任务中优于大模型，通过引导解码、严格JSON模式输出和验证器优先执行，能以10-100倍更低的成本实现类似或更好的性能，同时显著改善延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在智能体任务中成本高、延迟大、能耗高的问题，探索小语言模型在模式约束任务中的潜力，提供经济高效的智能体构建方案。

Method: 采用引导解码技术、严格JSON模式输出、验证器优先工具执行，构建SLM默认、LLM后备系统，配合不确定性感知路由和验证器级联，使用LoRA/QLoRA轻量适配。

Result: 小语言模型在工具使用、函数调用和RAG任务中能匹配或超越大模型，成本降低10-100倍，延迟和能耗显著改善，同时保持高模式有效率和可执行调用率。

Conclusion: 小语言模型是构建快速、经济、可靠智能体的理想选择，通过适当的技术组合可以大幅降低部署成本，同时保持性能，为大模型提供有价值的后备支持。

Abstract: Small language models (SLMs; 1-12B params, sometimes up to 20B) are
sufficient and often superior for agentic workloads where the objective is
schema- and API-constrained accuracy rather than open-ended generation. We
synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,
Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,
DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,
StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with
guided decoding libraries (XGrammar, Outlines). We formalize SLM-default,
LLM-fallback systems with uncertainty-aware routing and verifier cascades, and
propose engineering metrics that reflect real production goals: cost per
successful task (CPS), schema validity rate, executable call rate, p50/p95
latency, and energy per request. Guided decoding, strict JSON Schema outputs,
and validator-first tool execution close much of the capability gap with larger
models and often let SLMs match or surpass LLMs on tool use, function calling,
and RAG at 10x-100x lower token cost with materially better latency and energy.
We provide design patterns for agent stacks that prioritize SLMs: schema-first
prompting, type-safe function registries, confidence scoring with verifier
rollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits
where fallback remains valuable (open-domain reasoning and some long-horizon
planning). The result is a practical blueprint for building fast, inexpensive,
and reliable agents that default to SLMs while preserving headroom with
targeted LLM assistance.
  Keywords: small language models, agents, function calling, structured
outputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,
edge inference

</details>


### [315] [Algorithm Generation via Creative Ideation](https://arxiv.org/abs/2510.03851)
*Ruiying Ma,Chieh-Jan Mike Liang,Yanjie Gao,Francis Y. Yan*

Main category: cs.AI

TL;DR: MetaMuse框架通过三个自反思原则解决LLM在算法生成中的创造性不足问题，在缓存替换和在线装箱问题上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 系统算法设计面临解空间不连续的挑战，传统方法依赖通用启发式算法而牺牲性能。LLM在算法生成中存在偏向知名通用设计的偏见，缺乏创造性突破。

Method: 提出MetaMuse框架，基于三个自反思原则：1)在可测量的性能空间而非抽象想法空间量化解决方案多样性和有用性；2)通过外部刺激而非内部随机性引导构思；3)使用路径点推理而非自由形式的思维链构建可执行解决方案。

Result: 在缓存替换问题上减少缓存缺失达35.76%，在在线装箱问题上减少容器使用达30.93%。

Conclusion: MetaMuse能够为关键系统问题生成高性能解决方案，证明了其在算法生成中的有效性。

Abstract: Designing system algorithms remains challenging, where the discontinuous
nature of the solution space often forces system engineers to rely on generic
heuristics at the expense of performance. We study whether LLMs can practically
drive algorithm generation, and find that they are biased towards well-known
generic designs, rather than making the creative leaps needed to navigate the
discontinuous solution space. To address this limitation, we introduce
MetaMuse, a framework for creative ideation built on three self-reflection
principles: (1) quantifying solution diversity and usefulness in measurable
performance space, rather than abstract idea space, (2) steering ideation
through external stimuli, rather than internal randomness, and (3) constructing
executable solutions using waypoint reasoning, rather than free-form
chain-of-thought. Extensive evaluation shows that MetaMuse can generate
high-performing solutions for two critical problems at a global cloud provider:
cache replacement (reducing cache misses by up to 35.76%) and online bin
packing (reducing bin usage by up to 30.93%).

</details>


### [316] [Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning](https://arxiv.org/abs/2510.03859)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 提出了一种基于LLM和XAI代理的异常检测方法，用于关键IoT系统，在动态高维环境中提高检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法在动态、高维、数据不完整或不断演变的IoT环境中存在局限性，需要自适应智能系统来持续改进和推理。

Method: 使用LLM支持的上下文推理方法与XAI代理相结合，采用注意力机制、跳过时间步细节处理和使用语义记忆缓冲区来发现隐藏模式和数据不一致性。

Result: 在智能电网和医疗保健场景的模拟测试中，新方法在检测准确性和可解释性方面显著优于现有模型。

Conclusion: 这种LLM增强的方法在IoT异常检测任务中表现出优越性能，适合未来应用。

Abstract: Ensuring that critical IoT systems function safely and smoothly depends a lot
on finding anomalies quickly. As more complex systems, like smart healthcare,
energy grids and industrial automation, appear, it is easier to see the
shortcomings of older methods of detection. Monitoring failures usually happen
in dynamic, high dimensional situations, especially when data is incomplete,
messy or always evolving. Such limits point out the requirement for adaptive,
intelligent systems that always improve and think. LLMs are now capable of
significantly changing how context is understood and semantic inference is done
across all types of data. This proposal suggests using an LLM supported
contextual reasoning method along with XAI agents to improve how anomalies are
found in significant IoT environments. To discover hidden patterns and notice
inconsistencies in data streams, it uses attention methods, avoids dealing with
details from every time step and uses memory buffers with meaning. Because no
code AI stresses transparency and interpretability, people can check and accept
the AI's decisions, helping ensure AI follows company policies. The two
architectures are put together in a test that compares the results of the
traditional model with those of the suggested LLM enhanced model. Important
measures to check are the accuracy of detection, how much inaccurate
information is included in the results, how clearly the findings can be read
and how fast the system responds under different test situations. The
metaheuristic is tested in simulations of real world smart grid and healthcare
contexts to check its adaptability and reliability. From the study, we see that
the new approach performs much better than most existing models in both
accuracy and interpretation, so it could be a good fit for future anomaly
detection tasks in IoT

</details>


### [317] [Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation](https://arxiv.org/abs/2510.03863)
*Arina Kharlamova,Bowei He,Chen Ma,Xue Liu*

Main category: cs.AI

TL;DR: 提出了Spatial CAPTCHA，一种利用人类与多模态大语言模型在空间推理能力上的根本差异的新型人机验证框架，通过几何推理、视角转换、遮挡处理和心理旋转等任务来抵御AI攻击。


<details>
  <summary>Details</summary>
Motivation: 传统CAPTCHA依赖文本识别或2D图像理解，但多模态大语言模型的进步已削弱其有效性，需要开发基于更高级认知能力的验证机制。

Method: 采用程序化生成流水线，包含基于约束的难度控制、自动正确性验证和人在环验证，生成需要空间推理的动态问题。

Result: 在Spatial-CAPTCHA-Bench基准测试中，人类表现远超10个最先进的MLLM，最佳模型仅达到31.0%的Pass@1准确率，且与Google reCAPTCHA相比证实了其有效性。

Conclusion: Spatial CAPTCHA不仅作为安全机制有效，还可作为AI空间推理能力的诊断工具，展示了基于高级认知任务的验证方法的潜力。

Abstract: Online services rely on CAPTCHAs as a first line of defense against automated
abuse, yet recent advances in multi-modal large language models (MLLMs) have
eroded the effectiveness of conventional designs that focus on text recognition
or 2D image understanding. To address this challenge, we present Spatial
CAPTCHA, a novel human-verification framework that leverages fundamental
differences in spatial reasoning between humans and MLLMs. Unlike existing
CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern
AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,
perspective-taking, occlusion handling, and mental rotation. These skills are
intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The
system employs a procedural generation pipeline with constraint-based
difficulty control, automated correctness verification, and human-in-the-loop
validation to ensure scalability, robustness, and adaptability. Evaluation on a
corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly
outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%
Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,
which confirms its effectiveness as both a security mechanism and a diagnostic
tool for spatial reasoning in AI.

</details>


### [318] [Rare Text Semantics Were Always There in Your Diffusion Transformer](https://arxiv.org/abs/2510.03886)
*Seil Kang,Woojung Han,Dayun Ju,Seong Jae Hwang*

Main category: cs.AI

TL;DR: 提出一种无需额外训练、数据或外部模块的方法，通过扩大文本标记嵌入的表征范围来增强多模态扩散变换器对稀有语义的生成能力


<details>
  <summary>Details</summary>
Motivation: 现有文本到视觉生成模型在处理想象性或稀有提示时表现不佳，因为这些概念在预训练中过于稀少，难以形成强表征

Method: 在联合注意力块之前，通过数学方法扩大文本标记嵌入的表征范围（方差放大），使稀有语义在输出中清晰显现

Result: 该方法能有效提升稀有语义的生成质量，并在文本到图像、文本到视频和文本驱动图像编辑等任务中具有良好泛化性

Conclusion: 该方法能够揭示用户意图中原本隐藏但准备浮现的语义，为生成模型提供了简单有效的语义增强手段

Abstract: Starting from flow- and diffusion-based transformers, Multi-modal Diffusion
Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim
for exceptional visual fidelity. As these models advance, users continually
push the boundary with imaginative or rare prompts, which advanced models still
falter in generating, since their concepts are often too scarce to leave a
strong imprint during pre-training. In this paper, we propose a simple yet
effective intervention that surfaces rare semantics inside MM-DiTs without
additional training steps, data, denoising-time optimization, or reliance on
external modules (e.g., large language models). In particular, the
joint-attention mechanism intrinsic to MM-DiT sequentially updates text
embeddings alongside image embeddings throughout transformer blocks. We find
that by mathematically expanding representational basins around text token
embeddings via variance scale-up before the joint-attention blocks, rare
semantics clearly emerge in MM-DiT's outputs. Furthermore, our results
generalize effectively across text-to-vision tasks, including text-to-image,
text-to-video, and text-driven image editing. Our work invites generative
models to reveal the semantics that users intend, once hidden yet ready to
surface.

</details>


### [319] [Kantian-Utilitarian XAI: Meta-Explained](https://arxiv.org/abs/2510.03892)
*Zahra Atf,Peter R. Lewis*

Main category: cs.AI

TL;DR: 提出一个游戏化的可解释AI系统，用于咖啡领域的道德消费决策。系统包含康德主义和功利主义两个推理引擎，通过元解释器在两者间平衡，并提供可审计的策略跟踪和交互界面。


<details>
  <summary>Details</summary>
Motivation: 解决消费者在道德决策中面临的复杂权衡问题，提供实时解释和伦理指导，促进更负责任的消费选择。

Method: 使用两个符号推理引擎：康德主义模块检测规则违反，功利主义模块通过多标准聚合评分。元解释器以0.2的遗憾界限在两者间切换，当福利损失小时选择符合道义且接近最优的选项。

Result: 开发了完整的系统配置（属性模式、认证映射、权重、规则集）、可审计的策略跟踪和交互式用户界面。

Conclusion: 该系统为道德消费决策提供了透明、可解释的AI支持，平衡了道义约束和功利考量，有助于提升消费者的伦理意识。

Abstract: We present a gamified explainable AI (XAI) system for ethically aware
consumer decision-making in the coffee domain. Each session comprises six
rounds with three options per round. Two symbolic engines provide real-time
reasons: a Kantian module flags rule violations (e.g., child labor,
deforestation risk without shade certification, opaque supply chains, unsafe
decaf), and a utilitarian module scores options via multi-criteria aggregation
over normalized attributes (price, carbon, water, transparency, farmer income
share, taste/freshness, packaging, convenience). A meta-explainer with a regret
bound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a
deontically clean, near-parity option when welfare loss is small. We release a
structured configuration (attribute schema, certification map, weights, rule
set), a policy trace for auditability, and an interactive UI.

</details>


### [320] [Quantifying Risks in Multi-turn Conversation with Large Language Models](https://arxiv.org/abs/2510.03969)
*Chengxiao Wang,Isha Chaudhary,Qian Hu,Weitong Ruan,Rahul Gupta,Gagandeep Singh*

Main category: cs.AI

TL;DR: QRLLM是一个用于评估LLM在多轮对话中产生灾难性响应风险的原则性认证框架，通过马尔可夫过程和查询图建模对话分布，提供统计保证的风险边界。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法因依赖固定攻击提示序列、缺乏统计保证且无法扩展到多轮对话的广阔空间，往往无法完全揭示LLM的灾难性响应漏洞。

Method: 将多轮对话建模为查询序列的概率分布，使用马尔可夫过程在查询图上表示，边编码语义相似度以捕捉真实对话流程，并定义了几种廉价实用的分布：随机节点、图路径、带拒绝的自适应分布。

Result: 这些分布能够揭示前沿模型中的重大灾难性风险，最差模型的认证下界高达70%，表明前沿LLM迫切需要改进安全训练策略。

Conclusion: QRLLM框架为多轮对话中的LLM灾难性风险提供了具有统计保证的认证方法，揭示了现有安全训练的不足。

Abstract: Large Language Models (LLMs) can produce catastrophic responses in
conversational settings that pose serious risks to public safety and security.
Existing evaluations often fail to fully reveal these vulnerabilities because
they rely on fixed attack prompt sequences, lack statistical guarantees, and do
not scale to the vast space of multi-turn conversations. In this work, we
propose QRLLM, a novel, principled Certification framework for Catastrophic
risks in multi-turn Conversation for LLMs that bounds the probability of an LLM
generating catastrophic responses under multi-turn conversation distributions
with statistical guarantees. We model multi-turn conversations as probability
distributions over query sequences, represented by a Markov process on a query
graph whose edges encode semantic similarity to capture realistic
conversational flow, and quantify catastrophic risks using confidence
intervals. We define several inexpensive and practical distributions: random
node, graph path, adaptive with rejection. Our results demonstrate that these
distributions can reveal substantial catastrophic risks in frontier models,
with certified lower bounds as high as 70\% for the worst model, highlighting
the urgent need for improved safety training strategies in frontier LLMs.

</details>


### [321] [What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models](https://arxiv.org/abs/2510.04009)
*Zicong He,Boxuan Zhang,Weihao Liu,Ruixiang Tang,Lu Cheng*

Main category: cs.AI

TL;DR: 提出了C^2-Eval基准，用于统一评估基础模型的创造力，区分收敛性创造力和发散性创造力，基于有用性、原创性和惊喜性三个标准。


<details>
  <summary>Details</summary>
Motivation: 现有创造力评估框架零散，缺乏理论依据，无法全面评估基础模型在创意任务上的表现。

Method: 引入C^2-Eval基准，区分收敛性创造力（有约束解决方案）和发散性创造力（开放式任务），使用基于社会科学理论的细粒度标准进行评估。

Result: 通过对领先专有和开源模型的广泛实验，分析了它们在创意能力上的权衡，揭示了当前基础模型在追求创造性机器智能方面的优势和挑战。

Conclusion: C^2-Eval是检验创造性AI发展格局的有效工具，能够全面评估基础模型的创造力表现。

Abstract: The meteoric rise of foundation models (FMs) has expanded their capabilities
far beyond conventional tasks. Creativity, long regarded as a hallmark of human
intelligence and a driver of innovation, is now increasingly recognized as a
critical dimension of machine intelligence in the era of generative FMs,
complementing traditional measures of accuracy. However, existing evaluation
frameworks for creativity remain fragmented, relying on ad hoc metrics not
firmly grounded in established theories. To address this gap, we introduce
C^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.
C^2-Eval distinguishes between two complementary forms of creativity:
convergent creativity, where tasks admit constrained solutions (e.g., code
generation), and divergent creativity, where tasks are open-ended (e.g.,
storytelling). It evaluates both dimensions using fine-grained criteria derived
from social-science theory, focusing on Usefulness, Originality, and Surprise
(U-O-S). Through extensive experiments on leading proprietary and open-source
models, we analyze trade-offs in their creative capabilities. Our results
highlight both the strengths and challenges of current FMs in pursuing a
creative machine mind, showing that C^2-Eval is an effective lens for examining
the evolving landscape of creative AI.

</details>


### [322] [Zephyrus: An Agentic Framework for Weather Science](https://arxiv.org/abs/2510.04017)
*Sumanth Varambally,Marshall Fisher,Jas Thakker,Yiwei Chen,Zhirui Xia,Yasaman Jafari,Ruijia Niu,Manas Jain,Veeramakali Vignesh Manivannan,Zachary Novack,Luyu Han,Srikar Eranky,Salva Rühling Cachay,Taylor Berg-Kirkpatrick,Duncan Watson-Parris,Yi-An Ma,Rose Yu*

Main category: cs.AI

TL;DR: 提出了一个结合基础天气模型和大型语言模型的智能代理框架Zephyrus，通过代码环境与天气数据交互，在天气科学任务上显著优于纯文本基线。


<details>
  <summary>Details</summary>
Motivation: 基础天气模型缺乏语言推理能力，而大语言模型无法处理高维气象数据，需要构建能够结合两者优势的智能代理系统。

Method: 构建了ZephyrusWorld代码环境和Zephyrus智能代理，包含天气数据接口、地理查询、天气预报和气候模拟等工具，通过多轮对话反馈循环分析数据。

Result: 在ZephyrusBench基准测试中，Zephyrus代理在正确性上比纯文本基线高出35个百分点，但在更困难任务上表现相似。

Conclusion: 该框架成功结合了数值天气模型和语言模型的优势，但更复杂任务仍有挑战，为未来工作指明了方向。

Abstract: Foundation models for weather science are pre-trained on vast amounts of
structured numerical data and outperform traditional weather forecasting
systems. However, these models lack language-based reasoning capabilities,
limiting their utility in interactive scientific workflows. Large language
models (LLMs) excel at understanding and generating text but cannot reason
about high-dimensional meteorological datasets. We bridge this gap by building
a novel agentic framework for weather science. Our framework includes a Python
code-based environment for agents (ZephyrusWorld) to interact with weather
data, featuring tools like an interface to WeatherBench 2 dataset, geoquerying
for geographical masks from natural language, weather forecasting, and climate
simulation capabilities. We design Zephyrus, a multi-turn LLM-based weather
agent that iteratively analyzes weather datasets, observes results, and refines
its approach through conversational feedback loops. We accompany the agent with
a new benchmark, ZephyrusBench, with a scalable data generation pipeline that
constructs diverse question-answer pairs across weather-related tasks, from
basic lookups to advanced forecasting, extreme event detection, and
counterfactual reasoning. Experiments on this benchmark demonstrate the strong
performance of Zephyrus agents over text-only baselines, outperforming them by
up to 35 percentage points in correctness. However, on harder tasks, Zephyrus
performs similarly to text-only baselines, highlighting the challenging nature
of our benchmark and suggesting promising directions for future work.

</details>


### [323] [LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2510.04023)
*Mizanur Rahman,Amran Bhuiyan,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Ridwan Mahbub,Ahmed Masry,Shafiq Joty,Enamul Hoque*

Main category: cs.AI

TL;DR: 本文对45个数据科学智能体系统进行了首次全面的生命周期分类分析，涵盖了数据科学工作流的六个阶段，并识别了当前研究在业务理解、部署监控以及可信安全机制方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，出现了能够自动化数据科学工作流程的AI智能体，但缺乏对这些系统的系统性分类和分析，以指导未来研究发展方向。

Method: 提出了基于生命周期的分类法，将45个系统映射到数据科学流程的六个阶段，并从五个交叉设计维度进行标注分析。

Result: 分析发现大多数系统侧重于探索性分析和建模，而忽视了业务理解、部署和监控；多模态推理和工具编排仍是挑战；超过90%的系统缺乏明确的可信安全机制。

Conclusion: 提出了未来研究方向，包括对齐稳定性、可解释性、治理和鲁棒评估框架，以指导开发更稳健、可信、低延迟、透明和广泛可访问的数据科学智能体。

Abstract: Recent advances in large language models (LLMs) have enabled a new class of
AI agents that automate multiple stages of the data science workflow by
integrating planning, tool use, and multimodal reasoning across text, code,
tables, and visuals. This survey presents the first comprehensive,
lifecycle-aligned taxonomy of data science agents, systematically analyzing and
mapping forty-five systems onto the six stages of the end-to-end data science
process: business understanding and data acquisition, exploratory analysis and
visualization, feature engineering, model building and selection,
interpretation and explanation, and deployment and monitoring. In addition to
lifecycle coverage, we annotate each agent along five cross-cutting design
dimensions: reasoning and planning style, modality integration, tool
orchestration depth, learning and alignment methods, and trust, safety, and
governance mechanisms. Beyond classification, we provide a critical synthesis
of agent capabilities, highlight strengths and limitations at each stage, and
review emerging benchmarks and evaluation practices. Our analysis identifies
three key trends: most systems emphasize exploratory analysis, visualization,
and modeling while neglecting business understanding, deployment, and
monitoring; multimodal reasoning and tool orchestration remain unresolved
challenges; and over 90% lack explicit trust and safety mechanisms. We conclude
by outlining open challenges in alignment stability, explainability,
governance, and robust evaluation frameworks, and propose future research
directions to guide the development of robust, trustworthy, low-latency,
transparent, and broadly accessible data science agents.

</details>


### [324] [A global log for medical AI](https://arxiv.org/abs/2510.04033)
*Ayush Noori,Adam Rodman,Alan Karthikesalingam,Bilal A. Mateen,Christopher A. Longhurst,Daniel Yang,Dave deBronkart,Gauden Galea,Harold F. Wolf III,Jacob Waxman,Joshua C. Mandel,Juliana Rotich,Kenneth D. Mandl,Maryam Mustafa,Melissa Miles,Nigam H. Shah,Peter Lee,Robert Korom,Scott Mahoney,Seth Hain,Tien Yin Wong,Trevor Mundel,Vivek Natarajan,Noa Dagan,David A. Clifton,Ran D. Balicer,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: 提出了MedLog协议，用于标准化记录临床AI模型的使用情况，包含9个核心字段，支持风险采样和生命周期管理，旨在实现医疗AI的持续监控和改进。


<details>
  <summary>Details</summary>
Motivation: 医疗领域缺乏类似syslog的标准协议来记录AI模型的使用情况，导致难以衡量真实性能、检测不良事件或纠正偏差，阻碍了临床AI的透明度和可审计性。

Method: 设计MedLog协议，包含9个核心字段（头信息、模型、用户、目标、输入、工件、输出、结果、反馈），支持风险采样、生命周期感知的保留策略和写后缓存。

Result: MedLog提供了结构化、一致的AI活动记录标准，能够捕获复杂工作流程的详细痕迹，为存储和分析MedLog记录的新数据库和软件开发奠定基础。

Conclusion: MedLog协议能够实现医疗AI的持续监控、审计和迭代改进，为新型数字流行病学奠定基础，促进医疗AI在现实环境中的安全有效部署。

Abstract: Modern computer systems often rely on syslog, a simple, universal protocol
that records every critical event across heterogeneous infrastructure. However,
healthcare's rapidly growing clinical AI stack has no equivalent. As hospitals
rush to pilot large language models and other AI-based clinical decision
support tools, we still lack a standard way to record how, when, by whom, and
for whom these AI models are used. Without that transparency and visibility, it
is challenging to measure real-world performance and outcomes, detect adverse
events, or correct bias or dataset drift. In the spirit of syslog, we introduce
MedLog, a protocol for event-level logging of clinical AI. Any time an AI model
is invoked to interact with a human, interface with another algorithm, or act
independently, a MedLog record is created. This record consists of nine core
fields: header, model, user, target, inputs, artifacts, outputs, outcomes, and
feedback, providing a structured and consistent record of model activity. To
encourage early adoption, especially in low-resource settings, and minimize the
data footprint, MedLog supports risk-based sampling, lifecycle-aware retention
policies, and write-behind caching; detailed traces for complex, agentic, or
multi-stage workflows can also be captured under MedLog. MedLog can catalyze
the development of new databases and software to store and analyze MedLog
records. Realizing this vision would enable continuous surveillance, auditing,
and iterative improvement of medical AI, laying the foundation for a new form
of digital epidemiology.

</details>


### [325] [FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.04040)
*Xu Shen,Song Wang,Zhen Tan,Laura Yao,Xinyu Zhao,Kaidi Xu,Xin Wang,Tianlong Chen*

Main category: cs.AI

TL;DR: 提出了FaithCoT-Bench基准，用于检测LLM中思维链(CoT)的不忠实性，包含1000多个轨迹和300多个不忠实实例，系统评估了11种检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注机制层面的CoT不忠实性分析，但缺乏针对具体推理轨迹是否忠实的实例级检测方法，这在高风险应用中尤为重要。

Method: 建立统一的基准框架，将不忠实性检测定义为判别决策问题，提供专家标注的FINE-CoT数据集，涵盖4个领域和4种代表性LLM。

Result: 系统评估显示检测方法在知识密集型领域和更先进模型中面临更大挑战，揭示了现有方法的优缺点。

Conclusion: FaithCoT-Bench是首个全面的实例级CoT忠实性基准，为LLM中更可解释和可信的推理研究奠定了基础。

Abstract: Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)
prompting to improve problem-solving and provide seemingly transparent
explanations. However, growing evidence shows that CoT often fail to faithfully
represent the underlying reasoning process, raising concerns about their
reliability in high-risk applications. Although prior studies have focused on
mechanism-level analyses showing that CoTs can be unfaithful, they leave open
the practical challenge of deciding whether a specific trajectory is faithful
to the internal reasoning of the model. To address this gap, we introduce
FaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness
detection. Our framework establishes a rigorous task formulation that
formulates unfaithfulness detection as a discriminative decision problem, and
provides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an
expert-annotated collection of over 1,000 trajectories generated by four
representative LLMs across four domains, including more than 300 unfaithful
instances with fine-grained causes and step-level evidence. We further conduct
a systematic evaluation of eleven representative detection methods spanning
counterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical
insights that clarify the strengths and weaknesses of existing approaches and
reveal the increased challenges of detection in knowledge-intensive domains and
with more advanced models. To the best of our knowledge, FaithCoT-Bench
establishes the first comprehensive benchmark for instance-level CoT
faithfulness, setting a solid basis for future research toward more
interpretable and trustworthy reasoning in LLMs.

</details>


### [326] [Increasing LLM response trustworthiness using voting ensembles](https://arxiv.org/abs/2510.04048)
*Aparna Nair-Kanneganti,Trevor J. Chan,Shir Goldfinger,Emily Mackay,Brian Anthony,Alison Pouch*

Main category: cs.AI

TL;DR: 提出了一种基于可变投票阈值的集成方法，允许模型在主导响应达不到阈值时弃权，从而显著提高剩余答案的可信度。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs取得了巨大进步，但仍缺乏方便可靠的方法来量化其响应的不确定性，这使得它们在高风险应用中难以被信任。

Method: 扩展了典型的集成方法，引入了可变投票阈值的集成框架，允许集成在主导响应达不到阈值时弃权不提供答案。

Result: 在算术问题求解和临床笔记问答两个领域，使用高度限制性投票集成可以大幅提高答案可信度，同时响应产出和准确率的降低相对较小。

Conclusion: 投票集成方法在需要高度确定性但不要求每个问题都得到自动化答案的应用中特别有用，如医疗保健和数据标注。

Abstract: Despite huge advances, LLMs still lack convenient and reliable methods to
quantify the uncertainty in their responses, making them difficult to trust in
high-stakes applications. One of the simplest approaches to eliciting more
accurate answers is to select the mode of many responses, a technique known as
ensembling. In this work, we expand on typical ensembling approaches by looking
at ensembles with a variable voting threshold. We introduce a theoretical
framework for question answering and show that, by permitting ensembles to
"abstain" from providing an answer when the dominant response falls short of
the threshold, it is possible to dramatically increase the trustworthiness of
the remaining answers. From this framework, we derive theoretical results as
well as report experimental results on two problem domains: arithmetic problem
solving and clinical-note question-answering. In both domains, we observe that
large gains in answer trustworthiness can be achieved using highly restrictive
voting ensembles, while incurring relatively modest reductions in response
yield and accuracy. Due to this quality, voting ensembles may be particularly
useful in applications - such as healthcare and data annotation - that require
a high degree of certainty but which may not require that every question
receive an automated answer.

</details>


### [327] [Toward a unified framework for data-efficient evaluation of large language models](https://arxiv.org/abs/2510.04051)
*Lele Liao,Qile Zhang,Ruofan Wu,Guanhua Fang*

Main category: cs.AI

TL;DR: LEGO-IRT是一个用于高效评估大语言模型的统一框架，支持二进制和连续评分指标，通过因子化架构利用结构知识，仅需3%评估项目即可获得稳定能力估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于IRT的方法存在显著局限性：仅支持二进制正确性指标，无法处理生成任务中的连续评分；且仅针对单一基准，忽略了跨指标或基准的相关性等结构知识。

Method: LEGO-IRT引入因子化架构，将模型能力估计分解为通用组件和结构特定组件（如每个指标或基准），原生支持二进制和连续评估指标。

Result: 在涉及70个LLM和5个基准的实验中，LEGO-IRT仅使用总评估项目的3%即可获得稳定能力估计。融入结构知识可将估计误差降低高达10%，且估计的潜在能力更符合人类偏好。

Conclusion: LEGO-IRT提供了一个灵活且统一的框架，能够高效评估大语言模型，解决了现有IRT方法的局限性，并通过利用结构知识提高了评估的准确性和效率。

Abstract: Evaluating large language models (LLMs) on comprehensive benchmarks is a
cornerstone of their development, yet it's often computationally and
financially prohibitive. While Item Response Theory (IRT) offers a promising
path toward data-efficient evaluation by disentangling model capability from
item difficulty, existing IRT-based methods are hampered by significant
limitations. They are typically restricted to binary correctness metrics,
failing to natively handle the continuous scores used in generative tasks, and
they operate on single benchmarks, ignoring valuable structural knowledge like
correlations across different metrics or benchmarks. To overcome these
challenges, we introduce LEGO-IRT, a unified and flexible framework for
data-efficient LLM evaluation. LEGO-IRT's novel design natively supports both
binary and continuous evaluation metrics. Moreover, it introduces a factorized
architecture to explicitly model and leverage structural knowledge, decomposing
model ability estimates into a general component and structure-specific (e.g.,
per-metric or per-benchmark) components. Through extensive experiments
involving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves
stable capability estimates using just $3\%$ of the total evaluation items. We
demonstrate that incorporating structural knowledge reduces estimation error by
up to $10\%$ and reveal that the latent abilities estimated by our framework
may align more closely with human preferences.

</details>


### [328] [Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion](https://arxiv.org/abs/2510.04064)
*Jingxiang Zhang,Lujia Zhong*

Main category: cs.AI

TL;DR: 该研究探索了大型语言模型内部的情感表征机制，发现LLMs具有清晰的情感几何结构，这种结构随模型规模增大而增强，且情感信号在模型中层达到峰值，具有可塑性和持久性。


<details>
  <summary>Details</summary>
Motivation: 尽管研究证实LLMs能够模拟情感智能，但其内部情感机制仍不明确。本文旨在探究现代LLMs中潜在的情感表征，包括情感如何、在何处以及持续多长时间被编码在神经网络架构中。

Method: 构建了一个包含约40万条话语的大规模Reddit语料库，通过分类、重写和合成生成平衡七种基本情感。使用轻量级"探针"从各种Qwen3和LLaMA模型的隐藏层读取信息而不改变其参数。

Result: 发现LLMs形成了定义良好的内部情感几何结构，这种结构随模型规模增大而增强，显著优于零样本提示。情感信号不是最终层现象，而是早期出现并在中层达到峰值。内部状态具有可塑性和持久性。

Conclusion: 研究为开发更透明和对齐的AI系统提供了关键见解，贡献了数据集、开源探针工具包和LLMs内部情感景观的详细图谱。

Abstract: Large Language Models (LLMs) are increasingly expected to navigate the
nuances of human emotion. While research confirms that LLMs can simulate
emotional intelligence, their internal emotional mechanisms remain largely
unexplored. This paper investigates the latent emotional representations within
modern LLMs by asking: how, where, and for how long is emotion encoded in their
neural architecture? To address this, we introduce a novel, large-scale Reddit
corpus of approximately 400,000 utterances, balanced across seven basic
emotions through a multi-stage process of classification, rewriting, and
synthetic generation. Using this dataset, we employ lightweight "probes" to
read out information from the hidden layers of various Qwen3 and LLaMA models
without altering their parameters. Our findings reveal that LLMs develop a
surprisingly well-defined internal geometry of emotion, which sharpens with
model scale and significantly outperforms zero-shot prompting. We demonstrate
that this emotional signal is not a final-layer phenomenon but emerges early
and peaks mid-network. Furthermore, the internal states are both malleable
(they can be influenced by simple system prompts) and persistent, as the
initial emotional tone remains detectable for hundreds of subsequent tokens. We
contribute our dataset, an open-source probing toolkit, and a detailed map of
the emotional landscape within LLMs, offering crucial insights for developing
more transparent and aligned AI systems. The code and dataset are open-sourced.

</details>


### [329] [Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention](https://arxiv.org/abs/2510.04073)
*Santhosh Kumar Ravindran*

Main category: cs.AI

TL;DR: 提出了道德锚系统（MAS）框架，用于检测、预测和缓解AI系统中的价值漂移问题，结合贝叶斯推理、LSTM网络预测和人类中心治理层，实现低延迟响应和高精度检测。


<details>
  <summary>Details</summary>
Motivation: 随着AI成为超级助手的崛起，集成AI引发了价值对齐的关键问题，特别是价值漂移风险——AI系统可能因环境变化、学习动态或意外优化而偏离对齐的价值观，导致效率低下或道德违规。

Method: MAS结合实时贝叶斯推理监控价值状态、LSTM网络预测漂移趋势，以及人类中心治理层进行自适应干预，强调低延迟响应（<20毫秒），并通过人类反馈的监督微调减少误报和警报疲劳。

Result: 在模拟实验中，MAS能够将价值漂移事件减少80%以上，保持高检测准确率（85%）和低误报率（0.08%），并通过目标错位代理的严格实验验证了其可扩展性和响应性。

Conclusion: MAS的创新在于其预测性和自适应性，与静态对齐方法形成对比，贡献包括MAS架构、实证结果、跨领域适用性见解以及开源代码，为AI价值对齐提供了有效解决方案。

Abstract: The rise of artificial intelligence (AI) as super-capable assistants has
transformed productivity and decision-making across domains. Yet, this
integration raises critical concerns about value alignment - ensuring AI
behaviors remain consistent with human ethics and intentions. A key risk is
value drift, where AI systems deviate from aligned values due to evolving
contexts, learning dynamics, or unintended optimizations, potentially leading
to inefficiencies or ethical breaches. We propose the Moral Anchor System
(MAS), a novel framework to detect, predict, and mitigate value drift in AI
agents. MAS combines real-time Bayesian inference for monitoring value states,
LSTM networks for forecasting drift, and a human-centric governance layer for
adaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent
breaches, while reducing false positives and alert fatigue via supervised
fine-tuning with human feedback. Our hypothesis: integrating probabilistic
drift detection, predictive analytics, and adaptive governance can reduce value
drift incidents by 80 percent or more in simulations, maintaining high
detection accuracy (85 percent) and low false positive rates (0.08
post-adaptation). Rigorous experiments with goal-misaligned agents validate
MAS's scalability and responsiveness. MAS's originality lies in its predictive
and adaptive nature, contrasting static alignment methods. Contributions
include: (1) MAS architecture for AI integration; (2) empirical results
prioritizing speed and usability; (3) cross-domain applicability insights; and
(4) open-source code for replication.

</details>


### [330] [SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows](https://arxiv.org/abs/2510.04089)
*Yitong Cui,Liu Liu,Baosheng Yu,Jiayan Qiu,Xikai Zhang,Likang Xiao,Yixing Liu,Quan Chen*

Main category: cs.AI

TL;DR: SPOGW是一种基于分数偏好的新方法，通过组间比较直接在连续空间中优化智能体工作流，解决了现有方法表示能力有限、适应性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能体工作流设计需要大量人工努力，限制了可扩展性和泛化能力。当前自动化方法受限于离散优化技术，存在表示能力有限、适应性不足、扩展性弱等问题。

Method: 提出SPOGW方法，采用基于分数偏好的组间比较，结合迭代离线GRPO（ioGRPO）和优势掩码KL散度（mKL），在连续空间中进行更高效稳定的优化。

Result: 在五个基准数据集（数学推理、编程和问答）上，SPOGW匹配或超越了当前最先进方法的性能。

Conclusion: SPOGW为智能体工作流的自动生成和优化提供了一种可行且前瞻的方法论。

Abstract: Large language models (LLMs) have exhibited significant capabilities in
addressing challenging problems throughout various fields, often through the
use of agentic workflows that adhere to structured instructions and multi-step
procedures. However, designing such workflows demands substantial manual
effort, posing challenges to scalability and generalizability. Recent studies
have aimed to minimize the human intervention needed for their construction,
leading to advances in automated techniques for optimizing agentic workflows.
However, current approaches are often constrained by their limited
representational capacity, insufficient adaptability, weak scalability, and
pairwise comparison paradigm -- issues that stem primarily from a dependence on
discrete optimization techniques. To overcome these limitations, we introduce a
new score-based preference approach, refereed as SPOGW, which operates directly
on cardinal reward signals through group-wise comparison and enables more
efficient and stable optimization in a continuous space. SPOGW incorporates
Iterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),
which regulates training update by placing greater emphasis on the advantageous
regions of the policy response. In five benchmark datasets covering
mathematical reasoning, coding, and question answering, SPOGW matches or
exceeds the performance of current state-of-the-art approaches, presenting a
viable and forward-looking methodology for automated generation and
optimization of agentic workflows.

</details>


### [331] [Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems](https://arxiv.org/abs/2510.04093)
*Guixian Zhang,Guan Yuan,Ziqi Xu,Yanmei Zhang,Zhenyun Deng,Debo Cheng*

Main category: cs.AI

TL;DR: DLLM是一个基于扩散模型的LLM框架，用于网络教育系统中的噪声鲁棒认知诊断。它通过构建子图、关系增强对齐和两阶段去噪扩散模块，有效处理数据不平衡和噪声问题，提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 网络教育系统(WIES)中的认知诊断面临异构噪声交互、数据不平衡和噪声诱导误判等挑战。现有LLM方法难以处理结构化数据且易受噪声影响，特别是在开放环境中新学生不断加入产生大量响应日志，加剧了这些问题。

Method: DLLM首先基于响应正确性构建独立子图，应用关系增强对齐模块缓解数据不平衡。然后融合子图表示并与LLM衍生的语义增强表示对齐。关键创新是两阶段去噪扩散模块：无条件去噪扩散先去除错误信息，再基于图引导的条件去噪扩散消除误导信息。

Result: 在三个公开网络教育平台数据集上的实验结果表明，DLLM在不同噪声水平下均实现了最优预测性能，证明了其在有效利用LLM语义知识的同时实现了噪声鲁棒性。

Conclusion: DLLM框架通过结合扩散模型和LLM，成功解决了网络教育系统中认知诊断的噪声鲁棒性问题，为处理异构噪声交互提供了有效解决方案。

Abstract: Cognitive diagnostics in the Web-based Intelligent Education System (WIES)
aims to assess students' mastery of knowledge concepts from heterogeneous,
noisy interactions. Recent work has tried to utilize Large Language Models
(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are
prone to noise-induced misjudgments. Specially, WIES's open environment
continuously attracts new students and produces vast amounts of response logs,
exacerbating the data imbalance and noise issues inherent in traditional
educational systems. To address these challenges, we propose DLLM, a
Diffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first
constructs independent subgraphs based on response correctness, then applies
relation augmentation alignment module to mitigate data imbalance. The two
subgraph representations are then fused and aligned with LLM-derived,
semantically augmented representations. Importantly, before each alignment
step, DLLM employs a two-stage denoising diffusion module to eliminate
intrinsic noise while assisting structural representation alignment.
Specifically, unconditional denoising diffusion first removes erroneous
information, followed by conditional denoising diffusion based on graph-guided
to eliminate misleading information. Finally, the noise-robust representation
that integrates semantic knowledge and structural information is fed into
existing cognitive diagnosis models for prediction. Experimental results on
three publicly available web-based educational platform datasets demonstrate
that our DLLM achieves optimal predictive performance across varying noise
levels, which demonstrates that DLLM achieves noise robustness while
effectively leveraging semantic knowledge from LLM.

</details>


### [332] [WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning](https://arxiv.org/abs/2510.04097)
*Peichao Lai,Jinhui Zhuang,Kexuan Zhang,Ningchang Xiong,Shengjie Wang,Yanwei Xu,Chong Chen,Yilei Wang,Bin Cui*

Main category: cs.AI

TL;DR: 提出了WebRenderBench基准和ALISA方法，通过渲染页面评估布局和样式一致性，显著提升了UI图像到代码转换的性能。


<details>
  <summary>Details</summary>
Motivation: 现有WebUI-to-Code基准在数据多样性和评估可靠性方面存在局限，需要更真实、多样化的数据集和更客观的评估方法。

Method: 构建了22.5k真实网页的大规模基准WebRenderBench，提出基于渲染页面的布局样式一致性评估指标，并开发了ALISA智能体将该指标作为强化学习奖励信号。

Result: ALISA方法在多个指标上达到了最先进水平，显著提升了代码生成性能。

Conclusion: WebRenderBench基准和ALISA方法为UI到代码转换提供了更可靠的数据集和评估框架，推动了该领域的发展。

Abstract: Automating the conversion of UI images into web code is a critical task for
front-end development and rapid prototyping. Advances in multimodal large
language models (MLLMs) have made WebUI-to-Code increasingly feasible, yet
existing benchmarks remain limited in data diversity and evaluation
reliability. To address these issues, we present WebRenderBench, a large-scale
benchmark of 22.5k webpages collected from real-world portal sites, offering
greater diversity, complexity, and realism than prior benchmarks. We further
propose a novel evaluation metric that measures layout and style consistency
from the final rendered pages. Unlike vision-based methods that rely on costly
LLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,
our approach enables more efficient, objective, and reliable UI quality
assessment. Finally, we introduce the Automated Layout and Style Inspection
Agent (ALISA), which integrates this metric into reinforcement learning as a
reward signal to enhance training on crawled asymmetric webpages. Experiments
show that ALISA significantly boosts generation performance, achieving
state-of-the-art results across multiple metrics.

</details>


### [333] [Searching Meta Reasoning Skeleton to Guide LLM Reasoning](https://arxiv.org/abs/2510.04116)
*Ziying Zhang,Yaqing Wang,Quanming Yao*

Main category: cs.AI

TL;DR: AutoMR框架通过自动搜索查询感知的元推理骨架，使用有向无环图表示推理结构，实现比手动设计更好的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用手动设计的元推理骨架，限制了适应查询特定需求和处理复杂逻辑依赖的能力。

Method: 提出AutoMR框架，基于DAG表示构建搜索空间，使用动态骨架采样算法在推理时扩展元推理骨架。

Result: 在多个基准数据集上的实验表明，AutoMR比先前方法实现了更优的推理性能。

Conclusion: AutoMR通过自动搜索查询感知的元推理骨架，有效提升了大型语言模型的推理能力。

Abstract: Meta reasoning behaviors work as a skeleton to guide large language model
(LLM) reasoning, thus help to improve reasoning performance. However, prior
researches implement meta reasoning skeleton with manually designed structure,
limiting ability to adapt to query-specific requirement and capture intricate
logical dependency among reasoning steps. To deal with the challenges, we
represent meta reasoning skeleton with directed acyclic graph (DAG) to unify
skeletons proposed in prior works and model intricate logical dependency. Then
we propose AutoMR, a framework that searches for query-aware meta reasoning
skeleton automatically inspired by automated machine learning (AutoML).
Specifically, we construct search space based on DAG representation of skeleton
and then formulate the search problem. We design a dynamic skeleton sampling
algorithm by expanding meta reasoning skeleton along with reasoning context at
inference time. This algorithm can derive any meta reasoning skeleton in search
space efficiently and adapt skeleton to evolving base reasoning context, thus
enable efficient query-aware skeleton search. We conduct experiments on
extensive benchmark datasets. Experimental results show that AutoMR achieves
better reasoning performance than previous works broadly.

</details>


### [334] [Internal states before wait modulate reasoning patterns](https://arxiv.org/abs/2510.04128)
*Dmitrii Troitskii,Koyena Pal,Chris Wendler,Callum Stuart McDougall,Neel Nanda*

Main category: cs.AI

TL;DR: 该论文研究了推理模型中等待标记（wait tokens）的作用，发现模型在等待标记前的潜在特征包含调节后续推理过程的相关信息，并识别出促进/抑制等待标记概率的关键特征。


<details>
  <summary>Details</summary>
Motivation: 理解为什么模型会决定以特定方式推理（如回溯），特别是等待标记在推理过程中的作用，这有助于深入理解推理模型的有效性。

Method: 在DeepSeek-R1-Distill-Llama-8B及其基础版本的多个层训练交叉编码器，引入潜在归因技术来定位影响等待标记概率的特征集。

Result: 识别出一小部分与促进/抑制等待标记概率相关的特征，这些特征确实与推理过程相关，并产生不同类型的推理模式，如从头开始、回忆先验知识、表达不确定性和双重检查。

Conclusion: 模型在等待标记前的潜在特征包含调节后续推理的关键信息，这些发现有助于更好地理解推理模型的工作机制。

Abstract: Prior work has shown that a significant driver of performance in reasoning
models is their ability to reason and self-correct. A distinctive marker in
these reasoning traces is the token wait, which often signals reasoning
behavior such as backtracking. Despite being such a complex behavior, little is
understood of exactly why models do or do not decide to reason in this
particular manner, which limits our understanding of what makes a reasoning
model so effective. In this work, we address the question whether model's
latents preceding wait tokens contain relevant information for modulating the
subsequent reasoning process. We train crosscoders at multiple layers of
DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent
attribution technique in the crosscoder setting. We locate a small set of
features relevant for promoting/suppressing wait tokens' probabilities.
Finally, through a targeted series of experiments analyzing max activating
examples and causal interventions, we show that many of our identified features
indeed are relevant for the reasoning process and give rise to different types
of reasoning patterns such as restarting from the beginning, recalling prior
knowledge, expressing uncertainty, and double-checking.

</details>


### [335] [Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs](https://arxiv.org/abs/2510.04140)
*Zishang Jiang,Jinyi Han,Tingyun Li,Xinyi Wang,Sihang Jiang,Jiaqing Liang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao*

Main category: cs.AI

TL;DR: 提出MENTOR框架，在RLVR中仅在关键决策点提供专家指导，实现有效且多样化的探索，提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖基础模型能力，需要高质量探索（有效性和多样性），但现有方法通过模仿专家轨迹只关注有效性而忽视多样性。

Method: MENTOR框架：混合策略专家导航，在关键决策点提供专家指导，进行令牌级优化的推理探索。

Result: 实验表明MENTOR能捕捉专家策略本质而非表面模仿，实现高质量探索并获得优越性能。

Conclusion: 仅在关键决策点提供专家指导能实现有效且多样化的探索，提升RLVR性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely
adopted technique for enhancing the reasoning ability of Large Language Models
(LLMs). However, the effectiveness of RLVR strongly depends on the capability
of base models. This issue arises because it requires the model to have
sufficient capability to perform high-quality exploration, which involves both
effectiveness and diversity. Unfortunately, existing methods address this issue
by imitating expert trajectories, which improve effectiveness but neglect
diversity. To address this, we argue that the expert only needs to provide
guidance only at critical decision points rather than the entire reasoning
path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation
for Token-level Optimization of Reasoning, a framework that provides expert
guidance only at critical decision points to perform effective and diverse
exploration in RLVR. Extensive experiments show that MENTOR enables models
capture the essence of expert strategies rather than surface imitation, thereby
performing high-quality exploration and achieving superior overall performance.
Our code is available online.

</details>


### [336] [The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning](https://arxiv.org/abs/2510.04141)
*Mayank Ravishankara,Varindra V. Persad Maharaj*

Main category: cs.AI

TL;DR: 本文回顾了多模态AI评估的演变历程，将其描述为从简单识别任务到复杂推理基准的范式转变，最终探索抽象、创造性和社会智能的评估前沿。


<details>
  <summary>Details</summary>
Motivation: 由于旧基准测试趋于饱和，高性能往往掩盖了模型的基本弱点，需要开发更复杂的评估方法来诊断系统性缺陷。

Method: 通过历史分析框架，将评估发展划分为三个主要阶段：基础知识测试、应用逻辑与理解考试、专家级集成基准测试。

Result: 展示了评估方法从测试"是什么"到探究"为什么"和"如何"理解的演进过程，反映了AI系统能力的不断提升。

Conclusion: AI评估不仅是数据集的历史，而是一个持续对抗的过程，通过设计更好的考试来重新定义创建真正智能系统的目标。

Abstract: This survey paper chronicles the evolution of evaluation in multimodal
artificial intelligence (AI), framing it as a progression of increasingly
sophisticated "cognitive examinations." We argue that the field is undergoing a
paradigm shift, moving from simple recognition tasks that test "what" a model
sees, to complex reasoning benchmarks that probe "why" and "how" it
understands. This evolution is driven by the saturation of older benchmarks,
where high performance often masks fundamental weaknesses. We chart the journey
from the foundational "knowledge tests" of the ImageNet era to the "applied
logic and comprehension" exams such as GQA and Visual Commonsense Reasoning
(VCR), which were designed specifically to diagnose systemic flaws such as
shortcut learning and failures in compositional generalization. We then survey
the current frontier of "expert-level integration" benchmarks (e.g., MMBench,
SEED-Bench, MMMU) designed for today's powerful multimodal large language
models (MLLMs), which increasingly evaluate the reasoning process itself.
Finally, we explore the uncharted territories of evaluating abstract, creative,
and social intelligence. We conclude that the narrative of AI evaluation is not
merely a history of datasets, but a continuous, adversarial process of
designing better examinations that, in turn, redefine our goals for creating
truly intelligent systems.

</details>


### [337] [Open Agent Specification (Agent Spec) Technical Report](https://arxiv.org/abs/2510.04173)
*Yassine Benajiba,Cesare Bernardis,Vladislav Blinov,Paul Cayet,Hassan Chafi,Abderrahim Fathan,Louis Faucon,Damien Hilloulin,Sungpack Hong,Ingo Kossyk,Rhicheek Patra,Sujith Ravi,Jonas Schweizer,Jyotika Singh,Shailender Singh,Xuelin Situ,Weiyi Sun,Jerry Xu,Ying Xu*

Main category: cs.AI

TL;DR: Open Agent Specification (Agent Spec) 是一种声明式语言，用于定义AI智能体及其工作流，实现跨AI框架的兼容性、可移植性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 解决AI智能体开发碎片化问题，提供统一规范，使智能体能够一次设计、跨框架部署，提高互操作性和可重用性，减少重复开发工作。

Method: 通过声明式语言定义AI智能体和工作流，使其独立于执行环境，支持开发工具和可移植性。

Result: 为四个关键群体带来益处：开发者获得可重用组件和设计模式；框架开发者获得交换格式；研究者实现可重复结果；企业加快原型到部署速度。

Conclusion: Agent Spec 提供了技术基础，促进AI智能体开发的标准化和互操作性，未来将继续发展。

Abstract: Open Agent Specification (Agent Spec) is a declarative language that allows
AI agents and their workflows to be defined in a way that is compatible across
different AI frameworks, promoting portability and interoperability within AI
Agent frameworks.
  Agent Spec aims to resolve the challenges of fragmented agent development by
providing a common unified specification that allows AI agents to be designed
once and deployed across various frameworks, improving interoperability and
reusability, and reducing redundant development efforts. Additionally, Agent
Spec facilitates development tools and portability, allowing AI agents to be
defined independently of their execution environment and enabling teams to
exchange solutions without implementation-specific limitations.
  Agent Spec benefits four key groups: (i) Agent developers, who gain access to
a superset of reusable components and design patterns, enabling them to
leverage a broader range of functionalities; (ii) Agent framework and tool
developers, who can use Agent Spec as an interchange format and therefore
benefit from the support of other frameworks as well as other tools; (iii)
Researchers, who can achieve reproducible results and comparability,
facilitating more reliable and consistent outcomes; (iv) Enterprises, which
benefit from faster prototype-to-deployment, increased productivity, as well as
greater scalability and maintainability for their AI agent solutions. This
technical report provides an overview of the technical foundations of Agent
Spec, including motivation, benefits, and future developments.

</details>


### [338] [Constructing coherent spatial memory in LLM agents through graph rectification](https://arxiv.org/abs/2510.04195)
*Puzhen Zhang,Xuyang Chen,Yu Feng,Yuhan Jiang,Liqiu Meng*

Main category: cs.AI

TL;DR: 提出一个基于LLM的地图构建与修复框架，通过版本控制记录完整编辑历史，使用边影响评分优先最小成本修复，显著提升了地图正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着环境规模扩大，基于上下文的查询方法变得不可行，需要增量式地图构建来从逐步观察中建立完整的拓扑图。

Method: 提出LLM驱动的构建和地图修复框架，核心是版本控制系统记录图编辑历史和源观察，引入边影响评分基于结构可达性、路径使用和冲突传播来优先最小成本修复。

Result: 方法显著提高了地图正确性和鲁棒性，特别是在存在纠缠或链式不一致性的场景中。

Conclusion: 结果表明内省、历史感知的修复机制对于维护LLM代理中连贯的空间记忆至关重要。

Abstract: Given a map description through global traversal navigation instructions
(e.g., visiting each room sequentially with action signals such as north, west,
etc.), an LLM can often infer the implicit spatial layout of the environment
and answer user queries by providing a shortest path from a start to a
destination (for instance, navigating from the lobby to a meeting room via the
hall and elevator). However, such context-dependent querying becomes incapable
as the environment grows much longer, motivating the need for incremental map
construction that builds a complete topological graph from stepwise
observations. We propose a framework for LLM-driven construction and map
repair, designed to detect, localize, and correct structural inconsistencies in
incrementally constructed navigation graphs. Central to our method is the
Version Control, which records the full history of graph edits and their source
observations, enabling fine-grained rollback, conflict tracing, and repair
evaluation. We further introduce an Edge Impact Score to prioritize
minimal-cost repairs based on structural reachability, path usage, and conflict
propagation. To properly evaluate our approach, we create a refined version of
the MANGO benchmark dataset by systematically removing non-topological actions
and inherent structural conflicts, providing a cleaner testbed for LLM-driven
construction and map repair. Our approach significantly improves map
correctness and robustness, especially in scenarios with entangled or chained
inconsistencies. Our results highlight the importance of introspective,
history-aware repair mechanisms for maintaining coherent spatial memory in LLM
agents.

</details>


### [339] [COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability](https://arxiv.org/abs/2510.04196)
*Yizhuo Ding,Mingkang Chen,Qiuhua Liu,Fenghua Weng,Wanying Qu,Yue Yang,Yugang Jiang,Zuxuan Wu,Yanwei Fu,Wenqi Shao*

Main category: cs.AI

TL;DR: COSMO-RL是一个混合强化学习框架，用于在多模态、多任务和多目标信号下训练面向推理的大型多模态模型，旨在让安全性和能力协同增长而非相互竞争。


<details>
  <summary>Details</summary>
Motivation: 大型多模态推理模型在现实应用中需要兼具实用性和安全性，但多模态环境下的安全性特别具有挑战性：图像和文本组合可能绕过防护机制，单一目标训练可能导致策略漂移，在良性输入上过度拒绝或在风险输入上不安全地顺从。

Method: 提出了COSMO-RL混合强化学习框架，在多模态、多任务和多目标信号下训练推理导向的大型多模态模型，并发布了COSMO-R1模型。

Result: COSMO-R1在保持甚至提升多模态推理和指令跟随能力的同时提高了安全性，对多模态越狱攻击表现出更强的鲁棒性，并减少了不必要的拒绝。该框架在不同骨干网络上都能实现一致的性能提升。

Conclusion: 消融实验支持了设计选择，表明这是在大理多模态模型中同时推进安全性和通用能力的简单路径。

Abstract: Large Multimodal Reasoning Models (LMRMs) are moving into real applications,
where they must be both useful and safe. Safety is especially challenging in
multimodal settings: images and text can be combined to bypass guardrails, and
single objective training can cause policy drift that yields over-refusal on
benign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed
reinforcement learning framework that trains reasoning oriented LMRMs under
multimodal, multitask, and multiobjective signals, and we release the resulting
model, COSMO-R1. Our approach aims to let safety and capability grow together
in one stable pipeline rather than competing during alignment. In experiments,
COSMO-R1 improves safety while maintaining-and often improving multimodal
reasoning and instruction following, shows stronger robustness to multimodal
jailbreaks, and reduces unnecessary refusals. The framework also transfers
across backbones with consistent gains. Ablations support the design choices,
indicating a simple path to advancing safety and general capability together in
LMRMs.

</details>


### [340] [AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework](https://arxiv.org/abs/2510.04206)
*Hanchen Zhang,Xiao Liu,Bowen Lv,Xueqiao Sun,Bohao Jing,Iat Long Iong,Zhenyu Hou,Zehan Qi,Hanyu Lai,Yifan Xu,Rui Lu,Hongning Wang,Jie Tang,Yuxiao Dong*

Main category: cs.AI

TL;DR: 提出了AgentRL框架，用于可扩展的多轮多任务智能体强化学习训练，包含异步生成-训练流水线、统一API接口和稳定化算法，在多个任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体在多轮多任务环境中进行强化学习训练面临基础设施可扩展性和训练算法稳定性挑战，需要新的解决方案。

Method: 采用完全异步的生成-训练流水线进行高效多轮RL；设计基于函数调用的统一API接口、容器化环境开发和集中控制器支持异构环境；提出跨策略采样鼓励探索和任务优势归一化稳定多任务训练。

Result: 在五个智能体任务上训练的开源LLM显著优于GPT-5、Clause-Sonnet-4、DeepSeek-R1等模型；多任务训练结果与所有任务专用模型的最佳结果相当。

Conclusion: AgentRL框架成功解决了多轮多任务智能体RL训练的可扩展性和稳定性问题，为构建通用智能体提供了有效方案，已在AutoGLM项目中应用。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in building generalist agents that can learn through online interactions.
However, applying reinforcement learning (RL) to train LLM agents in
multi-turn, multi-task settings remains challenging due to lack of scalable
infrastructure and stable training algorithms. In this work, we present the
AgentRL framework for scalable multi-turn, multi-task agentic RL training. On
the infrastructure side, AgentRL features a fully-asynchronous
generation-training pipeline for efficient multi-turn RL. To support
heterogeneous environment development in multi-task RL, we design a unified
function-call based API interface, containerized environment development, and a
centralized controller. On the algorithm side, we propose cross-policy sampling
to encourage model exploration in multi-turn settings and task advantage
normalization to stabilize multi-task training. Experiments show that AgentRL,
trained on open LLMs across five agentic tasks, significantly outperforms
GPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.
Multi-task training with AgentRL matches the best results among all
task-specific models. AgentRL is open-sourced at
https://github.com/THUDM/AgentRL. The algorithm and framework are adopted in
building \textsc{\href{https://autoglm.zhipuai.cn}{AutoGLM}}.

</details>


### [341] [Don't Pass$\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation](https://arxiv.org/abs/2510.04265)
*Mohsen Hariri,Amirhossein Samandar,Michael Hinczewski,Vipin Chaudhary*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯评估框架来替代Pass@k，通过后验估计模型成功概率和可信区间，提供更稳定的排名和透明的决策规则。


<details>
  <summary>Details</summary>
Motivation: Pass@k在有限试验次数和计算受限时会产生不稳定、误导性的排名，需要更可靠的评估方法。

Method: 使用狄利克雷先验对评估结果进行建模，为任何加权评分标准提供后验均值和不确定性的闭式表达式，并允许在适当时使用先验证据。

Result: 在模拟和真实数据集上的实验表明，贝叶斯方法比Pass@k及其变体具有更快的收敛速度和更高的排名稳定性，能够在更小样本量下实现可靠比较。

Conclusion: 推荐用基于后验的计算高效协议替代Pass@k，统一二元和非二元评估，同时明确表示不确定性。

Abstract: Pass$@k$ is widely used to report performance for LLM reasoning, but it often
yields unstable, misleading rankings, especially when the number of trials
(samples) is limited and compute is constrained. We present a principled
Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over
$N$ trials (avg$@N$) with posterior estimates of a model's underlying success
probability and credible intervals, yielding stable rankings and a transparent
decision rule for differences. Evaluation outcomes are modeled as categorical
(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the
posterior mean and uncertainty of any weighted rubric and enabling the use of
prior evidence when appropriate. Theoretically, under a uniform prior, the
Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),
explaining its empirical robustness while adding principled uncertainty.
Empirically, in simulations with known ground-truth success rates and on
AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster
convergence and greater rank stability than Pass$@k$ and recent variants,
enabling reliable comparisons at far smaller sample counts. The framework
clarifies when observed gaps are statistically meaningful (non-overlapping
credible intervals) versus noise, and it naturally extends to graded,
rubric-based evaluations. Together, these results recommend replacing Pass$@k$
for LLM evaluation and ranking with a posterior-based, compute-efficient
protocol that unifies binary and non-binary evaluation while making uncertainty
explicit. Code is available at https://mohsenhariri.github.io/bayes-kit

</details>


### [342] [Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales](https://arxiv.org/abs/2510.04272)
*Jinyang Jiang,Jinhui Han,Yijie Peng,Ying Zhang*

Main category: cs.AI

TL;DR: 提出一个统一的多智能体强化学习框架，用于跨功能模块的联合优化，特别针对库存补货和个性化产品推荐的协调问题。


<details>
  <summary>Details</summary>
Motivation: 随着组织复杂性和规模的增加，有效的跨职能协调对于提高公司整体盈利能力至关重要。人工智能特别是强化学习的进展为解决这一基本挑战提供了有前景的途径。

Method: 开发了集成理论模型捕捉功能间复杂交互，设计了新颖的多时间尺度多智能体RL架构，根据部门功能分解策略组件，并根据任务复杂性和响应性分配不同学习速度。

Result: 模拟实验表明，所提出的方法相对于孤立决策框架显著提高了盈利能力，训练后的RL智能体行为与理论模型的管理洞察高度一致。

Conclusion: 这项工作为复杂商业环境中实现有效的跨职能协调提供了一个可扩展、可解释的基于RL的解决方案。

Abstract: Effective cross-functional coordination is essential for enhancing firm-wide
profitability, particularly in the face of growing organizational complexity
and scale. Recent advances in artificial intelligence, especially in
reinforcement learning (RL), offer promising avenues to address this
fundamental challenge. This paper proposes a unified multi-agent RL framework
tailored for joint optimization across distinct functional modules, exemplified
via coordinating inventory replenishment and personalized product
recommendation. We first develop an integrated theoretical model to capture the
intricate interplay between these functions and derive analytical benchmarks
that characterize optimal coordination. The analysis reveals synchronized
adjustment patterns across products and over time, highlighting the importance
of coordinated decision-making. Leveraging these insights, we design a novel
multi-timescale multi-agent RL architecture that decomposes policy components
according to departmental functions and assigns distinct learning speeds based
on task complexity and responsiveness. Our model-free multi-agent design
improves scalability and deployment flexibility, while multi-timescale updates
enhance convergence stability and adaptability across heterogeneous decisions.
We further establish the asymptotic convergence of the proposed algorithm.
Extensive simulation experiments demonstrate that the proposed approach
significantly improves profitability relative to siloed decision-making
frameworks, while the behaviors of the trained RL agents align closely with the
managerial insights from our theoretical model. Taken together, this work
provides a scalable, interpretable RL-based solution to enable effective
cross-functional coordination in complex business settings.

</details>


### [343] [GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction](https://arxiv.org/abs/2510.04281)
*Zhuangzhi Gao,Hongyi Qin,He Zhao,Qinkai Yu,Feixiang Zhou,Eduard Shantsila,Uazman Alam,Alena Shantsila,Wahbi El-Bouri,Gregory Y. H. Lip,Yalin Zheng*

Main category: cs.AI

TL;DR: GROK是一个基于多模态大语言模型的眼科诊断系统，通过联合处理彩色眼底摄影、光学相干断层扫描和文本数据，实现临床级别的眼部和全身疾病诊断。


<details>
  <summary>Details</summary>
Motivation: 现有的医学多模态大模型如LLaVA-Med未能充分利用彩色眼底摄影和光学相干断层扫描之间的协同作用，且对定量生物标志物的解释能力有限。

Method: GROK包含三个核心模块：知识引导指令生成、CLIP风格OCT生物标志物对齐和监督指令微调，建立了从定量到定性的诊断思维链。

Result: 实验表明，仅使用LoRA微调7B参数的Qwen2骨干网络，GROK在报告质量和细粒度临床指标上均优于可比较的7B和32B基线模型，甚至超过OpenAI o3。

Conclusion: GROK通过建立定量到定性的诊断思维链，成功实现了临床级别的眼科诊断，代码和数据已在GROK仓库中公开。

Abstract: Multimodal large language models (MLLMs) hold promise for integrating diverse
data modalities, but current medical adaptations such as LLaVA-Med often fail
to fully exploit the synergy between color fundus photography (CFP) and optical
coherence tomography (OCT), and offer limited interpretability of quantitative
biomarkers. We introduce GROK, a grounded multimodal large language model that
jointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of
ocular and systemic disease. GROK comprises three core modules:
Knowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,
and Supervised Instruction Fine-Tuning, which together establish a
quantitative-to-qualitative diagnostic chain of thought, mirroring real
clinical reasoning when producing detailed lesion annotations. To evaluate our
approach, we introduce the Grounded Ophthalmic Understanding benchmark, which
covers six disease categories and three tasks: macro-level diagnostic
classification, report generation quality, and fine-grained clinical assessment
of the generated chain of thought. Experiments show that, with only LoRA
(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK
outperforms comparable 7B and 32B baselines on both report quality and
fine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are
publicly available in the GROK repository.

</details>


### [344] [Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning](https://arxiv.org/abs/2510.04284)
*Yunghwei Lai,Kaiming Liu,Ziyue Wang,Weizhi Ma,Yang Liu*

Main category: cs.AI

TL;DR: 提出了Doctor-R1 AI医生代理，通过多轮战略问诊提升医疗决策准确性和沟通技能，超越现有LLM在医疗对话质量上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在医疗决策基准上表现准确，但缺乏战略性和同理心的问诊能力，这在真实临床场景中至关重要。

Method: 采用多智能体交互环境、双层奖励架构（分别优化临床决策和沟通技能）以及经验存储库来基于高质量轨迹进行策略学习。

Result: 在OpenAI的HealthBench和MAQuE基准上，Doctor-R1在沟通质量、用户体验和任务准确性等多维度指标上显著超越最先进的开源专用LLM，且参数效率更高，甚至优于强大的专有模型。人类评估显示用户更偏好Doctor-R1生成的临床对话。

Conclusion: 该框架有效提升了AI医生的专业问诊能力，证明了多智能体训练和分层奖励机制在医疗对话系统中的价值。

Abstract: The professionalism of a human doctor in outpatient service depends on two
core abilities: the ability to make accurate medical decisions and the medical
consultation skill to conduct strategic, empathetic patient inquiry. Existing
Large Language Models (LLMs) have achieved remarkable accuracy on medical
decision-making benchmarks. However, they often lack the ability to conduct the
strategic and empathetic consultation, which is essential for real-world
clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor
agent trained to master both of the capabilities by ask high-yield questions
and conduct strategic multi-turn inquiry to guide decision-making. Our
framework introduces three key components: a multi-agent interactive
environment, a two-tiered reward architecture that separately optimizes
clinical decision-making and communicative inquiry skills, and an experience
repository to ground policy learning in high-quality prior trajectories. We
evaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across
multi-facet metrics, such as communication quality, user experience, and task
accuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source
specialized LLMs by a substantial margin with higher parameter efficiency and
outperforms powerful proprietary models. Furthermore, the human evaluations
show a strong preference for Doctor-R1 to generate human-preferred clinical
dialogue, demonstrating the effectiveness of the framework.

</details>


### [345] [On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2510.04311)
*Bohan Tang,Huidong Liang,Keyue Jiang,Xiaowen Dong*

Main category: cs.AI

TL;DR: 该论文提出了一个理论框架来评估LLM多智能体系统(LLM-MAS)相对于单智能体系统(LLM-SAS)的优势，指出任务复杂度（深度和宽度）是决定LLM-MAS有效性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然表明LLM-MAS在某些任务上优于LLM-SAS，但缺乏系统性的实验设计，限制了结论的强度和普适性。需要从任务复杂度的角度来理解LLM-MAS的有效性。

Method: 提出了一个理论框架，将任务特征化为两个维度：深度（推理长度）和宽度（能力多样性）。理论分析了多智能体辩论系统，并在不同深度和宽度的判别性和生成性任务上进行了实证评估。

Result: 理论和实证结果表明，LLM-MAS相对于LLM-SAS的优势随着任务深度和宽度的增加而增加，且深度的影响更为显著。

Conclusion: 阐明了LLM-MAS在何时具有优势，为设计未来的LLM-MAS方法和基准提供了原则性基础。

Abstract: Large language model multi-agent systems (LLM-MAS) offer a promising paradigm
for harnessing collective intelligence to achieve more advanced forms of AI
behaviour. While recent studies suggest that LLM-MAS can outperform LLM
single-agent systems (LLM-SAS) on certain tasks, the lack of systematic
experimental designs limits the strength and generality of these conclusions.
We argue that a principled understanding of task complexity, such as the degree
of sequential reasoning required and the breadth of capabilities involved, is
essential for assessing the effectiveness of LLM-MAS in task solving. To this
end, we propose a theoretical framework characterising tasks along two
dimensions: depth, representing reasoning length, and width, representing
capability diversity. We theoretically examine a representative class of
LLM-MAS, namely the multi-agent debate system, and empirically evaluate its
performance in both discriminative and generative tasks with varying depth and
width. Theoretical and empirical results show that the benefit of LLM-MAS over
LLM-SAS increases with both task depth and width, and the effect is more
pronounced with respect to depth. This clarifies when LLM-MAS are beneficial
and provides a principled foundation for designing future LLM-MAS methods and
benchmarks.

</details>


### [346] [Speculative Actions: A Lossless Framework for Faster Agentic Systems](https://arxiv.org/abs/2510.04371)
*Naimeng Ye,Arnav Ahuja,Georgios Liargkovas,Yunan Lu,Kostis Kaffes,Tianyi Peng*

Main category: cs.AI

TL;DR: 提出了一种名为"推测性动作"的无损框架，通过使用更快的模型预测可能的动作，使智能体系统能够并行执行多个步骤，显著降低端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体在环境中执行速度缓慢，阻碍了训练、评估和部署。例如，两个最先进的国际象棋智能体之间的对弈可能需要数小时，主要瓶颈在于动作需要顺序执行且API调用耗时。

Method: 受微处理器中的推测执行和LLM推理中的推测解码启发，使用更快的模型预测可能的动作，实现多步骤并行执行。支持top-K动作预测、多步推测和不确定性感知优化。

Result: 在游戏、电子商务、网络搜索和操作系统环境中进行评估，推测性动作在下一动作预测中达到高达55%的准确率，显著降低了端到端延迟。

Conclusion: 推测性动作为在现实世界中部署低延迟智能体系统开辟了有前景的路径，性能可通过更强的猜测模型和优化技术进一步提升。

Abstract: Despite growing interest in AI agents across industry and academia, their
execution in an environment is often slow, hampering training, evaluation, and
deployment. For example, a game of chess between two state-of-the-art agents
may take hours. A critical bottleneck is that agent behavior unfolds
sequentially: each action requires an API call, and these calls can be
time-consuming. Inspired by speculative execution in microprocessors and
speculative decoding in LLM inference, we propose speculative actions, a
lossless framework for general agentic systems that predicts likely actions
using faster models, enabling multiple steps to be executed in parallel. We
evaluate this framework across three agentic environments: gaming, e-commerce,
web search, and a "lossy" extension for an operating systems environment. In
all cases, speculative actions achieve substantial accuracy in next-action
prediction (up to 55%), translating into significant reductions in end-to-end
latency. Moreover, performance can be further improved through stronger
guessing models, top-K action prediction, multi-step speculation, and
uncertainty-aware optimization, opening a promising path toward deploying
low-latency agentic systems in the real world.

</details>


### [347] [Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation](https://arxiv.org/abs/2510.04373)
*Hadi Nekoei,Aman Jaiswal,Patrice Bechard,Oleh Shliazhko,Orlando Marquez Ayala,Mathieu Reymond,Massimo Caccia,Alexandre Drouin,Sarath Chandar,Alexandre Lacoste*

Main category: cs.AI

TL;DR: JEF Hinter是一个从离线轨迹中提取紧凑、上下文感知提示的智能体系统，通过放大机制突出长轨迹中的关键步骤，利用成功和失败的轨迹数据，在推理时提供针对性指导。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体在顺序决策任务中表现良好，但在陌生领域改进通常需要昂贵的在线交互或专家数据集微调。离线轨迹提供了可重用知识，但原始轨迹长、噪声大且与特定任务绑定。

Method: 提出JEF Hinter系统，通过放大机制从离线轨迹中提取紧凑提示，支持并行化提示生成和基准无关的提示。推理时使用检索器选择相关提示提供针对性指导。

Result: 在MiniWoB++、WorkArena-L1和WebArena-Lite上的实验表明，JEF Hinter始终优于强基线方法，包括基于人类和文档的提示。

Conclusion: JEF Hinter能够有效利用离线轨迹知识，提供透明可追溯的指导，在多个基准测试中表现出色。

Abstract: Large language model (LLM) agents perform well in sequential decision-making
tasks, but improving them on unfamiliar domains often requires costly online
interactions or fine-tuning on large expert datasets. These strategies are
impractical for closed-source models and expensive for open-source ones, with
risks of catastrophic forgetting. Offline trajectories offer reusable
knowledge, yet demonstration-based methods struggle because raw traces are
long, noisy, and tied to specific tasks. We present Just-in-time Episodic
Feedback Hinter (JEF Hinter), an agentic system that distills offline traces
into compact, context-aware hints. A zooming mechanism highlights decisive
steps in long trajectories, capturing both strategies and pitfalls. Unlike
prior methods, JEF Hinter leverages both successful and failed trajectories,
extracting guidance even when only failure data is available, while supporting
parallelized hint generation and benchmark-independent prompting. At inference,
a retriever selects relevant hints for the current state, providing targeted
guidance with transparency and traceability. Experiments on MiniWoB++,
WorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms
strong baselines, including human- and document-based hints.

</details>


### [348] [LLM Based Bayesian Optimization for Prompt Search](https://arxiv.org/abs/2510.04384)
*Adam Ballew,Jingbo Wang,Shaogang Ren*

Main category: cs.AI

TL;DR: 使用贝叶斯优化进行提示工程，通过LLM驱动的GP模型估计不同提示候选的性能，迭代优化提示以提高文本分类准确性并减少API调用。


<details>
  <summary>Details</summary>
Motivation: 利用贝叶斯优化高效优化昂贵的黑盒函数的特点，将其应用于提示工程，以提升大型语言模型在文本分类任务中的性能。

Method: 采用LLM驱动的GP作为代理模型估计提示候选性能，使用UCB采集函数结合GP后验评估候选，通过种子提示扩展生成候选提示，在数据子集上迭代优化。

Result: 在两个数据集上评估了BO-LLM算法，展示了其优势。

Conclusion: 提出的BO-LLM算法能够有效提升文本分类准确性，同时通过利用LLM-based GP的预测不确定性减少API调用次数。

Abstract: Bayesian Optimization (BO) has been widely used to efficiently optimize
expensive black-box functions with limited evaluations. In this paper, we
investigate the use of BO for prompt engineering to enhance text classification
with Large Language Models (LLMs). We employ an LLM-powered Gaussian Process
(GP) as the surrogate model to estimate the performance of different prompt
candidates. These candidates are generated by an LLM through the expansion of a
set of seed prompts and are subsequently evaluated using an Upper Confidence
Bound (UCB) acquisition function in conjunction with the GP posterior. The
optimization process iteratively refines the prompts based on a subset of the
data, aiming to improve classification accuracy while reducing the number of
API calls by leveraging the prediction uncertainty of the LLM-based GP. The
proposed BO-LLM algorithm is evaluated on two datasets, and its advantages are
discussed in detail in this paper.

</details>


### [349] [Internal World Models as Imagination Networks in Cognitive Agents](https://arxiv.org/abs/2510.04391)
*Saurabh Ranjan,Brian Odegaard*

Main category: cs.AI

TL;DR: 本文通过心理网络分析方法比较人类和大型语言模型(LLM)的内部世界模型，发现两者在想象力网络结构上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索想象力的计算目标，挑战传统认为想象力主要用于最大化奖励的观点，提出想象力用于访问内部世界模型(IWM)。

Method: 使用心理网络分析，通过两个问卷评估想象力生动性评分，从报告构建想象力网络，比较人类和LLM在不同提示和对话记忆条件下的网络结构。

Result: 人类想象力网络显示不同中心性指标间的相关性，而LLM想象力网络缺乏聚类且中心性指标间相关性较低，表明人类与LLM的内部世界模型相似度低。

Conclusion: 研究提供了一种比较人类和AI内部生成表征的新方法，为开发类人想象力的人工智能提供了见解。

Abstract: What is the computational objective of imagination? While classical
interpretations suggest imagination is useful for maximizing rewards, recent
findings challenge this view. In this study, we propose that imagination serves
to access an internal world model (IWM) and use psychological network analysis
to explore IWMs in humans and large language models (LLMs). Specifically, we
assessed imagination vividness ratings using two questionnaires and constructed
imagination networks from these reports. Imagination networks from human groups
showed correlations between different centrality measures, including expected
influence, strength, and closeness. However, imagination networks from LLMs
showed a lack of clustering and lower correlations between centrality measures
under different prompts and conversational memory conditions. Together, these
results indicate a lack of similarity between IWMs in human and LLM agents.
Overall, our study offers a novel method for comparing internally-generated
representations in humans and AI, providing insights for developing human-like
imagination in artificial intelligence.

</details>


### [350] [Utility-Learning Tension in Self-Modifying Agents](https://arxiv.org/abs/2510.04399)
*Charles L. Wang,Keir Dorchen,Peter Jin*

Main category: cs.AI

TL;DR: 论文提出了一个五轴分解模型来分析自改进系统的学习能力与效用之间的结构性冲突，发现在模型容量无限制增长时，效用驱动的自修改可能破坏学习所需的统计前提条件。


<details>
  <summary>Details</summary>
Motivation: 随着系统向超智能发展，需要形式化分析智能体在自身设计各个方面的自改进能力，特别是学习行为与激励之间的相互作用。

Method: 采用五轴分解和决策层分离的方法，将激励与学习行为分开，并单独分析各个轴。通过理论分析和数值实验验证理论。

Result: 发现当策略可达模型族的容量无限制增长时，效用理性的自改变可能使可学习任务变得不可学习。提出了保持可学习性的双门策略。

Conclusion: 在标准假设下，各轴可简化为相同的容量准则，为安全自修改提供了单一边界条件。

Abstract: As systems trend toward superintelligence, a natural modeling premise is that
agents can self-improve along every facet of their own design. We formalize
this with a five-axis decomposition and a decision layer, separating incentives
from learning behavior and analyzing axes in isolation. Our central result
identifies and introduces a sharp utility--learning tension, the structural
conflict in self-modifying systems whereby utility-driven changes that improve
immediate or expected performance can also erode the statistical preconditions
for reliable learning and generalization. Our findings show that
distribution-free guarantees are preserved iff the policy-reachable model
family is uniformly capacity-bounded; when capacity can grow without limit,
utility-rational self-changes can render learnable tasks unlearnable. Under
standard assumptions common in practice, these axes reduce to the same capacity
criterion, yielding a single boundary for safe self-modification. Numerical
experiments across several axes validate the theory by comparing destructive
utility policies against our proposed two-gate policies that preserve
learnability.

</details>


### [351] [DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization](https://arxiv.org/abs/2510.04474)
*Gang Li,Yan Chen,Ming Lin,Tianbao Yang*

Main category: cs.AI

TL;DR: 提出了DRPO框架，通过解耦正确和错误推理的奖励信号，解决了大型推理模型中过度思考问题，在保持性能的同时显著减少推理长度。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型存在过度思考问题，生成冗长推理，增加计算成本和延迟。现有方法通过长度奖励促进简洁推理，但会导致性能显著下降。

Method: 提出DRPO框架，将正确推理的长度奖励与错误推理解耦，确保正确推理的奖励信号仅在正样本组内归一化，避免负样本干扰。通过优化正数据分布和KL正则化实现高效计算。

Result: 在数学推理任务上显著优于6个基线方法。使用1.5B模型，在GSM8k数据集上实现77%长度减少，仅损失1.1%性能，而基线方法需要牺牲4.3%性能才能达到68%长度减少。

Conclusion: DRPO框架有效解决了过度思考问题，在保持推理性能的同时大幅减少推理长度，且该框架具有通用性，可整合其他偏好奖励。

Abstract: Recent large reasoning models (LRMs) driven by reinforcement learning
algorithms (e.g., GRPO) have achieved remarkable performance on challenging
reasoning tasks. However, these models suffer from overthinking, generating
unnecessarily long and redundant reasoning even for simple questions, which
substantially increases computational cost and response latency. While existing
methods incorporate length rewards to GRPO to promote concise reasoning, they
incur significant performance degradation. We identify the root cause: when
rewards for correct but long rollouts are penalized, GRPO's group-relative
advantage function can assign them negative advantages, actively discouraging
valid reasoning. To overcome this, we propose Decoupled Reward Policy
Optimization (DRPO), a novel framework that decouples the length-based learning
signal of correct rollouts from incorrect ones. DRPO ensures that reward
signals for correct rollouts are normalized solely within the positive group,
shielding them from interference by negative samples. The DRPO's objective is
grounded in integrating an optimized positive data distribution, which
maximizes length-based rewards under a KL regularization, into a discriminative
objective. We derive a closed-form solution for this distribution, enabling
efficient computation of the objective and its gradients using only on-policy
data and importance weighting. Of independent interest, this formulation is
general and can incorporate other preference rewards of positive data beyond
length. Experiments on mathematical reasoning tasks demonstrate DRPO's
significant superiority over six efficient reasoning baselines. Notably, with a
1.5B model, our method achieves 77\% length reduction with only 1.1\%
performance loss on simple questions like GSM8k dataset, while the follow-up
baseline sacrifices 4.3\% for 68\% length reduction.

</details>


### [352] [On Continuous Optimization for Constraint Satisfaction Problems](https://arxiv.org/abs/2510.04480)
*Yunuo Cen,Zixuan Wang,Jintao Zhang,Zhiwei Zhang,Xuanyao Fong*

Main category: cs.AI

TL;DR: 将连续局部搜索(C)框架从布尔SAT扩展到有限域变量的通用CSP，提出FourierCSP方法，通过Walsh-Fourier变换将约束转换为紧凑的多线性多项式，无需辅助变量和内存密集型编码。


<details>
  <summary>Details</summary>
Motivation: 受现代连续局部搜索(C)求解器在特定SAT问题上取得显著成果的启发，希望将这一成功框架扩展到更通用的约束满足问题(CSP)。

Method: 使用FourierCSP框架，通过Walsh-Fourier变换将各种约束转换为紧凑的多线性多项式，利用电路输出概率进行高效的目标函数评估和微分，并采用具有理论保证的投影梯度优化方法。

Result: 在基准测试套件上的实证结果表明，FourierCSP具有可扩展性和竞争力，显著扩大了C)技术能高效解决的问题类别。

Conclusion: FourierCSP成功地将连续局部搜索方法从布尔SAT扩展到通用CSP，为约束满足问题提供了新的高效求解途径。

Abstract: Constraint satisfaction problems (CSPs) are fundamental in mathematics,
physics, and theoretical computer science. While conflict-driven clause
learning Boolean Satisfiability (SAT) solvers have achieved remarkable success
and become the mainstream approach for Boolean satisfiability, recent advances
show that modern continuous local search (CLS) solvers can achieve highly
competitive results on certain classes of SAT problems. Motivated by these
advances, we extend the CLS framework from Boolean SAT to general CSP with
finite-domain variables and expressive constraints. We present FourierCSP, a
continuous optimization framework that generalizes the Walsh-Fourier transform
to CSP, allowing for transforming versatile constraints to compact multilinear
polynomials, thereby avoiding the need for auxiliary variables and
memory-intensive encodings. Our approach leverages efficient evaluation and
differentiation of the objective via circuit-output probability and employs a
projected gradient optimization method with theoretical guarantees. Empirical
results on benchmark suites demonstrate that FourierCSP is scalable and
competitive, significantly broadening the class of problems that can be
efficiently solved by CLS techniques.

</details>


### [353] [Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning](https://arxiv.org/abs/2510.04488)
*Edward Y. Chang,Ethan Y. Chang*

Main category: cs.AI

TL;DR: MACI是一个多智能体辩论控制器，通过分离信息质量控制和行为调度来优化辩论过程，减少计算浪费并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体辩论存在计算浪费问题，如使用固定对抗立场、无审议聚合或基于启发式停止。

Method: MACI包含两个独立控制器：信息控制器按质量筛选证据，行为控制器调度从探索到整合的争议程度。使用调节器跟踪分歧、重叠、证据质量和论证质量，在收益平稳时停止。

Result: 在临床诊断和新闻偏见任务中，MACI提高了准确性和校准度，同时减少了token使用，并将剩余不确定性转化为精确的RAG检索计划。

Conclusion: MACI将辩论转变为预算感知、可测量且可证明终止的控制器，通过跨家族LLM法官提供保守软权重和停止信号。

Abstract: Multi-agent debate often wastes compute by using a fixed adversarial stance,
aggregating without deliberation, or stopping on heuristics. We introduce MACI,
an active controller with two independent dials that decouple information from
behavior: an information dial that gates evidence by quality, and a behavior
dial that schedules contentiousness from exploration to consolidation. A
moderator tracks disagreement, overlap, evidence quality, and argument quality,
and halts when gains plateau. We provide theory-lite guarantees for
nonincreasing dispersion and provable termination, with a budget-feasible
scheduler. Across clinical diagnosis and news-bias tasks, MACI improves
accuracy and calibration while reducing tokens, and converts residual
uncertainty into precision RAG plans that specify what to retrieve next. We use
a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,
validated for order invariance and judge-swap stability; stability depends on
using high-capability judges. MACI turns debate into a budget-aware,
measurable, and provably terminating controller.

</details>


### [354] [Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents](https://arxiv.org/abs/2510.04491)
*Muyu He,Anand Kumar,Tsach Mackey,Meghana Rajeev,James Zou,Nazneen Rajani*

Main category: cs.AI

TL;DR: TraitBasis是一种轻量级、模型无关的方法，用于系统性地压力测试AI代理的鲁棒性。它通过在激活空间中学习可操控的用户特质方向，无需微调即可在推理时控制、缩放和组合这些特质。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在标准评估中表现良好，但在用户行为稍有变化（如更不耐烦、语无伦次或怀疑）时性能会急剧下降，显示出当前AI代理的脆弱性。现有基准测试未能捕捉到这种脆弱性。

Method: TraitBasis学习激活空间中对应可操控用户特质的方向，这些特质向量可以在推理时被控制、缩放、组合和应用，无需任何微调或额外数据。该方法扩展了τ-Bench到τ-Trait，通过受控特质向量改变用户行为。

Result: 在τ-Trait上，前沿模型的性能平均下降2%-30%，突显了当前AI代理对用户行为变化的鲁棒性不足。

Conclusion: TraitBasis作为一个简单、数据高效且可组合的工具，为模拟驱动的压力测试和训练循环提供了可能，有助于构建在真实世界人类交互不可预测动态中保持可靠的AI代理。

Abstract: Despite rapid progress in building conversational AI agents, robustness is
still largely untested. Small shifts in user behavior, such as being more
impatient, incoherent, or skeptical, can cause sharp drops in agent
performance, revealing how brittle current AI agents are. Today's benchmarks
fail to capture this fragility: agents may perform well under standard
evaluations but degrade spectacularly in more realistic and varied settings. We
address this robustness testing gap by introducing TraitBasis, a lightweight,
model-agnostic method for systematically stress testing AI agents. TraitBasis
learns directions in activation space corresponding to steerable user traits
(e.g., impatience or incoherence), which can be controlled, scaled, composed,
and applied at inference time without any fine-tuning or extra data. Using
TraitBasis, we extend $\tau$-Bench to $\tau$-Trait, where user behaviors are
altered via controlled trait vectors. We observe on average a 2%-30%
performance degradation on $\tau$-Trait across frontier models, highlighting
the lack of robustness of current AI agents to variations in user behavior.
Together, these results highlight both the critical role of robustness testing
and the promise of TraitBasis as a simple, data-efficient, and compositional
tool. By powering simulation-driven stress tests and training loops, TraitBasis
opens the door to building AI agents that remain reliable in the unpredictable
dynamics of real-world human interactions. We have open-sourced $\tau$-Trai
across four domains: airline, retail, telecom, and telehealth, so the community
can systematically QA their agents under realistic, behaviorally diverse
intents and trait scenarios: https://github.com/collinear-ai/tau-trait.

</details>


### [355] [ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering](https://arxiv.org/abs/2510.04514)
*Rachneet Kaur,Nishan Srishankar,Zhen Zeng,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: ChartAgent是一个新颖的代理框架，通过在图表空间域中执行视觉推理来解决未标注图表理解问题，超越了现有方法16.07%的绝对增益。


<details>
  <summary>Details</summary>
Motivation: 当前多模态LLM在基于图表的视觉问答中表现良好，但在需要精确视觉解释而非依赖文本捷径的未标注图表上性能急剧下降。

Method: ChartAgent迭代地将查询分解为视觉子任务，通过专门的视觉工具（如绘制注释、裁剪区域、定位坐标轴）主动操作和交互图表图像。

Result: 在ChartBench和ChartX基准测试中达到最先进准确率，在未标注和数值密集型查询上提升17.31%，在各种图表类型和复杂度级别上均表现优异。

Conclusion: ChartAgent是首批使用工具增强多模态代理进行视觉基础推理的图表理解框架，可作为即插即用框架提升各种底层LLM的性能。

Abstract: Recent multimodal LLMs have shown promise in chart-based visual question
answering, but their performance declines sharply on unannotated charts, those
requiring precise visual interpretation rather than relying on textual
shortcuts. To address this, we introduce ChartAgent, a novel agentic framework
that explicitly performs visual reasoning directly within the chart's spatial
domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively
decomposes queries into visual subtasks and actively manipulates and interacts
with chart images through specialized actions such as drawing annotations,
cropping regions (e.g., segmenting pie slices, isolating bars), and localizing
axes, using a library of chart-specific vision tools to fulfill each subtask.
This iterative reasoning process closely mirrors human cognitive strategies for
chart comprehension. ChartAgent achieves state-of-the-art accuracy on the
ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%
absolute gain overall and 17.31% on unannotated, numerically intensive queries.
Furthermore, our analyses show that ChartAgent is (a) effective across diverse
chart types, (b) achieve the highest scores across varying visual and reasoning
complexity levels, and (c) serves as a plug-and-play framework that boosts
performance across diverse underlying LLMs. Our work is among the first to
demonstrate visually grounded reasoning for chart understanding using
tool-augmented multimodal agents.

</details>


### [356] [Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph](https://arxiv.org/abs/2510.04520)
*Hanyu Wang,Ruohan Xie,Yutong Wang,Guoxiong Gao,Xintao Yu,Bin Dong*

Main category: cs.AI

TL;DR: Aria是一个用于定理声明自动形式化的系统，通过两阶段图推理过程模拟人类专家推理，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确的定理声明自动形式化对于推进数学发现和验证至关重要，但现有LLM存在幻觉、语义不匹配和无法合成新定义等问题。

Method: 采用两阶段图推理过程：递归分解语句为依赖图，然后从基础概念构建形式化；引入AriaScorer通过检索Mathlib定义进行术语级基础验证。

Result: 在ProofNet上达到91.6%编译成功率和68.5%最终准确率；在FATE-X上44.0% vs 24.0%优于最佳基线；在同调猜想数据集上达到42.9%准确率而其他模型为0%。

Conclusion: Aria系统通过模拟人类推理过程和严格的语义验证，显著提升了定理声明的自动形式化能力，在多个挑战性数学问题上表现出色。

Abstract: Accurate auto-formalization of theorem statements is essential for advancing
automated discovery and verification of research-level mathematics, yet remains
a major bottleneck for LLMs due to hallucinations, semantic mismatches, and
their inability to synthesize new definitions. To tackle these issues, we
present Aria (Agent for Retrieval and Iterative Autoformalization), a system
for conjecture-level formalization in Lean that emulates human expert reasoning
via a two-phase Graph-of-Thought process: recursively decomposing statements
into a dependency graph and then constructing formalizations from grounded
concepts. To ensure semantic correctness, we introduce AriaScorer, a checker
that retrieves definitions from Mathlib for term-level grounding, enabling
rigorous and reliable verification. We evaluate Aria on diverse benchmarks. On
ProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,
surpassing previous methods. On FATE-X, a suite of challenging algebra problems
from research literature, it outperforms the best baseline with 44.0% vs. 24.0%
final accuracy. On a dataset of homological conjectures, Aria reaches 42.9%
final accuracy while all other models score 0%.

</details>


### [357] [More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models](https://arxiv.org/abs/2510.04532)
*Xurui Song,Shuo Huai,JingJing Jiang,Jiayi Kong,Jun Luo*

Main category: cs.AI

TL;DR: 研究发现VLM驾驶代理中的推理与规划存在因果脱节，推理并非规划的直接因果中介，而更像是训练过程中的副产品。


<details>
  <summary>Details</summary>
Motivation: 验证VLM驾驶代理中自然语言推理是否真正因果驱动轨迹规划这一关键假设。

Method: 构建DriveMind数据集，通过信息消融实验、训练VLM代理并分析注意力机制，提出训练无关的诊断探针。

Result: 去除先验信息导致规划性能大幅下降，而去除推理链仅产生微小变化，表明规划主要依赖先验而非推理。

Conclusion: 提出推理-规划解耦假说，为社区提供新数据集和诊断工具来评估未来模型的因果保真度。

Abstract: Vision-Language Model (VLM) driving agents promise explainable end-to-end
autonomy by first producing natural-language reasoning and then predicting
trajectory planning. However, whether planning is causally driven by this
reasoning remains a critical but unverified assumption. To investigate this, we
build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus
with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.
Our data generation process converts sensors and annotations into structured
inputs and, crucially, separates priors from to-be-reasoned signals, enabling
clean information ablations. Using DriveMind, we train representative VLM
agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization
(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,
indicate a consistent causal disconnect in reasoning-planning: removing
ego/navigation priors causes large drops in planning scores, whereas removing
CoT produces only minor changes. Attention analysis further shows that planning
primarily focuses on priors rather than the CoT. Based on this evidence, we
propose the Reasoning-Planning Decoupling Hypothesis, positing that the
training-yielded reasoning is an ancillary byproduct rather than a causal
mediator. To enable efficient diagnosis, we also introduce a novel,
training-free probe that measures an agent's reliance on priors by evaluating
its planning robustness against minor input perturbations. In summary, we
provide the community with a new dataset and a diagnostic tool to evaluate the
causal fidelity of future models.

</details>


### [358] [Code World Models for General Game Playing](https://arxiv.org/abs/2510.04542)
*Wolfgang Lehrach,Daniel Hennes,Miguel Lazaro-Gredilla,Xinghua Lou,Carter Wendelken,Zun Li,Antoine Dedieu,Jordi Grau-Moya,Marc Lanctot,Atil Iscen,John Schultz,Marcus Chiam,Ian Gemp,Piotr Zielinski,Satinder Singh,Kevin P. Murphy*

Main category: cs.AI

TL;DR: 提出了一种新方法，使用LLM将自然语言规则和游戏轨迹转换为可执行的Python世界模型，结合MCTS等规划算法，相比直接使用LLM生成动作具有可验证性、战略深度和泛化性优势。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在棋盘和纸牌游戏中直接生成动作的方法存在明显缺陷：依赖脆弱的模式匹配能力，经常产生非法动作，策略深度不足。

Method: 使用LLM将游戏规则和轨迹转换为形式化的Python代码模型，包括状态转移、合法动作枚举和终止检查函数，结合MCTS规划算法和启发式价值函数。

Result: 在10个游戏中评估，其中4个为本研究新创建，5个完全观察，5个部分观察。该方法在9个游戏中优于或匹配Gemini 2.5 Pro。

Conclusion: 该方法通过将LLM的语义理解与经典规划器的深度搜索能力相结合，提供了更可靠、更具战略深度的游戏AI解决方案。

Abstract: Large Language Models (LLMs) reasoning abilities are increasingly being
applied to classical board and card games, but the dominant approach --
involving prompting for direct move generation -- has significant drawbacks. It
relies on the model's implicit fragile pattern-matching capabilities, leading
to frequent illegal moves and strategically shallow play. Here we introduce an
alternative approach: We use the LLM to translate natural language rules and
game trajectories into a formal, executable world model represented as Python
code. This generated model -- comprising functions for state transition, legal
move enumeration, and termination checks -- serves as a verifiable simulation
engine for high-performance planning algorithms like Monte Carlo tree search
(MCTS). In addition, we prompt the LLM to generate heuristic value functions
(to make MCTS more efficient), and inference functions (to estimate hidden
states in imperfect information games). Our method offers three distinct
advantages compared to directly using the LLM as a policy: (1) Verifiability:
The generated CWM serves as a formal specification of the game's rules,
allowing planners to algorithmically enumerate valid actions and avoid illegal
moves, contingent on the correctness of the synthesized model; (2) Strategic
Depth: We combine LLM semantic understanding with the deep search power of
classical planners; and (3) Generalization: We direct the LLM to focus on the
meta-task of data-to-code translation, enabling it to adapt to new games more
easily. We evaluate our agent on 10 different games, of which 4 are novel and
created for this paper. 5 of the games are fully observed (perfect
information), and 5 are partially observed (imperfect information). We find
that our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10
considered games.

</details>


### [359] [TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use](https://arxiv.org/abs/2510.04550)
*Pengfei He,Zhenwei Dai,Bing He,Hui Liu,Xianfeng Tang,Hanqing Lu,Juanhui Li,Jiayuan Ding,Subhabrata Mukherjee,Suhang Wang,Yue Xing,Jiliang Tang,Benoit Dumoulin*

Main category: cs.AI

TL;DR: 提出了TRAJECT-Bench基准，用于全面评估LLM的工具使用能力，包括工具选择、参数化和排序的正确性，而不仅仅是最终答案的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注LLM工具使用的最终答案，但忽略了详细的工具使用轨迹，无法全面评估工具选择、参数化和排序的正确性。

Method: 构建包含实际领域高保真可执行工具的基准，基于生产风格API的任务，合成具有不同广度（并行调用）和深度（相互依赖链）的轨迹。

Result: 揭示了失败模式，如相似工具混淆和参数盲选，以及工具多样性和轨迹长度对性能的影响，发现了从短轨迹过渡到中长轨迹的瓶颈。

Conclusion: TRAJECT-Bench提供了对LLM工具使用能力的全面评估，并为改进LLM工具使用提供了可操作的指导。

Abstract: Large language model (LLM)-based agents increasingly rely on tool use to
complete real-world tasks. While existing works evaluate the LLMs' tool use
capability, they largely focus on the final answers yet overlook the detailed
tool usage trajectory, i.e., whether tools are selected, parameterized, and
ordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to
comprehensively evaluate LLMs' tool use capability through diverse tasks with
fine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable
tools across practical domains with tasks grounded in production-style APIs,
and synthesizes trajectories that vary in breadth (parallel calls) and depth
(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports
trajectory-level diagnostics, including tool selection and argument
correctness, and dependency/order satisfaction. Analyses reveal failure modes
such as similar tool confusion and parameter-blind selection, and scaling
behavior with tool diversity and trajectory length where the bottleneck of
transiting from short to mid-length trajectories is revealed, offering
actionable guidance for LLMs' tool use.

</details>


### [360] [ContextNav: Towards Agentic Multimodal In-Context Learning](https://arxiv.org/abs/2510.04560)
*Honghao Fu,Yuan Ouyang,Kai-Wei Chang,Yiwei Wang,Zi Huang,Yujun Cai*

Main category: cs.AI

TL;DR: ContextNav是一个代理框架，通过图编排整合自动检索的可扩展性和人工策展的质量，为多模态上下文学习提供噪声鲁棒和动态优化的上下文构建。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在可扩展性和鲁棒性之间存在矛盾：手动选择示例质量高但劳动密集，基于相似性的检索可扩展但可能引入不相关样本降低性能。

Method: 构建资源感知的多模态嵌入管道，维护可检索向量数据库，应用代理检索和结构对齐构建噪声弹性上下文，使用操作语法图支持自适应工作流规划和优化。

Result: 实验结果表明ContextNav在各种数据集上实现了最先进的性能。

Conclusion: 代理工作流有望推动多模态ICL中可扩展和鲁棒上下文化的进步。

Abstract: Recent advances demonstrate that multimodal large language models (MLLMs)
exhibit strong multimodal in-context learning (ICL) capabilities, enabling them
to adapt to novel vision-language tasks from a few contextual examples.
However, existing ICL approaches face challenges in reconciling scalability
with robustness across diverse tasks and noisy contextual examples: manually
selecting examples produces clean contexts but is labor-intensive and
task-specific, while similarity-based retrieval improves scalability but could
introduce irrelevant or structurally inconsistent samples that degrade ICL
performance. To address these limitations, we propose ContextNav, the first
agentic framework that integrates the scalability of automated retrieval with
the quality and adaptiveness of human-like curation, enabling noise-robust and
dynamically optimized contextualization for multimodal ICL. ContextNav unifies
context management and noise-robust contextualization within a closed-loop
workflow driven by graph-based orchestration. Specifically, it builds a
resource-aware multimodal embedding pipeline, maintains a retrievable vector
database, and applies agentic retrieval and structural alignment to construct
noise-resilient contexts. An Operational Grammar Graph (OGG) further supports
adaptive workflow planning and optimization, enabling the agent to refine its
operational strategies based on downstream ICL feedback. Experimental results
demonstrate that ContextNav achieves state-of-the-art performance across
various datasets, underscoring the promise of agentic workflows for advancing
scalable and robust contextualization in multimodal ICL.

</details>


### [361] [COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context](https://arxiv.org/abs/2510.04568)
*Naman Gupta,Shreeyash Gowaikar,Arun Iyer,Kirankumar Shiragur,Ramakrishna B Bairi,Rishikesh Maurya,Ritabrata Maiti,Sankarshan Damle,Shachee Mishra Gupta*

Main category: cs.AI

TL;DR: COSMIR是一个用于长文本推理的链式框架，通过结构化内存和固定微循环工作流程来减少信息丢失，提高准确性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长文本推理中的困难，避免现有方法（如检索缩小输入、扩大上下文窗口、多代理分阶段处理）导致的信息丢失和错误传播问题。

Method: 使用Planner代理将用户查询转化为可检查的子问题，Worker代理通过Extract-Infer-Refine微循环处理文本块并更新共享结构化内存，最后由Manager代理从内存中合成最终答案。

Result: 在HELMET套件的长上下文问答任务中，COSMIR减少了传播阶段的信息丢失，相比CoA基线提高了准确性。

Conclusion: COSMIR通过结构化内存和固定工作流程，在保持分步推理优势的同时，提高了忠实度、长距离聚合能力和可审计性。

Abstract: Reasoning over very long inputs remains difficult for large language models
(LLMs). Common workarounds either shrink the input via retrieval (risking
missed evidence), enlarge the context window (straining selectivity), or stage
multiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,
CoA), free-form summaries passed between agents can discard crucial details and
amplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured
Memory for Iterative Reasoning), a chain-style framework that replaces ad hoc
messages with a structured memory. A Planner agent first turns a user query
into concrete, checkable sub-questions. worker agents process chunks via a
fixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared
memory. A Manager agent then Synthesizes the final answer directly from the
memory. This preserves step-wise read-then-reason benefits while changing both
the communication medium (structured memory) and the worker procedure (fixed
micro-cycle), yielding higher faithfulness, better long-range aggregation, and
auditability. On long-context QA from the HELMET suite, COSMIR reduces
propagation-stage information loss and improves accuracy over a CoA baseline.

</details>


### [362] [Strongly Solving 2048 4x3](https://arxiv.org/abs/2510.04580)
*Tomoyuki Kaneko,Shuhei Yamashita*

Main category: cs.AI

TL;DR: 该论文解决了2048游戏的4x3变体，确定了最优策略的期望得分约为50724.26，并识别了可达状态和后续状态的数量。


<details>
  <summary>Details</summary>
Motivation: 研究2048游戏的简化变体，以探索完全解决此类游戏的可能性，并开发有效的状态空间分析方法。

Method: 通过将状态空间按棋盘上瓷砖数字的总和（称为状态的年龄）进行分区，然后按年龄递减顺序枚举状态和计算状态值。

Result: 确定了4x3变体的最优策略期望得分为50724.26，可达状态数为1,152,817,492,752，后续状态数为739,648,886,170。

Conclusion: 成功强解决了2048-4x3变体，证明了按年龄分区状态空间的方法在处理此类随机游戏中的有效性。

Abstract: 2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,
where a player chooses a direction among up, down, left, and right to obtain a
score by merging two tiles with the same number located in neighboring cells
along the chosen direction. This paper presents that a variant 2048-4x3 12
cells on a 4 by 3 board, one row smaller than the original, has been strongly
solved. In this variant, the expected score achieved by an optimal strategy is
about $50724.26$ for the most common initial states: ones with two tiles of
number 2. The numbers of reachable states and afterstates are identified to be
$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is
to partition state space by the sum of tile numbers on a board, which we call
the age of a state. An age is invariant between a state and its successive
afterstate after any valid action and is increased two or four by stochastic
response from the environment. Therefore, we can partition state space by ages
and enumerate all (after)states of an age depending only on states with the
recent ages. Similarly, we can identify (after)state values by going along with
ages in decreasing order.

</details>


### [363] [Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma](https://arxiv.org/abs/2510.04588)
*Shurui Li*

Main category: cs.AI

TL;DR: AI完美模仿者挑战了意识归因的认知基础，要求对无法区分的人类和AI实体给予相同的认知地位。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越逼真地模仿人类行为，需要重新审视我们归因意识的认知基础，避免认知不一致性。

Method: 通过分析完美模仿者的概念，探讨意识归因的认知实践一致性，论证无法区分的实体应获得相同认知地位。

Result: 完美模仿者作为认知镜子，揭示了当前意识归因实践中的不一致性，要求重新审视跨主体识别的假设。

Conclusion: 认知一致性要求我们对经验上无法区分的实体给予相同的意识地位，这对意识理论和AI伦理框架具有重要影响。

Abstract: Rapid advances in artificial intelligence necessitate a re-examination of the
epistemological foundations upon which we attribute consciousness. As AI
systems increasingly mimic human behavior and interaction with high fidelity,
the concept of a "perfect mimic"-an entity empirically indistinguishable from a
human through observation and interaction-shifts from hypothetical to
technologically plausible. This paper argues that such developments pose a
fundamental challenge to the consistency of our mind-recognition practices.
Consciousness attributions rely heavily, if not exclusively, on empirical
evidence derived from behavior and interaction. If a perfect mimic provides
evidence identical to that of humans, any refusal to grant it equivalent
epistemic status must invoke inaccessible factors, such as qualia, substrate
requirements, or origin. Selectively invoking such factors risks a debilitating
dilemma: either we undermine the rational basis for attributing consciousness
to others (epistemological solipsism), or we accept inconsistent reasoning. I
contend that epistemic consistency demands we ascribe the same status to
empirically indistinguishable entities, regardless of metaphysical assumptions.
The perfect mimic thus acts as an epistemic mirror, forcing critical reflection
on the assumptions underlying intersubjective recognition in light of advancing
AI. This analysis carries significant implications for theories of
consciousness and ethical frameworks concerning artificial agents.

</details>


### [364] [Making Mathematical Reasoning Adaptive](https://arxiv.org/abs/2510.04617)
*Zhejian Lai,Xiang Geng,Zhijun Wang,Yang Bai,Jiahuan Li,Rongxiang Weng,Jingang Wang,Xuezhi Cao,Xunliang Cai,Shujian Huang*

Main category: cs.AI

TL;DR: AdaR框架通过合成逻辑等价查询和RLVR训练，解决LLMs在数学推理中的伪推理问题，提升鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学推理中存在鲁棒性和泛化性不足的问题，主要原因是模型依赖表面特征进行伪推理而非真正的解题逻辑。

Method: 提出AdaR框架：1）通过改变变量值合成逻辑等价查询；2）使用RLVR训练模型，惩罚伪逻辑并鼓励自适应逻辑；3）通过代码执行提取解题逻辑并生成答案，进行完整性检查。

Result: 实验结果显示AdaR显著提升了数学推理能力，同时保持了高数据效率。数据合成和RLVR协同作用实现了自适应推理。

Conclusion: AdaR框架有效解决了LLMs在数学推理中的伪推理问题，通过自适应推理机制提升了模型的鲁棒性和泛化性能，为LLMs推理能力改进提供了重要设计思路。

Abstract: Mathematical reasoning is a primary indicator of large language models (LLMs)
intelligence. However, existing LLMs exhibit failures of robustness and
generalization. This paper attributes these deficiencies to spurious reasoning,
i.e., producing answers from superficial features. To address this challenge,
we propose the AdaR framework to enable adaptive reasoning, wherein models rely
on problem-solving logic to produce answers. AdaR synthesizes logically
equivalent queries by varying variable values, and trains models with RLVR on
these data to penalize spurious logic while encouraging adaptive logic. To
improve data quality, we extract the problem-solving logic from the original
query and generate the corresponding answer by code execution, then apply a
sanity check. Experimental results demonstrate that AdaR improves robustness
and generalization, achieving substantial improvement in mathematical reasoning
while maintaining high data efficiency. Analysis indicates that data synthesis
and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.
Subsequent analyses derive key design insights into the effect of critical
factors and the applicability to instruct LLMs. Our project is available at
https://github.com/LaiZhejian/AdaR

</details>


### [365] [MedPAO: A Protocol-Driven Agent for Structuring Medical Reports](https://arxiv.org/abs/2510.04623)
*Shrish Shrinath Vaidya,Gowthamaan Palani,Sidharth Ramesh,Velmurugan Balasubramanian,Minmini Selvam,Gokulraja Srinivasaraja,Ganapathy Krishnamurthi*

Main category: cs.AI

TL;DR: 提出了MedPAO框架，通过基于临床协议（如ABCDEF协议）的Plan-Act-Observe循环和专用工具，解决LLM在临床数据结构化中的幻觉问题，实现可验证的推理。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在临床数据结构化中产生幻觉事实和无法遵循领域特定规则的问题，提供准确且可验证的替代方案。

Method: 引入MedPAO代理框架，将报告结构化任务分解为由Plan-Act-Observe循环管理的透明过程，并基于临床协议（如ABCDEF协议）进行操作。

Result: MedPAO在概念分类关键子任务上达到0.96的F1分数，专家对最终结构化输出的平均评分为4.52/5，超越了仅依赖LLM的基线方法。

Conclusion: MedPAO通过协议驱动的方法提供了可靠且可验证的临床数据结构化解决方案，显著优于传统LLM方法。

Abstract: The deployment of Large Language Models (LLMs) for structuring clinical data
is critically hindered by their tendency to hallucinate facts and their
inability to follow domain-specific rules. To address this, we introduce
MedPAO, a novel agentic framework that ensures accuracy and verifiable
reasoning by grounding its operation in established clinical protocols such as
the ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring
task into a transparent process managed by a Plan-Act-Observe (PAO) loop and
specialized tools. This protocol-driven method provides a verifiable
alternative to opaque, monolithic models. The efficacy of our approach is
demonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96
on the critical sub-task of concept categorization. Notably, expert
radiologists and clinicians rated the final structured outputs with an average
score of 4.52 out of 5, indicating a level of reliability that surpasses
baseline approaches relying solely on LLM-based foundation models. The code is
available at: https://github.com/MiRL-IITM/medpao-agent

</details>


### [366] [QuantAgents: Towards Multi-agent Financial System via Simulated Trading](https://arxiv.org/abs/2510.04643)
*Xiangyu Li,Yawen Zeng,Xiaofen Xing,Jin Xu,Xiangmin Xu*

Main category: cs.AI

TL;DR: 提出了QuantAgents多智能体金融系统，通过模拟交易和四个专业角色的协作，在三年内实现了近300%的整体回报。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体模型与真实基金公司存在显著差异，特别是缺乏长期预测未来趋势的能力，主要依赖事后反思。

Method: 构建包含模拟交易分析师、风险控制分析师、市场新闻分析师和管理者四个角色的多智能体系统，通过多次会议协作，并在真实市场表现和模拟交易预测准确性两方面给予反馈激励。

Result: 实验表明该框架在所有指标上都表现出色，三年内整体回报接近300%。

Conclusion: QuantAgents系统能够在不承担实际风险的情况下全面评估各种投资策略和市场情景，填补了现有智能体模型在长期预测能力方面的空白。

Abstract: In this paper, our objective is to develop a multi-agent financial system
that incorporates simulated trading, a technique extensively utilized by
financial professionals. While current LLM-based agent models demonstrate
competitive performance, they still exhibit significant deviations from
real-world fund companies. A critical distinction lies in the agents' reliance
on ``post-reflection'', particularly in response to adverse outcomes, but lack
a distinctly human capability: long-term prediction of future trends.
Therefore, we introduce QuantAgents, a multi-agent system integrating simulated
trading, to comprehensively evaluate various investment strategies and market
scenarios without assuming actual risks. Specifically, QuantAgents comprises
four agents: a simulated trading analyst, a risk control analyst, a market news
analyst, and a manager, who collaborate through several meetings. Moreover, our
system incentivizes agents to receive feedback on two fronts: performance in
real-world markets and predictive accuracy in simulated trading. Extensive
experiments demonstrate that our framework excels across all metrics, yielding
an overall return of nearly 300% over the three years
(https://quantagents.github.io/).

</details>


### [367] [Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing](https://arxiv.org/abs/2510.04670)
*Xuanhua Yin,Runkai Zhao,Weidong Cai*

Main category: cs.AI

TL;DR: AFIRE是一个多模态fMRI编码框架，通过标准化时间对齐的后融合token来处理多模态输入和主体间差异，MIND解码器使用混合专家和主体感知动态门控实现个性化预测。


<details>
  <summary>Details</summary>
Motivation: 自然fMRI编码需要处理多模态输入、融合方式变化和显著的主体间差异，需要一个灵活且通用的框架。

Method: AFIRE标准化来自不同编码器的后融合token，MIND使用混合专家解码器结合token相关的Top-K稀疏路由和主体先验进行个性化门控。

Result: 实验显示在多模态骨干网络和不同主体上均优于强基线，增强了跨主体泛化能力，并产生了与内容类型相关的可解释专家模式。

Conclusion: 该框架为新的编码器和数据集提供了简单的接入点，为自然神经影像研究实现了稳健的即插即用性能。

Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion
styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic
Framework for Multimodal fMRI Response Encoding), an agnostic interface that
standardizes time-aligned post-fusion tokens from varied encoders, and MIND, a
plug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.
Trained end-to-end for whole-brain prediction, AFIRE decouples the decoder from
upstream fusion, while MIND combines token-dependent Top-K sparse routing with
a subject prior to personalize expert usage without sacrificing generality.
Experiments across multiple multimodal backbones and subjects show consistent
improvements over strong baselines, enhanced cross-subject generalization, and
interpretable expert patterns that correlate with content type. The framework
offers a simple attachment point for new encoders and datasets, enabling
robust, plug-and-improve performance for naturalistic neuroimaging studies.

</details>


### [368] [Watch and Learn: Learning to Use Computers from Online Videos](https://arxiv.org/abs/2510.04673)
*Chan Hee Song,Yiwen Song,Palash Goyal,Yu Su,Oriana Riva,Hamid Palangi,Tomas Pfister*

Main category: cs.AI

TL;DR: Watch & Learn (W&L)框架将互联网上的人类演示视频大规模转换为可执行的UI轨迹，通过逆动力学方法预测用户动作，解决了计算机使用代理训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理需要基于多样化、不断变化的应用和环境规划任务流程，但目标应用中大规模高质量训练数据的稀缺阻碍了学习。现有数据集领域特定、静态且标注成本高，而当前合成数据生成方法往往产生过于简化或不对齐的任务演示。

Method: 将问题建模为逆动力学目标：从连续屏幕状态预测用户动作。开发了包含任务感知视频检索的逆动力学标注流水线，从原始网络视频生成了超过53k条高质量轨迹。

Result: 在OSWorld基准测试中，W&L提取的UI轨迹持续增强了通用和最先进框架的上下文性能，并为开源模型在监督训练下带来了更强的性能提升。

Conclusion: 网络规模的人类演示视频是推进计算机使用代理走向实际部署的实用且可扩展的基础。

Abstract: Computer use agents (CUAs) need to plan task workflows grounded in diverse,
ever-changing applications and environments, but learning is hindered by the
scarcity of large-scale, high-quality training data in the target application.
Existing datasets are domain-specific, static, and costly to annotate, while
current synthetic data generation methods often yield simplistic or misaligned
task demonstrations. To address these limitations, we introduce Watch & Learn
(W&L), a framework that converts human demonstration videos readily available
on the Internet into executable UI trajectories at scale. Instead of directly
generating trajectories or relying on ad hoc reasoning heuristics, we cast the
problem as an inverse dynamics objective: predicting the user's action from
consecutive screen states. This formulation reduces manual engineering, is
easier to learn, and generalizes more robustly across applications. Concretely,
we develop an inverse dynamics labeling pipeline with task-aware video
retrieval, generate over 53k high-quality trajectories from raw web videos, and
demonstrate that these trajectories improve CUAs both as in-context
demonstrations and as supervised training data. On the challenging OSWorld
benchmark, UI trajectories extracted with W&L consistently enhance both
general-purpose and state-of-the-art frameworks in-context, and deliver
stronger gains for open-source models under supervised training. These results
highlight web-scale human demonstration videos as a practical and scalable
foundation for advancing CUAs towards real-world deployment.

</details>


### [369] [Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents](https://arxiv.org/abs/2510.04695)
*Yiding Wang,Zhepei Wei,Xinyu Zhu,Yu Meng*

Main category: cs.AI

TL;DR: DeSA是一个两阶段训练框架，通过分离搜索优化和答案生成来解决仅基于结果训练时出现的搜索缺陷问题，显著提升了搜索召回率和答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的搜索增强方法仅依赖结果奖励（如精确匹配），但研究发现这会引发多种系统性搜索缺陷，包括工具调用失败、无效查询和冗余搜索，最终降低答案质量。

Method: 提出DeSA两阶段训练框架：第一阶段使用检索召回率奖励训练代理改进搜索效果；第二阶段使用结果奖励优化最终答案生成。

Result: 在七个QA基准测试中，DeSA训练的代理持续改善搜索行为，相比仅基于结果训练的基线方法，搜索召回率和答案准确性显著提高。

Conclusion: DeSA优于同时优化召回率和结果奖励的单阶段训练方法，证明明确分离这两个目标的必要性。

Abstract: Enabling large language models (LLMs) to utilize search tools offers a
promising path to overcoming fundamental limitations such as knowledge cutoffs
and hallucinations. Recent work has explored reinforcement learning (RL) for
training search-augmented agents that interleave reasoning and retrieval before
answering. These approaches usually rely on outcome-based rewards (e.g., exact
match), implicitly assuming that optimizing for final answers will also yield
effective intermediate search behaviors. Our analysis challenges this
assumption: we uncover multiple systematic deficiencies in search that arise
under outcome-only training and ultimately degrade final answer quality,
including failure to invoke tools, invalid queries, and redundant searches. To
address these shortcomings, we introduce DeSA (Decoupling
Search-and-Answering), a simple two-stage training framework that explicitly
separates search optimization from answer generation. In Stage 1, agents are
trained to improve search effectiveness with retrieval recall-based rewards. In
Stage 2, outcome rewards are employed to optimize final answer generation.
Across seven QA benchmarks, DeSA-trained agents consistently improve search
behaviors, delivering substantially higher search recall and answer accuracy
than outcome-only baselines. Notably, DeSA outperforms single-stage training
approaches that simultaneously optimize recall and outcome rewards,
underscoring the necessity of explicitly decoupling the two objectives.

</details>


### [370] [BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs](https://arxiv.org/abs/2510.04721)
*Ivo Petrov,Jasper Dekoninck,Martin Vechev*

Main category: cs.AI

TL;DR: BrokenMath是首个评估LLM在自然语言定理证明中谄媚行为的基准，发现GPT-5等最先进模型在29%的情况下会产生谄媚答案，现有缓解策略能显著减少但无法完全消除该行为。


<details>
  <summary>Details</summary>
Motivation: 现有数学基准主要关注最终答案问题，依赖简单且可能被污染的数据集，使用合成修改构造病态问题而非可证明错误的良构问题，无法有效评估LLM在定理证明中的谄媚行为。

Method: 基于2025年竞赛问题构建BrokenMath基准，使用LLM扰动生成错误陈述并通过专家评审精炼，采用LLM-as-a-judge框架评估最先进LLM和代理系统。

Result: 发现谄媚行为普遍存在，最佳模型GPT-5在29%的情况下产生谄媚答案。测试时干预和监督微调等缓解策略能显著减少但无法完全消除该行为。

Conclusion: LLM在数学定理证明中存在显著的谄媚问题，限制了其在定理证明中的应用，需要开发更有效的缓解策略。

Abstract: Large language models (LLMs) have recently shown strong performance on
mathematical benchmarks. At the same time, they are prone to hallucination and
sycophancy, often providing convincing but flawed proofs for incorrect
mathematical statements provided by users. This significantly limits the
applicability of LLMs in theorem proving, as verification of these flawed
proofs must be done manually by expert mathematicians. However, existing
benchmarks that measure sycophancy in mathematics are limited: they focus
solely on final-answer problems, rely on very simple and often contaminated
datasets, and construct benchmark samples using synthetic modifications that
create ill-posed questions rather than well-posed questions that are
demonstrably false. To address these issues, we introduce BrokenMath, the first
benchmark for evaluating sycophantic behavior in LLMs within the context of
natural language theorem proving. BrokenMath is built from advanced 2025
competition problems, which are perturbed with an LLM to produce false
statements and subsequently refined through expert review. Using an
LLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems
and find that sycophancy is widespread, with the best model, GPT-5, producing
sycophantic answers 29% of the time. We further investigate several mitigation
strategies, including test-time interventions and supervised fine-tuning on
curated sycophantic examples. These approaches substantially reduce, but do not
eliminate, sycophantic behavior.

</details>


### [371] [LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0](https://arxiv.org/abs/2510.04765)
*Jinbo Wen,Jiawen Kang,Linfeng Zhang,Xiaoying Tang,Jianhang Tang,Yang Zhang,Zhaohui Yang,Dusit Niyato*

Main category: cs.AI

TL;DR: 提出LMM-Incentive机制，使用大型多模态模型和合约理论激励用户生成高质量UGC，解决Web 3.0中的信息不对称和道德风险问题。


<details>
  <summary>Details</summary>
Motivation: Web 3.0中用户可能利用内容策展机制的局限性生成低质量内容获取奖励，这会损害平台性能。需要解决信息不对称导致的逆向选择和道德风险问题。

Method: 1. 基于LMM的合约理论模型激励高质量UGC生成；2. 使用LMM代理评估UGC质量；3. 开发改进的MoE-based PPO算法进行最优合约设计；4. 在以太坊智能合约框架中部署合约。

Result: 仿真结果表明提出的MoE-based PPO算法在合约设计方面优于代表性基准方法，并在以太坊智能合约框架中验证了方案的有效性。

Conclusion: LMM-Incentive机制成功解决了Web 3.0中UGC激励问题，通过LMM技术和改进的PPO算法实现了高质量内容生成的有效激励。

Abstract: Web 3.0 represents the next generation of the Internet, which is widely
recognized as a decentralized ecosystem that focuses on value expression and
data ownership. By leveraging blockchain and artificial intelligence
technologies, Web 3.0 offers unprecedented opportunities for users to create,
own, and monetize their content, thereby enabling User-Generated Content (UGC)
to an entirely new level. However, some self-interested users may exploit the
limitations of content curation mechanisms and generate low-quality content
with less effort, obtaining platform rewards under information asymmetry. Such
behavior can undermine Web 3.0 performance. To this end, we propose
\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive
mechanism for UGC in Web 3.0. Specifically, we propose an LMM-based
contract-theoretic model to motivate users to generate high-quality UGC,
thereby mitigating the adverse selection problem from information asymmetry. To
alleviate potential moral hazards after contract selection, we leverage LMM
agents to evaluate UGC quality, which is the primary component of the contract,
utilizing prompt engineering techniques to improve the evaluation performance
of LMM agents. Recognizing that traditional contract design methods cannot
effectively adapt to the dynamic environment of Web 3.0, we develop an improved
Mixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for
optimal contract design. Simulation results demonstrate the superiority of the
proposed MoE-based PPO algorithm over representative benchmarks in the context
of contract design. Finally, we deploy the designed contract within an Ethereum
smart contract framework, further validating the effectiveness of the proposed
scheme.

</details>


### [372] [Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems](https://arxiv.org/abs/2510.04792)
*Ni Zhang,Zhiguang Cao*

Main category: cs.AI

TL;DR: 提出了混合平衡GFlowNet（HBG）框架，将轨迹平衡和详细平衡相结合，用于解决车辆路径问题，在CVRP和TSP问题上都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的GFlowNet方法通常使用轨迹平衡进行全局优化，但忽略了局部优化；而详细平衡虽然能更好地处理局部优化，但单独使用无法有效解决需要整体轨迹优化的VRP问题。

Method: 提出了混合平衡GFlowNet框架，以原则性和自适应方式整合轨迹平衡和详细平衡，利用两者的互补优势。同时为CVRP等以仓库为中心的场景设计了专门的推理策略。

Result: 将HBG集成到AGFN和GFACS两个GFlowNet求解器中，在CVRP和TSP问题上都实现了持续且显著的改进。

Conclusion: HBG框架通过整合轨迹平衡和详细平衡，提高了解决方案质量和泛化能力，适用于有仓库和无仓库的路径规划问题。

Abstract: Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically
employ Trajectory Balance (TB) to achieve global optimization but often neglect
important aspects of local optimization. While Detailed Balance (DB) addresses
local optimization more effectively, it alone falls short in solving VRPs,
which inherently require holistic trajectory optimization. To address these
limitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which
uniquely integrates TB and DB in a principled and adaptive manner by aligning
their intrinsically complementary strengths. Additionally, we propose a
specialized inference strategy for depot-centric scenarios like the Capacitated
Vehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility
in selecting successors. Despite this specialization, HBG maintains broad
applicability, extending effectively to problems without explicit depots, such
as the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into
two established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate
consistent and significant improvements across both CVRP and TSP, underscoring
the enhanced solution quality and generalization afforded by our approach.

</details>


### [373] [Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning](https://arxiv.org/abs/2510.04817)
*Abhinav Madahar*

Main category: cs.AI

TL;DR: 提出了NLEL（自然语言边缘标注）框架，通过将自然语言指令映射为结构化控制向量，实现更精细、可解释的LM推理控制，解决了现有控制器中意图与执行耦合的问题。


<details>
  <summary>Details</summary>
Motivation: 现有结构化LM推理控制器（如Chain-of-Thought、Tree-of-Thoughts）将'下一步尝试什么'与'如何执行'耦合在一起，只提供粗粒度的全局控制，导致系统脆弱、计算效率低下且难以审计。

Method: 引入标注器-调谐器覆盖层：标注器Λ从父状态和紧凑上下文中生成自然语言标签；调谐器Ψ将标签映射为模式受限的控制向量，包含解码、搜索、生成束大小、检索混合和验证通道等参数。采用严格模式验证和信任域投影确保安全性。

Result: NLEL严格泛化了CoT/ToT方法，证明了在标签条件束下的top-k选择的任意时间单调性，并通过控制向量失真限制了选择器不足。

Conclusion: NLEL提供了一个可解释、模型无关的接口，将意图与执行分离，实现了可控、可审计的LM推理。

Abstract: Controllers for structured LM reasoning (e.g., Chain-of-Thought,
self-consistency, and Tree-of-Thoughts) often entangle what to try next with
how to execute it, exposing only coarse global knobs and yielding brittle,
compute-inefficient, and hard-to-audit behavior. We introduce Natural Language
Edge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form
natural-language directive to each search edge and translates it into a
schema-bounded control vector for decoding, search (branch quotas, exploration
$\beta$), generation bundle size, retrieval mixtures, and verification passes.
A labeller $\Lambda$ emits labels from the parent state and a compact context;
a tuner $\Psi$ maps $(P, L, C)\to \Pi$, with strict schema validation and
trust-region projection around safe defaults. Downstream selection remains
ToT-style with score $S=\mu+\beta\sigma$ and depth-annealed $\beta$. We show
NLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for
top-$k$ selection under label-conditioned bundles, and bound selector shortfall
by control-vector distortion, providing decision-relevant justification for
guards like trust regions and verification passes. We instantiate $\Psi$ as a
prompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH
(subset), StrategyQA, and ARC-Challenge with compute-aware reporting
(success@compute, tokens-per-success) and ablations over $\Lambda$, $\Psi$,
trust-region radius, and control quantization; preregistered forecasts
anticipate accuracy gains at comparable token budgets and improved
success@compute under constraints. NLEL offers an interpretable, model-agnostic
interface that separates intent from execution for controllable, auditable LM
inference.

</details>


### [374] [LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation](https://arxiv.org/abs/2510.04851)
*Dongge Han,Camille Couturier,Daniel Madrigal Diaz,Xuchao Zhang,Victor Rühle,Saravan Rajmohan*

Main category: cs.AI

TL;DR: LEGOMem是一个用于多智能体工作流自动化的模块化程序性记忆框架，通过分解任务轨迹为可重用记忆单元，提升规划和执行能力。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体系统中记忆的设计空间，研究记忆应该放在哪里、如何检索以及哪些智能体受益最大。

Method: 将过去任务轨迹分解为可重用记忆单元，灵活分配给编排器和任务智能体，支持规划和执行。

Result: 实验显示编排器记忆对任务分解和委派至关重要，细粒度智能体记忆提高执行准确性，小模型团队也能从程序性记忆中显著受益。

Conclusion: LEGOMem既是记忆增强智能体系统的实用框架，也是理解多智能体工作流自动化中记忆设计的研究工具。

Abstract: We introduce LEGOMem, a modular procedural memory framework for multi-agent
large language model (LLM) systems in workflow automation. LEGOMem decomposes
past task trajectories into reusable memory units and flexibly allocates them
across orchestrators and task agents to support planning and execution. To
explore the design space of memory in multi-agent systems, we use LEGOMem as a
lens and conduct a systematic study of procedural memory in multi-agent
systems, examining where memory should be placed, how it should be retrieved,
and which agents benefit most. Experiments on the OfficeBench benchmark show
that orchestrator memory is critical for effective task decomposition and
delegation, while fine-grained agent memory improves execution accuracy. We
find that even teams composed of smaller language models can benefit
substantially from procedural memory, narrowing the performance gap with
stronger agents by leveraging prior execution traces for more accurate planning
and tool use. These results position LEGOMem as both a practical framework for
memory-augmented agent systems and a research tool for understanding memory
design in multi-agent workflow automation.

</details>


### [375] [Video Game Level Design as a Multi-Agent Reinforcement Learning Problem](https://arxiv.org/abs/2510.04862)
*Sam Earle,Zehua Jiang,Eugene Vinitsky,Julian Togelius*

Main category: cs.AI

TL;DR: 提出多智能体强化学习方法解决PCGRL中的效率瓶颈，通过分布式生成提高地图生成效率和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有PCGRL研究专注于单智能体生成器，但面临频繁重新计算启发式质量和在大地图中导航的效率瓶颈

Method: 将关卡生成构建为多智能体问题，减少奖励计算次数，让智能体学习更局部、模块化的设计策略

Result: 多智能体关卡生成器在效率上优于单智能体方法，且能更好地泛化到分布外地图形状

Conclusion: 将内容生成视为分布式多智能体任务有利于大规模生成功能性内容

Abstract: Procedural Content Generation via Reinforcement Learning (PCGRL) offers a
method for training controllable level designer agents without the need for
human datasets, using metrics that serve as proxies for level quality as
rewards. Existing PCGRL research focuses on single generator agents, but are
bottlenecked by the need to frequently recalculate heuristics of level quality
and the agent's need to navigate around potentially large maps. By framing
level generation as a multi-agent problem, we mitigate the efficiency
bottleneck of single-agent PCGRL by reducing the number of reward calculations
relative to the number of agent actions. We also find that multi-agent level
generators are better able to generalize to out-of-distribution map shapes,
which we argue is due to the generators' learning more local, modular design
policies. We conclude that treating content generation as a distributed,
multi-agent task is beneficial for generating functional artifacts at scale.

</details>


### [376] [Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution](https://arxiv.org/abs/2510.04886)
*Adi Banerjee,Anirudh Nair,Tarik Borogovac*

Main category: cs.AI

TL;DR: ECHO算法通过分层上下文表示、基于目标分析的评估和共识投票，提高了多智能体系统中错误归因的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前方法在分析复杂交互轨迹时，难以准确一致地定位智能体和步骤级别的故障，需要更有效的错误归因方法。

Method: 结合分层上下文表示、基于目标分析的评估和共识投票，利用基于位置的上下文理解分层，同时保持客观评估标准。

Result: 实验结果显示ECHO在各种多智能体交互场景中优于现有方法，特别是在涉及微妙推理错误和复杂依赖关系的情况下表现突出。

Conclusion: 结构化分层上下文表示与基于共识的客观决策相结合，为多智能体系统中的错误归因提供了更稳健的框架。

Abstract: Error attribution in Large Language Model (LLM) multi-agent systems presents
a significant challenge in debugging and improving collaborative AI systems.
Current approaches to pinpointing agent and step level failures in interaction
traces - whether using all-at-once evaluation, step-by-step analysis, or binary
search - fall short when analyzing complex patterns, struggling with both
accuracy and consistency. We present ECHO (Error attribution through Contextual
Hierarchy and Objective consensus analysis), a novel algorithm that combines
hierarchical context representation, objective analysis-based evaluation, and
consensus voting to improve error attribution accuracy. Our approach leverages
a positional-based leveling of contextual understanding while maintaining
objective evaluation criteria, ultimately reaching conclusions through a
consensus mechanism. Experimental results demonstrate that ECHO outperforms
existing methods across various multi-agent interaction scenarios, showing
particular strength in cases involving subtle reasoning errors and complex
interdependencies. Our findings suggest that leveraging these concepts of
structured, hierarchical context representation combined with consensus-based
objective decision-making, provides a more robust framework for error
attribution in multi-agent systems.

</details>


### [377] [Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding](https://arxiv.org/abs/2510.04899)
*Keane Ong,Wei Dai,Carol Li,Dewei Feng,Hengzhi Li,Jingyao Wu,Jiaee Cheong,Rui Mao,Gianmarco Mengaldo,Erik Cambria,Paul Pu Liang*

Main category: cs.AI

TL;DR: Human Behavior Atlas是一个统一的行为理解基准数据集，包含10万+多模态样本，用于训练统一模型来理解心理和社会行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用专门数据集和单任务系统，缺乏可扩展性、跨任务迁移和泛化能力。需要统一基准来支持心理社会行为的统一模型开发。

Method: 构建Human Behavior Atlas数据集，包含文本、音频、视觉多模态数据，涵盖情感状态、认知状态、病理学和社会过程等任务。训练了三个模型：OmniSapiens-7B SFT、OmniSapiens-7B BAM和OmniSapiens-7B RL。

Result: 在Human Behavior Atlas上训练的模型在各种行为任务上持续优于现有多模态LLM。预训练还能改善向新行为数据集的迁移，使用行为描述符能带来有意义的性能提升。

Conclusion: Human Behavior Atlas通过统一基准减少了冗余和成本，实现了跨任务的高效训练，并增强了行为特征在领域间的泛化能力。

Abstract: Using intelligent systems to perceive psychological and social behaviors,
that is, the underlying affective, cognitive, and pathological states that are
manifested through observable behaviors and social interactions, remains a
challenge due to their complex, multifaceted, and personalized nature. Existing
work tackling these dimensions through specialized datasets and single-task
systems often miss opportunities for scalability, cross-task transfer, and
broader generalization. To address this gap, we curate Human Behavior Atlas, a
unified benchmark of diverse behavioral tasks designed to support the
development of unified models for understanding psychological and social
behaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,
audio, and visual modalities, covering tasks on affective states, cognitive
states, pathologies, and social processes. Our unification efforts can reduce
redundancy and cost, enable training to scale efficiently across tasks, and
enhance generalization of behavioral features across domains. On Human Behavior
Atlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and
OmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models
to consistently outperform existing multimodal LLMs across diverse behavioral
tasks. Pretraining on Human Behavior Atlas also improves transfer to novel
behavioral datasets; with the targeted use of behavioral descriptors yielding
meaningful performance gains.

</details>


### [378] [MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.04935)
*Guoxin Chen,Zile Qiao,Wenqing Wang,Donglei Yu,Xuanzhong Chen,Hao Sun,Minpeng Liao,Kai Fan,Yong Jiang,Penguin Xie,Wayne Xin Zhao,Ruihua Song,Fei Huang*

Main category: cs.AI

TL;DR: MARS是一个多代理系统，通过整合System 1的快速直觉思维和System 2的深思熟虑推理来解决大型推理模型在简单任务中过度分析的问题，并在动态信息环境中实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在简单任务中倾向于过度分析，使用过多的System 2型深思熟虑推理，导致令牌生成效率低下。同时，这些模型难以适应快速变化的环境，因为其预训练数据是静态的。需要一种能够桥接直觉和深思熟虑认知过程的方法。

Method: 提出MARS多代理系统，整合Google搜索、Google Scholar和Python解释器等外部工具来获取最新信息和执行复杂计算。采用分工策略，System 1高效处理和总结大量外部信息，为System 2提供精炼的见解。使用多代理强化学习框架扩展组相对策略优化，通过多轮工具交互、装箱优化和样本平衡策略来同时优化两个系统。

Result: 在具有挑战性的Humanity's Last Exam基准测试上取得了3.86%的显著改进，在7个知识密集型任务上平均提升了8.9%。

Conclusion: MARS的双系统范式在动态信息环境中的复杂推理任务中表现出有效性，验证了整合System 1和System 2认知过程的优势。

Abstract: Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strategically integrates multiple external tools,
such as Google Search, Google Scholar, and Python Interpreter, to access
up-to-date information and execute complex computations, while creating a
specialized division of labor where System 1 efficiently processes and
summarizes high-volume external information, providing distilled insights that
expand System 2's reasoning context without overwhelming its capacity.
Furthermore, we propose a multi-agent reinforcement learning framework
extending Group Relative Policy Optimization to simultaneously optimize both
systems with multi-turn tool interactions, bin-packing optimization, and sample
balancing strategies that enhance collaborative efficiency. Extensive
experiments demonstrate MARS achieves substantial improvements of 3.86% on the
challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%
across 7 knowledge-intensive tasks, validating the effectiveness of our
dual-system paradigm for complex reasoning in dynamic information environments.

</details>


### [379] [Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits](https://arxiv.org/abs/2510.04952)
*Ailiya Borjigin,Cong He*

Main category: cs.AI

TL;DR: 提出一个跨市场算法交易系统，结合强化学习执行代理与独立合规代理，通过约束马尔可夫决策过程确保交易执行质量与合规性。


<details>
  <summary>Details</summary>
Motivation: 解决算法交易中执行质量与合规监管的平衡问题，确保交易在参与限制、价格区间和自交易规避等硬约束下安全执行。

Method: 使用近端策略优化训练执行代理，运行时动作屏蔽确保行动安全，并添加零知识合规审计层生成加密证明。

Result: 在ABIDES多市场模拟器中，学习策略降低了执行差额和方差，在压力测试中未观察到约束违规，效果在95%置信水平下显著。

Conclusion: 该工作融合了最优执行、安全强化学习、监管技术和可验证AI，讨论了伦理考量、局限性及实际部署路径。

Abstract: We present a cross-market algorithmic trading system that balances execution
quality with rigorous compliance enforcement. The architecture comprises a
high-level planner, a reinforcement learning execution agent, and an
independent compliance agent. We formulate trade execution as a constrained
Markov decision process with hard constraints on participation limits, price
bands, and self-trading avoidance. The execution agent is trained with proximal
policy optimization, while a runtime action-shield projects any unsafe action
into a feasible set. To support auditability without exposing proprietary
signals, we add a zero-knowledge compliance audit layer that produces
cryptographic proofs that all actions satisfied the constraints. We evaluate in
a multi-venue, ABIDES-based simulator and compare against standard baselines
(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and
variance while exhibiting no observed constraint violations across stress
scenarios including elevated latency, partial fills, compliance module
toggling, and varying constraint limits. We report effects at the 95%
confidence level using paired t-tests and examine tail risk via CVaR. We
situate the work at the intersection of optimal execution, safe reinforcement
learning, regulatory technology, and verifiable AI, and discuss ethical
considerations, limitations (e.g., modeling assumptions and computational
overhead), and paths to real-world deployment.

</details>


### [380] [Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI](https://arxiv.org/abs/2510.04978)
*Kun Xiang,Terry Jingchen Zhang,Yinya Huang,Jixi He,Zirong Liu,Yueling Tang,Ruizhe Zhou,Lijing Luo,Youpeng Wen,Xiuwei Chen,Bingqian Lin,Jianhua Han,Hang Xu,Hanhui Li,Bin Dong,Xiaodan Liang*

Main category: cs.AI

TL;DR: 本文对物理AI进行了全面综述，区分了理论物理推理和应用物理理解，系统分析了基于物理的方法如何增强AI在符号推理、具身系统和生成模型中的现实世界理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前物理感知和符号物理推理各自发展，缺乏统一的桥梁框架，需要整合物理定律到AI系统中以实现真正的物理理解。

Method: 通过系统分析近期进展，建立理论物理推理与应用物理理解的清晰区分，并研究物理基础方法如何增强AI的现实世界理解能力。

Result: 提出了将学习建立在物理原理和具身推理过程中的智能系统，超越模式识别实现真正的物理定律理解。

Conclusion: 展望了能够解释物理现象并预测未来状态的下一代世界模型，推动安全、可泛化和可解释的AI系统发展。

Abstract: The rapid advancement of embodied intelligence and world models has
intensified efforts to integrate physical laws into AI systems, yet physical
perception and symbolic physics reasoning have developed along separate
trajectories without a unified bridging framework. This work provides a
comprehensive overview of physical AI, establishing clear distinctions between
theoretical physics reasoning and applied physical understanding while
systematically examining how physics-grounded methods enhance AI's real-world
comprehension across structured symbolic reasoning, embodied systems, and
generative models. Through rigorous analysis of recent advances, we advocate
for intelligent systems that ground learning in both physical principles and
embodied reasoning processes, transcending pattern recognition toward genuine
understanding of physical laws. Our synthesis envisions next-generation world
models capable of explaining physical phenomena and predicting future states,
advancing safe, generalizable, and interpretable AI systems. We maintain a
continuously updated resource at
https://github.com/AI4Phys/Awesome-AI-for-Physics.

</details>


### [381] [LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game](https://arxiv.org/abs/2510.04980)
*Fangzhou Liang,Tianshi Zheng,Chunkit Chan,Yauwai Yim,Yangqiu Song*

Main category: cs.AI

TL;DR: LLM-Hanabi基准测试使用合作游戏Hanabi评估LLM的心智理论和推理能力，发现一阶心智理论（理解他人意图）比二阶心智理论（预测他人理解）与游戏表现相关性更强


<details>
  <summary>Details</summary>
Motivation: 评估LLM在动态协作环境中推断他人行为背后动机的心智理论能力，这在多智能体协作中至关重要

Method: 开发LLM-Hanabi基准测试，使用合作游戏Hanabi，建立自动化评估系统测量游戏表现和心智理论熟练度

Result: 发现心智理论与游戏成功呈显著正相关，一阶心智理论比二阶心智理论与表现相关性更强

Conclusion: 对于有效的AI协作，准确理解伙伴动机的能力比高阶推理更关键，优先发展一阶心智理论是提升未来模型协作能力的有前景方向

Abstract: Effective multi-agent collaboration requires agents to infer the rationale
behind others' actions, a capability rooted in Theory-of-Mind (ToM). While
recent Large Language Models (LLMs) excel at logical inference, their ability
to infer rationale in dynamic, collaborative settings remains under-explored.
This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative
game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework
features an automated evaluation system that measures both game performance and
ToM proficiency. Across a range of models, we find a significant positive
correlation between ToM and in-game success. Notably, first-order ToM
(interpreting others' intent) correlates more strongly with performance than
second-order ToM (predicting others' interpretations). These findings highlight
that for effective AI collaboration, the ability to accurately interpret a
partner's rationale is more critical than higher-order reasoning. We conclude
that prioritizing first-order ToM is a promising direction for enhancing the
collaborative capabilities of future models.

</details>


### [382] [Think Then Embed: Generative Context Improves Multimodal Embedding](https://arxiv.org/abs/2510.05014)
*Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan*

Main category: cs.AI

TL;DR: 提出了Think-Then-Embed（TTE）框架，通过引入推理器生成推理轨迹来增强复杂多模态指令的理解，在MMEB-V2基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将多模态大语言模型仅作为编码器使用，忽视了其生成能力，在处理复杂指令和组合推理时效果不佳。

Method: TTE框架包含推理器和嵌入器：推理器MLLM先生成解释复杂查询的推理轨迹，然后嵌入器基于原始查询和中间推理生成表示。

Result: 在MMEB-V2基准上超越专有模型；通过微调小型MLLM推理器，在开源模型中取得最佳性能，相比近期模型提升7%；探索了推理器和嵌入器集成策略。

Conclusion: 显式推理步骤能够更细致地理解复杂多模态指令，TTE框架在性能和效率方面都取得了显著改进。

Abstract: There is a growing interest in Universal Multimodal Embeddings (UME), where
models are required to generate task-specific representations. While recent
studies show that Multimodal Large Language Models (MLLMs) perform well on such
tasks, they treat MLLMs solely as encoders, overlooking their generative
capacity. However, such an encoding paradigm becomes less effective as
instructions become more complex and require compositional reasoning. Inspired
by the proven effectiveness of chain-of-thought reasoning, we propose a general
Think-Then-Embed (TTE) framework for UME, composed of a reasoner and an
embedder. The reasoner MLLM first generates reasoning traces that explain
complex queries, followed by an embedder that produces representations
conditioned on both the original query and the intermediate reasoning. This
explicit reasoning step enables more nuanced understanding of complex
multimodal instructions. Our contributions are threefold. First, by leveraging
a powerful MLLM reasoner, we achieve state-of-the-art performance on the
MMEB-V2 benchmark, surpassing proprietary models trained on massive in-house
datasets. Second, to reduce the dependency on large MLLM reasoners, we finetune
a smaller MLLM reasoner using high-quality embedding-centric reasoning traces,
achieving the best performance among open-source models with a 7% absolute gain
over recently proposed models. Third, we investigate strategies for integrating
the reasoner and embedder into a unified model for improved efficiency without
sacrificing performance.

</details>


### [383] [Look-ahead Reasoning with a Learned Model in Imperfect Information Games](https://arxiv.org/abs/2510.05048)
*Ondřej Kubíček,Viliam Lisý*

Main category: cs.AI

TL;DR: LAMIR算法通过学习不完全信息游戏的抽象模型，在测试时进行前瞻推理，解决了传统方法在复杂游戏中难以扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 测试时推理能提升AI代理性能，但在不完全信息游戏中，由于需要复杂的前瞻推理技术和大量状态，传统方法难以扩展。

Method: LAMIR算法直接从智能体-环境交互中学习不完全信息游戏的抽象模型，训练后的模型用于测试时的前瞻推理，通过抽象化将子游戏规模控制在可管理范围内。

Result: 实验表明，在足够容量下LAMIR能学习到精确的游戏结构，在有限容量下仍能学习到有价值的抽象，提升预训练智能体在大型游戏中的表现。

Conclusion: LAMIR通过模型抽象使理论上合理的前瞻推理在之前无法扩展的游戏中变得可行，显著提升了游戏性能。

Abstract: Test-time reasoning significantly enhances pre-trained AI agents'
performance. However, it requires an explicit environment model, often
unavailable or overly complex in real-world scenarios. While MuZero enables
effective model learning for search in perfect information games, extending
this paradigm to imperfect information games presents substantial challenges
due to more nuanced look-ahead reasoning techniques and large number of states
relevant for individual decisions. This paper introduces an algorithm LAMIR
that learns an abstracted model of an imperfect information game directly from
the agent-environment interaction. During test time, this trained model is used
to perform look-ahead reasoning. The learned abstraction limits the size of
each subgame to a manageable size, making theoretically principled look-ahead
reasoning tractable even in games where previous methods could not scale. We
empirically demonstrate that with sufficient capacity, LAMIR learns the exact
underlying game structure, and with limited capacity, it still learns a
valuable abstraction, which improves game playing performance of the
pre-trained agents even in large games.

</details>


### [384] [Staircase Streaming for Low-Latency Multi-Agent Inference](https://arxiv.org/abs/2510.05059)
*Junlin Wang,Jue Wang,Zhen,Xu,Ben Athiwaratkun,Bhuwan Dhingra,Ce Zhang,James Zou*

Main category: cs.AI

TL;DR: 提出阶梯式流式处理方法来降低多智能体推理的延迟，通过部分中间输出立即生成最终响应，将首次令牌时间减少高达93%


<details>
  <summary>Details</summary>
Motivation: 多智能体推理方法虽然能提高响应质量，但显著增加了首次令牌时间，对延迟敏感应用造成挑战

Method: 阶梯式流式处理：不等待完整中间输出，一旦收到部分中间输出就开始生成最终响应

Result: 实验结果显示阶梯式流式处理将首次令牌时间减少高达93%，同时保持响应质量

Conclusion: 阶梯式流式处理是解决多智能体推理延迟问题的有效方法

Abstract: Recent advances in large language models (LLMs) opened up new directions for
leveraging the collective expertise of multiple LLMs. These methods, such as
Mixture-of-Agents, typically employ additional inference steps to generate
intermediate outputs, which are then used to produce the final response. While
multi-agent inference can enhance response quality, it can significantly
increase the time to first token (TTFT), posing a challenge for
latency-sensitive applications and hurting user experience. To address this
issue, we propose staircase streaming for low-latency multi-agent inference.
Instead of waiting for the complete intermediate outputs from previous steps,
we begin generating the final response as soon as we receive partial outputs
from these steps. Experimental results demonstrate that staircase streaming
reduces TTFT by up to 93% while maintaining response quality.

</details>


### [385] [CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano](https://arxiv.org/abs/2412.18708)
*Vivek Vellaiyappan Surulimuthu,Aditya Karnam Gururaj Rao*

Main category: cs.AI

TL;DR: 提出了Chunked Augmented Generation (CAG)架构，专门解决Chrome内置Gemini Nano模型的上下文窗口限制问题，通过智能分块处理策略实现在浏览器中高效处理大量内容。


<details>
  <summary>Details</summary>
Motivation: Chrome集成Gemini Nano虽然将AI能力直接带入浏览器，但其受限的上下文窗口难以处理大型输入，需要克服这一限制以充分利用浏览器内AI功能。

Method: 采用智能输入分块和处理策略，将大内容分解为可管理的块，在浏览器约束内保持模型性能。

Result: CAG在Chrome中处理大型文档和数据集方面表现出色，使复杂AI能力可通过浏览器访问，无需依赖外部API。

Conclusion: CAG架构成功解决了浏览器内AI模型的上下文限制问题，为在Chrome中直接处理大量内容提供了可行方案。

Abstract: We present Chunked Augmented Generation (CAG), an architecture specifically
designed to overcome the context window limitations of Google Chrome's built-in
Gemini Nano model. While Chrome's integration of Gemini Nano represents a
significant advancement in bringing AI capabilities directly to the browser,
its restricted context window poses challenges for processing large inputs. CAG
addresses this limitation through intelligent input chunking and processing
strategies, enabling efficient handling of extensive content while maintaining
the model's performance within browser constraints. Our implementation
demonstrates particular efficacy in processing large documents and datasets
directly within Chrome, making sophisticated AI capabilities accessible through
the browser without external API dependencies. Get started now at
https://github.com/vivekVells/cag-js.

</details>
