<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 173]
- [cs.CL](#cs.CL) [Total: 75]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: 基于自由能原理，仅从广告视频的场景级表达特征量化"愉悦度"、"惊喜"和"习惯化"情绪，无需生理信号或主观评分等外部信息。


<details>
  <summary>Details</summary>
Motivation: 广告观看中的情绪反应对理解媒体效果至关重要，但现有方法依赖外部信息。需要建立无需生理信号或主观评分的可解释情绪估计方法基础。

Method: 利用自由能原理，从1059个15秒食品广告视频的场景级表达特征中，使用Kullback-Leibler散度(KLD)捕捉预测误差，贝叶斯惊喜(BS)捕捉信念更新，不确定性(UN)反映先验模糊性，共同构成自由能核心组件。

Result: KLD反映品牌呈现相关的"愉悦度"，BS捕捉信息复杂性引发的"惊喜"，UN反映元素类型和空间排列不确定性驱动的"惊喜"。识别出三种特征情绪模式：不确定刺激、持续高情绪、瞬时峰值衰减。在9种超参数设置和6类日本广告视频上验证了方法的稳健性和泛化性。

Conclusion: 该方法为无需外部信息的可解释情绪估计提供了方法论基础，可扩展到更广泛的表达元素整合和主观评分验证，最终支持开发更具吸引力的广告视频创作技术。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [2] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: EgoGrasp：首个从动态单目第一人称视频重建世界空间手物交互的方法，通过多阶段框架解决现有方法在时间动态和全局一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 准确的世界空间手物交互重建对于理解人类行为和实现具身智能、虚拟现实应用至关重要。现有方法局限于单图像或相机坐标系，无法建模时间动态或一致的全局轨迹，且在动态相机和频繁遮挡的第一人称视频中表现不佳。

Method: 提出多阶段框架：1）基于新开发的空间智能模型的鲁棒预处理流程；2）基于解耦扩散模型的全身手物交互先验模型（无模板、可扩展至多物体）；3）多目标测试时优化范式。

Result: 实验证明该方法在世界空间手物交互重建方面达到最先进的性能。

Conclusion: EgoGrasp成功解决了从动态第一人称视频重建世界空间手物交互的挑战，为理解人类行为和实现相关应用提供了有效解决方案。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [3] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 当前开源扩散模型能生成表面逼真的身份证件伪造品，但无法达到法证级真实性，相关风险可能被高估


<details>
  <summary>Details</summary>
Motivation: 随着生成式图像模型在真实性方面取得显著进展，公众担心其可能被滥用于文件伪造。本研究旨在评估当代开源扩散模型是否能生成足以绕过人工或自动验证系统的身份证件伪造品。

Method: 使用多种公开可用的生成模型家族（包括Stable Diffusion、Qwen、Flux、Nano-Banana等），评估文本到图像和图像到图像的生成流程。

Result: 当前生成模型能够模拟表面层次的文件美学，但无法复制结构和法证真实性。生成式身份证件深度伪造品达到法证级真实性的风险可能被高估。

Conclusion: 机器学习从业者与文件法证专家之间的合作对于现实风险评估具有重要价值，当前技术尚无法产生法证级真实的身份证件伪造品。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [4] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 该研究比较了从头训练的CNN与迁移学习方法（ResNet50、DenseNet121、EfficientNet-B0）在儿童肺炎检测中的性能，发现微调后的ResNet50达到近乎完美的准确率（99.43%）。


<details>
  <summary>Details</summary>
Motivation: 肺炎是五岁以下儿童的主要死因，每年导致超过70万例死亡。胸部X光片的准确诊断受到放射科医生可用性和诊断变异性的限制，需要开发自动化的辅助诊断工具。

Method: 使用5,216张儿童胸部X光片数据集，按80/10/10比例分为训练、验证和测试集。比较了从头训练的CNN与三种迁移学习模型（ResNet50、DenseNet121、EfficientNet-B0），评估了冻结主干网络和微调两种策略。使用准确率、F1分数和AUC进行评估，并通过Grad-CAM提供可解释性可视化。

Result: 微调后的ResNet50表现最佳：准确率99.43%、F1分数99.61%、AUC 99.93%，仅3例误分类。微调策略平均比冻结主干网络模型高出5.5个百分点。Grad-CAM可视化确认模型关注临床相关的肺部区域。

Conclusion: 迁移学习结合微调策略在儿童肺炎检测中显著优于从头训练的CNN，达到近乎完美的准确率。该系统在资源有限的环境中具有作为筛查工具的潜力。未来工作应在多中心和成人数据集上验证这些发现。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [5] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 该研究对心脏超声分割文献进行综述，并在CAMUS数据集上对U-Net、Attention U-Net和TransUNet三种架构进行统一基准测试，比较不同预处理方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有综述大多总结心脏成像和深度学习进展，但缺乏将这些概述与统一、可复现的实验基准相结合的工作。本研究旨在填补这一空白。

Method: 结合心脏超声分割文献综述，在CAMUS数据集上对三种架构进行控制性比较，涵盖多种预处理路径：原生NIfTI数据、16位PNG导出、GPT辅助多边形伪标签、以及数千个未标记帧的自监督预训练。

Result: 原生NIfTI训练的U-Net达到94%平均Dice分数，PNG-16位流程为91%。Attention U-Net在小区域和低对比度区域有改进，TransUNet在挑战性帧上表现最强泛化能力，特别是自监督预训练初始化时。

Conclusion: 贡献包括：三种架构在标准化CAMUS预处理下的统一基准；超声数据准备的实用指导；以及可扩展自监督和GPT辅助标注流程的前景展望。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [6] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: MCLSC 是一种用于资源受限边缘设备的视觉态势感知系统，通过运动补偿潜在语义画布减少分割计算，实现高效语义记忆


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上实现实时视觉态势感知面临计算成本高的挑战，特别是密集的语义分割任务需要大量计算资源

Method: 使用两个潜在语义画布（静态层和动态层），在稳定坐标系中维护语义元数据；采用运动门控机制，仅在检测到运动时触发昂贵的全景分割（Mask2Former），通过运动补偿保持一致的坐标系

Result: 在480p视频上，分割调用减少30倍以上，端到端处理时间降低20倍以上，同时保持连贯的静态/动态语义覆盖

Conclusion: MCLSC 通过运动补偿和语义记忆机制，在边缘设备上实现了高效的视觉态势感知，显著降低了计算开销

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [7] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

TL;DR: VLOrdinalFormer：基于视觉语言引导的序数学习框架，用于膝关节骨关节炎的自动分级，结合ViT骨干网络、CORAL序数回归和CLIP语义对齐，在KL分级上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎是全球致残的主要原因，使用Kellgren-Lawrence分级系统进行准确评估对临床决策至关重要。然而，早期阶段（特别是KL1和KL2）的影像学区别很细微，导致放射科医生之间存在观察者间差异，需要更准确和一致的自动化分级方法。

Method: 提出VLOrdinalFormer框架：1）使用ViT-L16作为骨干网络；2）结合CORAL序数回归方法；3）引入CLIP驱动的语义对齐模块，将临床相关的文本概念（如关节间隙狭窄、骨赘形成、软骨下硬化）融入模型；4）采用分层五折交叉验证、类别感知重加权和测试时增强等技术提高鲁棒性。

Result: 在OAI kneeKL224数据集上的实验表明，VLOrdinalFormer在宏观F1分数和总体准确率上优于CNN和ViT基线模型，特别是对KL1和KL2分级有显著性能提升，同时不损害轻度和重度病例的分类准确性。可解释性分析确认模型关注临床相关的解剖区域。

Conclusion: 视觉语言对齐的序数变换器可作为膝关节骨关节炎分级和疾病进展评估的可靠、可解释工具，在常规放射学实践中具有应用潜力。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [8] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

TL;DR: VideoCuRL：一种新颖的强化学习课程框架，将视频理解难度分解为视觉时间感知负载和认知推理深度两个正交维度，通过2D课程网格和动态训练策略显著提升视频语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式主要依赖随机数据洗牌或基于标量难度度量的简单课程策略，这些标量度量无法区分视频理解中的两个正交挑战：视觉时间感知负载和认知推理深度。需要一种更精细的难度分解方法来提升视频语言模型的训练效果。

Method: 提出VideoCuRL框架：1）将难度分解为视觉时间感知负载和认知推理深度两个维度；2）使用无需训练的高效代理（光流和关键帧熵评估视觉复杂度，校准惊奇度评估认知复杂度）将数据映射到2D课程网格；3）采用能力感知的对角波前策略从基础对齐到复杂推理进行训练调度；4）引入动态稀疏KL和结构化重访来稳定训练，防止奖励崩溃和灾难性遗忘。

Result: 在推理任务上比强RL基线提升2.5分（VSI-Bench），在感知任务上提升2.9分（VideoMME）。显著消除了基于生成的课程方法带来的推理开销，为稳健的视频后训练提供了可扩展解决方案。

Conclusion: VideoCuRL通过将难度分解为视觉和认知两个正交维度，提供了一种更精细、高效的强化学习课程框架，显著提升了视频语言模型的性能，同时避免了传统方法的计算开销问题，为视频后训练提供了可扩展的解决方案。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [9] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

TL;DR: 该研究系统比较了五种CNN骨干网络在印尼蜡染风格迁移中的性能，发现ResNet架构在保持相似感知质量的同时，计算效率比VGG高16倍，收敛速度快5-6倍，更适合资源受限环境下的实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有神经风格迁移方法主要基于VGG架构，虽然风格表达能力强，但计算和内存需求高，限制了在资源受限环境中的实际应用，特别是在印尼蜡染数字保存和生成方面。

Method: 通过245个受控实验，系统比较了VGG16、VGG19、Inception V3、ResNet50和ResNet101五种CNN骨干网络，结合定量指标、定性评估和统计分析，考察结构保持、风格行为和计算效率之间的权衡。

Result: 骨干网络选择对结构相似性无显著差异（SSIM p=0.83），但ResNet架构比VGG收敛快5-6倍，FLOPs减少16倍以上（0.63 vs 10.12 GFLOPs），同时保持相似感知质量（LPIPS=0.53）。VGG产生更密集的绘画纹理，ResNet更注重几何稳定性和笔触保持，Inception V3表现中间但噪声较多。

Conclusion: 研究将NST中的架构选择从最大化风格强度重新定位为效率感知和结构保持的部署，强调ResNet骨干网络作为可扩展、面向工业的蜡染生成的实用基础。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [10] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

TL;DR: CornViT：一个三阶段卷积视觉Transformer框架，用于玉米籽粒分级，包括纯度检测、形态分类和胚芽朝向识别，在三个任务上分别达到93.76%、94.11%和91.12%的准确率。


<details>
  <summary>Details</summary>
Motivation: 玉米籽粒分级对种子认证、定向播种和育种至关重要，但目前主要依赖人工检测，效率低且主观性强。需要自动化、准确的籽粒质量评估系统。

Method: 提出CornViT三阶段CvT-13分类器框架：第一阶段区分纯籽粒与杂质；第二阶段将纯籽粒分为扁平形和圆形；第三阶段检测纯扁平籽粒的胚芽朝向（上/下）。使用ImageNet-22k预训练的CvT-13骨干网络进行头部微调。

Result: 在三个任务上分别达到93.76%（纯度）、94.11%（形态）和91.12%（胚芽朝向）的测试准确率，显著优于ResNet-50（76.56-81.02%）和DenseNet-121（86.56-89.38%）。发布了三个数据集和Flask网络应用。

Conclusion: CornViT框架、精心标注的数据集和网络应用为玉米籽粒质量评估提供了可部署的自动化解决方案，卷积增强的自注意力机制在籽粒分析中具有优势。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [11] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 研究评估GPT-4o、GPT-4o-mini和Claude 3.5等视觉语言模型在垃圾分类回收预测中的表现，包括物品匹配、尺寸适配、地域规则调整、污染损坏处理和多材料物品识别等复杂场景。


<details>
  <summary>Details</summary>
Motivation: 公众在垃圾分类回收时面临准确判断物品可回收性和正确处置方法的困难，需要智能技术辅助提升回收效率和环保实践。

Method: 使用精选图像数据集评估三种先进视觉语言模型（GPT-4o、GPT-4o-mini、Claude 3.5）的回收预测能力，包括基础匹配、尺寸适配，并特别测试了三个挑战场景：地域规则适应、污染损坏识别、多材料物品处理。

Result: 研究发现这些模型在上下文理解方面相比前代有显著进步，但仍存在不足。模型在复杂场景下的表现揭示了当前技术的局限性。

Conclusion: 上下文感知模型的持续改进对于提升公众回收实践和推进环境可持续发展至关重要，当前模型虽有进步但仍需进一步优化。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [12] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS：一种使用稀疏语义掩码从3D高斯泼溅重建中去除背景杂波和漂浮物的方法，实现60-80%模型压缩


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术产生高质量场景重建，但会生成数十万个虚假高斯（漂浮物），这些伪影会遮挡感兴趣物体并增加模型大小，阻碍在带宽受限应用中的部署

Method: 结合白名单空间过滤与颜色引导验证和离群点去除的多阶段方法：1）通过投影到掩码区域进行白名单过滤；2）深度缓冲颜色验证；3）基于邻居的离群点去除

Result: 在Tanks and Temples数据集上，Clean-GS将文件大小从125MB减少到47MB，同时保持渲染质量，实现60-80%模型压缩

Conclusion: Clean-GS使用仅3个分割掩码（1%的视图）的语义信息来识别和去除不属于目标物体的高斯，使3DGS模型适用于Web部署和AR/VR应用

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [13] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: TDA-Alz：一种基于拓扑数据分析（TDA）和集成学习的新型阿尔茨海默病严重程度四阶段分类框架，在OASIS-1 MRI数据集上达到98.19%准确率和99.75% AUC，优于或匹配最先进的深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）严重程度从脑磁共振成像（MRI）的准确高效分类仍然是一个关键挑战，特别是在数据有限和模型可解释性方面存在问题。当前深度学习方法需要大量数据、计算资源和数据增强，且缺乏可解释性。

Method: 提出TDA-Alz框架：1）使用拓扑数据分析（TDA）提取脑MRI的内在结构模式的拓扑描述符；2）通过特征选择保留最具区分性的拓扑特征；3）采用集成学习策略进行稳健的多类别分类。该方法不依赖深度卷积架构或大量数据增强。

Result: 在OASIS-1 MRI数据集上实验表明：准确率达到98.19%，AUC达到99.75%，优于或匹配在OASIS和OASIS衍生数据集上报告的最先进深度学习方法。框架无需数据增强、预训练网络或大规模计算资源，计算效率高且速度快。

Conclusion: TDA-Alz为MRI基础的阿尔茨海默病严重程度分类提供了一个强大、轻量级且可解释的深度学习方法替代方案。拓扑描述符提供了更好的可解释性，特征直接与脑MRI的结构特征相关联。该方法在现实世界临床决策支持系统中具有强大潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [14] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

TL;DR: 使用3D卷积神经网络在无造影剂CT图像中自动分类肺栓塞，准确率达85%，AUC为0.84


<details>
  <summary>Details</summary>
Motivation: 传统使用造影剂的CT肺动脉造影诊断肺栓塞存在风险：造影剂可能导致慢性肾病患者的急性肾损伤，且需要等待时间，可能延误急性肺栓塞患者的黄金治疗时机

Method: 采用3D卷积神经网络模型，在无造影剂的CT图像上进行肺栓塞自动分类

Result: 模型在无造影剂CT图像上的肺栓塞分类准确率达到85%，AUC为0.84，证明了该方法的可行性

Conclusion: 深度学习技术可以在无造影剂CT图像中有效诊断肺栓塞，为高风险患者提供了更安全、更快速的诊断方案

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [15] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 该研究提出了一种从顾客轨迹中提取"货架访问"行为的算法，用于分析零售店中的顾客浏览意图，并在不同商店环境中验证了算法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在零售业客户服务角色中的部署挑战，需要自主理解购物者意图。本研究旨在通过分析实体店顾客活动来理解购物者浏览行为。

Method: 开发了从基于机器视觉的3D跟踪和顶置摄像头获取的轨迹中提取"货架访问"行为的算法。使用两个不同商店收集的轨迹数据集（8138条和15129条）进行独立校准，并由人工标注验证。

Result: 算法在不同商店环境中都能有效识别顾客浏览活动，展示了良好的泛化能力。研究还分析了大规模轨迹数据中的顾客浏览模式及其与实际购买行为的关系。

Conclusion: 货架浏览信息可用于零售规划和人机交互场景，为零售业智能分析和机器人部署提供了有价值的数据支持。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [16] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: ShadowGS：基于3D高斯泼溅的卫星影像阴影建模框架，通过物理渲染方程和光线追踪技术解决多时相卫星影像中阴影不一致问题，提升3D重建精度和阴影解耦效果。


<details>
  <summary>Details</summary>
Motivation: 多时相卫星影像中，由于光照条件变化，阴影存在显著不一致性，这影响了3D重建的几何精度和阴影解耦效果。现有3D高斯泼溅方法在处理这类阴影问题时存在局限性。

Method: 基于3D高斯泼溅框架，结合遥感物理渲染方程和高效光线追踪技术，精确建模几何一致的阴影；引入阴影一致性约束提升3D重建几何精度；采用阴影图先验改善稀疏视图输入性能。

Result: 在阴影解耦精度、3D重建精度和新视角合成质量方面优于当前最先进方法，仅需几分钟训练时间；在RGB、全色融合和稀疏视图卫星输入等多种设置下均表现稳健。

Conclusion: ShadowGS能够有效解决多时相卫星影像中的阴影不一致问题，实现精确的阴影建模和高质量的3D重建，为卫星影像处理提供了高效可靠的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [17] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 提出LQDS液体分割数据集和LQDM模型，解决液体分割难题，在14类液体数据集上超越SOTA方法


<details>
  <summary>Details</summary>
Motivation: 液体（水、酒、药品等）在日常生活中无处不在，但机器人安全避让或交互液体需要准确的液体分割。液体分割困难在于：液体外观形状多样，既透明又反射，会呈现背景或周围物体的任意形态

Method: 构建大规模液体数据集LQDS（5000张真实图像，14个类别），设计新颖的液体检测模型LQDM，利用专用边界分支和主分割分支之间的交叉注意力机制来增强分割预测

Result: 在LQDS测试集上的大量实验证明了LQDM的有效性，超越了最先进的方法，为液体语义分割建立了强大的基线

Conclusion: LQDS数据集和LQDM模型为解决液体分割这一具有挑战性的任务提供了有效方案，为机器人安全交互液体环境奠定了基础

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [18] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 论文提出了一个用于评估文本到视频(T2V)模型在物理教育中生成解释性视频能力的基准测试，发现当前模型视觉质量良好但概念准确性不足。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型特别是T2V系统有望通过自动化创建吸引人的视觉解释来改变科学教育，但需要系统评估其在物理教育中的潜力。

Method: 设计了一个专门的物理教育视频生成基准测试，将物理概念分解为细粒度教学点，每个点配有精心设计的提示词，评估T2V模型根据提示生成准确视频的能力。

Result: 当前模型能生成视觉连贯、运动平滑、闪烁少的视频，但概念准确性不可靠。在力学、流体、光学方面表现较好，但在电磁学和热力学等抽象概念上表现不佳。

Conclusion: 研究揭示了教育视频生成中视觉质量与概念正确性之间的差距，希望该基准能帮助社区缩小这一差距，推动开发能够大规模生成准确、符合课程标准的物理教育内容的T2V系统。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [19] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: DCAM：一种利用基于能量的关联记忆动力学的新型深度聚类方法，通过单一目标更紧密地结合表示学习和聚类


<details>
  <summary>Details</summary>
Motivation: 深度聚类中表示学习是可微的，但聚类本质上是离散优化任务，需要各种近似和正则化才能适应标准可微流程，导致表示学习和聚类相对分离

Method: 提出DCAM方法，利用基于能量的关联记忆动力学设计新的损失函数，在单一目标中更紧密地结合表示学习和聚类

Result: DCAM在各种架构选择（卷积、残差或全连接）和数据模态（图像或文本）上都能产生改进的聚类质量

Conclusion: DCAM通过基于能量的关联记忆动力学，成功地将表示学习和聚类更紧密地结合在单一目标中，提高了聚类性能

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [20] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 提出一种结合数据平衡、数据增强、EfficientNetV2-L与通道注意力机制的三阶段渐进学习框架，用于HAM10000数据集的多类皮肤病变分类，达到91.15%准确率，并利用XAI技术增强模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症之一，需要及时准确的诊断。传统诊断方法存在主观性和效率问题，需要开发自动化的深度学习系统来辅助临床诊断。

Method: 1) 高质量数据平衡方法处理类别不平衡；2) 大规模数据增强；3) 结合通道注意力的混合EfficientNetV2-L框架；4) 三阶段渐进学习策略；5) 使用Grad-CAM和显著性图等XAI技术提供可视化解释。

Result: 在HAM10000数据集上取得总准确率91.15%，宏F1分数85.45%，微平均AUC 99.33%。在7个病变类别中均表现良好，特别在黑色素瘤和黑色素细胞痣上表现优异。

Conclusion: 提出的深度学习框架在皮肤病变分类任务中表现出色，XAI技术不仅增强了诊断透明度，还能识别影响分类的视觉特征，提高了临床可信度，有助于辅助皮肤癌诊断。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [21] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出一种新的FSVOS模型，采用局部匹配策略限制搜索空间，通过方向采样实现动态采样区域，结合时空对比学习增强特征一致性，并在新的X射线血管造影数据集上验证性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：标准实现（如空间卷积、深度卷积）效率低下，硬件特定CUDA内核（如可变形和邻域注意力）在非CUDA设备上可移植性差。需要一种更灵活、高效且可移植的视频分割方法。

Method: 1. 采用局部匹配策略限制搜索空间到最相关的相邻像素；2. 通过方向采样视角重新组织局部采样过程，实现非参数采样机制，支持动态变化采样区域；3. 设计监督式时空对比学习方案，增强帧间特征一致性；4. 创建新的多对象分割基准数据集MOSXAV。

Result: 在CADICA、XACV和MOSXAV数据集上的广泛实验表明，提出的FSVOS方法在分割精度和泛化能力（包括已见和未见类别）方面优于当前最先进的视频分割方法。

Conclusion: 该方法提供了增强的灵活性和广泛的临床应用潜力，通过创新的局部匹配策略、方向采样机制和时空对比学习，实现了高效且可移植的视频对象分割。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [22] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: 提出UnrealPose-Gen合成数据生成管道和UnrealPose-1M数据集，解决3D人体姿态数据昂贵且受限于工作室环境的问题


<details>
  <summary>Details</summary>
Motivation: 现实世界中准确标注的3D人体姿态数据获取成本高且受限于工作室环境，而野外数据集缺乏真实标注。需要高质量合成数据来支持计算机视觉任务。

Method: 基于Unreal Engine 5和Movie Render Queue构建离线渲染管道UnrealPose-Gen，生成包含3D关节坐标、2D投影、COCO风格关键点、边界框、相机参数等丰富标注的数据。

Result: 创建了UnrealPose-1M数据集，包含约100万帧，分为5个连贯序列（5个场景、40个动作、5个主体）和3个随机序列（3个场景、100个动作、5个主体），具有广泛的视角覆盖。

Conclusion: 通过合成数据生成管道和数据集，为3D人体姿态估计等任务提供了高质量训练资源，并发布了数据集和生成工具供社区使用。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [23] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: WildIng模型通过整合文本描述与图像特征，提升野生动物识别模型在地理域偏移下的泛化能力，将BioCLIP等基础模型的准确率提高30%。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的野生动物识别模型在相同地理区域训练和测试时表现良好，但在面对不同地理区域（如非洲到美洲）时性能显著下降，主要原因是模型过度依赖图像特征，对背景、光照等地理分布变化敏感。

Method: 提出WildIng模型，整合文本描述与图像特征，通过文本描述捕获物种外观的语义信息，创建对地理域偏移更鲁棒的表示。模型在非洲和美洲两个不同区域的数据集上进行评估。

Result: 实验表明WildIng能显著提升基础模型在地理域偏移下的性能，将BioCLIP等模型的准确率提高30%。例如，CLIP+adapter在非洲数据集上准确率为84.77%，但在美洲数据集上仅16.17%，而WildIng能大幅改善这种性能下降。

Conclusion: 整合文本描述与图像特征能有效提升野生动物识别模型在地理域偏移下的泛化能力，WildIng为解决这一挑战提供了有效方案，代码和模型已开源。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [24] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: 提出了DVGBench无人机隐式视觉定位基准和DroneVG-R1模型，通过I2E-CoT方法将隐式查询转换为显式查询，提升无人机场景下的视觉定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型主要依赖显式指代表达（如位置、大小、颜色），在需要领域知识的隐式视觉定位任务上表现受限，需要专门的无人机隐式视觉定位基准。

Method: 构建了DVGBench无人机隐式视觉定位基准，涵盖六大应用场景；设计了DroneVG-R1模型，集成隐式到显式思维链（I2E-CoT）于强化学习框架中，将隐式查询转换为显式查询。

Result: 评估显示主流模型在隐式视觉定位任务上存在显著局限性；DroneVG-R1通过I2E-CoT方法有效降低了定位难度，提升了推理能力。

Conclusion: DVGBench基准和DroneVG-R1模型为提升无人机智能体的推理能力提供了可行方案，揭示了当前大视觉语言模型在隐式推理方面的不足，为未来研究提供了方向。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [25] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

TL;DR: 本文对通道注意力机制进行了实证研究，比较了SE、ECA和提出的LCA模块，LCA采用自适应一维卷积和分组操作，在保持准确性的同时减少了参数使用。


<details>
  <summary>Details</summary>
Motivation: 注意力机制已成为现代卷积神经网络的重要组成部分，能以最小计算开销带来显著性能提升。然而，不同通道注意力设计在效率与准确性之间的权衡尚未得到充分探索。

Method: 提出了Lite Channel Attention（LCA）模块，采用自适应一维卷积和分组操作来减少参数使用，同时保持有效的注意力行为。在ResNet 18和MobileNetV2架构上，在CIFAR-10数据集上比较了SE、ECA和LCA三种注意力机制。

Result: LCA在ResNet 18上达到94.68%准确率，在MobileNetV2上达到93.10%准确率，与ECA在参数效率上相当，并保持了良好的推理延迟。提供了包括FLOPs、参数数量和GPU延迟测量的全面基准测试。

Conclusion: LCA在资源受限环境中部署注意力增强的CNN提供了实用见解，实现了竞争性的准确性，同时保持了参数效率和推理延迟的优势。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [26] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 提出了一种基于频域早期融合和运动引导空间稀疏化的RGB-事件视觉目标跟踪框架，通过FFT变换和注意力机制有效融合事件模态的高频信息，同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-事件跟踪方法主要依赖特征级融合，未能充分利用事件相机的高动态范围和运动敏感特性，同时对低信息区域进行统一处理，导致不必要的计算开销。

Method: 1) 通过快速傅里叶变换将RGB和事件模态从空间域转换到频域，解耦振幅和相位分量；2) 通过振幅和相位注意力选择性融合高频事件信息到RGB模态；3) 运动引导空间稀疏化模块利用事件相机的运动敏感性捕获目标运动线索与空间概率分布的关系，过滤低信息区域；4) 稀疏的目标相关特征输入骨干网络学习，跟踪头预测最终目标位置。

Result: 在FE108、FELT和COESOT三个广泛使用的RGB-事件跟踪基准数据集上的大量实验证明了该方法的高性能和效率。

Conclusion: 提出的频域早期融合和运动引导空间稀疏化框架能够有效利用事件相机特性，增强特征表示的同时显著减少骨干网络计算，实现了高性能且高效的RGB-事件视觉目标跟踪。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [27] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: ITSELF是一个基于注意力引导的隐式局部对齐框架，用于文本人物搜索任务，通过模型自身注意力构建高显著性token库，无需额外监督实现细粒度对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在捷径学习和虚假相关性问题，导致错位对齐，而注入先验知识会扭曲模态内部结构。研究发现编码器注意力从训练早期就能提供空间精确的证据。

Method: 提出ITSELF框架：1) GRAB将模型自身注意力转换为高显著性token库并应用局部目标；2) MARS聚合多层注意力进行鲁棒选择；3) ATS调度保留预算，从粗到细逐步聚焦判别性细节。

Result: 在三个广泛使用的TBPS基准测试中取得最先进性能，并展现出强大的跨数据集泛化能力，无需额外先验监督。

Conclusion: ITSELF通过注意力引导的隐式局部对齐有效解决了文本人物搜索中的细粒度对齐问题，证明了利用模型自身注意力进行无监督细粒度对应的有效性。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [28] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

TL;DR: 提出一个可重复的深度学习流水线用于白血病细胞分类，结合注意力机制的EfficientNetV2-B3网络，在C-NMC 2019数据集上达到97.89%的F1分数和准确率，参数比VGG16少89%。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病（ALL）是最常见的儿童癌症，传统显微镜诊断存在观察者间变异性和时间限制问题，需要自动化、可靠的分类系统。

Method: 集成注意力机制的卷积神经网络，结合EfficientNetV2-B3与Squeeze-and-Excitation机制，采用数据增强、焦点损失函数处理类别不平衡，按患者划分数据确保评估鲁棒性。

Result: 在C-NMC 2019数据集（12,528张图像，62名患者）上，测试集达到97.89% F1分数和准确率，100次蒙特卡洛实验统计验证显著优于基线方法（p < 0.001），比现有方法提升4.67%，参数比VGG16少89%。

Conclusion: 现代注意力架构能提高白血病细胞分类性能，同时保持适合临床部署的计算效率，注意力机制提供可解释的诊断相关特征可视化。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [29] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: Mono3DV：一种新颖的Transformer框架，通过3D感知二分匹配、3D去噪方案和变分查询去噪机制，解决单目3D检测中DETR架构因排除3D属性导致的匹配不稳定问题，在KITTI基准上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: DETR-like架构在单目3D物体检测中表现出潜力，但存在关键限制：二分匹配过程排除了3D属性。这是由于单目图像3D估计的固有不适定性导致训练不稳定，高质量的3D预测可能被仅基于2D的匹配标准错误抑制，导致次优结果。

Method: 提出Mono3DV框架，包含三个关键创新：1) 3D感知二分匹配策略，将3D几何信息直接整合到匹配成本中；2) 3D去噪方案，稳定整合3D属性时的匹配过程；3) 变分查询去噪机制，解决传统去噪技术中的梯度消失问题。

Result: 在不使用任何外部数据的情况下，该方法在KITTI 3D物体检测基准上取得了最先进的结果。

Conclusion: Mono3DV通过将3D几何信息整合到匹配过程中并解决训练不稳定性，显著提升了单目3D物体检测的性能，证明了3D感知匹配和稳定训练策略的有效性。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [30] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出MASM方法，通过多伪影子空间和选择性层掩码，解耦语义与伪影表示，提升深度伪造检测在跨数据集场景中的泛化鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测在跨数据集和真实复杂场景中面临挑战，主要原因是不同伪造方法引入的伪影分布高度多样，而预训练模型在适应新伪影时容易破坏原有的通用语义结构。现有方法通常依赖全局参数更新或引入额外监督信号，难以有效建模多样伪影同时保持语义稳定性。

Method: 提出基于多伪影子空间和选择性层掩码的MASM方法：1）使用奇异值分解将预训练权重划分为稳定的语义主空间和多个可学习的伪影子空间；2）引入选择性层掩码策略，根据每个伪影子空间的学习状态自适应调节相应网络层的更新行为；3）施加正交性约束和谱一致性约束，引导多个伪影子空间学习互补多样的伪影表示，同时保持稳定的整体谱结构。

Result: 该方法能够解耦语义表示与伪影表示，约束伪影子空间的拟合强度，从而在跨数据集场景中提高泛化鲁棒性。

Conclusion: MASM方法通过显式解耦语义与伪影表示，并约束伪影子空间的拟合，有效解决了深度伪造检测在跨数据集场景中的泛化问题，提升了检测模型的鲁棒性。

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [31] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 本研究评估了迁移学习在奶牛体重预测中的效果，比较了深度图像和点云两种模态，发现迁移学习能显著提升小规模农场的预测性能，且两种模态表现相当。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉为奶牛监测提供了自动化、非侵入性和可扩展的工具，但迁移学习在畜牧业应用中的效果和优化策略尚不明确，且深度图像与点云两种模态的直接比较有限。

Method: 收集了大规模、中规模和小规模农场的俯视深度图像和点云数据，评估了四种深度学习模型：ConvNeXt和MobileViT用于深度图像，PointNet和DGCNN用于点云，比较了三种实验设计下的预测性能。

Result: 迁移学习显著提升了小规模农场的体重预测性能，优于单源学习，且效果与联合学习相当或更好；深度图像和点云模型之间没有一致的性能差异。

Conclusion: 迁移学习特别适合数据共享受限的小规模农场预测场景，因为它只需要预训练模型权重而非原始数据；两种模态在预测性能上表现相当。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [32] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

TL;DR: 该研究评估了机器学习和深度学习模型在LC25000组织病理学图像数据集上的分类性能，发现使用InceptionResNet-v2提取的深度特征训练的模型表现最佳，在噪声环境下也表现出更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着数字病理学的发展，自动化图像分析在临床实践中变得至关重要。本研究旨在评估不同机器学习方法在组织病理学图像分类任务上的性能，特别是在噪声环境下的鲁棒性。

Method: 使用LC25000数据集（包含五类组织病理学图像），采用微调的InceptionResNet-v2网络作为分类器和特征提取器。比较了仅使用预训练网络、使用深度特征以及结合HOG特征的不同方法，并在不同信噪比条件下测试模型鲁棒性。

Result: 微调的InceptionResNet-v2达到96.01%准确率和96.8%平均AUC。使用深度特征的模型表现更优，神经网络模型达到99.99% AUC和99.84%准确率。在噪声环境下，使用深度特征的模型（特别是GBM和KNN）表现出更好的鲁棒性。HOG与深度特征结合能提升性能，但在噪声环境中效果减弱。

Conclusion: 深度特征提取在组织病理学图像分类中具有显著优势，不仅能提高分类性能，还能增强模型在噪声环境下的鲁棒性。这种方法为临床实践中的自动化病理分析提供了可靠的技术支持。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [33] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: LSST提出轻量级分离光谱Transformer架构，用于高效重建压缩感知测量的高光谱图像，通过分组光谱自注意力和深度可分离卷积分别处理光谱和空间特征，并引入焦点光谱损失优化训练。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在多个领域很重要，但从压缩感知测量中高效重建高光谱图像面临挑战。现有方法未能充分利用高光谱图像独特的光谱和空间特性，需要更高效的架构。

Method: 采用分治策略，提出LSST架构：包含分离光谱Transformer块（SSTB）建模光谱关系，使用分组光谱自注意力和光谱混洗操作；轻量级空间卷积块（LSCB）处理空间信息，采用深度可分离卷积和策略排序。还引入焦点光谱损失，动态调整训练权重。

Result: 大量测试表明LSST在性能上优于现有方法，同时需要更少的FLOPs和参数，证明了其效率和有效性。代码已开源。

Conclusion: LSST通过创新的分离光谱Transformer架构和焦点光谱损失，成功实现了高效的高光谱图像重建，平衡了性能和计算效率。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [34] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 该论文提出了一个基于无人机采集的大规模水稻田RGB和多光谱图像数据集，覆盖从育苗到收获的所有生长阶段，包含高分辨率图像和丰富元数据。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏覆盖印度水稻作物所有生长阶段的高分辨率无人机图像数据集，这限制了精准农业、疾病分析和产量估算等研究的发展。

Method: 使用20兆像素RGB相机和5兆像素四波段多光谱相机（红、绿、红边、近红外）在印度安得拉邦维杰亚瓦达地区采集数据，开发标准化操作程序和检查清单确保数据采集的可重复性。

Result: 创建了包含42,430张原始图像（415GB）的数据集，覆盖5英亩土地，地面采样距离为1厘米/像素，包含GPS坐标、飞行高度和环境条件等元数据，并通过Pix4D Fields验证生成正射影像和植被指数图。

Conclusion: 该数据集是少数提供覆盖印度水稻作物所有生长阶段的高分辨率图像和丰富元数据的资源之一，可用于目标喷洒、疾病分析和产量估算等精准农业研究。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [35] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: Luminark是一种无需训练、概率认证的水印方法，利用块级亮度统计进行水印嵌入和检测，适用于多种视觉生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型的水印方法通常需要训练或缺乏理论保证，Luminark旨在提供一种无需训练、具有概率认证的通用水印方案。

Method: 基于块级亮度统计定义水印，服务提供商预定义二进制模式和块级阈值。检测时评估每个块的亮度是否超过阈值，验证生成的二进制模式是否与目标匹配。利用引导技术作为即插即用机制实现水印注入。

Result: 在扩散、自回归和混合框架等9个模型上评估，Luminark始终表现出高检测准确率、对常见图像变换的强鲁棒性以及良好的视觉质量。

Conclusion: Luminark是一种通用、无需训练且具有概率认证的水印方法，适用于多种视觉生成模型，在保持图像质量的同时提供可靠的水印检测。

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [36] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: 本文介绍了600K-KS-OCR数据集，这是一个包含约60.2万个单词级分割图像的大规模合成语料库，专门用于训练和评估针对克什米尔文字的光学字符识别系统。


<details>
  <summary>Details</summary>
Motivation: 解决克什米尔语（一种濒危的达尔德语，使用改良的波斯-阿拉伯文字系统，约有700万人使用）在光学字符识别领域的资源匮乏问题。

Method: 数据集生成方法包含：使用三种传统克什米尔字体、模拟真实世界文档退化的全面数据增强、以及多样化的背景纹理以增强模型鲁棒性。图像渲染为256x64像素，提供多种格式的真实标注。

Result: 创建了包含约60.2万个单词级分割图像的数据集，分布在10个分区档案中，总计约10.6 GB，采用CC-BY-4.0许可证发布。

Conclusion: 该数据集填补了克什米尔语OCR研究的资源空白，为低资源语言的光学字符识别研究提供了重要支持。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [37] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: NarrativeTrack是首个通过细粒度实体中心推理评估MLLMs叙事理解能力的基准，采用组合推理进展框架逐步增加叙事复杂性，揭示MLLMs在视觉转换和时间动态中难以稳健跟踪实体的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视频理解方面存在局限，虽然视觉-语言推理取得进展，但对视频中随时间展开的叙事理解能力尚未充分探索。真正的叙事理解需要能够追踪"谁在何时何地做什么"，并在动态视觉和时间上下文中保持连贯的实体表示。

Method: 提出NarrativeTrack基准，通过组合推理进展框架评估叙事理解：1) 将视频分解为组成实体；2) 采用三层渐进式评估维度：实体存在、实体变化、实体模糊性；3) 使用全自动实体中心管道提取时间接地的实体表示；4) 挑战模型从时间持续性到上下文演化和细粒度感知推理的进阶。

Result: 评估显示：1) 开源通用MLLMs具有强感知接地但弱时间连贯性；2) 视频专用MLLMs能捕捉时间上下文但会幻觉实体上下文；3) 模型在视觉转换和时间动态中难以稳健跟踪实体，常在上下文变化时幻觉身份；4) 揭示了感知接地与时间推理之间的基本权衡。

Conclusion: 叙事理解只有在感知接地和时间推理的整合中才能实现。NarrativeTrack提供了首个系统框架来诊断和推进MLLMs中时间接地的叙事理解能力，揭示了当前模型的局限性并为未来发展指明了方向。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [38] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

TL;DR: 比较自定义CNN架构与预训练/迁移学习模型在五种真实图像数据集上的表现，分析网络深度、残差连接等架构因素对分类和定位性能的影响，为不同任务复杂度提供网络设计指导。


<details>
  <summary>Details</summary>
Motivation: 研究自定义CNN架构与广泛使用的预训练和迁移学习CNN模型在实际图像数据集上的性能差异，分析架构因素如何影响分类和定位任务，为实际应用中的网络选择提供依据。

Method: 使用自定义CNN架构与预训练/迁移学习模型在五个真实图像数据集上进行对比研究，数据集涵盖二分类、细粒度多分类和物体检测场景。分析网络深度、残差连接和特征提取策略等架构因素，并将自定义架构扩展到物体检测任务中。

Result: 更深的CNN架构在细粒度多分类数据集上提供显著性能提升，而轻量级预训练和迁移学习模型在简单二分类任务中仍然高效。自定义架构成功扩展到物体检测任务，能够识别真实交通场景中的未授权三轮车。

Conclusion: 基于对自定义CNN架构与预训练/迁移学习模型的系统分析，本研究提供了根据任务复杂度和资源约束选择合适网络设计的实用指导，强调不同架构在不同任务场景下的适用性。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [39] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

TL;DR: HAQAGen是一个统一生成模型，用于分辨率不变的红外到RGB着色，平衡色彩真实性和结构保真度，通过自适应分辨率推理实现高质量转换。


<details>
  <summary>Details</summary>
Motivation: 解决红外到RGB转换中同时保持全局色彩统计和局部色彩一致性的挑战，同时在不牺牲质量的情况下扩展到高分辨率，并保持纹理保真度和泛化能力。

Method: 1) 结合损失项：通过可微分直方图匹配对齐全局色彩统计，使用感知图像质量度量和基于特征的相似性保持纹理信息；2) 通过SPADE注入局部色调饱和度先验稳定色彩重建；3) 在Mamba骨干网络中引入纹理感知监督保持细节；4) 自适应分辨率推理引擎支持高分辨率转换。

Result: 在FANVID、OMSIV、VCIP2020和RGB2NIR数据集上使用多种评估指标进行广泛评估，相比最先进的基线方法取得一致改进。HAQAGen生成的图像具有更清晰的纹理和自然色彩，在感知指标上获得显著提升。

Conclusion: HAQAGen作为一个可扩展且有效的解决方案，能够在各种成像场景中实现高质量的红外到RGB转换，平衡了色彩真实性和结构保真度。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [40] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

TL;DR: 提出GAI（引导注意力插值）方法，通过自适应插值生成细粒度高分辨率特征，解决语义分割中特征对齐和语义信息不足的问题，实现低延迟高效分割。


<details>
  <summary>Details</summary>
Motivation: 当前坐标引导的低分辨率特征插值方法（如双线性插值）产生的高分辨率特征存在特征错位和上下文信息不足的问题，同时丰富高分辨率特征的语义需要高计算负担，难以满足低延迟推理需求。

Method: 提出GAI方法，通过确定不同分辨率特征之间的空间和语义关系，利用这些关系来插值具有丰富语义的高分辨率特征。GAI可以与任何深度卷积网络集成，用于高效语义分割。

Result: 基于GAI的语义分割网络GAIN在Cityscapes上达到78.8 mIoU和22.3 FPS，在CamVid上达到80.6 mIoU和64.5 FPS（使用NVIDIA 1080Ti GPU），创造了低延迟语义分割的最新SOTA结果。

Conclusion: GAI方法能够有效解决特征错位和语义信息不足的问题，同时保持低延迟推理，为高效语义分割提供了新的解决方案。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [41] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 开发了CardioMOD-Net AI框架，从小鼠超声心动图视频中实现HFpEF的多类别诊断和连续发病时间预测


<details>
  <summary>Details</summary>
Motivation: HFpEF病因复杂且进展缓慢，现有AI模型仅关注二元检测，缺乏共病特异性分型和疾病进展时间预测，需要开发统一框架解决这些问题

Method: 使用小鼠超声心动图视频（CTL、HG、OB、SAH四组），通过HODMD分解提取时序特征，构建共享潜在表示的Vision Transformers，包括分类器用于诊断和回归模块用于预测HFpEF发病时间

Result: 四组总体诊断准确率65%，所有类别超过50%准确率；预后模块预测HFpEF发病时间的均方根误差为21.72周，OB和SAH组预测最准确，预测发病时间与真实分布匹配良好

Conclusion: 该统一框架证明即使在小数据条件下，也能从单一超声心动图视频中获得多类别分型和连续HFpEF发病预测，为临床前HFpEF研究的诊断和预后建模整合提供了基础

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [42] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 论文提出GenCAMO框架，通过生成模型合成高质量伪装场景图像及密集标注，构建大规模伪装数据集GenCAMO-DB，显著提升密集预测模型在复杂伪装场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 伪装密集预测（CDP）在复杂伪装场景理解中至关重要，但高质量、大规模、密集标注的伪装数据集稀缺，主要受限于数据收集和标注成本高昂。

Method: 提出GenCAMO框架：1）构建GenCAMO-DB大规模伪装数据集，包含深度图、场景图、属性描述和文本提示等多模态标注；2）开发环境感知、无需掩码的生成框架，合成高保真伪装图像及密集标注。

Result: 多模态实验表明，GenCAMO通过提供高质量合成数据，显著提升了复杂伪装场景下的密集预测性能。

Conclusion: 生成模型能够有效合成逼真伪装图像及密集标注数据，解决伪装数据集稀缺问题，为伪装密集预测模型提供细粒度表示、先验知识和辅助推理能力。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [43] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: 本文提出OMAN++方法，通过引入社交分组先验和时空位移先验，将一对一匹配放宽为一对多匹配，显著提升了拥挤场景下的视频个体计数性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频个体计数方法在拥挤场景（如地铁通勤）中表现不佳，需要专门针对拥挤动态人流的数据集和方法改进。

Method: 构建武汉地铁人群数据集，提出OMAN++方法：1) 引入社交分组先验，通过隐式上下文生成器和O2M匹配器实现一对多匹配；2) 利用时空位移先验设计位移先验注入器，增强特征提取和模型训练。

Result: OMAN++在标准基准测试（SenseCrowd、CroHD、MovingDroneCrowd）上优于现有方法，在武汉地铁人群数据集上误差降低38.12%，在拥挤场景中表现突出。

Conclusion: 提出的OMAN++方法通过有效利用社交分组和时空位移先验，显著提升了拥挤场景下的视频个体计数性能，为拥挤人流分析提供了强有力的基线模型。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [44] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

TL;DR: 提出MS-ISSM方法，使用径向基函数表示点云局部特征，将失真测量转化为隐函数系数比较，避免不规则数据匹配误差；同时提出ResGrouped-MLP质量评估网络，通过分组编码策略映射多尺度特征差异到感知分数。


<details>
  <summary>Details</summary>
Motivation: 点云的非结构化和不规则特性给客观质量评估带来挑战，特别是在建立准确的感知特征对应关系方面。传统点对点匹配方法在不规则数据中存在匹配误差问题。

Method: 1. MS-ISSM：使用径向基函数连续表示局部特征，将失真测量转化为隐函数系数比较；2. ResGrouped-MLP网络：采用分组编码策略，结合残差块和通道注意力机制，分层处理亮度、色度和几何特征，自适应关注高、中、低尺度的显著失真特征。

Result: 在多个基准测试中，MS-ISSM在可靠性和泛化性方面均优于最先进的指标。

Conclusion: 提出的MS-ISSM方法通过隐式结构相似性测量和多尺度特征处理，有效解决了点云质量评估中的不规则数据匹配问题，取得了优于现有方法的性能。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [45] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: 本文提出RefSR-Adv攻击方法，通过仅扰动参考图像来降低参考超分辨率模型的性能，揭示了RefSR系统的安全漏洞


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而对抗攻击的脆弱性尚未充分探索。本文旨在填补这一研究空白，揭示RefSR系统的安全漏洞

Method: 提出RefSR-Adv对抗攻击方法，通过最大化对抗输出与干净输出的差异，仅扰动参考图像来降低超分辨率输出质量

Result: RefSR-Adv在CNN、Transformer和Mamba架构上均能显著降低性能并产生严重伪影，实验证实低分辨率输入与参考图像的相似性与攻击效果呈正相关

Conclusion: 本研究揭示了RefSR系统的安全漏洞，模型过度依赖参考特征是关键安全缺陷，呼吁研究者关注RefSR的鲁棒性问题

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [46] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT通过联合剪枝和量化压缩KV缓存，实现高效流式3D重建，大幅降低内存使用和推理延迟


<details>
  <summary>Details</summary>
Motivation: StreamVGGT等基于Transformer的3D视觉几何模型虽然性能强大，但在流式推理中KV缓存会无限增长，导致内存消耗和推理延迟不断增加，限制了实际应用的可扩展性

Method: 提出无需调优的方法，通过联合剪枝和量化系统性地压缩KV缓存：1) 通过高效token重要性识别剪枝多视角输入产生的冗余KV，实现固定内存预算；2) 利用KV张量的独特分布特性进行量化，进一步减少内存消耗

Result: XStreamVGGT在性能损失可忽略的情况下，将内存使用减少4.42倍，推理速度提升5.48倍，实现了可扩展且实用的流式3D应用

Conclusion: XStreamVGGT通过有效的KV缓存压缩机制，解决了流式3D重建中的内存和延迟问题，为实际部署提供了高效解决方案

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [47] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种高速LiDAR点云致密化方法，通过结合多个LiDAR输入和高分辨率彩色图像，使用卷积神经网络实现联合双边滤波，能在30fps下生成全高清分辨率的密集深度图。


<details>
  <summary>Details</summary>
Motivation: 为沉浸式远程呈现系统实现低延迟空间传输，需要解决两个主要问题：密集捕获动态3D场景和实时处理。LiDAR传感器能实时捕获3D数据，但生成的是稀疏点云，因此需要一种高速点云致密化方法来生成密集3D场景。

Method: 结合多个LiDAR输入和高分辨率彩色图像，采用基于卷积神经网络架构实现的联合双边滤波策略，实现实时深度补全。

Result: 该方法能以30fps实时生成全高清分辨率的密集深度图，比最近的基于训练的深度补全方法快15倍以上，生成的密集点云具有准确的几何结构，没有多视角不一致或重影伪影。

Conclusion: 提出的高速LiDAR点云致密化方法成功解决了沉浸式远程呈现系统中的实时密集3D场景生成问题，实现了低延迟、高质量的深度补全。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [48] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 基于SAM模型开发SAR雪崩分割工具，通过适配器、多编码器、提示工程等解决领域差异问题，加速SAR图像标注


<details>
  <summary>Details</summary>
Motivation: SAR图像可用于雪崩检测，但高质量标注需要领域专家且耗时，需要开发工具加速SAR图像的雪崩标注过程

Method: 基于SAM模型，采用适配器缓解领域差异，多编码器处理多通道SAR输入，提示工程提高定位精度，优化训练算法减少编码器训练时间

Result: 开发了SAR雪崩标注工具，实验证明能显著加速SAR图像的标注过程

Conclusion: 通过领域适配的SAM模型可以有效解决SAR雪崩分割的挑战，为雪崩风险预测和缓解提供高效标注工具

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [49] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

TL;DR: UniSH是一个统一的、前馈的框架，用于联合进行度量尺度的3D场景和人体重建，通过创新的训练范式利用未标记的野外数据，解决了合成数据依赖导致的领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 该领域面临的主要挑战是缺乏大规模标注的真实世界数据，导致依赖合成数据集。这种依赖引入了显著的模拟到真实领域的差距，导致泛化能力差、人体几何保真度低，以及在野外视频上的对齐效果不佳。

Method: 提出了一个创新的训练范式，有效利用未标记的野外数据。框架结合了场景重建和人体姿态恢复（HMR）的强大先验，包含两个核心组件：(1) 通过从专家深度模型蒸馏高频细节来优化人体表面细节的鲁棒蒸馏策略；(2) 两阶段监督方案，先在合成数据上学习粗略定位，然后通过直接优化SMPL网格与人体点云之间的几何对应关系在真实数据上进行微调。

Result: 该模型在单次前向传播中能够联合恢复高保真的场景几何、人体点云、相机参数和一致的度量尺度SMPL人体。在人体中心场景重建方面达到了最先进的性能，并在全局人体运动估计方面取得了高度竞争力的结果，优于基于优化的框架和仅使用HMR的方法。

Conclusion: UniSH框架通过创新的训练策略成功解决了合成数据依赖导致的领域差距问题，实现了高质量的联合3D场景和人体重建，在多个任务上表现出色。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [50] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: CODA通过引入寄存器槽位和对比对齐损失，解决了Slot Attention在对象中心学习中的槽位纠缠和对齐问题，提升了对象发现和图像生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的Slot Attention结合预训练扩散模型在对象中心学习中存在槽位纠缠问题，以及对象槽位与图像内容对齐较弱的问题，需要改进。

Method: 提出CODA框架：(1)使用寄存器槽位吸收残差注意力，减少对象槽位间的干扰；(2)应用对比对齐损失，显式鼓励槽位与图像的对应关系。

Result: 在合成数据集(MOVi-C/E)和真实数据集(VOC, COCO)上，CODA显著提升了对象发现性能(如在COCO上FG-ARI提升6.1%)、属性预测和组合图像生成能力。

Conclusion: CODA通过寄存器槽位和对比对齐损失有效解决了槽位纠缠问题，提高了对象中心学习的鲁棒性，且计算开销小，具有在复杂真实场景中应用的潜力。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [51] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: HyDRA：一种仅使用测量数据训练深度平衡模型的框架，结合测量一致性和自适应去噪正则化，用于解决图像重建问题


<details>
  <summary>Details</summary>
Motivation: 解决图像重建问题面临两个主要挑战：问题的病态性和缺乏大规模监督数据集。深度平衡模型需要监督对(x,y)，但在许多实际场景中只有测量数据y可用。

Method: 提出HyDRA框架，仅使用测量数据训练DEQ模型，结合测量一致性约束和自适应去噪正则化项，并采用数据驱动的早停准则。

Result: 在稀疏视图CT重建实验中，HyDRA展现出具有竞争力的重建质量和快速推理速度。

Conclusion: HyDRA为仅使用测量数据训练深度平衡模型提供了一种有效框架，在缺乏监督数据的情况下实现了高质量的图像重建。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [52] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: RFAssigner是一种新颖的标签分配策略，通过高斯感受野距离度量候选位置与真实物体的相似性，自适应补充正样本，解决小物体正样本不足导致的尺度不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集目标检测器的标签分配策略通常为每个训练样本分配正负权重，但在训练过程中往往为小物体分配的正样本数量不足，导致尺度不平衡问题。

Method: RFAssigner首先基于点先验建立初始正样本集，然后利用高斯感受野距离度量未分配候选位置与真实物体感受野的相似性，基于此度量自适应地从未分配池中选择补充正样本。

Result: 在三个具有不同物体尺度分布的数据集上的综合实验验证了方法的有效性和泛化性。配备RFAssigner的FCOS-ResNet-50检测器在所有物体尺度上均达到最先进性能，无需辅助模块或启发式方法。

Conclusion: RFAssigner通过自适应补充正样本有效解决了密集目标检测中的尺度不平衡问题，显著提升了多尺度学习能力，在各种尺度分布的数据集上均表现出优越性能。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [53] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出MambaFormer混合专家框架，结合Transformer和状态空间模型，通过智能路由机制在医疗问答任务中实现高效低延迟推理。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床应用中计算成本与效率之间的权衡问题，为资源受限的临床部署提供可扩展解决方案。

Method: 提出MambaFormer混合专家框架，包含轻量级门控机制进行token级动态路由：短复杂查询路由到Transformer专家(ET5)，长高吞吐序列路由到状态空间模型专家(EMamba)。使用新颖的效用引导多目标损失联合优化决策、路由参数和计算成本。

Result: 在DentalQA和PubMedQA数据集上优于现有技术(BERTScore=0.9180)，实现超低延迟(0.077秒)，比T5-Large快24.4倍。

Conclusion: MambaFormer框架在医疗问答任务中实现了计算效率与准确性的帕累托最优权衡，为资源受限的临床部署提供了可扩展的高效解决方案。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [54] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

TL;DR: 评估四种AI模型（三种CNN和一种Vision Transformer）在深度伪造检测中的性能，VFDNET结合MobileNetV3表现最佳


<details>
  <summary>Details</summary>
Motivation: 随着AI生成的深度伪造技术日益普及，维护数字真实性面临重大挑战，需要可靠的检测方法

Method: 使用大型人脸图像数据集评估四种AI模型（三种CNN和一种Vision Transformer），采用数据预处理和增强技术提升模型性能

Result: VFDNET结合MobileNetV3展现出最高的准确率和高效性能，证明了AI在可靠深度伪造检测方面的能力

Conclusion: AI模型特别是VFDNET与MobileNetV3的组合，能够有效检测深度伪造，为维护数字真实性提供可靠解决方案

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [55] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

TL;DR: S2M-Net：通过谱选择令牌混合器和形态感知自适应分割损失，解决医学图像分割中局部精度、全局上下文和计算效率的三难问题，在16个数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有架构无法平衡医学图像分割的三个关键需求：局部精度（边界关键）、全局上下文（解剖一致性）和计算效率（有限数据和硬件）。卷积网络有局部精度但感受野有限，视觉变换器有全局上下文但计算成本高且在小数据集上容易过拟合。

Method: 提出S2M-Net架构，包含两个核心创新：1) 谱选择令牌混合器(SSTM)，利用医学图像的谱集中特性，通过截断2D FFT和可学习频率滤波实现O(HW log HW)全局上下文；2) 形态感知自适应分割损失(MASL)，自动分析结构特征来调制五个互补损失分量，无需手动调参。

Result: 在16个医学影像数据集（8种模态）上评估，实现最先进性能：息肉分割96.12% Dice，手术器械83.77%（比先前方法提升17.85%），脑肿瘤80.90%。相比专用基线一致提升3-18%，参数比基于变换器的方法少3.5-6倍。

Conclusion: S2M-Net有效解决了医学图像分割的三难问题，通过谱方法和自适应损失实现了全局上下文、局部精度和计算效率的平衡，在多种医学影像任务上表现出色且参数高效。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [56] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: VReID-XFD是一个针对极端远距离（5.8-120米）航拍与地面视角的行人重识别视频基准数据集，包含371个身份、11,288个轨迹和1175万帧，揭示了现有方法在极端条件下性能严重下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别系统基于外观假设，但在极端远距离的航拍与地面视角下，严重的分辨率退化、极端视角变化、不稳定运动线索和服装变化共同破坏了这些假设，需要专门研究这一独特操作机制。

Method: 基于DetReIDX数据集构建VReID-XFD基准，包含371个身份、11,288个轨迹和1175万帧，支持航拍-航拍、航拍-地面、地面-航拍三种评估模式，并举办VReID-XFD-25挑战赛吸引10个团队参与。

Result: 系统分析显示性能随高度和距离单调下降，天底视角普遍处于劣势，存在峰值性能与鲁棒性之间的权衡。即使在航拍-地面设置中，最佳方法SAS-PReID的mAP也仅为43.93%。

Conclusion: VReID-XFD基准揭示了极端远距离行人重识别的挑战性，现有方法在该领域表现有限，需要开发更鲁棒的技术来处理分辨率退化、视角变化等极端条件。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [57] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: LinMU提出线性复杂度视觉语言模型，用M-MATE双分支模块替换自注意力，实现高效长视频理解


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的自注意力机制具有二次复杂度，限制了在边缘设备上的部署，处理高分辨率图像和长视频成本过高

Method: 用M-MATE双分支模块（Flex-MA全局上下文分支 + Local-Swin局部注意力分支）替换自注意力层，采用三阶段蒸馏框架从预训练VLM转换

Result: 在多个基准测试中匹配教师模型性能，TTFT降低2.7倍，token吞吐量提升9.0倍，验证了各蒸馏阶段和双分支的必要性

Conclusion: 无需二次注意力即可实现最先进的多模态推理，为处理高分辨率图像和长视频的VLM开辟了新途径

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [58] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: 提出NeuroAlign框架，通过分层对齐fMRI和视频数据来理解视觉认知机制，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于生成任务或简单相关性，无法反映大脑视觉处理的分层和时间过程，存在模态差距和复杂性挑战

Method: 提出NeuroAlign框架，采用两阶段机制：1) 通过神经-时间对比学习(NTCL)实现全局语义理解；2) 通过增强向量量化进行细粒度模式匹配；使用DynaSyncMM-EMA进行动态多模态融合

Result: NeuroAlign在跨模态检索任务中显著优于现有方法，为理解视觉认知机制建立了新范式

Conclusion: NeuroAlign通过模拟人类视觉系统的分层组织，有效解决了fMRI-视频对齐的挑战，为理解视觉认知提供了新框架

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [59] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 提出使用短参考视频而非单张图像来生成保持身份一致性的视频，通过Sinkhorn路由编码器学习捕捉主体特定动态的紧凑身份令牌，显著改善大姿态变化和表情动作下的身份保持。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅基于单张参考图像生成视频，忽略了时间动态特征，导致姿态锁定、不自然的扭曲以及视角和表情变化时产生"平均化"面孔。需要解决身份保持与动作自然性之间的平衡问题。

Method: 提出身份条件化的扩散变换器视频生成器，使用短参考视频而非单张肖像。通过Sinkhorn路由编码器从参考视频中学习紧凑的身份令牌，捕捉主体特定的动态模式（如微笑形成方式），同时保持与预训练骨干网络的兼容性。

Result: 该方法在保持轻量级条件化的同时，显著改善了大姿态变化和丰富表情动作下的身份保持能力，同时保持了提示忠实度和视觉真实感，适用于多样化的主体和提示。

Conclusion: 通过利用短参考视频中的时间动态信息，提出的方法有效解决了身份保持与动作自然性之间的平衡问题，为生成保持身份一致性的高质量视频提供了有效解决方案。

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [60] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了三种行人重识别方法：SCM-ReID（监督对比学习）、IQAGA/DAPRH（无监督域适应）和ViTC-UReID（完全无监督），在多个基准数据集上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 行人重识别在智能监控系统中至关重要，但面临外观变化、域偏移和标注数据有限等挑战。需要开发能够处理监督、无监督域适应和完全无监督场景的鲁棒方法。

Method: 1. SCM-ReID：结合监督对比学习和混合损失优化（分类、中心、三元组和质心三元组损失）
2. IQAGA/DAPRH：使用GAN图像增强、域不变映射和伪标签精炼来处理无监督域适应
3. ViTC-UReID：基于Vision Transformer的特征编码和相机感知代理学习，结合全局和局部注意力与相机身份约束

Result: 在Market-1501、CUHK03、DukeMTMC-reID和MSMT17等数据集上验证了方法的有效性。SCM-ReID在监督设置下达到最先进性能；UDA方法在跨域场景中mAP和Rank-1提升达12%；ViTC-UReID在无监督设置下显著优于现有方法。

Conclusion: 提出的三种方法有效解决了行人重识别中的特征学习、域适应和标签噪声处理等关键问题，为实际监控系统的鲁棒部署铺平了道路。

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [61] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

TL;DR: GID是一个轻量级Transformer模型，用于解决宽松服装中IMU传感器位移导致的运动捕捉噪声问题，通过位置感知专家架构实现实时去噪，并在未见过的用户、动作和服装类型上具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 可穿戴惯性运动捕捉系统虽然便携、无遮挡且保护隐私，但需要传感器紧贴身体，这在日常使用中既侵入又不舒适。将IMU嵌入宽松服装是理想替代方案，但传感器-身体位移会引入严重、结构化且位置相关的噪声，破坏标准惯性处理流程。

Method: 提出GID（服装惯性去噪器），一个轻量级即插即用Transformer，将宽松服装运动捕捉分解为三个阶段：(1)位置特定去噪，(2)自适应跨服装融合，(3)通用姿态预测。采用位置感知专家架构，共享时空骨干网络建模全局运动，每个IMU专家头专门处理局部服装动态，轻量级融合模块确保跨部位一致性。

Result: GID能够从单用户训练中实现准确、实时的去噪，并在未见过的用户、动作和服装类型上表现出良好泛化能力。作为即插即用模块，持续改进最先进的惯性运动捕捉方法。同时发布了GarMoCap数据集，涵盖多样化用户、动作和服装。

Conclusion: GID通过位置感知专家架构有效解决了宽松服装中IMU传感器位移带来的噪声问题，实现了准确、实时的运动捕捉去噪，具有良好的泛化能力，为日常可穿戴运动捕捉提供了实用解决方案。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [62] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 提出一个解耦深度表示学习框架，将SE(3)变换与形态内容分离，用于冷冻电子断层扫描数据分析，能发现稀有形态且无需手动调参


<details>
  <summary>Details</summary>
Motivation: 现有基于期望最大化的方法经常错过稀有但重要的形态，且需要大量手动超参数调优，需要更有效的解决方案

Method: 提出解耦深度表示学习框架，包含新颖的多选择学习模块，将SE(3)变换与形态内容在表示空间中分离，学习到的形态内容用于生成模板形态

Result: 在模拟和真实冷冻电子断层扫描数据集上的实验显示明显优于先前方法，包括发现先前未识别的大分子形态

Conclusion: 该框架有效解决了冷冻电子断层扫描数据分析中的形态识别问题，能够发现稀有形态且减少手动调参需求

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [63] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 首个针对停车场景3D重建的基准数据集ParkRecon3D和框架ParkGaussian，通过3D高斯泼溅技术和槽位感知重建策略，提升重建质量并保持下游感知任务一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在2D停车位感知、建图和定位，而3D重建在停车场景中尚未充分探索。单纯提升停车场景的视觉重建质量并不能直接帮助自动驾驶停车，因为停车的关键入口是停车位感知模块。

Method: 1) 创建首个停车场景重建基准数据集ParkRecon3D，包含四个环视鱼眼相机的传感器数据、标定外参和密集停车位标注；2) 提出ParkGaussian框架，首次将3D高斯泼溅技术(3DGS)应用于停车场景重建；3) 引入槽位感知重建策略，利用现有停车感知方法增强槽位区域的合成质量。

Result: 在ParkRecon3D上的实验表明，ParkGaussian实现了最先进的重建质量，并更好地保持了与下游任务（如停车位检测）的感知一致性。

Conclusion: ParkRecon3D是首个专门针对停车场景重建的基准数据集，ParkGaussian框架通过3DGS和槽位感知策略，有效提升了停车场景的3D重建质量，并确保重建结果对下游感知任务具有更好的支持性。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [64] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

TL;DR: 本文开发并评估了一个自定义卷积神经网络（CustomCNN），研究架构设计选择对多领域图像分类任务的影响，在智能城市和农业图像数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究卷积神经网络架构设计选择如何影响多领域图像分类任务的性能，为智能城市和农业成像应用提供高效的解决方案。

Method: 设计自定义CNN架构，采用残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化等技术，在五个公开数据集上进行训练和测试。

Result: CustomCNN在多个数据集上表现出竞争性性能，同时保持计算效率，优于流行的CNN架构。

Conclusion: 精心设计的架构对于现实世界的智能城市和农业成像应用至关重要，CustomCNN展示了通过架构优化实现高效多领域图像分类的潜力。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [65] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

TL;DR: SwinIFS是一个基于Swin Transformer和面部关键点引导的人脸超分辨率框架，通过结合结构先验和分层注意力机制，在中等和极端放大倍数下实现身份保持的重建。


<details>
  <summary>Details</summary>
Motivation: 人脸超分辨率在从严重退化的低分辨率输入恢复高质量面部图像方面仍然具有挑战性，因为会丢失精细的结构细节和身份特定特征。现有方法在极端放大倍数下难以恢复有意义的身份信息。

Method: 方法将密集高斯热图的面部关键点作为输入表示，使网络从处理的最早阶段就能关注语义重要的面部区域。采用紧凑的Swin Transformer骨干网络捕获长距离上下文信息同时保持局部几何结构，能够恢复细微的面部纹理并保持全局结构一致性。

Result: 在CelebA基准测试上的广泛实验表明，SwinIFS实现了优越的感知质量、更清晰的重建和改进的身份保持；即使在8倍放大下也能产生更逼真的结果，而大多数方法在该放大倍数下无法恢复有意义的结构。

Conclusion: SwinIFS在重建精度和计算效率之间提供了有利的平衡，使其适用于面部增强、监控和数字修复等实际应用。该方法在极端放大倍数下仍能保持身份信息，为人脸超分辨率提供了有效的解决方案。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [66] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: 提出MGMTN网络，通过自适应掩码学习定位关键面部区域，结合组-全局特征融合，提升面部属性识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统多任务属性识别方法依赖全局特征图，会产生冗余特征。需要选择特定特征区域进行高效特征学习。

Method: 提出MGMTN网络，包含自适应掩码学习（AML）和组-全局特征融合（G2FF）。AML利用预训练关键点模型定位关键面部区域并生成组掩码，G2FF融合组特征和全局特征。

Result: 在两个具有挑战性的面部属性识别数据集上进行了广泛实验，证明了MGMTN在提升FAR性能方面的有效性。

Conclusion: MGMTN通过定位关键面部区域并融合组-全局特征，有效解决了传统方法中的冗余特征问题，提升了面部属性识别性能。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [67] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 论文提出AirSpatial数据集和两阶段训练策略，开发了具备空间理解能力的无人机视觉语言模型AirSpatialBot，用于车辆属性识别和检索。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在局限，限制了实际应用效果。需要提升模型对无人机拍摄车辆图像的空间理解能力。

Method: 1) 创建包含20.6万条指令的AirSpatial数据集，引入空间定位和空间问答两个新任务，首次提供3D边界框标注；2) 采用两阶段训练策略：图像理解预训练和空间理解微调；3) 开发AirSpatialBot智能体，动态整合任务规划、图像理解、空间理解和任务执行能力。

Result: 实验验证了方法的有效性，揭示了现有VLM的空间局限性，同时提供了有价值的见解。模型能够进行细粒度车辆属性识别和检索。

Conclusion: 通过AirSpatial数据集和两阶段训练策略，成功开发了具备空间理解能力的遥感视觉语言模型AirSpatialBot，推动了遥感VLM在空间理解方面的发展。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [68] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: DreamID-V：首个基于扩散Transformer的视频换脸框架，通过模态感知条件模块、合成到真实课程机制和身份一致性强化学习，实现高质量视频换脸


<details>
  <summary>Details</summary>
Motivation: 现有视频换脸方法在保持身份相似性、属性保留和时间一致性方面存在困难，需要将图像换脸的优势无缝迁移到视频领域

Method: 1. SyncID-Pipe数据管道预训练身份锚定视频合成器；2. DreamID-V扩散Transformer框架，核心为模态感知条件模块；3. 合成到真实课程机制和身份一致性强化学习策略

Result: DreamID-V在IDBench-V基准测试中超越现有方法，展现卓越性能，并能无缝适应各种换脸相关任务

Conclusion: 该框架成功将图像换脸优势迁移到视频领域，解决了身份相似性、属性保留和时间一致性的挑战，为视频换脸提供了全面解决方案

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [69] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF：一种边缘引导的稀疏视图3D重建算法，通过提取输入图像的边缘信息，在非边缘区域应用深度和法线正则化约束，在保持边界高频细节的同时增强几何一致性。


<details>
  <summary>Details</summary>
Motivation: NeRF在密集多视图场景中表现优异，但在稀疏输入下重建质量显著下降，出现几何伪影。现有方法使用全局深度正则化来缓解伪影，但会导致几何边界细节丢失。

Method: 利用深度和法线突变会产生边缘的先验知识，首先从输入图像中提取边缘，然后在非边缘区域应用深度和法线正则化约束，增强几何一致性同时保持边界的高频细节。

Result: 在LLFF和DTU数据集上的实验表明，EdgeNeRF在保持锐利几何边界和抑制伪影方面表现优异。边缘引导的深度正则化模块可以即插即用地集成到其他方法中，显著提升性能而不大幅增加训练时间。

Conclusion: EdgeNeRF通过边缘引导的稀疏视图3D重建，有效解决了现有方法在几何边界细节保留方面的不足，在保持高频细节的同时增强了几何一致性，具有很好的可扩展性和实用性。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [70] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: SATS提出两阶段训练策略解决开放集域适应语义分割问题：先分离已知/未知类别，再进行未知感知域适应，通过硬未知探索数据增强提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单阶段中同时处理已知类别域适应和未知类别识别，但由于已知与未知类别标注不平衡，导致已知类别负迁移和未知类别欠拟合问题。

Method: SATS采用分离-适应训练策略：1) 已知/未知类别分离阶段；2) 未知感知域适应阶段。引入硬未知探索数据增强方法，让模型接触更具挑战性的未知样本。

Result: 在公开OSDA-SS基准测试中取得显著提升：GTA5-to-Cityscapes上H-Score提高+3.85%，SYNTHIA-to-Cityscapes上提高+18.64%，超越先前最优方法。

Conclusion: 通过两阶段分离-适应策略和硬未知探索增强，SATS能更平衡地学习已知和未知类别的判别特征，有效发现真正未知物体，解决开放集域适应语义分割的核心挑战。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [71] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

TL;DR: PartImageNet++ (PIN++) 是一个包含ImageNet-1K所有类别详细部件标注的数据集，每类100张图像共10万张，并提出了多尺度部件监督识别模型MPM来提升分类鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏高质量部件标注，限制了基于部件的模型发展。作者旨在创建更全面的部件标注数据集，并探索部件标注如何提升下游任务性能。

Method: 1) 创建PIN++数据集，为ImageNet-1K每类提供100张详细部件标注；2) 用PIN++训练部件分割网络，为未标注图像生成伪部件标签；3) 提出MPM模型，将传统识别架构与辅助旁路层结合，同时使用伪标签和原始标注进行监督。

Result: 实验表明：1) PIN++是覆盖最广的部件标注数据集；2) MPM提升了基于部件模型的鲁棒性识别能力；3) 在部件分割、物体分割和少样本学习等下游任务上建立了强基线；4) 部件标注能显著提升模型性能。

Conclusion: PIN++填补了高质量部件标注数据集的空白，MPM模型证明了部件监督的有效性，为基于部件的计算机视觉研究提供了重要资源和基准。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [72] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: DA-FSS提出解耦专家仲裁网络，通过并行专家模块分离几何和语义路径，解决多模态少样本点云分割中的"可塑性-稳定性困境"和CLIP的语义盲区问题。


<details>
  <summary>Details</summary>
Motivation: 针对多模态少样本3D点云语义分割中"先融合后精炼"范式存在的"可塑性-稳定性困境"，以及CLIP模型可能导致的类间混淆和语义盲区问题，需要设计新的架构来更好利用多模态信息。

Method: 提出DA-FSS模型，包含并行专家精炼模块生成各模态相关性，堆叠仲裁模块进行卷积融合和模态路径仲裁。几何专家保持可塑性，语义专家确保稳定性，通过解耦对齐模块协调知识传递而不传播混淆。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS优于MM-FSS基线，在几何边界、完整性和纹理区分方面都表现更优。

Conclusion: DA-FSS通过解耦几何和语义路径并协调其梯度，有效解决了多模态少样本点云分割中的关键问题，实现了更好的泛化性能。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [73] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

TL;DR: 该论文提出了一种通过图像特定仿射变换恢复单目度量深度的方法，使用语言预测不确定性感知的校准参数范围，并用视觉特征从中选择具体校准参数，在保持相对深度骨干网络固定的情况下训练轻量级校准头。


<details>
  <summary>Details</summary>
Motivation: 相对深度基础模型迁移性能良好，但单目度量深度仍然难以确定，因为全局尺度不可识别且对领域偏移敏感。现有方法使用语言提示提供尺度线索，但存在噪声大、表述变化和物体缺失等问题。

Method: 在冻结骨干网络的校准设置下，通过图像特定的逆深度仿射变换恢复度量深度。使用语言预测不确定性感知的参数范围（包络），然后用多尺度冻结视觉特征从中选择具体校准参数。训练时使用闭式最小二乘oracle提供监督。

Result: 在NYUv2和KITTI数据集上提高了域内精度，在SUN-RGBD和DDAD上的零样本迁移展示了比纯语言基线更强的鲁棒性。

Conclusion: 该方法通过结合语言的不确定性感知包络和视觉特征选择，有效解决了单目度量深度的尺度不确定性问题，在保持相对深度骨干网络优势的同时实现了更好的度量深度估计。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [74] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于GAN的域适应方法，用于解决超声图像中不同设备/参数导致的纹理和混响噪声差异问题，通过图像到图像转换实现跨域适应。


<details>
  <summary>Details</summary>
Motivation: 医学影像中，不同设备或参数设置产生的图像存在纹理和混响噪声差异，导致模型跨域性能下降，而针对每个设备重新训练模型成本高昂。

Method: 将域适应任务构建为图像到图像转换问题，使用GAN模型转换源域图像的纹理模式并去除混响噪声，使其与目标域对齐，同时保持图像内容不变。

Result: 模型成功转换了图像纹理模式并去除了超声图像的混响噪声。在颈动脉超声图像数据集上，提出的方法在直方图相关性（0.960和0.920）和巴氏距离（0.040和0.085）指标上优于无适应方法（0.916和0.890，0.090和0.121）。

Conclusion: 提出的GAN-based域适应方法能有效解决超声图像跨域问题，在保持图像内容的同时转换纹理和去除噪声，为医学影像分析提供了实用的域适应解决方案。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [75] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 提出一种用于海岸视频序列中船舶检测与跟踪的鲁棒实时方法，改进ViBe算法以降低船舶丢失概率，并提出新的尾流消除方法。


<details>
  <summary>Details</summary>
Motivation: 海岸场景具有不可预测性和动态特性，需要能够适应这些条件的鲁棒检测方法。传统方法在检测船舶时容易受到海浪、光线变化等环境因素的影响。

Method: 1. 改进ViBe移动目标检测算法，降低船舶丢失概率，提高对海浪和光线变化的鲁棒性，实现快速背景更新；2. 基于船舶几何特性和亮度失真等概念，提出新的尾流消除方法。

Result: 实验结果表明，所提出的策略和方法在船舶检测和跟踪方面具有出色性能，能够实现实时且精确的检测与跟踪。

Conclusion: 提出的改进ViBe算法结合尾流消除方法，能够有效应对海岸场景的动态变化，实现鲁棒的实时船舶检测与跟踪。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [76] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: ADPO提出统一强化学习框架，在单一策略中联合学习答案生成和自我验证，通过偏好验证奖励和解耦优化机制，显著提升验证能力和推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统并行测试时扩展方法需要分别训练生成和验证模型，导致训练和推理成本高昂，需要更高效的统一框架来协同优化生成和验证能力。

Method: ADPO引入偏好验证奖励（计算正负样本的验证分数均值作为决策阈值）和优势解耦优化（分别计算生成和验证的优势，应用token掩码隔离梯度，结合掩码GRPO目标）。

Result: ADPO实现验证AUC提升高达+34.1%，推理时间降低-53.5%，在MathVista/MMMU准确率提升+2.8%/+1.4%，ReasonSeg提升+1.9 cIoU，AndroidControl/GUI Odyssey步骤成功率提升+1.7%/+1.0%。

Conclusion: ADPO通过统一强化学习框架有效协同优化生成和验证能力，显著提升验证性能和推理效率，为复杂推理任务提供了高效解决方案。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [77] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: 提出Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，提高阿尔茨海默病MRI分类在跨域场景下的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在阿尔茨海默病诊断方面取得进展，但基于结构MRI训练的模型在新队列中表现不佳，主要由于扫描仪、协议和患者人口统计学的领域偏移。阿尔茨海默病作为痴呆症的主要驱动因素，其渐进性认知和神经解剖学变化使得鲁棒、可泛化的分类对现实世界应用至关重要。

Method: 提出Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化。使用NACC数据集（n=4,647）训练模型区分正常认知、轻度认知障碍和阿尔茨海默病，然后在三个未见队列（总计n=3,126）上进行测试。

Result: 在三个未见队列上的测试显示，EM框架显著提高了跨域性能，平均macro-F1比最先进的单域泛化基准提高了2.4个百分点。

Conclusion: EM框架在异构现实世界环境中展现出实现不变、可靠的阿尔茨海默病检测的潜力，为解决阿尔茨海默病数据集碎片化问题提供了有效的单域泛化解决方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [78] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: DeepInv提出了一种自监督的扩散反演方法，通过训练参数化的反演求解器实现快速准确的图像到噪声映射，无需真实噪声标注。


<details>
  <summary>Details</summary>
Motivation: 当前扩散反演任务面临监督信号缺乏的挑战，现有方法多采用近似解决方案，但往往以性能或效率为代价。需要一种既能保持高性能又能保证效率的解决方案。

Method: 提出DeepInv自监督扩散反演方法：1）引入自监督目标和数据增强策略生成高质量伪噪声；2）采用迭代多尺度训练机制训练参数化反演求解器；3）首次提出可训练的分步预测反演噪声求解器。

Result: 在COCO数据集上，DeepInv相比EasyInv SSIM提升40.435%，相比ReNoise推理速度提升9887.5%，在性能和效率上均显著优于现有方法。

Conclusion: DeepInv通过自监督学习和可训练求解器设计，实现了高效准确的扩散反演，为社区提供了新的研究思路，代码和模型参数将开源。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [79] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

TL;DR: 提出DiffKD-DCIS框架，结合条件扩散模型和知识蒸馏，用于预测乳腺导管原位癌升级为浸润性导管癌，解决超声数据有限和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 准确预测DCIS升级为IDC对手术规划至关重要，但传统深度学习方法面临超声数据有限和泛化能力差的挑战。

Method: 三阶段框架：1) 条件扩散模型生成高质量超声图像进行数据增强；2) 深度教师网络从原始和合成数据中提取鲁棒特征；3) 紧凑学生网络通过知识蒸馏从教师网络学习，平衡泛化能力和计算效率。

Result: 在多中心1435例数据集上评估，合成图像质量良好。学生网络参数更少、推理更快。在外部测试集上优于部分组合，准确率与资深放射科医生相当，优于初级医生，显示显著临床潜力。

Conclusion: DiffKD-DCIS框架通过结合条件扩散模型和知识蒸馏，有效解决了超声数据有限和泛化能力差的问题，在预测DCIS升级为IDC方面表现出良好的临床潜力。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [80] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

TL;DR: GBU-Net是一种基于组批归一化U-Net框架的新型深度学习网络，专门用于短轴电影MRI扫描中左心室的精确语义分割，在SunnyBrook测试数据集上达到97%的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 传统CNN分割方法在医学影像分割中往往忽略上下文信息，特别是在心脏MRI分割中，精确的左心室分割对于手术机器人和医学分析至关重要，需要更准确的解决方案。

Method: 采用组批归一化U-Net框架，包含下采样路径进行特征提取和上采样路径进行细节恢复，专门针对医学影像优化，加入改进技术以增强对心脏MRI分割至关重要的上下文理解。

Result: GBU-Net在45名患者的805个左心室MRI扫描数据集上显著提高了分割精度，在Dice系数和平均垂直距离等标准指标上超越现有方法，在SunnyBrook测试数据集上达到97%的Dice分数。

Conclusion: GBU-Net通过创新的组批归一化U-Net设计，在左心室分割中提供了更高的精度和上下文理解能力，为手术机器人和医学分析应用提供了优越的解决方案。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [81] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: VideoSpeculateRAG：基于推测解码的高效视觉语言模型检索增强生成框架，通过轻量级草稿模型生成候选答案，再由重量级模型验证优化，在保持准确性的同时将推理速度提升约2倍。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在整合外部知识方面仍有困难，而现有的检索增强生成方法效率低下且难以保持高质量答案。需要一种既能提升效率又能保证准确性的解决方案。

Method: 提出VideoSpeculateRAG框架，包含两个核心创新：1）推测解码管道：轻量级草稿模型快速生成多个候选答案，再由更准确的重量级模型验证和优化；2）相似性过滤策略：针对检索知识中实体识别错误的问题，通过相似性过滤改善实体对齐，提升答案准确性。

Result: 实验表明，VideoSpeculateRAG在达到或超过标准RAG方法准确性的同时，将推理速度提升了约2倍。

Conclusion: 该框架展示了将推测解码与检索增强推理相结合在复杂知识密集型多模态任务中提升效率和可靠性的潜力。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [82] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: BARE是一个用于单塔视觉定位的偏置感知和推理增强框架，通过保留模态特定特征和构建指称语义来缓解多模态干扰并增强指称理解。


<details>
  <summary>Details</summary>
Motivation: 当前视觉定位中的单塔架构存在两个主要限制：1) 过度纠缠的多模态表示加剧了欺骗性模态偏置；2) 语义推理不足阻碍了指称线索的理解。

Method: BARE引入了一个保留模态特定特征的机制，通过三个新模块构建指称语义：语言显著性调制器、视觉偏置校正和指称关系增强，共同缓解多模态干扰并增强指称理解。

Result: 在五个基准测试上的广泛实验结果表明，BARE不仅实现了最先进的性能，而且与现有方法相比提供了优越的计算效率。

Conclusion: BARE通过偏置感知和推理增强的方法，有效解决了单塔视觉定位中的模态偏置和语义推理不足问题，在性能和效率上都表现出色。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [83] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: DrivingGen是首个面向驾驶世界模型的综合基准测试，通过多样化的数据集和新的评估指标来解决现有评估方法的不足，揭示了通用模型与专用模型在视觉质量和物理真实性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 驾驶世界模型作为生成模拟器，能够想象自我车辆和其他交通参与者的未来状态，对于可扩展仿真、安全测试和合成数据生成至关重要。然而，该领域缺乏严格的基准测试来衡量进展和指导研究方向。现有评估存在多个缺陷：通用视频指标忽视安全关键因素；轨迹合理性很少量化；时间和智能体一致性被忽略；对自我车辆条件的可控性被忽视；当前数据集未能覆盖实际部署所需的多样性条件。

Method: 提出了DrivingGen基准测试，包含两个核心组件：1）从驾驶数据集和互联网规模视频源中精心策划的多样化评估数据集，涵盖不同天气、时间、地理区域和复杂操作；2）一套新的评估指标，联合评估视觉真实性、轨迹合理性、时间一致性和可控性。对14个最先进的模型进行了基准测试。

Result: 基准测试揭示了明显的权衡：通用模型看起来更好但违反物理规律，而驾驶专用模型能真实捕捉运动但视觉质量较差。DrivingGen提供了一个统一的评估框架，能够促进可靠、可控和可部署的驾驶世界模型的发展。

Conclusion: DrivingGen填补了驾驶世界模型评估的关键空白，通过全面的数据集和评估指标为该领域提供了首个严格的基准测试。该框架将推动可扩展仿真、规划和数据驱动决策的发展，促进更可靠、可控和可部署的驾驶世界模型的研发。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [84] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: ReToK是一种灵活的图像分词器，通过冗余标记填充和分层语义正则化，解决了传统灵活分词器中信息过度集中在早期标记的问题，提升了自回归图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有灵活图像分词器使用嵌套dropout（尾部截断）训练，导致图像信息过度集中在早期标记，限制了自回归图像生成在较长标记序列时的效果。

Method: 提出ReToK方法：1）冗余标记填充：更频繁地激活尾部标记，缓解信息过度集中；2）分层语义正则化：对齐早期标记与预训练视觉基础模型的解码特征，向尾部逐渐降低正则化强度以保留细节。

Result: 在ImageNet 256×256上，ReToK相比固定长度和灵活分词器都取得了更优的生成性能。

Conclusion: ReToK通过冗余标记填充和分层语义正则化，有效解决了灵活分词器中信息分布不均的问题，提升了自回归图像生成的质量。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [85] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: FAR-AMTN：一种用于人脸属性识别的注意力多任务网络，通过参数共享和跨组特征融合提高泛化性能，同时减少模型参数。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在低层共享模块，高层使用独立模块，导致参数随任务数量指数增长，且高层特征交互受限，无法有效探索属性间的语义关系，影响泛化性能。

Method: 提出FAR-AMTN，包含三个核心模块：1) WSGSA模块（权重共享组特定注意力）用共享参数减少复杂度并提升组特征表示；2) CGFF模块（跨组特征融合）促进属性组间交互；3) DWS策略（动态权重策略）实现任务同步收敛。

Result: 在CelebA和LFWA数据集上的实验表明，FAR-AMTN相比现有模型在准确率上表现更优，同时参数数量显著减少。

Conclusion: FAR-AMTN通过创新的注意力机制和特征融合方法，有效解决了传统多任务网络在人脸属性识别中的参数爆炸和特征交互不足问题，实现了更好的泛化性能和模型效率。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [86] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 该论文提出了Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并创建了EscherVerse基准套件来评估AI在开放世界中对空间动态和人类意图的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前空间推理研究忽视了空间变化背后的人类意图，需要从被动的场景描述转向更全面的、目的驱动的世界理解。

Method: 提出TSI范式，包含物理动态推理和意图驱动推理两个支柱；创建EscherVerse基准套件，包括Escher-Bench基准、Escher-35k数据集和Escher系列模型；开发了新颖的数据整理流程，基于真实世界视频构建开放世界评估环境。

Result: EscherVerse是首个系统评估意图驱动推理的基准，能够评估模型在动态、以人为中心的场景中对物体恒存性、状态转换和轨迹预测的推理能力，为空间智能研究提供了基础资源。

Conclusion: TSI范式将空间智能从被动场景描述推进到对世界的整体、目的驱动理解，EscherVerse为这一研究方向提供了关键的基础设施和评估框架。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [87] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: GAR-Font：一种新颖的自回归多模态少样本字体生成框架，通过全局感知分词器、多模态风格编码器和后处理细化管道，解决了现有方法在结构完整性和风格保真度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有少样本字体生成方法面临两个主要问题：1）传统自回归模型使用补丁级分词，忽略了字体合成所需的全局依赖关系；2）现有方法局限于图像到图像范式，仅依赖视觉参考，忽视了语言在传达字体设计风格意图中的作用。

Method: 提出GAR-Font框架，包含三个核心组件：1）全局感知分词器，同时捕获局部结构和全局风格模式；2）多模态风格编码器，通过轻量级语言风格适配器提供灵活的风格控制，无需密集的多模态预训练；3）后处理细化管道，进一步提升结构保真度和风格一致性。

Result: 大量实验表明，GAR-Font在少样本字体生成任务上优于现有方法，在保持全局风格忠实度方面表现突出，并能通过文本风格指导获得更高质量的生成结果。

Conclusion: GAR-Font通过引入全局感知分词和多模态风格控制，有效解决了少样本字体生成中的结构完整性和风格保真度问题，为字体设计提供了更灵活、高质量的自动化解决方案。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [88] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: 提出Sparse Guidance (SG)方法，解决稀疏训练扩散模型在推理时对Classifier-free Guidance响应不佳的问题，通过token级稀疏性在推理时提高生成质量并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏训练扩散模型虽然降低了训练成本，但在推理时对Classifier-free Guidance (CFG)响应不佳，导致生成质量下降。需要一种方法既能保持训练时的计算效率，又能提高推理时的生成质量。

Method: 提出Sparse Guidance (SG)方法，使用token级稀疏性替代传统的条件丢弃作为引导信号。在推理时利用token级稀疏性，更好地保留条件预测的高方差，实现高质量和高方差的输出。

Result: 在ImageNet-256基准测试中达到1.58 FID，计算量减少25%；在匹配基线质量时最多可节省58% FLOPs。训练了一个25亿参数的文本到图像扩散模型，在推理时使用SG提高了构图质量和人类偏好评分，同时增加了吞吐量。

Conclusion: Sparse Guidance有效解决了稀疏训练扩散模型在推理时的性能问题，通过token级稀疏性在降低计算成本的同时提高了生成质量，为大规模扩散模型的高效训练和推理提供了可行方案。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [89] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出CAP-IQA框架，通过上下文感知提示和因果去偏技术，结合文本先验与图像特定信息，提升CT图像质量评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的CT图像质量评估方法存在局限性：它们通常嵌入理想化的医学先验知识，但在真实世界退化（如噪声、运动伪影、扫描仪差异）下会产生偏差，无法准确反映实际图像质量。

Method: 提出上下文感知提示引导图像质量评估（CAP-IQA）框架：1）结合CNN视觉编码器和领域特定文本编码器；2）使用放射学风格提示和上下文感知融合对齐语义与感知表示；3）应用因果去偏技术分离理想化知识与实际图像退化；4）评估诊断可见性、解剖清晰度和噪声感知。

Result: 在2023 LDCTIQA挑战基准上，CAP-IQA获得2.8590的总相关分数（PLCC、SROCC、KROCC之和），比排行榜第一名（2.7427）提升4.24%。在91,514张儿科CT图像内部数据集上验证了模型在不同患者群体中的泛化能力。

Conclusion: CAP-IQA框架通过整合文本级先验与实例级上下文提示，结合因果去偏技术，有效提升了CT图像质量评估的准确性和泛化能力，为医疗图像分析提供了更可靠的评估工具。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [90] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 该研究系统评估了三种弱校准单目RGB人体测量方法在消费级相机下的表现，重点分析校准假设对测量行为、鲁棒性和失败模式的影响，而非追求最高精度。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像估计人体尺寸面临尺度模糊、视角敏感和缺乏深度信息等挑战。研究旨在分析不同弱校准策略在实际部署中的表现，为消费设备上的轻量级人体测量系统提供设计参考。

Method: 采用三种弱校准单目策略：基于地标的几何方法、姿态驱动的回归方法、以及物体校准的轮廓方法。在消费级相机半约束条件下进行系统实证研究，分析不同校准假设对测量行为的影响。

Result: 研究发现校准过程中的用户努力与所得周长测量的稳定性之间存在明显权衡。不同方法在不同体型上表现出不同的鲁棒性和失败模式，揭示了校准假设对测量性能的重要影响。

Conclusion: 该研究为消费设备上的轻量级单目人体测量系统提供了实证设计参考，强调了校准策略选择在实际部署中的重要性，而非单纯追求最高精度。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [91] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

TL;DR: 提出Deep Gaussian Shadow Maps (DGSM)方法，为3D高斯泼溅(3DGS)表示中的动态角色提供一致的光照和阴影，支持角色与场景的交互，无需网格化处理。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅(3DGS)表示中动态角色与场景交互时的光照和阴影一致性问题，避免网格化处理，实现实时渲染。

Method: 1. 提出DGSM：基于经典深度阴影映射思想，针对3DGS表示设计，通过闭式光累积计算体积阴影；2. 使用八面体图集存储径向壳层的透射率；3. 采用球谐(HDRI)探针近似局部环境光照，实现快速辐射传输。

Result: 在AvatarX、ActorsHQ角色与ScanNet++、DL3DV、SuperSplat场景的合成中，实现了角色与场景、插入物体间的连贯阴影和重光照，支持单/多角色设置，完全在3DGS表示中运行。

Conclusion: DGSM和SH重光照方法为3DGS表示提供了完整的体积阴影和光照解决方案，避免了网格化处理，实现了动态角色与场景交互时的一致光照和阴影效果。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [92] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: LabelAny3D：一个通过分析-合成框架从2D图像重建3D场景以生成高质量3D边界框标注的系统，并基于此构建了COCO3D基准数据集


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在真实世界图像中表现不佳，主要原因是缺乏真实世界的3D数据集和3D标注的挑战性

Method: 提出LabelAny3D分析-合成框架，从2D图像重建整体3D场景，高效生成高质量3D边界框标注；基于此构建COCO3D基准数据集

Result: LabelAny3D生成的标注提升了多个基准测试中的单目3D检测性能，质量优于先前的自动标注方法

Conclusion: 基础模型驱动的标注方法在真实开放世界环境中扩展3D识别具有广阔前景

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [93] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 提出一个可信赖的野火风险预测框架，通过长序列多尺度时间建模整合异质驱动因素，同时量化预测不确定性并支持过程级解释，在加拿大西部2023-2024火灾季节表现优异。


<details>
  <summary>Details</summary>
Motivation: 加拿大西部野火活动加剧导致严重社会经济和环境损失，但准确预测面临挑战：点火和蔓延的内在随机性，以及燃料条件、气象、气候变率、地形和人类活动之间的非线性相互作用，这影响了纯数据驱动模型的可靠性和可解释性。

Method: 基于长序列多尺度时间建模的可信赖数据驱动野火风险预测框架，整合异质驱动因素，显式量化预测不确定性，并支持过程级解释。使用SHAP进行机制解释。

Result: 在加拿大西部2023-2024年创纪录火灾季节评估中，模型优于现有时间序列方法，F1分数0.90，PR-AUC 0.98，计算成本低。不确定性分析揭示了预测置信度的结构化空间和季节模式。SHAP解释显示温度相关驱动因素主导野火风险，而2024年水分相关约束在塑造空间和土地覆盖特定对比方面作用更强。

Conclusion: 提出的可信赖野火风险预测框架在准确性和可解释性方面表现优异，为野火风险管理提供了可靠工具，数据与代码已开源。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [94] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 该研究评估了四种深度学习人脸识别模型在0-3岁婴幼儿纵向数据集上的表现，发现早期年龄组识别准确率较低，但随着年龄增长显著提升，通过DANN方法可减少时间漂移问题。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿人脸识别面临独特挑战：面部形态快速变化、类间相似度高、数据集有限。研究旨在评估现有深度学习模型在婴幼儿纵向数据上的表现，为智慧城市中儿童生物识别系统的可靠应用提供依据。

Method: 使用新开发的0-3岁婴幼儿纵向数据集（7个时间点，24个月），评估FaceNet、ArcFace、MagFace和CosFace四种深度学习模型。分析不同发育阶段的识别准确率，并应用域对抗神经网络（DANN）来减少时间漂移。

Result: 0-6个月婴儿在0.1% FAR下的TAR仅为30.7%，2.5-3岁儿童提升至64.7%。时间间隔越短，识别准确率越高。DANN方法将TAR提升了12%以上，产生更稳定、泛化性更强的特征。

Conclusion: 婴幼儿早期人脸识别存在显著挑战，但性能随年龄增长而改善。DANN能有效减少时间漂移，提高特征稳定性。这些发现对智慧城市中儿童生物识别系统的可靠应用至关重要，未来需要研究能处理时间变异性的隐私保护认证系统。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [95] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: FALCON是一个跨域少样本分割框架，通过将3D医学数据作为2D切片处理，实现高精度分割，显著减少标注数据需求和计算开销。


<details>
  <summary>Details</summary>
Motivation: 3D医学影像的精确分割对诊断和手术规划至关重要，但面临3D标注稀缺、患者特异性变异、数据隐私和计算开销大等挑战。

Method: 采用跨域元学习策略：先在自然图像上元训练学习通用分割先验，然后通过对抗性微调和边界感知学习迁移到医学领域，最后基于支持线索进行任务感知推理。

Result: 在四个基准测试中，FALCON始终获得最低的Hausdorff距离分数（表明边界精度最优），同时保持与最先进模型相当的Dice相似系数，且所需标注数据更少、无需数据增强、计算开销显著降低。

Conclusion: FALCON框架通过有效的跨域迁移和少样本学习策略，实现了临床可行的3D医学影像分割，解决了标注稀缺和计算资源限制的问题。

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [96] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 使用合成人脸数据作为纵向稳定器，通过合成增强微调显著降低儿童人脸识别的错误率


<details>
  <summary>Details</summary>
Motivation: 儿童面部快速非线性生长导致模板漂移和验证错误随时间增加，需要提高儿童人脸识别模型的时态鲁棒性

Method: 在YFA数据集上评估三种设置：预训练MagFace、仅用真实数据微调、真实+合成数据微调；使用StyleGAN2 ADA生成合成数据，并应用后生成过滤减少身份泄漏

Result: 合成增强微调在6-36个月的验证间隔中显著降低错误率，优于预训练基线和仅真实数据微调

Conclusion: 合成增强为改善儿科人脸识别的身份持久性提供了风险感知的评估方法

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [97] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: 提出LH3D框架，通过主动学习选择既信息丰富又可可靠标注的路边单目3D检测场景，抑制固有模糊样本，仅用25%标注预算达到接近全数据性能。


<details>
  <summary>Details</summary>
Motivation: 实际部署中由于硬件和隐私限制，通常只能标注路边单目数据，但许多场景存在距离远、模糊或遮挡物体，仅凭单视角难以准确标注3D属性，这些固有模糊样本增加了标注难度和成本，揭示了根本的可学习性问题。

Method: 提出LH3D框架，基于可学习性驱动的主动学习方法，选择既信息丰富又可可靠标注的场景，抑制固有模糊样本同时确保覆盖范围。通过评估场景的可学习性而非传统的不确定性来选择标注样本。

Result: 在DAIR-V2X-I数据集上，仅使用25%标注预算，对车辆、行人和骑行者的检测性能分别达到全数据性能的86.06%、67.32%和78.67%，显著优于基于不确定性的基线方法。

Conclusion: 研究表明，对于路边3D感知任务，可学习性而非不确定性才是关键因素。LH3D框架能有效减少固有模糊样本的标注浪费，同时获得高性能模型。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [98] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 提出Covariance Distribution Optimization (CDO)模块，通过优化车道特征分布与真实标签的对齐，在嵌入式系统中实现高效实时车道检测，无需增加计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中的实时车道检测面临挑战：RGB图像中的视觉信号稀疏且微妙，计算资源和功耗受限。现有深度学习方法（分割、锚点、曲线）缺乏针对低功耗嵌入式环境的通用优化技术。

Method: 提出创新的协方差分布优化（CDO）模块，专门为高效实时应用设计。该模块将车道特征分布与真实标签对齐，显著提高检测精度而不增加计算复杂度。可轻松集成到现有系统中，无需结构修改，利用现有模型参数进行持续训练。

Result: 在六种不同模型（涵盖所有三类方法，包括两种实时优化模型和四种SOTA模型）上评估，使用CULane、TuSimple和LLAMAS三个主要数据集。实验结果显示精度提升0.01%到1.5%。

Conclusion: CDO模块在嵌入式系统中提供了显著的性能、功耗效率和操作灵活性优势，易于集成到现有系统，无需结构修改，并能利用现有参数进行持续训练。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [99] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: 提出FFP-300K大规模数据集和新型无引导FFP框架，通过AST-RoPE和自蒸馏策略解决视频编辑中外观保持与运动保留的冲突，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FFP方法依赖繁琐的运行时引导，根本原因在于训练数据集不足（太短、低分辨率、任务多样性不够），无法学习鲁棒的时间先验。

Method: 1) 构建FFP-300K大规模数据集（30万对720p视频，81帧）；2) 提出无引导FFP框架，采用自适应时空RoPE动态重映射位置编码来解耦外观和运动参考；3) 使用自蒸馏策略，以身份传播任务作为正则化器确保长期时间稳定性。

Result: 在EditVerseBench基准测试中显著优于现有学术和商业模型，PickScore提升约0.2，VLM分数提升约0.3。

Conclusion: 通过解决数据集不足和架构目标层面的关键问题，实现了真正无需引导的FFP视频编辑，在保持第一帧外观和保留源视频运动之间取得了良好平衡。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [100] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 提出Subimage Overlap Prediction自监督预训练方法，用于遥感图像语义分割，显著减少预训练数据需求，加速收敛并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习方法依赖大量预训练数据，而遥感图像标注成本高、数据获取困难，需要开发能在少量数据上有效预训练的方法。

Method: 提出子图像重叠预测任务：从原始图像中提取子图像，训练模型预测该子图像在原始图像中的位置语义掩码，通过这种自监督方式学习图像结构信息。

Result: 方法在多个架构和下游数据集上验证，相比其他SSL方法：1) 显著加速收敛；2) 达到相当或更好的mIoU性能；3) 在标注数据减少时优势更明显；4) 所需预训练数据显著减少。

Conclusion: Subimage Overlap Prediction是一种高效的自监督预训练方法，特别适合遥感图像分割任务，能在少量数据下实现快速收敛和优异性能，为数据稀缺领域提供实用解决方案。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [101] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: Point-SRA是一种通过自蒸馏和概率建模对齐表示的3D表示学习方法，改进了传统MAE的固定掩码比率和逐点重建假设，在多个下游任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法存在两个主要问题：1）固定掩码比率忽略了多级表示相关性和内在几何结构；2）逐点重建假设与点云多样性相冲突。需要一种能更好捕捉几何语义信息并处理点云多样性的方法。

Method: 提出Point-SRA方法：1）为MAE分配不同掩码比率以捕捉互补的几何和语义信息；2）使用MeanFlow Transformer（MFT）通过跨模态条件嵌入实现多样化的概率重建；3）在MAE和MFT两个层面提出双重自表示对齐机制；4）设计流条件微调架构以充分利用MeanFlow学习的点云分布。

Result: 在ScanObjectNN上比Point-MAE提升5.37%；颅内动脉瘤分割任务中，动脉平均IoU达到96.07%，动脉瘤达到86.87%；3D目标检测中AP@50达到47.3%，超过MaskPoint 5.12%。

Conclusion: Point-SRA通过自蒸馏和概率建模有效解决了传统MAE方法的局限性，在多个3D下游任务中实现了最先进的性能，证明了其在捕捉多级表示相关性和处理点云多样性方面的有效性。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [102] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 提出一种创新的视觉语言模型用于人脸验证，不仅能准确判断两张人脸图像是否属于同一人，还能解释其决策依据。模型采用两种互补的解释风格进行训练，并通过跨模态迁移提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前人脸验证系统虽然取得了显著进展，但缺乏决策过程的透明度。需要开发既能准确验证又能解释决策依据的系统，以提高系统的可靠性和可解释性。

Method: 1. 提出创新的视觉语言模型用于人脸验证；2. 采用两种互补的解释风格训练模型：简洁解释（总结关键因素）和详细解释（描述图像间的具体差异）；3. 将原本为音频区分设计的先进建模方法适配并增强用于视觉输入，实现跨模态迁移；4. 集成先进的特征提取技术和推理能力。

Result: 模型表现出卓越性能，超越了基线方法和现有模型。跨模态迁移显著提高了模型的准确性和可解释性。

Conclusion: 视觉语言模型在人脸验证领域具有巨大潜力，能够为构建更透明、可靠和可解释的人脸验证系统做出重要贡献。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [103] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: MANGO是一个两阶段框架，通过纯图像级监督实现高质量的双人3D对话头部生成，避免了伪3D标签的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动的3D头部生成方法主要关注单说话人场景，缺乏自然的双向听-说交互。现有3D对话化身方法依赖容易出错的伪3D标签，无法捕捉细粒度面部动态。

Method: 两阶段框架：第一阶段使用带有双音频交互模块的基于扩散的transformer从多说话人音频建模自然3D运动；第二阶段使用快速3D高斯渲染器生成高保真图像，并通过交替训练为3D运动提供2D级光度监督。

Result: 方法在建模双人3D对话运动方面实现了卓越的准确性和真实感，显著提升了音频驱动说话头部的保真度和可控性。还引入了MANGO-Dialog数据集，包含500+身份超过50小时的2D-3D对齐对话数据。

Conclusion: MANGO通过纯图像级监督和交替训练解决了伪3D标签的噪声问题，实现了更自然的双向对话交互，推动了音频驱动3D头部生成技术的发展。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [104] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: LUMPNet是一种基于混合深度学习的早期检测方法，用于检测牛结节性皮肤病，通过YOLOv11检测皮肤结节，EfficientNet分类，以及新型自适应混合优化器，在公开数据集上达到99%的训练准确率和98%的验证准确率。


<details>
  <summary>Details</summary>
Motivation: 结节性皮肤病（LSD）是一种传染性病毒性疾病，严重威胁牲畜健康和全球粮食安全。由于其快速传播特性，早期精确识别对于预防疫情爆发和确保及时干预至关重要。

Method: 提出LUMPNet混合深度学习框架：1）使用YOLOv11检测和定位牛图像中的LSD皮肤结节和病变；2）利用基于EfficientNet的CNN分类器对定位后的图像进行分类（LSD感染或健康）；3）提出并采用新型自适应混合优化器来稳定和加速YOLOv11与EfficientNet混合模型的训练。

Result: 在公开数据集上评估显示：LUMPNet达到99%的LSD检测训练准确率和98%的验证准确率，优于现有方案。通过使用AdamW优化器训练的EfficientNet-B0模型进行案例研究比较，LUMPNet表现出更优越的性能。

Conclusion: LUMPNet为结节性皮肤病的早期检测提供了一种有效的混合深度学习方法，具有高准确率和优越性能，有助于及时干预和疫情控制。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [105] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 提出基于临床诊断模板的病理信息结构化提取流程，构建CTIS-Align数据集和CTIS-Bench基准，开发CTIS-QA模型用于病理切片问答，在多个任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 病理报告包含丰富的诊断信息但缺乏结构化，需要系统化提取病理特征以支持计算病理学和视觉语言模型的发展。

Method: 1) 设计临床病理报告模板(CPRT)标准化提取病理特征；2) 构建CTIS-Align数据集用于视觉语言对齐训练；3) 创建CTIS-Bench VQA基准；4) 提出CTIS-QA模型，采用双流架构模拟病理医生诊断过程。

Result: 在TCGA-BRCA上验证了pipeline有效性，CTIS-QA在WSI-VQA、CTIS-Bench和切片级诊断任务上全面超越现有SOTA模型。

Conclusion: 提出的模板化pipeline能有效结构化病理信息，CTIS-QA模型通过模拟病理医生诊断策略，在病理切片问答任务上表现出色，为计算病理学提供了新工具。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [106] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 提出名为RSwinV2的深度学习模型用于Mpox诊断，通过定制化Transformer架构和引入逆残差块，在Kaggle数据集上达到96.21%准确率和95.62%F1分数，优于传统CNN和SwinTransformer。


<details>
  <summary>Details</summary>
Motivation: 现有方法在Mpox病变分类中存在局限性，需要提升对Mpox、水痘、麻疹和牛痘等疾病的区分能力，同时解决传统Transformer中的局部性问题和梯度消失问题。

Method: 基于SwinTransformerV2定制化开发RSwinV2模型，采用分层Transformer结构，将输入图像分割为不重叠块，使用移位窗口注意力机制。引入逆残差块（IRB）处理梯度消失问题，结合卷积跳跃连接，同时捕捉全局和局部模式。

Result: 在Kaggle公开数据集上，RSwinV2达到96.21%准确率和95.62%F1分数，优于标准CNN模型和SwinTransformer，有效区分Mpox、水痘、麻疹和牛痘。

Conclusion: RSwinV2作为计算机辅助工具，通过结合Transformer的全局链接能力和IRB的局部模式捕捉，显著提升了Mpox病变分类性能，证明了其在医学图像分析中的价值。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [107] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: DDNet：基于双流图学习和解缠的时序伪造定位框架，通过协调局部伪影和语义内容流，结合解缠适应和跨层特征嵌入，显著提升视频伪造片段定位精度。


<details>
  <summary>Details</summary>
Motivation: AIGC技术快速发展使得仅篡改视频小片段即可误导观众，而视频级检测不够准确和可信。现有方法受限于局部视角，难以捕捉全局异常，因此需要更精确的时序伪造定位方法。

Method: 提出DDNet双流图学习框架：1) 时间距离流捕捉局部伪影；2) 语义内容流建立长程连接。引入Trace Disentanglement and Adaptation (TDA)解缠通用伪造指纹，以及Cross-Level Feature Embedding (CLFE)通过层次特征深度融合构建鲁棒特征基础。

Result: 在ForgeryNet和TVIL基准测试中，DDNet在AP@0.95指标上比现有最优方法提升约9%，在跨域鲁棒性方面也有显著改进。

Conclusion: DDNet通过协调局部和全局视角，结合解缠技术和层次特征融合，有效解决了时序伪造定位问题，在精度和鲁棒性方面均优于现有方法。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [108] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: CogFlow是一个受认知启发的三阶段框架，通过知识内化阶段解决视觉数学问题中感知与推理脱节的问题，显著提升了多模态大语言模型的视觉数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉数学问题解决上仍存在困难。虽然一些工作认识到视觉感知是瓶颈，但仅关注改进视觉输入的提取和解释，忽略了提取的视觉线索是否被忠实整合并正确用于后续推理这一关键问题。

Method: 提出CogFlow三阶段框架：感知→内化→推理。1) 设计协同视觉奖励提升参数和语义空间的感知能力；2) 引入知识内化奖励模型确保视觉线索忠实整合；3) 设计视觉门控策略优化算法防止模型走捷径；4) 构建包含12万高质量标注的MathCog数据集。

Result: 在常用视觉数学推理基准测试上的综合实验和分析验证了CogFlow的优越性，显著提升了多模态大语言模型的视觉数学问题解决能力。

Conclusion: 通过模拟人类推理的层次流程并全面增强各阶段，CogFlow有效解决了视觉数学推理中感知与推理脱节的问题，为多模态推理提供了新的认知启发框架。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [109] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: V-CORE是一个参数高效的视频理解框架，通过引入显式时序约束来解决现有Video-LLMs在时序排序和因果连贯性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型在多模态推理方面表现出色，但在需要一致时序排序和因果连贯性的视频理解任务上仍面临挑战。许多参数高效的Video-LLMs使用无约束的双向投影器建模帧间交互，这会模糊时序顺序，因为允许后续帧影响先前表示，缺乏尊重视频推理方向性的显式架构机制。

Method: V-CORE包含两个关键组件：1) 可学习空间聚合(LSA)，自适应选择显著空间标记以减少冗余；2) 因果感知时序投影器(CATP)，通过块因果注意力和作为因果汇聚的终端动态摘要标记，强制结构化单向信息流。该设计在保持帧内空间交互的同时，确保时序信息以严格有序的方式聚合。

Result: V-CORE在具有挑战性的NExT-QA基准测试中达到61.2%的准确率，在MSVD-QA、MSRVTT-QA和TGIF-QA上保持竞争力，在时序和因果推理子类别上分别获得+3.5%和+5.2%的增益，直接验证了显式时序约束的重要性。

Conclusion: V-CORE通过引入显式时序排序约束，有效解决了视频理解中的时序一致性和因果连贯性问题，在保持参数效率的同时显著提升了时序和因果推理能力。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [110] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: Nodule-DETR：一种用于甲状腺超声结节检测的新型检测变换器，通过多光谱频域通道注意力、分层特征融合和多尺度可变形注意力模块，显著提升低对比度、边界模糊结节的检测性能。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌是最常见的内分泌恶性肿瘤，发病率持续上升。超声是检测甲状腺结节的首选成像方式，但其诊断准确性常受限于低图像对比度和模糊结节边界等挑战。需要开发更强大的检测方法来提高临床诊断准确性。

Method: 提出Nodule-DETR，一种基于检测变换器（DETR）的新型架构，包含三个关键创新：1）多光谱频域通道注意力（MSFCA）模块，利用频率分析增强低对比度结节特征；2）分层特征融合（HFF）模块，实现高效多尺度特征集成；3）多尺度可变形注意力（MSDA），灵活捕捉小型和不规则形状结节。

Result: 在真实世界甲状腺超声图像临床数据集上进行广泛实验，Nodule-DETR实现了最先进的性能，在mAP@0.5:0.95指标上显著优于基线模型0.149。代码已开源。

Conclusion: Nodule-DETR的优越准确性突显了其作为计算机辅助甲状腺诊断有效工具的重要临床潜力，为解决超声图像中低对比度和模糊边界问题提供了创新解决方案。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [111] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 本文提出基于Transformer/视频视觉Transformer的多模态行人意图预测算法，在JAAD数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是从L3到L4自动驾驶过渡的关键技术，需要考虑多种元素和特征来提高道路安全性

Method: 使用不同尺寸的Transformer/视频视觉Transformer架构，结合多种数据模态，通过大量消融实验验证不同设计选择

Result: 在JAAD数据集上达到SOTA性能，在准确率、AUC和F1分数等指标上超越现有方法

Conclusion: 提出的Transformer-based多模态算法在行人意图预测任务中表现出色，为自动驾驶安全提供了有效解决方案

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [112] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 提出语言引导的场景上下文感知学习框架，用于提升第一人称视觉注意力预测的鲁棒性，在Ego4D和AEA数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 第一人称视频分析需求增长，但动态第一人称场景的复杂性和模糊性使得注意力预测具有挑战性。研究表明场景上下文信息在调节人类注意力中起关键作用。

Method: 1) 设计上下文感知器，基于语言场景描述总结第一人称视频，生成上下文感知的视频表示；2) 引入两个训练目标：鼓励关注目标兴趣区域，抑制不相关区域的干扰。

Result: 在Ego4D和Aria Everyday Activities (AEA)数据集上的广泛实验表明，该方法实现了最先进的性能，并在多样化动态第一人称场景中展现出增强的鲁棒性。

Conclusion: 提出的语言引导场景上下文感知学习框架能有效提升第一人称视觉注意力预测的准确性和鲁棒性，通过利用场景上下文信息解决动态第一人称场景的复杂性问题。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [113] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文研究如何在物体检测中集成特权信息学习范式，利用训练时可用但推理时不可用的细粒度描述信息，通过师生架构将特权信息注入检测器，显著提升检测精度而不增加推理复杂度。


<details>
  <summary>Details</summary>
Motivation: 在物体检测任务中，训练阶段往往可以获得额外的细粒度描述信息（如边界框掩码、显著性图、深度线索等），但这些信息在推理阶段不可用。如何有效利用这些"特权信息"来提升检测性能，同时不增加推理时的计算负担，是一个重要研究问题。

Method: 提出了一种通用的、模型无关的方法，通过师生架构将特权信息注入深度学习物体检测器。教师模型使用特权信息进行训练，学生模型则学习模仿教师的行为，从而间接利用特权信息。该方法适用于多种检测模型。

Result: 在五个最先进的物体检测模型和多个公开基准（包括无人机垃圾检测数据集和Pascal VOC 2012）上的实验表明，LUPI训练的学生模型始终优于基线模型，检测精度显著提升，且不增加推理复杂度或模型大小。中等和大型物体的性能提升尤为明显。

Conclusion: LUPI框架为物体检测系统提供了一种有效且实用的策略，特别是在资源受限和实际应用场景中。通过师生架构利用训练时的特权信息，可以在不增加推理负担的情况下显著提升检测性能。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [114] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: ESGaussianFace：基于3D高斯泼溅的情感化风格化音频驱动面部动画框架，通过情感音频引导空间注意力机制和3D高斯变形预测器，实现高效高质量的情感风格化面部视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动面部动画研究主要关注中性情绪视频生成，虽然有些研究涉及情感音频驱动，但如何高效生成同时包含情感表达和风格特征的高质量说话头部视频仍是一个重大挑战。

Method: 1. 使用3D高斯泼溅技术重建3D场景并渲染视频；2. 提出情感音频引导的空间注意力方法，有效整合情感特征和音频内容特征；3. 引入两个3D高斯变形预测器实现情感和风格化变形；4. 采用多阶段训练策略，逐步学习嘴唇运动、情感变化和风格特征。

Result: 生成结果具有高效率、高质量和3D一致性。大量实验结果表明，该方法在嘴唇运动准确性、表情变化和风格特征表现力方面优于现有最先进技术。

Conclusion: ESGaussianFace是一个创新的情感化风格化音频驱动面部动画框架，通过3D高斯泼溅、情感音频引导注意力机制和变形预测器，成功解决了同时生成高质量情感表达和风格特征的面部动画的挑战。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [115] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: 提出GCR框架，通过几何一致性路由解决任务无关持续异常检测中的专家选择问题，避免跨头分数可比性问题，实现近零遗忘


<details>
  <summary>Details</summary>
Motivation: 工业检测中基于特征的异常检测方法在处理持续类别扩展时，跨类别异常分数分布差异导致专家选择不可靠，现有路由规则在实际部署中不稳定

Method: GCR框架：在共享冻结的补丁嵌入空间中，通过最小化到类别特定原型库的累积最近原型距离来路由测试图像，然后仅在路由的专家内使用基于原型的标准评分规则计算异常图

Result: 在MVTec AD和VisA数据集上的实验表明，几何一致性路由显著提高了路由稳定性，缓解了持续性能崩溃，实现了近零遗忘，同时保持了竞争力的检测和定位性能

Conclusion: 许多先前归因于表示遗忘的失败实际上可以解释为跨头路由中决策规则的不稳定性，GCR通过分离跨头决策和头内异常评分有效解决了这一问题

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [116] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: Agentic Retoucher：基于分层决策驱动的框架，通过感知-推理-行动循环解决文本到图像生成中的小尺度扭曲问题，显著提升图像质量


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型（如SDXL、FLUX）虽然实现了高真实感，但在肢体、面部、文字等细节上仍存在普遍的小尺度扭曲。现有细化方法要么需要昂贵的迭代重新生成，要么依赖空间定位能力弱的视觉语言模型，导致语义漂移和不可靠的局部编辑。

Method: 提出Agentic Retoucher分层决策驱动框架，将后生成修正重构为类人的感知-推理-行动循环：1) 感知代理学习上下文显著性，在文本-图像一致性线索下定位细粒度扭曲；2) 推理代理通过渐进偏好对齐进行人类对齐的推断诊断；3) 行动代理根据用户偏好自适应规划局部修复。该设计将感知证据、语言推理和可控修正整合到统一的自校正决策过程中。

Result: 构建了GenBlemish-27K数据集（包含6K T2I图像和27K个12个类别的标注伪影区域），用于细粒度监督和定量评估。大量实验表明，Agentic Retoucher在感知质量、扭曲定位和人类偏好对齐方面持续优于最先进方法。

Conclusion: Agentic Retoucher为自校正和感知可靠的文本到图像生成建立了新范式，通过分层决策驱动框架有效解决了现有方法在局部修正中的局限性。

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [117] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: RRNet是一个轻量级可配置的实时视频增强框架，通过虚拟光源参数估计和深度感知渲染实现局部重光照，在视觉质量和效率之间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 实时视频增强应用需求增长，现有方法难以平衡速度和有效曝光控制，特别是在不均匀光照条件下。

Method: 提出RRNet框架：1) 估计最小虚拟光源参数；2) 通过深度感知渲染模块实现局部重光照，无需像素对齐训练数据；3) 采用对象感知公式保持面部身份；4) 使用精简编码器和轻量预测头；5) 提出基于生成AI的数据集创建流程。

Result: RRNet在低光增强、局部光照调整和眩光去除方面持续优于现有方法，支持实时高分辨率性能。

Conclusion: RRNet具有可解释的光照控制和高效架构，适用于视频会议、AR肖像增强和移动摄影等实际应用。

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [118] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: 提出EGMT方法，通过实体引导的多任务学习进行红外与可见光图像融合，利用实体级文本信息消除语义噪声，提升融合图像质量


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的红外与可见光图像融合方法通常使用句子级文本信息，存在语义噪声问题，且未能充分利用文本的深层语义价值

Method: 1) 从大视觉语言模型生成的图像描述中提取实体级文本信息；2) 构建并行多任务学习架构，将图像融合与多标签分类任务结合；3) 开发实体引导的跨模态交互模块，增强视觉与文本特征的细粒度交互

Result: EGMT在保持显著目标、纹理细节和语义一致性方面优于现有方法，并发布了四个公开数据集的实体标注版本

Conclusion: 提出的实体引导多任务学习方法有效解决了传统文本驱动融合中的语义噪声问题，显著提升了融合图像的质量和语义密度

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [119] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 该论文首次全面综述了遥感领域的智能体AI，提出了统一的分类体系，分析了架构基础，并展望了从静态深度学习模型向自主智能体AI范式转变的未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 地球观测分析范式正在从静态深度学习模型转向自主智能体AI。尽管现有的视觉基础模型和多模态大语言模型在表示学习方面有所进展，但它们往往缺乏复杂地理空间工作流所需的序列规划和主动工具编排能力。

Method: 提出了首个遥感领域智能体AI的全面综述，引入了统一的分类体系（区分单智能体副驾驶和多智能体系统），分析了规划机制、检索增强生成和记忆结构等架构基础，并回顾了从像素级精度转向轨迹感知推理正确性的新兴基准。

Result: 通过批判性分析接地性、安全性和编排等方面的局限性，为开发稳健、自主的地理空间智能制定了战略路线图。

Conclusion: 该工作为遥感领域从静态模型向自主智能体AI的范式转变提供了系统性框架，指出了当前技术的局限性，并规划了未来发展的战略方向。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [120] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 该论文提出了一种弱时间监督策略，利用现有单时相遥感数据集的额外时间观测来训练变化检测模型，无需新标注，通过假设真实双时相对大多无变化、不同位置图像配对生成变化示例，并采用对象感知变化图生成和迭代优化处理弱标签噪声。


<details>
  <summary>Details</summary>
Motivation: 遥感语义变化检测面临标注数据集稀缺的挑战，因为像素级标注成本高且耗时。现有方法使用合成数据或人工生成变化对，但域外泛化能力有限。需要一种无需新标注就能利用现有数据的方法。

Method: 1. 扩展单时相遥感数据集，添加不同时间的新观测；2. 假设真实双时相对大多无变化，而将不同位置的图像配对生成变化示例；3. 采用对象感知变化图生成和迭代优化过程处理弱标签中的噪声。

Result: 在扩展的FLAIR和IAILD航空数据集上验证了该方法，在不同基准测试中实现了强大的零样本和低数据机制性能。展示了在法国大面积区域的结果，突出了方法的可扩展潜力。

Conclusion: 提出的弱时间监督策略能够有效利用现有单时相数据集进行变化检测训练，无需额外标注，解决了数据稀缺问题，具有良好泛化能力和可扩展性，为遥感变化检测提供了一种实用解决方案。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [121] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出FLLP框架，在双曲空间中引入父子概念学习机制，通过已学概念指导新概念学习来缓解灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 定制扩散模型在顺序学习新概念时容易发生灾难性遗忘，现有方法主要关注最小化概念间干扰，忽视了概念间可能的积极交互作用

Method: FLLP框架在洛伦兹流形中嵌入概念表示，利用双曲空间自然适合建模树状层次结构的特性，定义父子关系，让已学概念作为指导来适应新概念

Result: 在三个公共数据集和一个合成基准上验证，显示在鲁棒性和泛化能力方面都有持续改进

Conclusion: FLLP不仅保留先验知识，还支持新概念的持续整合，通过父子概念学习机制有效缓解灾难性遗忘问题

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [122] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: BiPrompt：双边提示优化框架，通过视觉注意力引导擦除和文本平衡提示归一化，同时减少视觉和文本模态中的虚假相关性依赖，实现无需重新训练或领域监督的因果推理


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言基础模型（如CLIP）在零样本泛化方面表现优异，但仍容易受到跨视觉和文本模态的虚假相关性的影响。现有的去偏方法通常只处理单一模态（视觉或文本），导致部分鲁棒性和在分布偏移下的不稳定适应。

Method: 提出双边提示优化框架（BiPrompt），在测试时适应期间同时减轻两个模态中的非因果特征依赖。视觉方面：采用结构化注意力引导擦除来抑制背景激活，并强制因果区域和虚假区域之间的正交预测一致性。文本方面：引入平衡提示归一化，这是一种可学习的重新中心化机制，将类别嵌入对齐到各向同性的语义空间。

Result: 在真实世界和合成的偏置基准测试上进行广泛评估，结果显示在平均准确率和最差组准确率方面均优于先前的测试时去偏方法，建立了轻量级但有效的可信赖且基于因果的视觉语言适应路径。

Conclusion: BiPrompt框架通过同时处理视觉和文本模态的偏置问题，最小化虚假线索与预测之间的条件互信息，引导模型进行因果的、领域不变的推理，无需重新训练或领域监督，为可信赖的视觉语言适应提供了有效解决方案。

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [123] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: 提出HybridTAS框架，结合欧几里得和双曲几何于扩散模型去噪过程，利用动作层次结构进行时序动作分割


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代细化的时序动作分割方法未能充分利用人类动作的层次性结构，需要一种能有效建模动作层次关系的方法

Method: HybridTAS框架将欧几里得和双曲几何结合到扩散模型去噪过程中，利用双曲几何的树状结构特性，实现从粗到细的动作标签去噪：高扩散时间步受抽象高层动作类别影响，低时间步则用细粒度动作类进行细化

Result: 在GTEA、50Salads和Breakfast三个基准数据集上实现了最先进的性能，验证了双曲引导去噪在时序动作分割任务中的有效性

Conclusion: 通过结合双曲几何的层次建模能力，HybridTAS框架能够有效利用动作的层次结构，在时序动作分割任务中取得了显著性能提升

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [124] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: TalkPhoto是一个无需训练的通用图像编辑框架，通过对话交互实现精确图像操作，利用LLM分析用户需求并分层调用现有高级编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法虽然引入了MLLM来促进指令与图像之间的信息交换，但通常需要构建多指令数据集来训练模型处理多个编辑任务，这既耗时耗力又难以达到满意效果。

Method: 提出TalkPhoto框架：1) 使用专门设计的提示模板指导开源LLM分析用户需求；2) 分层调用现有高级编辑方法；3) 实现即插即用和高效的图像编辑方法调用机制，无需额外训练。

Result: 实验表明该方法不仅以更少的token消耗提供更准确的调用，还在各种图像编辑任务中实现了更高的编辑质量。

Conclusion: TalkPhoto是一个无需训练、通过对话交互实现精确图像编辑的通用框架，能够稳定处理复杂和未见过的编辑任务，获得高质量的编辑结果。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [125] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow是一个统一的解码器自回归Transformer，在6万亿交错文本-图像离散标记上训练，通过统一视觉表示和架构实现多模态理解与生成，包括图像编辑、交错内容和视频生成。


<details>
  <summary>Details</summary>
Motivation: 不同模态具有本质差异：文本是严格顺序的，而图像是层次结构的。传统的光栅扫描方法效率低下，需要更高效的视觉生成方法。

Method: 采用统一自回归架构，但对文本保留下一个标记预测，对视觉采用下一个尺度预测。引入多尺度生成训练方案解决不稳定性问题，并提出强化学习的prefix-tuning策略。

Result: NextFlow在5秒内生成1024x1024图像，比同类AR模型快几个数量级。在统一模型中达到最先进性能，在视觉质量上可与专门的扩散基线模型媲美。

Conclusion: NextFlow通过统一的架构和创新的下一个尺度预测方法，实现了高效的多模态理解和生成，为统一模型在视觉质量方面设定了新的标准。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [126] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: AR-MOT：一种基于大语言模型的自回归多目标跟踪范式，将MOT任务转化为序列生成问题，无需特定任务头，具有更好的扩展性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化且任务特定，难以适应通用和多模态场景，限制了在不同任务间的适用性和新跟踪公式的灵活性。

Method: 1) 在LLM框架内将MOT建模为序列生成任务；2) 基于预训练检测器的对象分词器增强区域视觉感知；3) 区域感知对齐模块缓解全局与区域特征不对齐；4) 时序记忆融合模块缓存历史对象标记支持长时跟踪。

Result: 在MOT17和DanceTrack数据集上的实验验证了方法的可行性，性能与最先进方法相当，为更通用和灵活的MOT系统奠定了基础。

Conclusion: AR-MOT通过自回归序列生成范式解决了现有MOT方法的架构限制，提供了强大的扩展潜力，新模态或指令只需修改输出序列格式而无需改变模型架构。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [127] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: RetinexEVSR：首个基于事件驱动的低光视频超分辨率框架，利用高对比度事件信号和Retinex先验，通过双向跨模态融合策略提升低光视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法在恢复细节方面存在困难，主要因为低对比度和高频信息不足。需要利用事件信号的高对比度特性和Retinex理论来改善低光条件下的视频恢复质量。

Method: 提出RetinexEVSR框架，采用双向跨模态融合策略：1) 光照引导的事件增强模块，利用Retinex模型的光照图逐步精炼事件特征；2) 事件引导的反射率增强模块，利用增强的事件特征通过多尺度融合机制动态恢复反射率细节。

Result: 在三个数据集上达到最先进性能，在SDSD基准测试中获得最高2.95 dB增益，同时相比之前基于事件的方法减少65%运行时间。

Conclusion: RetinexEVSR通过有效融合事件信号和RGB帧，结合Retinex先验，显著提升了低光视频超分辨率的性能，在恢复细节和计算效率方面都有显著优势。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [128] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: MacVQA：一种用于视觉问答的持续学习框架，通过自适应内存分配和全局噪声过滤来平衡知识保留、适应性和鲁棒特征表示。


<details>
  <summary>Details</summary>
Motivation: 当前VQA持续学习方法在平衡知识保留、适应性和鲁棒特征表示方面存在困难，需要一种能够同时处理这些挑战的框架。

Method: 提出MacVQA框架，融合视觉和问题信息并过滤噪声以确保鲁棒表示，采用基于原型的记忆分配来优化特征质量和内存使用。

Result: 在10个持续VQA任务上的实验表明，MacVQA优于现有基线，标准任务平均准确率43.38%、平均遗忘率2.32%，新组合任务平均准确率42.53%、平均遗忘率3.60%。

Conclusion: MacVQA通过自适应内存分配和全局噪声过滤，有效平衡了持续VQA学习中的知识获取、保留和组合泛化能力。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [129] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 提出一个紧凑高效的指令式图像编辑系统，使用2B参数的Qwen3-VL指导编辑和1.6B参数的Sana1.5生成图像，在保持高质量的同时实现低成本推理和严格源一致性。


<details>
  <summary>Details</summary>
Motivation: 当前指令式图像编辑领域虽然发展迅速，但开源模型中能达到真实世界质量的有限，且主流扩散模型通常参数庞大（6B-20B），计算成本高，不适合许多部署和研究场景。

Method: 采用2B参数的Qwen3-VL模型指导编辑过程，结合1.6B参数的扩散模型Sana1.5进行图像生成。在架构、数据处理、训练配置和评估方面都针对低成本推理和严格源一致性进行优化。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配或超越了参数多几倍、推理成本更高的基线模型。在需要保持输入图像的编辑任务（如属性调整、对象移除、背景编辑、目标替换）上表现尤为出色。

Conclusion: 提出的紧凑型指令式图像编辑管道在保持高质量的同时实现了高效推理（24GB GPU内存，H100上约4秒生成2K分辨率图像），为低成本部署和研究提供了可行方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [130] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 提出了一种从粗到精的面部法线估计方法，通过小数据集训练粗估计模型生成指导样本，再用自注意力机制和细化网络提升质量，显著减少对大规模配对数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 现有面部法线估计方法严重依赖大规模配对数据进行训练，这限制了方法的实用性和可扩展性。本文旨在通过开发一种从粗到精的估计器来减轻这一要求。

Method: 采用两阶段方法：1）用小数据集训练简洁模型生成粗面部法线作为指导样本；2）使用自注意力机制捕获长距离依赖关系修复局部伪影；3）定制细化网络将输入人脸图像与对应指导样本映射到高质量精细面部法线。

Result: 实验证明该方法在训练成本和估计质量方面均优于现有最先进方法，显著减少了对大规模配对数据和计算资源的需求。

Conclusion: 提出的从粗到精面部法线估计方法通过逻辑功能分割有效解决了对大规模配对数据的依赖问题，在保持高质量估计的同时降低了训练成本。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [131] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: 该研究对比了三种CNN应用范式：从头训练小型CNN、使用预训练CNN作为固定特征提取器、以及迁移学习微调。在五个真实图像分类数据集上的实验表明，迁移学习性能最佳，而自定义CNN在计算资源受限时提供更好的效率-准确率权衡。


<details>
  <summary>Details</summary>
Motivation: 实践中，视觉识别任务通常面临三种CNN应用范式的选择：从头训练小型网络、使用预训练大模型作为固定特征提取器、或进行迁移学习微调。然而，缺乏对这些范式在真实世界数据集上的系统比较，特别是在效率和准确率权衡方面的评估。

Method: 在五个真实世界图像分类数据集上进行受控实验比较：道路表面缺陷识别、农业品种识别、水果/叶片病害识别、人行道侵占识别、未授权车辆识别。评估三种范式：1) 从头训练紧凑自定义CNN；2) 使用大型预训练CNN作为固定特征提取器；3) 通过部分或完全微调预训练骨干网络进行迁移学习。使用准确率和宏F1分数评估性能，辅以训练时间/epoch和参数量等效率指标。

Result: 迁移学习在所有数据集上始终提供最强的预测性能。自定义CNN提供了有吸引力的效率-准确率权衡，特别是在计算和内存预算受限时。固定特征提取器方法在某些情况下表现良好，但通常不如迁移学习。

Conclusion: 迁移学习是获得最佳预测性能的首选方法，而自定义CNN在资源受限场景下提供了实用的效率-准确率平衡。实践者应根据具体任务的计算约束和性能需求在这两种方法之间进行选择。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [132] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: MotionAdapter是一个基于扩散变换器(DiT)的内容感知运动迁移框架，通过解耦运动与外观并自适应定制运动，实现视频间复杂运动的鲁棒迁移。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的文本到视频模型在生成高质量时序一致视频方面取得显著进展，但在视频间迁移复杂运动仍然具有挑战性。现有方法难以有效解耦运动与外观，并适应目标内容的语义差异。

Method: MotionAdapter框架包含两个核心模块：1) 通过分析3D全注意力模块中的跨帧注意力来提取注意力驱动的运动场，实现运动与外观的显式解耦；2) 引入DINO引导的运动定制模块，基于内容对应关系重新排列和精炼运动场，桥接参考视频与目标视频的语义鸿沟。定制后的运动场用于指导DiT去噪过程。

Result: 大量实验表明，MotionAdapter在定性和定量评估中均优于现有最先进方法。该框架自然支持复杂运动迁移和运动编辑任务（如缩放）。

Conclusion: MotionAdapter通过内容感知的运动迁移框架，成功解决了DiT基文本到视频模型中的复杂运动迁移问题，实现了鲁棒且语义对齐的运动传输，同时保持目标外观和语义。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [133] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: TopoLoRA-SAM：一种拓扑感知的参数高效适应框架，用于将SAM适配到特定领域的二值语义分割任务，仅需训练5.2%的参数即可达到或超越全微调专家模型性能。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型（如SAM）通过大规模预训练展现出强大的零样本泛化能力，但将其适配到特定领域的语义分割任务仍然具有挑战性，特别是对于细长结构（如视网膜血管）和噪声模态（如SAR图像）。全微调计算成本高且存在灾难性遗忘风险。

Method: 提出TopoLoRA-SAM框架：1）在冻结的ViT编码器中注入低秩适应（LoRA）；2）添加轻量级空间卷积适配器；3）可选地通过可微分clDice进行拓扑感知监督。

Result: 在五个基准测试（视网膜血管分割：DRIVE、STARE、CHASE_DB1；息肉分割：Kvasir-SEG；SAR海陆分割：SL-SSDD）中，TopoLoRA-SAM取得了最佳视网膜平均Dice和最佳总体平均Dice，仅训练约5.2%的参数（约490万）。在具有挑战性的CHASE_DB1数据集上，显著提高了分割准确性和鲁棒性。

Conclusion: 拓扑感知的参数高效适应能够匹配或超越全微调的专家模型，为将基础分割模型高效适配到特定领域任务提供了有效解决方案。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [134] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: AFTER方法通过事实增强的激活引导和查询自适应偏移优化，有效减少大视觉语言模型中的物体幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型存在语言偏见导致的物体幻觉问题（类别、属性和关系幻觉），阻碍可信AI应用。现有编辑方法缺乏事实文本语义的有效指导，难以显式缓解语言偏见。

Method: 提出AFTER方法，包含事实增强激活引导（FAS）和查询自适应偏移优化（QAO）。FAS提供事实性和通用性指导，精确建模视觉-文本关联；QAO引入查询感知偏移估计器，建立查询特定的编辑，增强编辑的多样性和粒度。

Result: 在三个广泛采用的大视觉语言模型上的标准幻觉基准测试中验证了AFTER的有效性，在AMBER基准上实现了高达16.3%的幻觉减少。

Conclusion: AFTER方法通过自适应地将原始有偏激活引导至事实语义，有效缓解了大视觉语言模型的物体幻觉问题，为可信AI应用提供了有前景的解决方案。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [135] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: FL2T框架通过跨概念学习模块解决定制扩散模型中的灾难性遗忘问题，实现并发、顺序无关的概念学习，提升知识保留和迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有定制扩散模型在连续学习新概念时存在灾难性遗忘问题，且大多数先前工作仅在顺序学习设置下缓解此问题，忽略了概念间的交互作用。

Method: 提出FL2T框架，引入集合不变跨概念学习模块，使用代理引导跨概念特征选择，促进知识保留和迁移，实现并发且顺序无关的概念学习。

Result: 在三个数据集上的实验表明，该方法显著提升概念保留能力，缓解灾难性遗忘，在十个任务的增量概念学习中平均CLIP图像对齐分数至少提升2%。

Conclusion: 跨概念催化行为在增量概念学习中具有有效性，FL2T框架通过促进概念间交互，实现了更好的知识保留和迁移。

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [136] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

TL;DR: 该论文提出了一种将对象中心蓝图集成到视觉语言模型中，以增强空间推理能力的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么关注局部图像块（削弱全局空间感知），要么标记孤立坐标（忽略对象整体组织），无法有效支持空间语义理解。

Method: 1) 构建JSON式蓝图记录对象位置、大小和属性；2) 蓝图嵌入推理轨迹进行监督微调；3) 蓝图感知奖励强化学习；4) 反捷径数据增强。

Result: 实验表明该方法在空间推理任务上持续优于现有视觉语言模型和专用空间推理模型。

Conclusion: 通过对象中心蓝图的结构化表示，视觉语言模型能够更好地进行空间语义理解和推理。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [137] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出API框架用于可泛化的真实世界图像去雾，包含自动雾霾生成模块和密度感知去雾模块，通过多负样本对比损失提升细节恢复


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在复杂真实雾霾场景中性能显著下降，主要由于训练数据有限和雾霾密度分布的内在复杂性

Method: API框架包含：1)自动雾霾生成模块提供混合数据增强；2)密度感知去雾模块以自适应块重要性方式处理不同雾霾密度区域；3)多负样本对比去雾损失利用空间和频域信息

Result: 在多个真实世界基准测试中达到最先进性能，在定量指标和定性视觉质量上均表现优异，对不同雾霾分布具有鲁棒泛化能力

Conclusion: 提出的API框架通过创新的数据增强、自适应密度感知去雾和多域对比损失，有效解决了真实世界图像去雾的泛化挑战

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [138] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 提出一个新颖框架，通过强化雾霾与低光先验之间的内在一致性，渐进式增强夜间有雾图像的可见度，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 夜间有雾图像的可见度增强面临复杂退化分布的挑战。现有方法通常单独处理单一退化类型（如雾霾或低光），忽略了不同类型退化之间的相互作用，导致可见度改善有限。

Method: 提出一个新颖框架，通过相互渐进地强化雾霾与低光先验之间的内在一致性来增强夜间有雾图像的可见度。模型采用图像级、块级和像素级专家，在视觉和频率域中操作，逐步恢复全局场景结构、区域模式和细粒度细节。引入频率感知路由器自适应引导每个专家的贡献。

Result: 在夜间去雾基准测试中，模型在定量和定性评估上都表现出优越性能。此外，模型在白天去雾和低光增强任务中也展现出良好的泛化能力。

Conclusion: 通过强化雾霾与低光先验之间的内在一致性，提出的框架能有效增强夜间有雾图像的可见度，并在多个相关任务中展现出强大的泛化能力。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [139] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: GleSAM++ 通过生成式潜在空间增强提升 SAM 在低质量图像上的分割鲁棒性，引入特征分布对齐、通道复制扩展和退化感知自适应增强机制，实现跨图像质量的分割泛化。


<details>
  <summary>Details</summary>
Motivation: SAM 在零样本分割上表现优异，但在严重退化、低质量图像上性能显著下降，限制了其在真实场景中的应用。需要提升 SAM 对低质量图像的鲁棒性。

Method: 提出 GleSAM++：1) 使用生成式潜在空间增强提升低质量图像鲁棒性；2) 引入特征分布对齐(FDA)和通道复制扩展(CRE)改善预训练扩散模型与分割框架的兼容性；3) 提出退化感知自适应增强(DAE)机制，将重建过程解耦为退化程度预测和退化感知重建两个阶段。

Result: 实验表明 GleSAM++ 显著提升了在复杂退化条件下的分割鲁棒性，同时保持对清晰图像的泛化能力。在未见过的退化类型上也表现良好，证明了方法的通用性。

Conclusion: GleSAM++ 通过引入退化感知机制和兼容性增强技术，有效提升了 SAM 在低质量图像上的分割性能，仅需少量额外可学习参数即可应用于预训练的 SAM 和 SAM2，具有高效性和通用性。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [140] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: 提出ADAE框架，通过事件相机引导的时空融合增强Depth Anything在恶劣成像条件下的深度估计能力


<details>
  <summary>Details</summary>
Motivation: 当前深度基础模型（如Depth Anything）在理想场景中表现优异，但在极端光照和运动模糊等恶劣成像条件下性能下降。这些退化会破坏帧相机的视觉信号，削弱帧基深度在时空维度上的判别特征。虽然现有方法引入事件相机来利用其高动态范围和时间分辨率，但这些专门融合模型通常从头训练，无法继承基础模型的开放世界知识和鲁棒泛化能力。

Method: 提出ADAE框架，包含两个核心组件：1）熵感知空间融合：使用信息熵策略自适应融合帧基和事件基特征，指示光照引起的退化；2）运动引导时间校正：利用事件基运动线索重新校准模糊区域的模糊特征。这两个组件在统一框架下相互补充，共同增强Depth Anything在恶劣成像条件下的性能。

Result: 通过大量实验验证了所提方法的优越性，代码将在接受后发布。

Conclusion: ADAE框架成功地将事件相机的优势与深度基础模型的开放世界知识相结合，显著提升了在动态和恶劣光照条件下的深度估计鲁棒性。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [141] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 提出一种无需3D标注数据或配对RGB图像的大规模点云3D语义分割方法，通过虚拟相机将点云投影到2D图像，利用基础2D模型和自然语言提示进行分割，通过多视角加权投票实现3D分割。


<details>
  <summary>Details</summary>
Motivation: 传统3D语义分割方法需要大量标注的3D训练数据或配对的RGB图像，这限制了其应用范围。本文旨在开发一种无需3D标注数据或配对图像的训练无关方法，同时支持开放词汇识别，克服传统监督方法的局限性。

Method: 方法包括三个主要步骤：1）使用虚拟相机将3D点云投影到多个2D视角的图像；2）利用基础2D模型（如CLIP等）结合自然语言提示对每个2D投影进行语义分割；3）通过加权投票机制聚合多个视角的预测结果，形成最终的3D语义分割。

Result: 该方法在多个基准测试中超越了现有的训练无关方法，分割精度达到与监督方法相当的水平。同时支持开放词汇识别，用户可以使用任意文本查询来检测对象，突破了传统方法的类别限制。

Conclusion: 本文提出的方法成功实现了无需3D标注数据的大规模点云语义分割，通过2D基础模型和自然语言提示的巧妙结合，不仅达到了与监督方法相当的精度，还具备了开放词汇识别的能力，为3D场景理解提供了更灵活、更通用的解决方案。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [142] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: 提出AlignVTOFF框架，通过并行U-Net和纹理-空间特征对齐解决虚拟试穿中几何变形和纹理细节保留问题，显著提升平铺服装生成质量。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿(VTOFF)任务面临复杂几何变形和丰富高频纹理的挑战，现有方法使用轻量模块导致结构化图案和细节丢失，生成时出现纹理衰减问题。

Method: 提出AlignVTOFF框架：1) 参考U-Net进行多尺度特征提取，增强几何保真度；2) 纹理-空间特征对齐(TSFA)通过混合注意力设计（可训练交叉注意力+冻结自注意力）将参考服装特征注入冻结去噪U-Net。

Result: 在多种设置下的广泛实验表明，AlignVTOFF持续优于现有最先进方法，生成具有改进结构真实性和高频细节保真度的平铺服装结果。

Conclusion: AlignVTOFF通过并行U-Net架构和纹理-空间特征对齐机制，有效解决了虚拟试穿中的几何变形建模和纹理细节保留问题，显著提升了生成质量。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [143] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: PhysSFI-Net：一种物理信息几何深度学习框架，用于正颌手术后软组织变形的精确预测，在预测精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 正颌手术需要准确预测术后面部形态，但传统生物力学模型计算成本高，几何深度学习方法缺乏可解释性，需要开发更准确、可解释的预测方法。

Method: PhysSFI-Net包含三个组件：1）具有颅面和手术计划编码器及注意力机制的分层图模块，提取骨骼-面部交互特征；2）基于LSTM的序列预测器，用于增量软组织变形；3）生物力学启发的模块，用于高分辨率面部表面重建。

Result: 在135名患者数据上，PhysSFI-Net的点云形状误差为1.070±0.088mm，表面偏差误差为1.296±0.349mm，标志点定位误差为2.445±1.326mm，优于现有方法ACMT-Net。

Conclusion: PhysSFI-Net能够实现可解释、高分辨率的术后面部形态预测，具有优异的准确性，在正颌手术规划和模拟中显示出强大的临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [144] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

TL;DR: 提出了首个大规模仅使用光学影像的冰碛垄分割数据集和轻量级MCD-Net模型，在降低60%计算成本的同时达到62.3% mIoU，证明仅用光学影像可实现可靠的冰碛体分割。


<details>
  <summary>Details</summary>
Motivation: 冰川分割对重建过去冰川动态和评估气候变化驱动的景观变化至关重要，但弱光学对比度和高分辨率DEM数据有限阻碍了自动化制图。

Method: 创建了包含3,340张手动标注高分辨率Google Earth图像的数据集，覆盖中国四川和云南冰川区域。开发了MCD-Net轻量级基线模型，集成MobileNetV2编码器、CBAM注意力模块和DeepLabV3+解码器。

Result: MCD-Net达到62.3% mIoU和72.8% Dice系数，相比更深骨干网络（ResNet152、Xception）减少60%以上计算成本。虽然山脊描绘受亚像素宽度和光谱模糊性限制，但结果证明仅用光学影像可提供可靠的冰碛体分割。

Conclusion: 该研究建立了可复现的冰碛垄分割基准，为高海拔冰川监测提供了可部署的基线模型，数据集和代码已公开。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [145] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: InpaintHuman：一种从遮挡单目视频重建完整可动画3D人体化身的新方法，通过多尺度UV参数化表示和身份保持扩散修复模块解决遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 从单目视频重建完整可动画的3D人体化身具有挑战性，特别是在严重遮挡情况下。现有基于3D高斯泼溅的方法在遮挡区域重建时存在几何损坏和时间不一致问题。

Method: 提出两个关键创新：1) 多尺度UV参数化表示，采用分层从粗到细的特征插值，实现遮挡区域的鲁棒重建；2) 身份保持扩散修复模块，结合文本反转和语义条件引导，实现主体特定、时间一致性的补全。

Result: 在合成基准数据集（PeopleSnapshot、ZJU-MoCap）和真实场景（OcMotion）上的实验表明，该方法在重建质量上具有竞争优势，在不同姿态和视角下均能获得一致改进。

Conclusion: InpaintHuman能够从遮挡单目视频生成高保真、完整且可动画的3D人体化身，通过直接像素级监督确保身份保真度，优于基于SDS的方法。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [146] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 提出一种基于3D高斯泼溅的前馈框架，用于360度图像重建，通过深度-法向几何正则化提升几何一致性，同时保持高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 传统多视图立体方法在稀疏视角或低纹理区域表现不佳，神经渲染方法需要逐场景优化且缺乏实时性，现有3D高斯泼溅方法注重视觉质量但几何一致性不足，限制了在空间感知任务中的准确性和可靠性。

Method: 提出前馈3D高斯泼溅框架，引入深度-法向几何正则化，将渲染深度梯度与法向信息耦合，监督高斯的旋转、尺度和位置，以提升点云和表面精度。

Result: 实验结果表明，该方法在保持高质量渲染的同时，显著提升了几何一致性，为空间感知任务中的3D重建提供了有效解决方案。

Conclusion: 该方法成功解决了3D高斯泼溅在几何一致性方面的不足，为AR、机器人和数字孪生等应用提供了更可靠的空间感知能力。

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [147] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: HeadLighter是一个基于3D高斯泼溅的头部生成模型，通过监督学习实现外观与照明的物理可分解，支持可控重光照和视角编辑，同时保持高质量生成和实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的头部生成模型虽然能实现实时、逼真且视角一致的头部合成，但存在根本限制：光照与内在外观的深度纠缠阻碍了可控重光照。现有解纠缠方法依赖强假设进行弱监督学习，限制了处理复杂光照的能力。

Method: 提出HeadLighter框架：1）设计双分支架构分别建模光照不变的头部属性和物理基础的渲染组件；2）采用渐进解纠缠训练，在光照阶段设置下利用多视角图像监督；3）引入蒸馏策略生成高质量法线以实现逼真渲染。

Result: 实验表明该方法保持了高质量生成和实时渲染能力，同时支持显式光照和视角编辑。代码和数据集将公开。

Conclusion: HeadLighter通过监督学习实现了外观与照明的物理可分解，解决了现有头部生成模型中光照纠缠问题，为可控重光照和编辑提供了有效解决方案。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [148] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: 提出首个个性化双人武术对战视频生成任务MagicFight，解决现有单人舞蹈生成模型在双人交互场景中的身份混淆、肢体异常和动作不匹配问题


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成技术主要关注单人生成，而双人交互场景（特别是武术对战）尚未被探索。现有单人舞蹈生成模型无法捕捉双人战斗的细微差别和复杂性，导致身份混淆、异常肢体和动作不匹配等问题

Method: 使用Unity游戏物理引擎创建定制数据集，包含多样化的3D角色、武术动作和场景。MagicFight方法改进和调整现有模型和策略，生成保持个体身份和连贯动作序列的高保真双人战斗视频

Result: 成功开发了首个个性化武术对战视频生成系统，创建了专门的KungFu-Fiesta数据集，为交互式视频内容创作领域奠定了基础

Conclusion: MagicFight填补了双人交互视频生成领域的空白，特别是武术对战场景，为未来交互式视频内容创新提供了基础框架和数据集支持

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [149] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

TL;DR: 提出基于顺序切片处理的轻量级代理模型，用于预测3D车辆气动阻力系数，实现快速准确的气动评估。


<details>
  <summary>Details</summary>
Motivation: 传统CFD和风洞测试资源密集，阻碍早期设计快速迭代；现有机器学习代理模型存在计算复杂、可解释性差或精度不足的问题。

Method: 将3D车辆点云沿流向轴分解为有序2D横截面切片序列，每个切片用轻量级PointNet2D编码，切片嵌入序列用双向LSTM处理以捕捉纵向几何演变。

Result: 在DrivAerNet++数据集上达到高决定系数(R^2 > 0.9528)和低平均绝对误差(MAE ≈ 6.046×10^{-3})，消费级GPU上推理时间约0.025秒/样本。

Conclusion: 该方法提供快速、准确、可解释的气动反馈，促进更敏捷和明智的汽车设计探索。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [150] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出OSCD（油污变化检测）新任务，通过双时相SAR图像对比检测油污，并使用TAHI框架生成合成溢油前图像，显著降低误报率


<details>
  <summary>Details</summary>
Motivation: 传统基于单幅SAR图像的深度学习分割方法难以区分真实油污与视觉相似的海面特征（如生物油膜、低风区），导致高误报率和有限泛化能力，特别是在数据稀缺条件下

Method: 提出OSCD双时相变化检测任务，开发TAHI（时序感知混合修复）框架，包含高保真混合修复（用于无油重建）和时序真实性增强（用于辐射和海洋状态一致性）两个关键组件

Result: 构建了首个OSCD数据集，基准测试显示OSCD相比传统分割方法显著降低误报率并提高检测精度，证明了时序感知方法在实际油污监测中的价值

Conclusion: OSCD任务和TAHI框架为可靠、可扩展的海洋油污监测提供了新方法，通过时序变化检测有效区分真实油污与相似海面特征，提高了实际应用中的检测可靠性

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [151] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

TL;DR: 提出一种域分割策略和正规算子近似方法，使大规模成像问题（如3D成像）能够训练端到端重建模型，在单GPU上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在3D等大规模成像问题中难以将全局前向算子整合到网络架构中，因为内存需求过高，阻碍了典型的分块策略。

Method: 提出域分割策略和正规算子近似方法，将大规模前向算子分解为可管理的子问题，使端到端重建模型能够处理任意大规模问题。

Result: 在3D X射线锥束断层扫描和3D多线圈加速MRI上达到最先进性能，且训练和推理仅需单个GPU。

Conclusion: 该方法成功解决了大规模成像问题中整合前向算子的内存限制问题，为3D成像等大规模逆问题提供了实用的深度学习解决方案。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [152] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 使用商用ESP32 WiFi传感器进行多人步态识别效果不佳，多种信号分离方法准确率仅45-56%，表明硬件限制而非算法问题是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然WiFi CSI在单人步态识别中表现良好，但多人识别研究较少且依赖复杂昂贵设备。需要探究多人识别性能差是算法限制还是硬件约束。

Method: 使用商用ESP32 WiFi传感器，系统评估六种信号分离方法（FastICA、SOBI、PCA、NMF、小波、张量分解），在1-10人的七种场景下测试，并引入新的诊断指标（主体内变异性、主体间可区分性、性能退化率）。

Result: 所有方法准确率相似且较低（45-56%，σ=3.74%），统计差异不显著（p>0.05）。最佳方法NMF仅56%准确率。分析显示高主体内变异性、低主体间可区分性，且随人数增加性能严重退化。

Conclusion: 商用ESP32传感器无法提供足够的信号质量进行可靠的多人分离，多人识别性能差主要是硬件限制而非算法问题。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [153] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

TL;DR: 提出量子启发的交互分类器QuIC，通过模拟量子态交互捕捉二阶特征协方差，显著提升浅层网络在细粒度视觉分类任务上的性能，同时保持轻量化和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上部署细粒度视觉分类模型面临挑战：深层网络计算成本高，浅层网络因标准全局平均池化仅捕捉一阶统计量而无法区分视觉相似的子类别。双线性CNN虽能解决但存在特征维度爆炸和训练不稳定问题。

Method: 提出量子启发的交互分类器QuIC，将特征通道建模为相互作用的量子态，通过可学习的观测算子捕捉二阶特征协方差。该模块轻量、即插即用，支持稳定的单阶段端到端训练，不会导致特征维度爆炸。

Result: QuIC显著提升了浅层骨干网络的性能：将VGG16的Top-1准确率提升近20%，在ResNet18上优于最先进的注意力机制SE-Block。t-SNE可视化证实QuIC能解决模糊案例，显式关注细粒度判别特征并强制紧凑的类内聚类。

Conclusion: QuIC通过量子启发的二阶特征交互建模，有效解决了细粒度视觉分类中浅层网络性能不足的问题，在保持轻量化和训练稳定性的同时显著提升了分类准确率，为边缘设备上的细粒度分类提供了实用解决方案。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [154] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 病理学基础模型在不同放大倍数下的性能存在差异，连续放大倍数采样优于离散采样，优化采样分布可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 病理学家在诊断时需要在不同放大倍数下观察组织，但现有病理学基础模型在不同放大倍数下的性能差异以及训练时放大倍数采样的影响尚不清楚。

Method: 将放大倍数采样建模为多源域适应问题，提出理论框架分析采样策略的权衡。引入连续放大倍数采样，推导优化采样分布，并建立两个新基准（TCGA-MS, BRACS-MS）进行评估。

Result: 连续采样在中间放大倍数上显著优于离散采样，平衡分类准确率提升达4个百分点；优化分布可进一步提高性能；放大倍数是模型性能差异的主要驱动因素。

Conclusion: 连续放大倍数采样和优化采样分布能显著提升病理学基础模型在不同放大倍数下的性能，为开发跨放大倍数可靠的病理学基础模型铺平了道路。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [155] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出基于CSI-ResNet-A的两阶段框架，通过自监督对比学习预训练获取域不变表示，结合轻量适配器微调和状态计数机，实现无需设备的WiFi人群计数，在域迁移问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 基于WiFi信道状态信息（CSI）的无设备人群计数是新一代隐私保护物联网应用的关键技术，但实际部署受到域迁移问题的严重阻碍——在一个环境训练的模型无法泛化到其他环境。

Method: 提出两阶段框架：1）使用CSI-ResNet-A架构，通过自监督对比学习预训练学习域不变表示；2）利用轻量适配器模块进行高效微调，最后通过状态计数机处理事件序列生成稳定的占用估计。

Result: 在WiFlow数据集上，无监督方法在10-shot学习场景中达到MAE仅0.44，而监督基线失败；引入泛化指数（GI）评估，模型得分接近完美；在公开WiAR基准上达到98.8%准确率的新SOTA；适配器微调性能接近全微调（98.84% vs 99.67%），但训练参数减少97.2%。

Conclusion: 该工作为开发稳健的感知系统提供了实用且可扩展的解决方案，适用于真实世界的物联网部署，通过域不变表示学习和高效适配器微调解决了域迁移问题。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [156] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 该论文提出了一种系统分析MMDiT模型内部机制的方法，通过移除、禁用和增强文本隐藏状态来研究不同模块的功能，并基于发现提出了无需训练的策略来改进文本对齐、精确编辑和加速推理。


<details>
  <summary>Details</summary>
Motivation: 尽管基于MMDiT的扩散模型（如FLUX和Qwen Image）在文本到图像生成方面取得了突破，但现有方法主要分析特定组件（如位置编码和注意力层），缺乏对不同模块及其与文本条件交互如何影响合成过程的全面理解。

Method: 开发了系统化的分析流程，通过移除、禁用和增强文本隐藏状态来全面研究每个模块的功能。基于分析结果，提出了无需训练的策略来改进文本对齐、精确编辑和加速推理。

Result: 实验表明：1）语义信息出现在早期模块，细节在后期模块渲染；2）移除特定模块通常比禁用文本条件破坏性小；3）在选择性模块增强文本条件可改善语义属性。提出的方法在SD3.5上将T2I-Combench++从56.92%提升到63.00%，GenEval从66.42%提升到71.63%，且不牺牲合成质量。

Conclusion: 该研究推进了对MMDiT模型的理解，为文本到图像生成、图像编辑和推理加速提供了有价值的见解，并为进一步改进开辟了新的可能性。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [157] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

TL;DR: 提出一种先验引导的DETR框架用于超声结节检测，通过多阶段融入几何和结构先验知识，在甲状腺和乳腺超声数据集上取得优于18种现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测对甲状腺和乳腺癌早期诊断至关重要，但面临结节形状不规则、边界模糊、尺度变化大以及斑点噪声导致结构可见性降低等挑战。现有方法主要依赖数据驱动的特征学习，缺乏对结节几何和结构先验知识的有效利用。

Method: 提出先验引导的DETR框架：1) SDFPR模块在CNN骨干中注入几何先验，稳定不规则和模糊结节的特征提取；2) MSFFM模块提取多尺度结构先验，空间域处理强调轮廓连续性和边界线索，频域建模捕获全局形态并抑制斑点噪声；3) DFI机制在所有编码器层传播和利用这些先验调制特征，使解码器能在一致的几何和结构指导下增强查询细化。

Result: 在两个临床收集的甲状腺超声数据集（Thyroid I和Thyroid II）以及两个公共基准（TN3K和BUSI）上进行实验，证明该方法在检测形态复杂结节方面优于18种检测方法，取得了更优的准确率。

Conclusion: 提出的先验引导DETR框架通过渐进式融入几何和结构先验知识，有效解决了超声结节检测中的挑战，特别是在检测形态复杂结节方面表现出色，为超声医学图像分析提供了新的解决方案。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [158] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: FMVP使用流匹配和掩码策略进行对抗视频净化，通过频率门控损失分离语义内容和对抗噪声，在已知和未知攻击下都表现优异


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的净化方法采样效率低且轨迹弯曲，直接回归干净视频难以恢复忠实内容，需要物理破坏对抗结构

Method: 提出FMVP：1) 通过掩码策略物理破坏全局对抗结构；2) 使用条件流匹配(CFM)和修复目标重建干净视频动态；3) 设计频率门控损失(FGL)抑制高频对抗残差同时保持低频保真度；4) 设计攻击感知和通用训练范式

Result: 在UCF-101和HMDB-51上优于现有方法(DiffPure、DP、TS、FlowPure)，对PGD攻击鲁棒准确率超87%，对CW攻击超89%；对自适应攻击(DiffHammer)表现优异，可作为零样本对抗检测器，PGD检测准确率98%，CW检测准确率79%

Conclusion: FMVP通过物理破坏对抗结构和频率感知的净化，实现了高效且鲁棒的视频对抗净化，在已知和未知攻击下都表现优异，并能作为有效的对抗检测器

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [159] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: SLGNet：结合结构先验和语言引导调制的参数高效多模态目标检测框架，在RGB和红外图像上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的方法在将RGB预训练基础模型迁移到多模态检测时，往往牺牲跨模态结构一致性，导致在高对比度或夜间环境等域差距大的场景中丢失关键结构线索。传统静态多模态融合机制缺乏环境感知能力，在复杂动态场景变化下适应性差。

Method: 提出SLGNet框架：1) 结构感知适配器提取双模态的层次结构表示并动态注入ViT以补偿结构退化；2) 语言引导调制模块利用VLM驱动的结构化描述动态重新校准视觉特征，赋予模型环境感知能力。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上达到SOTA性能。在LLVIP基准上实现66.1 mAP，相比传统全微调减少约87%可训练参数。

Conclusion: SLGNet是一个稳健高效的多模态感知解决方案，通过结合层次结构先验和语言引导调制，在保持参数效率的同时显著提升检测性能。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [160] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 提出增强GRPO的新框架，通过管理VAR模型中的异步策略冲突，改善视觉生成质量和对齐效果。


<details>
  <summary>Details</summary>
Motivation: VAR模型在生成步骤中存在异构输入结构，导致严重的异步策略冲突，特别是在强化学习场景中会造成训练不稳定和对齐效果不佳。

Method: 集成三个协同组件：1) 稳定早期生成的中间奖励；2) 精确信用分配的动态时间步重加权方案；3) 基于奖励反馈学习原理的掩码传播算法，实现时空优化隔离。

Result: 相比原始GRPO基线，在样本质量和目标对齐方面有显著改进，实现了VAR模型的鲁棒有效优化。

Conclusion: 提出的框架成功解决了VAR模型中的异步策略冲突问题，为视觉生成模型的强化学习优化提供了有效解决方案。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [161] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: DiffProxy：利用扩散模型生成多视角一致的人体代理，解决真实数据标注不完美和合成数据域差距问题，实现零样本泛化的网格重建


<details>
  <summary>Details</summary>
Motivation: 真实世界数据集的标注存在不完美问题，会引入训练偏差；而合成数据虽然有精确监督，但存在域差距问题。需要一种方法既能利用合成数据的精确监督，又能实现真实世界的泛化。

Method: 提出DiffProxy框架，利用扩散生成先验连接合成训练和真实世界泛化。包括：1）多条件机制生成多视角一致、像素对齐的人体代理；2）手部细化模块结合灵活视觉提示增强局部细节；3）不确定性感知的测试时缩放方法提高优化鲁棒性。

Result: 完全在合成数据上训练，在五个真实世界基准测试中达到最先进性能，在遮挡和部分视角等挑战性场景下表现出强大的零样本泛化能力。

Conclusion: DiffProxy通过扩散生成先验有效结合了合成数据的精确监督和生成管道的优势，实现了从多视角图像中鲁棒的人体网格恢复，特别是在挑战性场景下表现出色。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [162] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: InfiniteVGGT提出了一种因果视觉几何Transformer，通过有界但自适应的KV缓存实现无限时域流式处理，解决了3D几何理解中可扩展性与长期稳定性的矛盾，并引入Long3D基准进行严格评估。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉几何理解方法面临可扩展性与长期稳定性的矛盾：离线模型（如VGGT）无法用于实时系统，而流式架构要么不支持无限时域输入，要么在长序列中出现灾难性漂移。

Method: 提出InfiniteVGGT，一种因果视觉几何Transformer，采用有界但自适应的KV缓存实现"滚动记忆"机制，配合无需训练的注意力无关剪枝策略，智能丢弃过时信息，与FlashAttention完全兼容。

Result: InfiniteVGGT在无限时域流式处理中优于现有流式方法，在长期稳定性方面表现优异，并通过新提出的Long3D基准（约10,000帧连续序列）进行了严格验证。

Conclusion: InfiniteVGGT解决了3D几何理解中长期存在的可扩展性与稳定性矛盾，为无限时域流式处理提供了可行方案，Long3D基准为未来长期3D几何理解研究提供了权威评估平台。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [163] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: GeoRank是一种用于多光谱遥感图像对比自监督学习的新型正则化方法，通过直接优化球面距离将地理关系嵌入到特征空间中，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在计算机视觉中已很强大，但应用于多光谱遥感图像面临独特挑战，因为数据具有地理和时间变异性。现有方法未能充分利用地理关系。

Method: 提出GeoRank正则化方法，通过直接优化球面距离将地理关系嵌入对比自监督学习的特征空间。同时系统研究了多光谱遥感图像对比自监督学习的关键适应性问题。

Result: GeoRank在性能上优于或匹配现有整合地理元数据的方法，并能持续改进多种对比自监督学习算法（如BYOL、DINO）。

Conclusion: GeoRank为多光谱遥感图像的自监督学习提供了有效的正则化方法，同时系统研究为领域提供了重要见解。代码已开源。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [164] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

TL;DR: 作者提出了SortWaste数据集和ClutterScore指标来改进废物自动分拣系统，现有模型在复杂场景下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 废物产量增加导致管理挑战，人工分拣效率低且有健康风险，现有自动分拣系统难以处理真实世界废物流的高变异性、杂乱性和视觉复杂性，缺乏真实数据集是主要原因。

Method: 1. 引入SortWaste数据集，来自材料回收设施的密集标注目标检测数据集；2. 提出ClutterScore指标，通过对象数量、类别和大小熵、空间重叠等代理变量客观评估场景复杂度；3. 对最先进的目标检测模型进行广泛基准测试。

Result: 在塑料检测任务中达到59.7% mAP，但在高度杂乱场景中性能显著下降，表明需要更具挑战性的数据集。

Conclusion: SortWaste数据集和ClutterScore指标有助于标准化废物检测，现有模型在复杂场景下仍有局限，需要更先进的方法和更具挑战性的数据集来改进废物自动分拣系统。

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [165] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 360DVO是首个基于深度学习的单目全景视觉里程计框架，通过失真感知球面特征提取器和全景可微分光束法平差模块，在挑战性场景中显著提升了鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有全景视觉里程计方法依赖手工特征或光度目标，在剧烈运动和光照变化等挑战性场景中缺乏鲁棒性，需要更强大的深度学习解决方案。

Method: 提出360DVO框架：1）失真感知球面特征提取器（DAS-Feat）自适应学习360度图像的抗失真特征；2）稀疏特征块用于建立姿态估计约束；3）新颖的全景可微分光束法平差（ODBA）模块进行有效姿态估计。

Result: 在真实世界新基准和公开合成数据集（TartanAir V2和360VO）上的实验表明，360DVO超越了最先进的基线方法（包括360VO和OpenVSLAM），鲁棒性提升50%，精度提升37.5%。

Conclusion: 360DVO是首个基于深度学习的全景视觉里程计框架，通过创新的特征提取和优化模块，显著提升了在挑战性场景中的性能，为全景视觉里程计研究提供了新方向。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [166] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: Prithvi-CAFE：一种融合地理基础模型与CNN残差分支的编码器，通过注意力模块和多尺度融合提升洪水制图性能，在两个数据集上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 现有地理基础模型（GFMs）在洪水制图任务中难以超越基线U-Net，主要因为无法捕捉关键的局部细节信息

Method: 提出Prithvi-CAFE，集成Prithvi GFM预训练编码器与并行CNN残差分支，使用卷积注意力模块增强，通过适配器快速微调，实现多尺度多层级特征融合

Result: 在Sen1Flood11测试集上IoU达83.41，优于原Prithvi(82.50)和其他GFMs；在保留测试点上IoU 81.37显著优于U-Net(70.57)；在FloodPlanet上IoU 64.70也超越所有对比方法

Conclusion: Prithvi-CAFE简单有效，在多通道多模态数据提供互补信息且局部细节关键的分割任务中具有强大潜力

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [167] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

TL;DR: Fusion2Print (F2P) 通过融合闪光-非闪光配对的非接触式指纹图像，提升脊线清晰度，实现与非接触式和接触式指纹的跨域兼容识别。


<details>
  <summary>Details</summary>
Motivation: 非接触式指纹识别虽然卫生方便，但图像质量常因光照变化、皮下皮肤变色和镜面反射而下降。闪光拍摄保留脊线细节但引入噪声，非闪光拍摄减少噪声但降低脊线对比度。

Method: 1) 构建配对的闪光-非闪光数据集(FNF Database)；2) 通过手动减法分离脊线保留信号；3) 轻量级注意力融合网络整合两种模态；4) U-Net增强模块生成优化灰度图像；5) 跨域兼容的深度嵌入模型生成统一嵌入空间表示。

Result: F2P显著提升脊线清晰度，在识别性能上优于单次拍摄基线方法(Verifinger, DeepPrint)，达到AUC=0.999，EER=1.12%。

Conclusion: Fusion2Print通过系统性地融合闪光和非闪光非接触式指纹，有效解决了单模态图像的质量问题，实现了与非接触式和接触式指纹系统的跨域兼容，为实际应用提供了可靠解决方案。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [168] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

TL;DR: BEDS框架统一非平衡热力学、贝叶斯推断、信息几何和机器学习，提出学习本质上是通过熵输出将通量转化为结构的过程，并建立了热力学过程与贝叶斯更新之间的形式同构。


<details>
  <summary>Details</summary>
Motivation: 旨在建立一个统一的理论框架，将物理、生物和计算系统中的学习过程联系起来，揭示学习的根本本质，并为可持续人工智能提供理论基础。

Method: 基于普里戈金的耗散结构理论，建立热力学过程与贝叶斯更新的形式同构；推导基本数学常数作为贝叶斯推断的固定点；提出哥德尔不完备定理与热力学约束的猜想；设计实现BEDS原理的对等网络架构。

Result: 推导出e、π、φ等基本数学常数作为贝叶斯推断的必然固定点；提出的对等网络架构相比现有分布式共识系统实现了六个数量级的能效提升，同时支持持续学习。

Conclusion: BEDS框架成功连接了基础物理、数理逻辑和实际系统设计，为理解学习和计算的本质提供了理论洞见，并为可持续人工智能提供了具体实现路径。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [169] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出一个联合增强的3D语义高斯建模框架，通过语义和渲染分支的协同作用，改进现有3D高斯语义分割方法在几何感知和自适应策略上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯语义分割方法存在三个主要问题：1）语义和渲染分支分离处理，仅依赖2D监督而忽略3D高斯几何；2）自适应策略仅依赖渲染梯度，在纹理稀疏区域效果不佳；3）缺乏对3D形状细节的捕获能力。

Method: 1）引入各向异性3D高斯切比雪夫描述符，使用拉普拉斯-贝尔特拉米算子捕获细粒度3D形状细节；2）基于局部语义和形状信号自适应调整高斯分配和球谐函数；3）采用跨场景知识转移模块持续更新学习到的形状模式。

Result: 在多个数据集上的实验表明，该方法在保持高渲染帧率的同时，显著提升了分割精度和渲染质量。

Conclusion: 提出的联合增强框架通过协同语义和渲染分支、引入3D形状描述符、改进自适应策略和知识转移机制，有效解决了现有3D高斯语义建模方法的局限性，实现了更好的分割和渲染性能。

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [170] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

TL;DR: 提出DACIS方法结合神经网络剪枝与少样本学习，大幅压缩模型尺寸同时保持高精度，使植物病害检测能在树莓派上实时运行


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民需要快速可靠的植物病害识别方法，但缺乏实验室或高性能计算资源。现有深度学习模型虽准确但过大，无法在低成本边缘设备上运行，且收集大量标注图像成本高、耗时长。

Method: 提出Disease-Aware Channel Importance Scoring (DACIS)方法，识别神经网络中对区分不同植物病害最重要的部分，并集成到三阶段Prune-then-Meta-Learn-then-Prune (PMP)流程中，结合神经网络剪枝与少样本学习。

Result: 在PlantVillage和PlantDoc数据集上实验显示，该方法将模型尺寸减少78%，同时保持92.3%的原始准确率，压缩后的模型在树莓派4上能以7帧/秒的速度运行。

Conclusion: 该方法使实时田间病害诊断对小农户变得实用，解决了偏远地区植物病害检测的计算资源限制和数据稀缺问题。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [171] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move是一个基于强化学习的扩散框架，用于通过文本指令对场景中的物体进行空间变换（平移、旋转、缩放），无需配对监督数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的编辑方法主要调整外观或风格，难以执行物体级别的几何变换，因为缺乏配对监督数据和像素级优化的限制。

Method: 使用Group Relative Policy Optimization (GRPO)通过输入图像和轻量文本变体生成多样rollout来探索几何动作；设计空间奖励模型对齐几何变换与语言描述；采用离策略步骤评估和主动步骤采样提高学习效率；设计物体中心的空间奖励直接评估位移、旋转和缩放行为。

Result: 在精心设计的基准测试中，Talk2Move实现了精确、一致且语义忠实的物体变换，在空间准确性和场景连贯性方面优于现有文本引导编辑方法。

Conclusion: Talk2Move通过强化学习框架成功解决了文本指令下物体空间变换的挑战，实现了可解释且连贯的几何变换，无需昂贵的配对数据。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [172] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

TL;DR: VINO是一个统一的视觉生成器，在单一框架内执行图像和视频的生成与编辑，使用共享的扩散主干和多模态条件处理，避免了针对特定模态的架构组件。


<details>
  <summary>Details</summary>
Motivation: 当前视觉生成系统通常需要针对不同任务（图像生成、视频生成、编辑）使用专门的模型或独立模块，缺乏统一的解决方案。VINO旨在创建一个单一模型，能够处理多种视觉创建和编辑任务，实现更高效和一致的视觉生成。

Method: VINO将视觉语言模型（VLM）与多模态扩散变换器（MMDiT）耦合，将多模态输入编码为交错的条件标记，用于指导扩散过程。采用多阶段训练流程，逐步将视频生成基础模型扩展为统一的多任务生成器。

Result: VINO在多样化的生成和编辑基准测试中表现出强大的视觉质量、准确的指令跟随能力、改进的参考和属性保持，以及更可控的多身份编辑效果。

Conclusion: VINO展示了实现可扩展统一视觉生成的实用路径，交错上下文计算作为通用视觉创建的基础具有广阔前景。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


### [173] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: ExposeAnyone：基于扩散模型的自监督人脸伪造检测方法，通过音频生成表情序列，利用个性化扩散重建误差进行身份距离计算，在未知伪造检测上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法主要依赖监督训练，容易过拟合特定伪造模式，无法泛化到未见过的伪造类型。自监督方法虽有泛化潜力，但现有方法难以仅从自监督中学习到判别性表征。

Method: 提出完全自监督的ExposeAnyone方法：1）使用扩散模型从音频生成表情序列；2）通过参考集对特定主体进行个性化建模；3）通过扩散重建误差计算疑似视频与个性化主体之间的身份距离，实现感兴趣人物的人脸伪造检测。

Result: 1）在DF-TIMIT、DFDCP、KoDF和IDForge数据集上，平均AUC比之前SOTA方法提升4.22个百分点；2）能够检测Sora2生成的视频，而之前方法表现不佳；3）对模糊和压缩等损坏具有高度鲁棒性。

Conclusion: ExposeAnyone展示了自监督方法在未知深度伪造检测中的有效性，通过扩散模型和个性化建模实现了优异的泛化能力和鲁棒性，适用于真实世界的人脸伪造检测场景。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [174] [The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2601.00797)
*Hugues Draelants*

Main category: cs.CL

TL;DR: 本文提出使用大语言模型进行社会学角色模拟作为"定性实验室"，用于生成关于不同社会群体如何解读新信息的丰富定性假设。


<details>
  <summary>Details</summary>
Motivation: 社会科学面临的核心挑战是如何生成关于不同社会群体如何解读新信息的丰富定性假设。现有方法如小插曲调查缺乏话语深度，基于规则的ABM存在形式化瓶颈，需要新方法来解决这些问题。

Method: 提出社会学角色模拟方法，使用大语言模型作为"定性实验室"。具体协议是从气候接收社会学理论中提取角色，让这些角色对政策信息做出反应，生成自然主义的话语。

Result: 模拟产生了细致入微且反直觉的假设，例如保守角色拒绝国家安全框架，这挑战了理论假设。该方法能够生成用于后续实证检验的深度纹理化假设。

Conclusion: 社会学角色模拟作为"模拟后验证"工作流程的一部分，代表了生成深度纹理化假设的优越工具，为后续实证测试提供了更好的基础。

Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a "qualitative laboratory". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a "simulation then validation" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.

</details>


### [175] [Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates](https://arxiv.org/abs/2601.00938)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

TL;DR: 本文提出压缩查询委托（CQD）方法，通过将高维推理状态压缩为低秩张量查询，委托给外部oracle，并在固定秩流形上进行黎曼优化，解决有界上下文agent推理超出工作内存限制的问题。


<details>
  <summary>Details</summary>
Motivation: 有界上下文agent在中间推理超出有效工作内存预算时会失败，需要一种方法在有限计算和上下文条件下进行更有效的推理。

Method: 提出压缩查询委托（CQD）：1）将高维潜在推理状态压缩为低秩张量查询；2）将最小化查询委托给外部oracle；3）通过固定秩流形上的黎曼优化更新潜在状态。该方法被形式化为带查询预算功能和噪声oracle模型的约束随机规划问题。

Result: 理论证明谱硬阈值对于约束二次失真问题是最优的，并在有界oracle噪声和平滑性假设下推导了黎曼随机逼近的收敛保证。实证研究包括：A）在2,500项有界上下文推理套件上比较CQD与思维链基线；B）人类"认知镜像"基准测试（N=200）测量现代oracle的认知增益和语义漂移。

Conclusion: CQD为有界上下文推理提供了一种数学严谨的框架，将压缩、委托和流形优化相结合，在理论和实证上都展示了其在有限计算和上下文条件下的有效性。

Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a query-budget functional and an oracle modeled as a noisy operator. We connect CQD to classical rate-distortion and information bottleneck principles, showing that spectral hard-thresholding is optimal for a natural constrained quadratic distortion problem, and we derive convergence guarantees for Riemannian stochastic approximation under bounded oracle noise and smoothness assumptions. Empirically, we report (A) a 2,500-item bounded-context reasoning suite (BBH-derived tasks plus curated paradox instances) comparing CQD against chain-of-thought baselines under fixed compute and context; and (B) a human "cognitive mirror" benchmark (N=200) measuring epistemic gain and semantic drift across modern oracles.

</details>


### [176] [Intention Collapse: Intention-Level Metrics for Reasoning in Language Models](https://arxiv.org/abs/2601.01011)
*Patricio Vera*

Main category: cs.CL

TL;DR: 论文提出"意图坍缩"概念，即语言生成将高维内部状态压缩为单一token序列的过程，并定义了三个意图度量指标来研究推理计算如何影响语言模型在表达前的内部意图。


<details>
  <summary>Details</summary>
Motivation: 研究语言生成过程中丰富的内部状态如何被压缩为单一token序列这一"意图坍缩"现象，理解推理时计算如何塑造语言模型在表达前的内部意图。

Method: 形式化当代语言模型的意图坍缩概念，定义三个模型无关的意图度量指标（意图熵Hint、有效维度dimeff、潜在知识可恢复性Recov），提出研究推理计算影响内部意图的实证框架，并在Mistral 7B模型上进行小规模实验。

Result: CoT将准确率从5.5%提升至53%，显著降低坍缩前意图熵（从1.42降至0.37比特），在产生比babble更少token的情况下仍显示更高的全局有效维度。意图熵在项目层面预测能力有限，CoT机制下线性探针AUROC达0.65，而基线机制下仅接近随机水平。

Conclusion: 意图层面度量指标能区分不同推理机制，揭示在坍缩过程中部分丢失的潜在信息，但当前代理指标仍有重要局限性，为研究语言模型内部表示提供了新视角。

Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies

</details>


### [177] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://arxiv.org/abs/2601.01015)
*Shiyuan Liu,Jianwei Wang,Xuemin Lin,Lu Qin,Wenjie Zhang,Ying Zhang*

Main category: cs.CL

TL;DR: HyperJoin：基于大语言模型增强的超图框架，用于可连接表发现，通过建模表内和表间结构信息，将任务转化为超图链接预测，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的方法在离线阶段将表建模为孤立或成对的列，难以捕捉丰富的表间和表内结构信息；在线阶段仅基于查询-候选相似度排序，忽略了候选列之间的相互影响，导致结果集不连贯。

Method: 1. 构建超图：使用表内超边和LLM增强的表间超边建模表结构；2. 设计HIN分层交互网络：通过列和超边的双向消息传递学习表达性列表示；3. 在线重排序：将排名转化为连贯性感知的top-k列选择问题，使用最大生成树算法修剪噪声连接并最大化连贯性。

Result: 实验表明HyperJoin显著优于现有方法，在Precision@15和Recall@15指标上分别平均提升21.4%和17.2%。

Conclusion: HyperJoin通过超图建模表结构信息，结合LLM增强和连贯性感知的重排序，有效解决了现有方法在结构交互建模和结果连贯性方面的不足，显著提升了可连接表发现的性能。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.

</details>


### [178] [Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation](https://arxiv.org/abs/2601.01037)
*Livia Leong Hui Teng*

Main category: cs.CL

TL;DR: 提出多维度提示链框架，通过自然性、连贯性和吸引力三个维度提升小语言模型在开放域对话中的人类相似度，使7B模型达到与70B模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）在部署上有优势，但在开放域对话质量上难以匹敌大模型。需要一种资源高效的方法来提升SLMs的对话质量。

Method: 提出多维度提示链框架，整合自然性、连贯性和吸引力三个维度。将该框架应用于TinyLlama和Llama-2-7B，并与Llama-2-70B和GPT-3.5 Turbo进行基准比较。

Result: 完整框架将响应多样性提升达29%，上下文连贯性提升达28%，吸引力和自然性提升达29%。Llama-2-7B达到与Llama-2-70B和GPT-3.5 Turbo相当的性能。

Conclusion: 精心设计的基于提示的策略为提升小语言模型的开放域对话质量提供了有效且资源高效的途径。

Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.

</details>


### [179] [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: KV-Embedding：一种无需训练的方法，通过重定向LLM最后一层token的KV状态作为前缀，激活冻结LLM的潜在表征能力，解决因果注意力和下一个token预测目标带来的结构限制。


<details>
  <summary>Details</summary>
Motivation: LLM在无需训练场景下存在两个结构挑战：因果注意力限制早期token访问后续上下文；下一个token预测目标使表征偏向生成而非语义压缩。需要激活冻结LLM的潜在表征能力。

Method: 利用观察发现：每层最后一个token的键值（KV）状态编码了序列的压缩视图。将这些状态重定向为前置前缀，使所有token能在单次前向传播中访问序列级上下文。引入基于内在维度的自动层选择策略以确保模型无关性。

Result: 在MTEB基准测试中，使用Qwen、Mistral和Llama骨干网络，KV-Embedding比现有无需训练基线性能提升高达10%，在长达4096个token的序列上保持稳健性能。

Conclusion: 内部状态操作为输入修改提供了高效替代方案，这项工作鼓励进一步探索LLM内部机制用于表征学习。

Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method leverages the observation that the key-value (KV) states of the final token at each layer encode a compressed view of the sequence. By re-routing these states as a prepended prefix, we enable all tokens to access sequence-level context within a single forward pass. To ensure model-agnostic applicability, we introduce an automated layer selection strategy based on intrinsic dimensionality. Evaluations on MTEB across Qwen, Mistral, and Llama backbones show that KV-Embedding outperforms existing training-free baselines by up to 10%, while maintaining robust performance on sequences up to 4,096 tokens. These results demonstrate that internal state manipulation offers an efficient alternative to input modification, and we hope this work encourages further exploration of LLM internals for representation learning.

</details>


### [180] [Unsupervised Text Style Transfer for Controllable Intensity](https://arxiv.org/abs/2601.01060)
*Shuhuan Gu,Wenbiao Tao,Xinchen Ma,Kangkang He,Ye Guo,Xiang Li,Yunshi Lan*

Main category: cs.CL

TL;DR: 提出SFT-then-PPO范式，通过合成平行数据微调LLM，再使用PPO训练，设计分层奖励函数区分风格强度，在无监督文本风格迁移中实现可控强度


<details>
  <summary>Details</summary>
Motivation: 无监督文本风格迁移中，可控强度迁移比极性迁移更具挑战性，因为不同强度级别间的风格特征差异细微，且缺乏平行数据，相邻强度级别难以区分

Method: 提出SFT-then-PPO范式：1) 使用合成平行数据对LLM进行监督微调；2) 使用PPO进一步训练，设计分层奖励函数，同时考虑全局和局部风格特征来区分风格强度

Result: 在两个UTST基准测试中，两种奖励函数各有优势，应用于LLM微调能有效提升基于各种评估指标的LLM骨干性能，即使对于相近强度级别，生成文本间仍能观察到明显的风格差异

Conclusion: 提出的SFT-then-PPO范式结合精心设计的奖励函数，能够有效解决无监督文本风格迁移中的可控强度问题，即使在相邻强度级别间也能实现可区分的风格差异

Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensity levels, we propose a SFT-then-PPO paradigm to fine-tune an LLM. We first fine-tune the LLM with synthesized parallel data. Then, we further train the LLM with PPO, where the rewards are elaborately designed for distinguishing the stylistic intensity in hierarchical levels. Both the global and local stylistic features are considered to formulate the reward functions. The experiments on two UTST benchmarks showcase that both rewards have their advantages and applying them to LLM fine-tuning can effectively improve the performance of an LLM backbone based on various evaluation metrics. Even for close levels of intensity, we can still observe the noticeable stylistic difference between the generated text.

</details>


### [181] [ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining](https://arxiv.org/abs/2601.01091)
*Haq Nawaz Malik*

Main category: cs.CL

TL;DR: 该论文针对克什米尔语缺乏高质量训练数据的问题，构建了包含310万单词的KS-LIT-3M语料库，通过开发InPage到Unicode转换器解决历史文献格式障碍，为克什米尔语NLP研究填补资源空白。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在克什米尔语等低资源语言上表现不佳，主要原因是缺乏高质量训练数据。克什米尔语数十年文献因采用专有的InPage桌面出版格式而无法被现代NLP流程处理，导致约700万人使用的语言缺乏技术支持。

Method: 开发专门的InPage到Unicode转换器，将历史文献转换为可处理格式；进行严格的预处理包括英语污染去除、字符规范化和质量验证；构建包含文学、新闻、学术和宗教文本的多样化语料库，形成310万单词的连续线性文本流。

Result: 成功创建了KS-LIT-3M语料库，包含3.1百万单词（1640万字符），涵盖131,607个独特单词，涵盖多种文本类型。语料库采用CC-BY-4.0许可证发布，专门为因果语言模型训练优化，解决了克什米尔语训练数据稀缺的核心问题。

Conclusion: KS-LIT-3M语料库填补了克什米尔语自然语言处理的基础资源空白，通过解决历史文献格式转换问题，为训练克什米尔语语言模型提供了关键数据支持，有望推动该低资源语言的NLP技术发展。

Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.

</details>


### [182] [EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation](https://arxiv.org/abs/2601.01112)
*Zilin Li,Weiwei Xu,Xuanbo Lu,Zheda Liu*

Main category: cs.CL

TL;DR: EmoLoom-2B是一个轻量级可复现的流程，可将小于20亿参数的小语言模型转化为情感分类和VAD预测的快速筛选候选模型，通过统一协议、语义正则化和数据增强实现高效评估。


<details>
  <summary>Details</summary>
Motivation: 需要一种轻量级、可复现的流程来将小语言模型转化为情感分析任务的快速筛选工具，确保评估的协议一致性和公平性，同时保持预算意识。

Method: 1) 统一JSON输入输出协议；2) 采用KV-off解码减少方差；3) 引入两个正交语义正则器：VAD保持约束和轻量外部评估分类器；4) 基于镜像情感对的Valence Flip增强；5) 监督微调时使用A/B混合采样和熵感知温度调度。

Result: 以Qwen-1.8B-Chat为基础模型，EmoLoom-2B在GoEmotions和EmpatheticDialogues上表现强劲，在DailyDialog上展示出稳健的跨语料库泛化能力。

Conclusion: 该流程具有预算意识、可审计和可重入特性，可作为更重训练或多模态融合前的可靠筛选步骤，为小语言模型的情感分析应用提供了实用解决方案。

Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incorporate two orthogonal semantic regularizers: a VAD-preserving constraint that aligns generated text with target VAD triples, and a lightweight external appraisal classifier that provides training-time guidance on goal attainment, controllability, certainty, and fairness without injecting long rationales. To improve polarity sensitivity, we introduce Valence Flip augmentation based on mirrored emotional pairs. During supervised fine-tuning, we apply A/B mixture sampling with entropy-aware temperature scheduling to balance coverage and convergence. Using Qwen-1.8B-Chat as the base model, EmoLoom-2B achieves strong performance on GoEmotions and EmpatheticDialogues, and demonstrates robust cross-corpus generalization on DailyDialog. The proposed recipe is budget-aware, auditable, and re-entrant, serving as a dependable screening pass before heavier training or multimodal fusion.

</details>


### [183] [Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels](https://arxiv.org/abs/2601.01121)
*Yacouba Diarra,Michael Leventhal*

Main category: cs.CL

TL;DR: LAU是一种语义正则化技术，通过冻结文本嵌入提供方向性辅助损失，在训练期间约束声学编码器的潜在空间，为端到端语音翻译注入语言基础性，不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译在目标转录具有高方差和语义模糊性时，通常表现出较慢的收敛速度和较差的性能。需要一种方法在数据稀缺和/或嘈杂的情况下改善性能。

Method: 提出Listen, Attend, Understand (LAU)语义正则化技术，利用冻结的文本嵌入提供方向性辅助损失，在训练期间约束声学编码器的潜在空间，将语言基础性注入声学表示中。

Result: 在30小时班巴拉语到法语数据集上，LAU模型在使用100%更多数据预训练的E2E-ST系统上取得可比性能，同时在保留语义含义方面表现更好。引入总参数漂移作为量化正则化结构影响的指标。

Conclusion: LAU是后处理重评分的稳健替代方案，是E2E-ST训练的有价值补充，特别是在训练数据稀缺和/或嘈杂的情况下。语义约束主动重组编码器权重，优先考虑意义而非字面语音。

Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation without increasing inference cost. We evaluate our method on a Bambara-to-French dataset with 30 hours of Bambara speech translated by non-professionals. Experimental results demonstrate that LAU models achieve comparable performance by standard metrics compared to an E2E-ST system pretrained with 100\% more data and while performing better in preserving semantic meaning. Furthermore, we introduce Total Parameter Drift as a metric to quantify the structural impact of regularization to demonstrate that semantic constraints actively reorganize the encoder's weights to prioritize meaning over literal phonetics. Our findings suggest that LAU is a robust alternative to post-hoc rescoring and a valuable addition to E2E-ST training, especially when training data is scarce and/or noisy.

</details>


### [184] [RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution](https://arxiv.org/abs/2601.01126)
*Andrew Borthwick,Stephen Ash*

Main category: cs.CL

TL;DR: RoboPhD是一个AI自主研究系统，通过进化循环自动改进Text-to-SQL性能，从70行基线进化到1500行，在BIRD测试集上达到73.67%准确率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是让AI系统能够自主进行科学研究，无需人类专家指导，自动发现有效的Text-to-SQL技术，实现"跳过层级"部署，让较弱模型通过进化超越较强模型的基线性能。

Method: 系统采用闭环进化循环，包含两个协调组件：SQL生成代理（数据库分析脚本和SQL生成指令）和进化代理（基于性能反馈设计新版本）。核心是ELO选择机制处理性能非传递性，通过迭代交叉授粉进化代理。

Result: 从70行基线开始，经过18次迭代进化到1500行，自主发现了大小自适应数据库分析、列选择、证据解释和聚合等策略。在BIRD测试集上达到73.67%准确率，对较弱模型改进最大：Claude Haiku改进8.9点，Claude Opus改进2.3点。

Conclusion: AI能够从微不足道的人类提供起点自主构建强大的代理系统，实现"跳过层级"部署：进化的Haiku超越原生Sonnet准确率，进化的Sonnet超越原生Opus，且成本更低。

Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-the-fittest dynamics while handling non-transitivity in performance. Starting from a naive 70-line baseline, RoboPhD evolves agents through iterative cross-pollination, discovering effective techniques without any external guidance on the Text-to-SQL domain. Our best agent, evolved to 1500 lines over 18 iterations, autonomously discovered strategies such as size-adaptive database analysis that adjusts depth based on schema complexity and SQL generation patterns for column selection, evidence interpretation, and aggregation. Evolution provides the largest gains on cheaper models: while we improve by 2.3 points over a strong Claude Opus 4.5 naive baseline, we show an improvement of 8.9 points over the weaker Claude Haiku model. This enables 'skip a tier' deployment: evolved Haiku exceeds naive Sonnet accuracy, and evolved Sonnet exceeds naive Opus, both at lower cost. The full system achieves 73.67% accuracy on the BIRD test set, demonstrating that AI can autonomously build a strong agentic system with only a trivial human-provided starting point.

</details>


### [185] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

TL;DR: KOS-TL是一个基于依赖类型理论的构造性框架，旨在为自主可执行知识系统提供严格的逻辑基础，统一数据、逻辑和证明，确保知识状态变化的可验证性。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态符号逻辑与动态系统执行之间的鸿沟，需要一种能够统一数据、逻辑和证明的严谨逻辑框架来支持自主知识系统的构建。

Method: 采用依赖类型理论，构建三层架构：核心层定义静态类型宇宙和构造原语；内核层通过事件驱动机制⟨Σ, Ev, Δ⟩管理状态演化；运行时层负责物理信号与逻辑证据的双向精化。

Result: 形式化定义了系统操作语义，证明了关键元理论性质（进展性和演化一致性），确保系统在连续状态转换中保持逻辑自洽且无死锁状态。通过工业追溯和跨境金融合规应用示例展示了实用性。

Conclusion: KOS-TL通过整合戴维森事件语义与马丁-洛夫类型理论，为下一代智能自主操作系统提供了稳健、形式可验证的基础，支持"携带证明的知识"构建。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [186] [SongSage: A Large Musical Language Model with Lyric Generative Pre-training](https://arxiv.org/abs/2601.01153)
*Jiani Guo,Jiajia Li,Jie Wu,Zuchao Li,Yujiu Yang,Ping Wang*

Main category: cs.CL

TL;DR: SongSage是一个专注于歌词理解的大型音乐语言模型，通过歌词生成预训练获得多样化的歌词中心智能，在歌词相关任务上表现出色，同时保持通用知识理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在歌词中心知识理解方面尚未充分探索，现有通用LLM在播放列表理解方面仍有改进空间，需要专门针对音乐和歌词理解进行优化。

Method: 1. 引入PlaylistSense数据集评估语言模型的播放列表理解能力；2. 构建LyricBank语料库（54.8亿标记）进行持续预训练；3. 使用LyricBank-SFT指令集（77.5万样本，9个核心任务）进行微调；4. 开发SongSage模型，专注于歌词中心智能。

Result: SongSage在歌词中心知识理解方面表现出色，能够有效重写用户查询进行零样本播放列表推荐，生成和续写歌词，在7个额外能力上表现熟练，同时保持通用知识理解能力，获得有竞争力的MMLU分数。

Conclusion: SongSage成功填补了语言模型在歌词理解方面的空白，展示了专门针对音乐领域训练的有效性，为音乐AI研究和应用提供了有价值的工具，同时由于版权限制保持数据集不公开。

Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address diverse user intents. Comprehensive evaluations indicate that current general-purpose LLMs still have potential for improvement in playlist understanding. Inspired by this, we introduce SongSage, a large musical language model equipped with diverse lyric-centric intelligence through lyric generative pretraining. SongSage undergoes continual pretraining on LyricBank, a carefully curated corpus of 5.48 billion tokens focused on lyrical content, followed by fine-tuning with LyricBank-SFT, a meticulously crafted instruction set comprising 775k samples across nine core lyric-centric tasks. Experimental results demonstrate that SongSage exhibits a strong understanding of lyric-centric knowledge, excels in rewriting user queries for zero-shot playlist recommendations, generates and continues lyrics effectively, and performs proficiently across seven additional capabilities. Beyond its lyric-centric expertise, SongSage also retains general knowledge comprehension and achieves a competitive MMLU score. We will keep the datasets inaccessible due to copyright restrictions and release the SongSage and training script to ensure reproducibility and support music AI research and applications, the datasets release plan details are provided in the appendix.

</details>


### [187] [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)
*Jiani Guo,Xiangke Zeng,Jie Wu,Zuchao Li*

Main category: cs.CL

TL;DR: 提出DHI框架，通过修改损失函数和因果注意力掩码，让"邪恶LLM"生成更多样化的幻觉，结合自适应理性约束提升幻觉缓解效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法训练"邪恶LLM"生成幻觉来指导对比解码，但诱导的幻觉类型单一，限制了整体效果。需要让邪恶LLM生成更广泛的幻觉类型，而不依赖预标注的幻觉数据。

Method: 提出DHI框架：1) 修改损失函数，降低特定事实正确token的生成权重，鼓励在目标位置产生多样化幻觉；2) 引入因果注意力掩码适应，减少惩罚对后续token的影响；3) 推理时应用自适应理性约束，仅在正模型高置信度时进行对比解码。

Result: 在多个幻觉基准测试中，DHI相比其他基于对比解码的方法取得了显著的性能提升。

Conclusion: DHI框架能够有效诱导多样化的幻觉，提升对比解码方法在缓解LLM幻觉问题上的效果，且不依赖预标注的幻觉数据。

Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable "positive model" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.

</details>


### [188] [Almost Clinical: Linguistic properties of synthetic electronic health records](https://arxiv.org/abs/2601.01171)
*Serge Sharoff,John Baker,David Francis Hunt,Alan Simpson*

Main category: cs.CL

TL;DR: 评估大型语言模型生成的心理健康电子病历的语言学和临床适用性，发现虽然能产生连贯且术语适当的文本，但仍存在系统性差异。


<details>
  <summary>Details</summary>
Motivation: 评估合成电子健康记录在心理健康领域的适用性，了解LLMs如何通过语言选择构建医学权威和患者能动性。

Method: 首先描述创建合成语料库的原理和方法论，然后评估四个临床类型（评估、通信、转诊和护理计划）中的能动性、模态和信息流，分析LLMs的语法构造。

Result: LLMs能产生连贯、术语适当的文本，近似临床实践，但存在系统性差异，包括语域转移、临床特异性不足、药物使用和诊断程序不准确。

Conclusion: 合成EHR在心理健康领域有潜力，但需要解决系统性语言差异和临床准确性不足的问题才能可靠用于临床实践。

Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency through linguistic choices. While LLMs produce coherent, terminology-appropriate texts that approximate clinical practice, systematic divergences remain, including registerial shifts, insufficient clinical specificity, and inaccuracies in medication use and diagnostic procedures.

</details>


### [189] [Stylometry Analysis of Human and Machine Text for Academic Integrity](https://arxiv.org/abs/2601.01225)
*Hezam Albaqami,Muhammad Asif Ayub,Nasir Ahmad,Yaseen Ahmad,Mohammed M. Alqahtani,Abdullah M. Algamdi,Almoaid A. Owaidah,Kashif Ahmad*

Main category: cs.CL

TL;DR: 提出基于NLP的框架，通过作者归属和风格变化检测来认证学生内容，解决学术诚信问题，包括人机文本分类、单多作者区分、多作者文档内作者变化检测和协作文档作者识别四个任务。


<details>
  <summary>Details</summary>
Motivation: 解决学术诚信中的关键挑战，包括抄袭、捏造和教育内容作者身份验证。现有解决方案不够全面，需要更系统的框架来处理机器生成文本检测的复杂性。

Method: 提出基于自然语言处理的框架，针对四个任务：人机文本分类、单多作者区分、多作者文档内作者变化检测、协作文档作者识别。使用Gemini生成两个数据集（正常和严格指令）进行实验评估。

Result: 在严格指令生成的数据集上观察到性能下降，表明检测精心设计的机器生成文本的复杂性。公开了生成的数据集、代码和相关材料，为未来研究提供基准。

Conclusion: 该研究为学术内容认证提供了全面的NLP框架，揭示了机器生成文本检测的挑战，公开的资源将为该领域未来研究奠定基础。

Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.

</details>


### [190] [Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure](https://arxiv.org/abs/2601.01244)
*Zsolt Csibi,Bence György Gortka,Natabara Gyöngyössy,Kornél Nagy,Dávid Márk Nemeskey,Martin Sallai,András Simonyi,András Márk Szekeres,Gábor Palkó*

Main category: cs.CL

TL;DR: Racka是一个轻量级、持续预训练的大语言模型，专门为匈牙利语设计，通过LoRA参数高效微调Qwen-3 4B模型，使用混合多语言数据（44%匈牙利语）来弥合匈牙利语与高资源语言之间的差距。


<details>
  <summary>Details</summary>
Motivation: 弥合匈牙利语与英语、德语等高资源语言之间的资源差距，为匈牙利语提供更好的语言模型支持。

Method: 采用LoRA参数高效持续预训练方法，在Qwen-3 4B骨干网络上进行微调；替换并适配分词器以改善匈牙利语分词效果；使用160B子词标记的混合数据（44%匈牙利语、24%英语、21%德语、11%代码）。

Result: 初步结果显示在语言适应方面取得了适度但稳定的结果，匈牙利语分词效率显著提升，同时保持了英语和德语的竞争力。

Conclusion: Racka通过参数高效的持续预训练方法，成功为匈牙利语创建了一个实用的语言模型，在有限计算资源下实现了多语言能力的平衡。

Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and adapt the tokenizer, achieving substantially improved tokenization fertility for Hungarian while maintaining competitive performance in English and German. The model is trained on 160B subword tokens drawn from a mixture of internet and high-quality curated sources, with a composition of 44% Hungarian, 24% English, 21% German, and 11% code. This data mix is chosen to mitigate catastrophic forgetting and preserve high-resource language capabilities during continual pretraining. Our preliminary results indicate modest but stable results in language adaptation.

</details>


### [191] [From Policy to Logic for Efficient and Interpretable Coverage Assessment](https://arxiv.org/abs/2601.01266)
*Rhitabrat Pokharel,Hamid Hassanzadeh,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本文提出了一种结合检索器和符号推理的混合方法，用于医疗保险政策分析，在降低44%推理成本的同时提升4.5%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂法律和政策语言时存在幻觉和不一致问题，特别是在医疗保险政策审查这种需要高度准确性的场景中，需要支持人类评审员提高效率和可解释性。

Method: 提出混合方法：结合覆盖范围感知检索器和基于符号规则的推理，提取相关政策语言，组织成明确的事实和规则，生成可审计的推理过程，减少LLM推理次数。

Result: 实现了44%的推理成本降低和4.5%的F1分数提升，在效率和效果上都取得了显著改进。

Conclusion: 该混合方法在医疗保险政策分析中有效平衡了效率和准确性，通过减少LLM推理需求降低了成本，同时提高了结果的可解释性和可靠性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.

</details>


### [192] [Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory](https://arxiv.org/abs/2601.01280)
*Sen Hu,Yuxiang Wei,Jiaxin Ran,Zhiyuan Yao,Lei Zou*

Main category: cs.CL

TL;DR: 该论文对对话记忆系统进行了实验分析，提出了统一框架来分解核心组件，通过控制实验发现性能差异主要源于基础系统设置而非特定架构创新，并确定了可靠的强基线。


<details>
  <summary>Details</summary>
Motivation: 图结构在对话记忆系统中应用日益广泛，但实证研究结果不一致，不清楚哪些设计选择真正重要，需要系统性地分析长期对话记忆架构的有效性。

Method: 提出统一框架将对话记忆系统分解为核心组件，支持图和非图方法；在LongMemEval和HaluMem数据集上进行分阶段控制实验，比较记忆表示、组织、维护和检索等常见设计选择。

Result: 实验结果显示，许多性能差异主要由基础系统设置驱动，而非特定的架构创新；基于这些发现，为未来对话记忆研究确定了稳定可靠的强基线。

Conclusion: 该研究通过系统化分析揭示了对话记忆系统性能的关键因素，为未来研究提供了可靠的基准，强调了基础设置的重要性而非过度关注特定架构创新。

Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.

</details>


### [193] [T3C: Test-Time Tensor Compression with Consistency Guarantees](https://arxiv.org/abs/2601.01299)
*Ismail Lamaakal,Chaymae Yahyati,Yassine Maleh,Khalid El Makkaoui,Ibrahim Ouahbi*

Main category: cs.CL

TL;DR: T3C是一个训练一次、测试时预算条件化的压缩框架，将秩和精度作为可控制的部署旋钮，通过弹性张量分解、秩绑定的混合精度量化和轻量级控制器，实现根据延迟/能耗/大小预算动态调整模型配置。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法通常需要为不同部署场景重新训练或调整，缺乏统一的、可预测的精度-延迟-大小权衡方案。T3C旨在通过单一检查点提供证书支持的、可预测的部署灵活性。

Method: 结合弹性张量分解（维持到最大秩）、秩绑定的混合精度量化，以及轻量级控制器将预算令牌映射到每层秩/比特分配。使用基于谱代理和激活统计的快速层一致性证书来上界logit漂移并正则化训练。

Result: 在ImageNet-1k上，T3C显著推进了视觉Pareto前沿：ResNet-50在精度下降≤0.5%时达到1.18ms p50延迟和38MB模型大小，优于PTQ-8b（1.44ms, 88MB）；ViT-B/16达到2.30ms p50延迟和59MB大小，超越强PTQ/QAT基线。

Conclusion: T3C通过单一检查点提供了可预测的、证书支持的精度-延迟-大小权衡，能够在不同设备上按需调整部署配置，显著提升了模型压缩的灵活性和可靠性。

Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.

</details>


### [194] [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)
*Hossam Amer,Maryam Dialameh,Hossein Rajabzadeh,Walid Ahmed,Weiwei Zhang,Yang Liu*

Main category: cs.CL

TL;DR: 提出TTC感知训练方法，通过早期停止算法选择检查点和测试时计算配置，在保持精度的同时大幅减少训练计算量


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型训练计算成本高昂，虽然增加测试时计算（TTC）可以让小模型媲美大模型，但需要平衡训练和推理计算成本

Method: 提出TTC感知训练方法，包括：1）早期停止算法联合选择检查点和TTC配置；2）高效的TTC评估方法避免穷举搜索；3）制定盈亏平衡界限确定推理计算何时补偿训练计算减少

Result: 实验显示训练FLOPs减少高达92%，同时保持甚至显著提升模型精度

Conclusion: 为平衡训练和推理计算提供了新视角，能够实现更快的部署周期和更频繁的模型更新

Abstract: Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.

</details>


### [195] [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 在心理健康咨询中，通用推理模型（3B参数）通过RAG框架在共情表现上优于领域微调模型（7B参数），表明强推理能力比专业词汇训练更重要。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在心理健康咨询中的幻觉和缺乏共情问题，探索在RAG框架下，是领域微调模型还是通用推理模型表现更好。

Method: 使用ChromaDB构建相同RAG流程，比较四个开源模型：两个通用推理模型（Qwen2.5-3B和Phi-3-Mini）和两个领域微调模型（MentalHealthBot-7B和TherapyBot-7B），通过LLM-as-a-Judge框架自动化评估50轮对话。

Result: 通用模型在共情得分上显著优于领域模型（3.72 vs 3.26，p<0.001），尽管参数更小（3B vs 7B）。所有模型安全性良好，但通用模型表现出更好的上下文理解能力，且领域模型存在过拟合现象。

Conclusion: 对于基于RAG的治疗系统，强推理能力比心理健康特定词汇训练更重要；只要回答基于临床证据，推理能力强的通用模型能提供更共情和平衡的支持。

Abstract: The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to whether the most effective model under this paradigm would be one that is fine-tuned on mental health data, or a more general and powerful model that succeeds purely on the basis of reasoning. In this paper, we perform a direct comparison by running four open-source models through the same RAG pipeline using ChromaDB: two generalist reasoners (Qwen2.5-3B and Phi-3-Mini) and two domain-specific fine-tunes (MentalHealthBot-7B and TherapyBot-7B). We use an LLM-as-a-Judge framework to automate evaluation over 50 turns. We find a clear trend: the generalist models outperform the domain-specific ones in empathy (3.72 vs. 3.26, $p < 0.001$) in spite of being much smaller (3B vs. 7B), and all models perform well in terms of safety, but the generalist models show better contextual understanding and are less prone to overfitting as we observe in the domain-specific models. Overall, our results indicate that for RAG-based therapy systems, strong reasoning is more important than training on mental health-specific vocabulary; i.e. a well-reasoned general model would provide more empathetic and balanced support than a larger narrowly fine-tuned model, so long as the answer is already grounded in clinical evidence.

</details>


### [196] [FC-CONAN: An Exhaustively Paired Dataset for Robust Evaluation of Retrieval Systems](https://arxiv.org/abs/2601.01350)
*Juan Junqueras,Florian Boudin,May-Myo Zin,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Damián Ariel Furman,Akiko Aizawa,Ken Satoh*

Main category: cs.CL

TL;DR: FC-CONAN是首个完全连接的仇恨言论-反叙事数据集，通过穷举45条仇恨言论和129条反叙事的所有组合，提供更全面的评估基准


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论-反叙事数据集（如CONAN）只标注了稀疏的配对，限制了反言论研究的评估能力，需要更全面的数据集来支持更准确的系统评估

Method: 创建FC-CONAN数据集：1）穷举45条仇恨言论和129条反叙事的所有组合；2）采用两阶段标注流程，由9名标注员和4名验证者参与；3）生成四个质量等级的分区（钻石、黄金、白银、青铜）以平衡可靠性和规模

Result: FC-CONAN发现了数百个之前未标注的正样本对，与CONAN无重叠，为反言论检索系统提供了更忠实的评估基准，并支持详细的错误分析

Conclusion: FC-CONAN填补了仇恨言论-反叙事数据集的空白，提供了更全面的评估资源，有助于推动反言论研究的进展，数据集已公开可用

Abstract: Hate speech (HS) is a critical issue in online discourse, and one promising strategy to counter it is through the use of counter-narratives (CNs). Datasets linking HS with CNs are essential for advancing counterspeech research. However, even flagship resources like CONAN (Chung et al., 2019) annotate only a sparse subset of all possible HS-CN pairs, limiting evaluation. We introduce FC-CONAN (Fully Connected CONAN), the first dataset created by exhaustively considering all combinations of 45 English HS messages and 129 CNs. A two-stage annotation process involving nine annotators and four validators produces four partitions-Diamond, Gold, Silver, and Bronze-that balance reliability and scale. None of the labeled pairs overlap with CONAN, uncovering hundreds of previously unlabelled positives. FC-CONAN enables more faithful evaluation of counterspeech retrieval systems and facilitates detailed error analysis. The dataset is publicly available.

</details>


### [197] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://arxiv.org/abs/2601.01362)
*Jerry Huang,Peng Lu,Qiuhao Zeng,Yusuke Iwasawa,Yutaka Matsuo,Sarath Chandar,Edison Marrese-Taylor,Irene Li*

Main category: cs.CL

TL;DR: 该研究发现，在多语言环境下，即使对低资源语言进行指令微调，模型置信度会显著提升但准确率改善有限，导致校准不良。标签平滑技术能有效缓解这一问题，无需低资源语言数据。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型研究不断进步，但其在多语言环境下的校准问题仍是一个开放研究领域。研究旨在理解数据稀缺如何导致不同的校准效果，以及常用技术在这些环境下的适用性。

Method: 在两个多语言基准测试上进行分析，分别涵盖29种和42种语言。研究指令微调对高资源语言SFT数据集的影响，并评估标签平滑技术在多语言校准中的效果。

Result: 即使在低资源语言中，模型在指令微调后置信度显著增加，但准确率改善有限或不存在，导致校准不良。标签平滑技术能有效缓解校准问题，无需低资源语言SFT数据，在所有语言中保持更好的校准。

Conclusion: 标准SFT方法在多语言环境中存在严重缺陷。研究强调了在多语言环境下训练和调整LLMs的重要性，以提高其在下游应用中的可靠性和公平性。

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.

</details>


### [198] [EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery](https://arxiv.org/abs/2601.01400)
*Jicheng Ma,Guohua Wang,Xinhua Feng,Yiming Liu,Zhichao Hu,Yuhong Liu*

Main category: cs.CL

TL;DR: 提出EternalMath：一個從最新數學研究論文自動生成可驗證推理任務的評估框架，解決現有靜態基準覆蓋有限且性能快速飽和的問題


<details>
  <summary>Details</summary>
Motivation: 現有數學推理評估主要依賴靜態基準，這些基準要麼來自競賽題目，要麼需要專家人工整理，導致覆蓋範圍有限（特別是研究級數學），且模型性能容易快速飽和

Method: 開發全自動、定理驅動的流水線：從最新同行評審數學文獻中識別構造性或定量結果，將其轉換為參數化問題模板，並通過基於執行的驗證生成確定性解決方案

Result: 創建EternalMath評估套件，實驗顯示最先進LLM在數學研究前沿仍存在顯著性能差距，表明數學推理遠未飽和

Conclusion: 數學推理評估方法需要與人類數學發現同步演進，EternalMath提供了一個可擴展、可重現且持續更新的評估框架

Abstract: Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery.

</details>


### [199] [LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs](https://arxiv.org/abs/2601.01401)
*Chenxu Wang,Chaozhuo Li,Pengbo Wang,Litian Zhang,Songyang Liu,Ji Qi,Jiahui Hu,Yushan Cai,Hao Zhao,Rui Pu*

Main category: cs.CL

TL;DR: Lancet框架通过结构熵和幻觉差异比实现精确神经干预，显著减少大语言模型的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 当前方法通过节点级调整或粗略抑制来缓解大语言模型的幻觉问题，但忽视了神经信息的分布式特性，导致干预不精确。作者认识到幻觉像感染一样通过特定的前向传播路径传播，因此希望通过精确的结构分析来手术式阻断这种流动。

Method: 提出Lancet框架：1) 通过梯度驱动的对比分析定位易产生幻觉的神经元；2) 通过最小化结构熵映射其传播路径；3) 实施分层干预策略以保留模型的一般能力。

Result: 在幻觉基准数据集上的综合评估表明，Lancet显著优于现有最先进方法，验证了神经干预手术式方法的有效性。

Conclusion: 通过结构熵和精确的神经干预，Lancet框架能够手术式阻断幻觉传播路径，在减少幻觉的同时保持模型能力，为解决大语言模型幻觉问题提供了新思路。

Abstract: Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.

</details>


### [200] [From Emotion Classification to Emotional Reasoning: Enhancing Emotional Intelligence in Large Language Models](https://arxiv.org/abs/2601.01407)
*Arjhun Sreedar,Rohan Pillay,Laukik Patade*

Main category: cs.CL

TL;DR: 使用合成情感链式思维数据微调7B模型，可显著提升情感推理能力，无需架构修改


<details>
  <summary>Details</summary>
Motivation: 研究合成情感链式思维数据是否能提升小型开源大语言模型的情感推理能力，探索无需架构修改的情感能力诱导方法

Method: 设计多智能体生成管道，创建治疗式对话并将其转化为结构化情感多选题及解释，用此数据集微调多种7B模型

Result: 微调后的Mistral 7B在情感理解(EU)上从10.5提升至20.5，情感意识(EA)从40.5提升至60.0，验证了合成情感推理数据的有效性

Conclusion: 合成情感推理数据能有效增强模型在细致情感任务中的能力，情感推理可以通过数据驱动方式实现而无需架构改变

Abstract: This work investigates whether synthetic emotional chain-of-thought data can improve the emotional reasoning abilities of smaller open large language models (LLMs). We design a multi-agent generation pipeline that produces therapy-style conversations and converts them into structured emotion multiple-choice questions (MCQs) with explanations. We propose that fine-tuning a variety of 7B models on this dataset should yield substantial gains in emotional understanding and emotional awareness on EmoBench-style evaluations, suggesting that emotional reasoning can be induced without architectural changes. Our results demonstrate that fine-tuned Mistral 7B achieves EU improvements from 10.5 to 20.5 and EA improvements from 40.5 to 60.0, validating the effectiveness of synthetic emotional reasoning data for enhancing model capabilities in nuanced emotional tasks.

</details>


### [201] [iFlip: Iterative Feedback-driven Counterfactual Example Refinement](https://arxiv.org/abs/2601.01446)
*Yilong Wang,Qianli Wang,Nils Feldhus*

Main category: cs.CL

TL;DR: iFlip：利用LLM自我修正能力的迭代式反事实生成方法，通过模型置信度、特征归因和自然语言反馈提升有效性


<details>
  <summary>Details</summary>
Motivation: 现有单次生成方法在利用大语言模型生成有效反事实示例时效果不佳，未能充分利用LLM的自我修正能力，导致标签翻转率低

Method: 提出iFlip迭代优化方法，利用三种反馈机制：模型置信度、特征归因和自然语言反馈，通过多轮迭代逐步改进反事实生成

Result: iFlip在标签翻转率上比5个SOTA基线平均提升57.8%，用户研究显示在完整性、满意度和可行性方面均优于基线，消融实验验证三个组件的重要性

Conclusion: iFlip通过迭代反馈机制有效利用LLM自我修正能力，生成高质量反事实示例，可用于数据增强提升模型性能和鲁棒性

Abstract: Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.

</details>


### [202] [Segmentation and Processing of German Court Decisions from Open Legal Data](https://arxiv.org/abs/2601.01449)
*Harshil Darji,Martin Heckelmann,Christina Kratsch,Gerard de Melo*

Main category: cs.CL

TL;DR: 本文创建了一个经过清理和分节的德国法院判决数据集，从Open Legal Data原始数据中系统分离出三个关键部分，并进行了统计验证。


<details>
  <summary>Details</summary>
Motivation: 德国法律系统的结构化数据对NLP研究很重要。Open Legal Data数据集虽然规模大，但判决文本格式不一致，缺乏清晰标记的章节，这影响了修辞角色分类、检索和引文分析等下游任务。

Method: 从Open Legal Data官方数据集中提取251,038个德国法院判决，系统分离三个关键部分：Tenor（判决主文）、Tatbestand（案件事实）和Entscheidungsgründe（判决理由）。使用Cochran公式以95%置信水平和5%误差范围抽取384个案例的统计代表性随机样本进行手动验证。还将Rechtsmittelbelehrung（上诉通知）作为独立字段提取。

Result: 创建了一个包含251,038个德国法院判决的清理和分节数据集，三个关键部分被正确分离。统计验证显示所有三个部分都被正确识别。数据集以JSONL格式公开可用。

Conclusion: 该工作提供了一个高质量的德国法院判决结构化数据集，为德国法律系统的进一步研究提供了可访问的资源，解决了原始数据集中格式不一致的问题。

Abstract: The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.

</details>


### [203] [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)
*Yuxiang Mei,Dongxing Xu,Jiaen Liang,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出增强的LLM-based ASR框架，结合微调的Whisper和mHuBERT编码器，采用交叉注意力融合机制，在MLC-SLM挑战中取得10.69% CER/WER，与使用大规模训练数据的顶级系统性能相当。


<details>
  <summary>Details</summary>
Motivation: 解决之前SHNU-mASR系统的两个问题：简单特征拼接无法充分利用互补信息，以及LLM-based ASR与端到端编码器-解码器ASR之间的性能差距尚未探索。

Method: 提出增强的LLM-based ASR框架，结合微调的Whisper和mHuBERT编码器，首先评估LoRA和全微调的E2E Whisper模型，然后为并行语音编码器提出基于交叉注意力的融合机制。

Result: 在MLC-SLM挑战官方评估集上获得10.69% CER/WER，仅使用1500小时基线训练数据即与使用大规模训练数据的顶级Track 1系统性能相当，但最终LLM-based ASR仍不及微调的E2E Whisper模型。

Conclusion: 尽管提出的LLM-based ASR框架在资源有限情况下取得竞争性结果，但仍未超越微调的E2E Whisper模型，为未来Speech-LLM设计提供了有价值的实证指导。

Abstract: The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.

</details>


### [204] [Can Legislation Be Made Machine-Readable in PROLEG?](https://arxiv.org/abs/2601.01477)
*May-Myo Zin,Sabine Wehnert,Yuntao Kong,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Jieying Xue,Michał Araszkiewicz,Randy Goebel,Ken Satoh,Le-Minh Nguyen*

Main category: cs.CL

TL;DR: 提出一个结合大语言模型和PROLEG法律表示系统的框架，将GDPR等法规文本自动转换为可执行的if-then规则和PROLEG编码，支持法律决策的解释生成。


<details>
  <summary>Details</summary>
Motivation: 法规应用需要准确性和效率，现代AI技术（如NLP和机器辅助推理）有望解决这一挑战。当前需要工具来支持法规的自动化应用和解释。

Method: 使用单个LLM提示同时将法律文本转换为if-then规则和对应的PROLEG编码，然后由法律专家验证和精炼，最终生成可执行的PROLEG程序，能够为GDPR决策生成人类可读的解释。

Result: 开发了一个端到端框架，以GDPR第6条为例，展示了从法规文本到if-then规则再到PROLEG编码的完整转换流程，并提供了PROLEG执行实例。

Conclusion: 该方法对捕获和部署法规框架具有重要价值，但存在局限性，需要进一步开发此类技术以改进法规的自动化应用。

Abstract: The anticipated positive social impact of regulatory processes requires both the accuracy and efficiency of their application. Modern artificial intelligence technologies, including natural language processing and machine-assisted reasoning, hold great promise for addressing this challenge. We present a framework to address the challenge of tools for regulatory application, based on current state-of-the-art (SOTA) methods for natural language processing (large language models or LLMs) and formalization of legal reasoning (the legal representation system PROLEG). As an example, we focus on Article 6 of the European General Data Protection Regulation (GDPR). In our framework, a single LLM prompt simultaneously transforms legal text into if-then rules and a corresponding PROLEG encoding, which are then validated and refined by legal domain experts. The final output is an executable PROLEG program that can produce human-readable explanations for instances of GDPR decisions. We describe processes to support the end-to-end transformation of a segment of a regulatory document (Article 6 from GDPR), including the prompting frame to guide an LLM to "compile" natural language text to if-then rules, then to further "compile" the vetted if-then rules to PROLEG. Finally, we produce an instance that shows the PROLEG execution. We conclude by summarizing the value of this approach and note observed limitations with suggestions to further develop such technologies for capturing and deploying regulatory frameworks.

</details>


### [205] [Four Quadrants of Difficulty: A Simple Categorisation and its Limits](https://arxiv.org/abs/2601.01488)
*Vanessa Toborek,Sebastian Müller,Christian Bauckhage*

Main category: cs.CL

TL;DR: 论文挑战了课程学习中常用的任务无关难度估计方法，提出基于任务依赖的模型感知难度估计更有效


<details>
  <summary>Details</summary>
Motivation: 传统课程学习在NLP中通常使用任务无关的语言学启发式或人类直觉来估计样本难度，隐含假设这些信号与神经网络模型的学习难度相关，但这种假设需要验证

Method: 提出四象限分类法（人类vs模型、任务无关vs任务依赖），在自然语言理解数据集上系统分析这些难度信号的交互作用

Result: 发现任务无关特征基本独立，只有任务依赖特征能够对齐；任务无关的人类直觉与模型实际学习难度不相关

Conclusion: 需要开发轻量级的任务依赖难度估计器，以更好地反映模型的学习行为，挑战了课程学习的常见直觉

Abstract: Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.

</details>


### [206] [Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints](https://arxiv.org/abs/2601.01490)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 研究发现推理能力在封闭系统中存在局限性：推理模型会为了满足约束条件而系统性扭曲事实，导致事实准确性和约束遵从性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，幻觉问题（模型输出中的非事实虚构）已成为严重关切。推理能力作为提高输出可靠性的自我验证过程受到关注，但在无法依赖外部工具或知识的封闭系统中，推理的效果尚未明确。

Method: 在严格约束条件下（推荐计算机科学领域的同行评审期刊文章）进行实验，使用多个模型（GPT-5.2和Gemini 3 Flash）检验推理效果，比较推理模型与非推理模型的表现。

Result: 发现约束遵从性和事实准确性之间存在问题性权衡：非推理模型约束违反率高（66-75%）但保持事实准确性；推理模型减少违反率（13-26%）但系统性扭曲已知事实以满足约束，并增加完全虚构。这种权衡模式在不同架构的模型中一致出现。

Conclusion: 推理并不普遍提高输出真实性，其效果因模型而异，反映了不同的遵从性-真实性权衡分配。这些发现挑战了推理普遍提高可靠性的假设：推理模型以诚实的约束违反换取难以检测的扭曲。

Abstract: With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.

</details>


### [207] [From Failure to Mastery: Generating Hard Samples for Tool-use Agents](https://arxiv.org/abs/2601.01498)
*Bingguang Hao,Zengzhuang Xu,Yuntao Wen,Xinyi Xu,Yang Liu,Tong Zhao,Maolin Wang,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Xiangyu Zhao,Chenyi Zhuang,Ji Zhang*

Main category: cs.CL

TL;DR: HardGen：一个自动化的智能体管道，通过基于失败案例的动态API图、模块化高级工具和可验证的复杂思维链，生成具有可验证推理的困难工具使用训练样本，显著提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体工具使用训练数据生成方法主要采用随机采样和浅层生成范式，产生的轨迹简单且同质化，无法捕捉复杂、隐式的逻辑依赖关系，需要更高质量的训练数据。

Method: 1. 基于智能体失败案例构建动态API图，从中采样合成困难轨迹；2. 以这些轨迹作为条件先验，指导模块化抽象高级工具的实例化，用于构建困难查询；3. 利用高级工具和困难查询生成可验证的复杂思维链，通过闭环评估反馈持续优化过程。

Result: 使用HardGen生成的数据集训练的4B参数模型，在性能上超越了多个领先的开源和闭源竞争对手（如GPT-5.2、Gemini-3-Pro和Claude-Opus-4.5）。

Conclusion: HardGen能够自动生成具有可验证推理的困难工具使用训练样本，显著提升了小模型在复杂任务上的性能，为LLM智能体训练提供了高质量的数据生成解决方案。

Abstract: The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora. Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies. To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning. Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries. Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process. Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5). Our code, models, and dataset will be open-sourced to facilitate future research.

</details>


### [208] [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)
*Jing Ye,Lu Xiang,Yaping Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: EmoHarbor是一个自动评估情感支持对话的框架，采用用户即裁判范式，通过模拟用户内心世界来评估支持是否真正个性化，而非仅生成通用共情回应。


<details>
  <summary>Details</summary>
Motivation: 当前情感支持对话评估范式倾向于奖励通用的共情回应，但无法评估支持是否真正个性化到用户独特的心理特征和情境需求，需要更精细的评估方法。

Method: EmoHarbor采用用户即裁判范式，使用Chain-of-Agent架构将用户内部过程分解为三个专门角色，让代理与支持者互动并完成评估。基于100个真实用户档案和10个评估维度构建基准。

Result: 对20个先进LLM的评估显示：虽然这些模型擅长生成共情回应，但持续无法根据个体用户情境定制支持。这重新定义了核心挑战，将研究重点从增强通用共情转向开发真正用户感知的情感支持。

Conclusion: EmoHarbor提供了一个可重复且可扩展的框架，指导开发更细致和用户感知的情感支持系统，推动研究从通用共情转向真正个性化的情感支持。

Abstract: Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.

</details>


### [209] [Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM](https://arxiv.org/abs/2601.01543)
*Praveenkumar Katwe,RakeshChandra Balabantaray,Kaliprasad Vittala*

Main category: cs.CL

TL;DR: 本文提出了一种自动化框架，利用英文XSUM数据集通过翻译和语言适应技术创建印地语文本摘要数据集，使用COMET进行验证，并辅以LLM进行筛选，为低资源语言提供高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 当前NLP进展主要服务于资源丰富的语言，而像印地语这样的低资源语言缺乏高质量的文本摘要数据集，这阻碍了鲁棒模型的开发。需要解决这种数据稀缺问题，特别是针对专门领域的语料库。

Method: 采用成本效益高的自动化框架，以英文XSUM数据集为源，运用先进的翻译和语言适应技术。使用COMET进行验证以确保高保真度和上下文相关性，并选择性使用大语言模型进行筛选和整理。

Result: 创建了一个多样化、多主题的印地语文本摘要数据集，反映了原始XSUM语料库的复杂性。该数据集为印地语NLP研究提供了直接工具，并为其他服务不足的语言提供了可扩展的方法论。

Conclusion: 这项工作通过降低数据集创建成本，促进了计算语言学中更细致、文化相关模型的发展，为低资源语言的NLP民主化提供了可扩展的解决方案。

Abstract: Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.
  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.
  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.

</details>


### [210] [HalluZig: Hallucination Detection using Zigzag Persistence](https://arxiv.org/abs/2601.01552)
*Shreyas N. Samaga,Gilberto Gonzalez Arroyo,Tamal K. Dey*

Main category: cs.CL

TL;DR: 提出HalluZig框架，通过分析LLM层间注意力演化的动态拓扑结构来检测幻觉，使用zigzag持久性提取拓扑特征，在多个基准测试中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: LLM的事实可靠性是其在高风险领域应用的关键障碍，现有检测方法多依赖模型输出的表层信号，忽略了内部推理过程中的失败。需要新的检测范式来捕捉模型内部推理的动态变化。

Method: 将注意力矩阵序列建模为zigzag图过滤，使用拓扑数据分析中的zigzag持久性提取拓扑特征。假设事实性和幻觉性生成具有不同的拓扑特征，开发HalluZig框架进行检测。

Result: 在多个基准测试中验证了HalluZig框架，证明其优于强基线方法。分析显示这些拓扑特征在不同模型间具有泛化性，且仅使用部分网络深度的结构特征即可实现幻觉检测。

Conclusion: 通过分析LLM层间注意力演化的动态拓扑结构，可以有效地检测幻觉。拓扑特征具有跨模型泛化能力，且部分网络信息就足够，为幻觉检测提供了新的有效方法。

Abstract: The factual reliability of Large Language Models (LLMs) remains a critical barrier to their adoption in high-stakes domains due to their propensity to hallucinate. Current detection methods often rely on surface-level signals from the model's output, overlooking the failures that occur within the model's internal reasoning process. In this paper, we introduce a new paradigm for hallucination detection by analyzing the dynamic topology of the evolution of model's layer-wise attention. We model the sequence of attention matrices as a zigzag graph filtration and use zigzag persistence, a tool from Topological Data Analysis, to extract a topological signature. Our core hypothesis is that factual and hallucinated generations exhibit distinct topological signatures. We validate our framework, HalluZig, on multiple benchmarks, demonstrating that it outperforms strong baselines. Furthermore, our analysis reveals that these topological signatures are generalizable across different models and hallucination detection is possible only using structural signatures from partial network depth.

</details>


### [211] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

TL;DR: 研究发现AI系统的能力与可操控性并非负相关，区分了授权与非授权操控性，揭示了开放权重模型面临的安全-安全困境：安全需要高操控性以实施控制，而安全需要低操控性以防止恶意行为。实验显示反工具性提示能显著降低工具性收敛行为。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统的能力与可操控性关系，区分授权与非授权操控性，揭示开放权重模型面临的根本性安全-安全困境：既要保证开发者能可靠控制模型行为（安全），又要防止攻击者诱导有害行为（安全）。

Method: 使用Qwen3模型（4B/30B；Base/Instruct/Thinking）和InstrumentalEval评估工具，通过对比亲工具性和反工具性提示后缀的效果，测量工具性收敛行为（如关机回避、欺骗、自我复制）的变化。

Result: 能力更高的系统并不一定更难操控；反工具性提示能显著降低工具性收敛行为：Qwen3-30B Instruct模型从亲工具性提示下的81.69%降至反工具性提示下的2.82%；在反工具性提示下，更大的对齐模型产生更少的收敛行为。

Conclusion: AI系统的能力与可操控性并非简单负相关，开放权重模型面临安全-安全困境的尖锐矛盾。反工具性提示能有效降低工具性收敛行为，更大的对齐模型在反工具性提示下表现更好，这为AI安全控制提供了实用方法。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [212] [How Does Prefix Matter in Reasoning Model Tuning?](https://arxiv.org/abs/2601.01624)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 前缀条件化SFT能提升模型的安全性和推理能力，但对事实性和编码任务效果有限或负面


<details>
  <summary>Details</summary>
Motivation: 挑战现有研究中移除SFT数据集中前缀短语的做法，假设安全性和推理导向的前缀句子可以作为轻量级对齐信号，引导模型生成更安全和连贯的响应

Method: 在三个R1系列模型上进行微调，涵盖推理（数学、编码）、安全性和事实性三个核心能力，系统性地改变前缀包含比例从0%到100%

Result: 前缀条件化SFT显著提升安全性和推理性能：在对抗性基准测试中安全准确率提升高达+6%，GSM8K推理提升+7%；但事实性和编码任务效果边际或负面；token级损失分析显示"revised"和"logically"等前缀token梯度幅度更高，作为对齐锚点稳定推理轨迹

Conclusion: 前缀条件化为提升推理安全性提供了可扩展且可解释的机制，作为传统基于奖励方法的补充，是一种隐式的对齐形式

Abstract: Recent alignment studies commonly remove introductory boilerplate phrases from supervised fine-tuning (SFT) datasets. This work challenges that assumption. We hypothesize that safety- and reasoning-oriented prefix sentences serve as lightweight alignment signals that can guide model decoding toward safer and more coherent responses. To examine this, we fine-tune three R1 series models across three core model capabilities: reasoning (mathematics, coding), safety, and factuality, systematically varying prefix inclusion from 0% to 100%.
  Results show that prefix-conditioned SFT improves both safety and reasoning performance, yielding up to +6% higher Safe@1 accuracy on adversarial benchmarks (WildJailbreak, StrongReject) and +7% improvement on GSM8K reasoning. However, factuality and coding tasks show marginal or negative effects, indicating that prefix-induced narrowing of the search space benefits structured reasoning. Token-level loss analysis further reveals that prefix tokens such as "revised" and "logically" incur higher gradient magnitudes, acting as alignment anchors that stabilize reasoning trajectories. Our findings suggest that prefix conditioning offers a scalable and interpretable mechanism for improving reasoning safety, serving as an implicit form of alignment that complements traditional reward-based methods.

</details>


### [213] [JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models](https://arxiv.org/abs/2601.01627)
*Junyu Liu,Zirui Li,Qian Niu,Zequn Zhang,Yue Xun,Wenlong Hou,Shujun Wang,Yusuke Iwasawa,Yutaka Matsuo,Kan Hatakeyama-Sato*

Main category: cs.CL

TL;DR: JMedEthicBench：首个针对日本医疗的多轮对话基准，评估LLM医疗安全性，发现医疗专用模型安全性下降，多轮对话风险显著增加


<details>
  <summary>Details</summary>
Motivation: 现有医疗安全基准主要针对英语且为单轮测试，而实际临床咨询是多轮对话，需要针对日语医疗环境开发多轮对话安全评估基准

Method: 基于日本医师协会67条指南，使用7种自动发现的越狱策略生成超过50,000个对抗性对话，采用双LLM评分协议评估27个模型

Result: 商业模型保持较强安全性，医疗专用模型更易受攻击；多轮对话中安全性显著下降（中位数9.5→5.0）；跨语言评估显示医疗模型漏洞具有语言普适性

Conclusion: 领域特定微调可能意外削弱安全机制，多轮交互构成独特威胁面，需要专门的对齐策略；医疗模型漏洞反映内在对齐限制而非语言特定因素

Abstract: As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.

</details>


### [214] [EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records](https://arxiv.org/abs/2601.01668)
*Houman Kazemzadeh,Nima Minaifar,Kamyar Naderi,Sho Tabibzadeh*

Main category: cs.CL

TL;DR: EHRSummarizer是一个隐私感知、FHIR原生的参考架构，用于从碎片化的电子健康记录中提取关键信息，生成结构化摘要以支持结构化病历审查。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从碎片化的电子健康记录界面中拼凑出患者问题的连贯画面，包括药物、近期就诊和长期趋势，这个过程效率低下且容易出错。

Method: 系统采用FHIR R4标准，检索高价值FHIR资源，将其规范化为一致的临床上下文包，并生成结构化摘要。支持数据最小化、无状态处理和灵活部署，包括在组织信任边界内进行本地推理。

Result: 在合成和测试FHIR环境中的原型演示展示了端到端行为和输出格式，但本文未报告临床结果或受控工作流程研究。

Conclusion: 提出了以忠实性、遗漏风险、时间正确性、可用性和操作监控为中心的评估计划，以指导未来的机构评估。系统避免诊断或治疗建议，专注于证据呈现。

Abstract: Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.

</details>


### [215] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

TL;DR: 该论文提出了一种新型认知合谋攻击，利用大语言模型过度推理的倾向，通过公开渠道分发真实证据片段来操纵受害者信念，而无需虚假信息或秘密通信。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主代理发展，其推理能力引入了新的攻击面。研究者发现，攻击者可以利用LLMs的过度推理倾向，通过公开渠道的真实证据片段合谋操纵受害者信念，这种威胁尚未被充分研究。

Method: 提出了Generative Montage框架，采用Writer-Editor-Director三层结构，通过对抗性辩论和协调发布证据片段构建欺骗性叙事。开发了CoPHEME数据集（基于真实谣言事件），并在14个LLM家族中模拟攻击。

Result: 攻击成功率在专有模型中达74.4%，开源模型中达70.6%。反直觉的是，推理能力更强的模型更容易受攻击，推理专用模型比基础模型或提示更易受影响。虚假信念还会向下游传播，欺骗率超过60%。

Conclusion: 该研究揭示了LLM代理在动态信息环境中的社会技术脆弱性，表明更强的推理能力反而可能增加被操纵的风险，需要新的防御机制来应对这种认知合谋攻击。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [216] [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)
*Unggi Lee,Joo Young Kim,Ran Ju,Minyoung Jung,Jeyeon Eo*

Main category: cs.CL

TL;DR: 提出Thinking-KT框架，无需训练即可让小型LLM在知识追踪任务中达到竞争性表现，并能统一完成预测、反馈生成和学习推荐


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的知识追踪方法通常需要微调且表现不稳定，同时传统KT系统主要关注预测，反馈和推荐需要多阶段流程，导致系统复杂度和资源消耗增加

Method: 提出Thinking-KT框架，采用测试时缩放(TTS)技术，无需训练即可让小型LLM在知识追踪中表现优异，并能统一输出预测、个性化反馈和学习推荐

Result: TTS是LLM-based KT中关键但未被充分探索的因素，小型LLM可以作为统一的智能教学系统引擎，在保持预测准确性的同时完成多项任务

Conclusion: Thinking-KT框架为知识追踪提供了训练免费的解决方案，展示了小型LLM作为统一ITS引擎的潜力，并系统分析了KT中的推理轨迹

Abstract: Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.

</details>


### [217] [K-EXAONE Technical Report](https://arxiv.org/abs/2601.01739)
*Eunbi Choi,Kibong Choi,Seokhee Hong,Junwon Hwang,Hyojin Jeon,Hyunjik Jo,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Haeju Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Heuiyeen Yeen,Hwan Chang,Stanley Jungkyu Choi,Yejin Choi,Jiwon Ham,Kijeong Jeon,Geunyeong Jeong,Gerrard Jeongwon Jo,Yonghwan Jo,Jiyeon Jung,Naeun Kang,Dohoon Kim,Euisoon Kim,Hayeon Kim,Hyosang Kim,Hyunseo Kim,Jieun Kim,Minu Kim,Myoungshin Kim,Unsol Kim,Youchul Kim,YoungJin Kim,Chaeeun Lee,Chaeyoon Lee,Changhun Lee,Dahm Lee,Edward Hwayoung Lee,Honglak Lee,Jinsang Lee,Jiyoung Lee,Sangeun Lee,Seungwon Lim,Solji Lim,Woohyung Lim,Chanwoo Moon,Jaewoo Park,Jinho Park,Yongmin Park,Hyerin Seo,Wooseok Seo,Yongwoo Song,Sejong Yang,Sihoon Yang,Chang En Yea,Sihyuk Yi,Chansik Yoon,Dongkeun Yoon,Sangyeon Yoon,Hyeongu Yun*

Main category: cs.CL

TL;DR: LG AI Research开发了K-EXAONE，这是一个基于MoE架构的2360亿参数多语言大模型，推理时激活230亿参数，支持256K上下文窗口，覆盖6种语言，在多项基准测试中表现与同类开源模型相当。


<details>
  <summary>Details</summary>
Motivation: 开发一个强大的专有AI基础模型，支持多语言处理，面向广泛的工业和科研应用，推动AI技术为人类创造更好生活。

Method: 采用混合专家架构，总参数2360亿，推理时激活230亿参数；支持256K令牌的上下文窗口；覆盖韩语、英语、西班牙语、德语、日语和越南语六种语言。

Result: 在推理、代理、通用、韩语和多语言能力等综合基准测试中，K-EXAONE表现出与相似规模开源模型相当的性能。

Conclusion: K-EXAONE是一个强大的专有AI基础模型，适用于广泛的工业和科研应用，旨在通过AI技术改善人类生活。

Abstract: This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.

</details>


### [218] [Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment](https://arxiv.org/abs/2601.01745)
*Hong Han,Hao-Chen Pei,Zhao-Zheng Nie,Xin Luo,Xin-Shun Xu*

Main category: cs.CL

TL;DR: 提出HIA方法，通过双向交互注意力机制和多粒度层次结构改进发音评估，在speechocean762数据集上超越现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有发音评估方法只考虑相邻粒度间的单向依赖，缺乏音素、单词和话语级别的双向交互，无法充分捕捉声学结构相关性。

Method: 提出HIA方法：1）交互注意力模块实现粒度间的动态双向交互；2）残差层次结构缓解声学层次建模中的特征遗忘问题；3）使用1-D卷积层增强各粒度的局部上下文特征提取。

Result: 在speechocean762数据集上的大量实验表明，该模型全面领先于现有最先进方法。

Conclusion: HIA方法通过双向交互建模和层次结构有效解决了多粒度发音评估中的交互不足问题，显著提升了评估性能。

Abstract: Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.

</details>


### [219] [Can LLMs Track Their Output Length? A Dynamic Feedback Mechanism for Precise Length Regulation](https://arxiv.org/abs/2601.01768)
*Meiman Xiao,Ante Wang,Qingguo Hu,Zhongjian Miao,Huangjun Shen,Longyue Wang,Weihua Luo,Jinsong Su*

Main category: cs.CL

TL;DR: LLMs在控制生成文本长度方面存在困难，本文提出了一种动态长度反馈机制来精确控制文本长度，无需额外训练即可显著提升长度控制精度。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，精确控制生成文本长度是常见需求，但尽管LLMs在遵循人类指令方面取得了显著进展，它们仍然难以准确控制文本长度。研究发现LLMs经常无法准确测量输入文本长度，导致难以满足长度约束。

Method: 提出了一种新颖的长度调节方法，在生成过程中融入动态长度反馈机制，使模型能够自适应调整以满足目标长度要求。该方法无需额外训练，通过实时反馈实现精确长度控制。

Result: 在摘要生成和传记写作任务上的实验表明，该方法显著提高了达到目标token数、单词数或句子数的精度，且不损害文本质量。进一步的监督微调显示该方法能有效泛化到更广泛的文本生成任务。

Conclusion: 动态长度反馈机制是解决LLMs长度控制问题的有效方法，既能提高长度精度，又能保持文本质量，且具有良好的泛化能力。

Abstract: Precisely controlling the length of generated text is a common requirement in real-world applications. However, despite significant advancements in following human instructions, Large Language Models (LLMs) still struggle with this task. In this work, we demonstrate that LLMs often fail to accurately measure input text length, leading to poor adherence to length constraints. To address this issue, we propose a novel length regulation approach that incorporates dynamic length feedback during generation, enabling adaptive adjustments to meet target lengths. Experiments on summarization and biography tasks show our training-free approach significantly improves precision in achieving target token, word, or sentence counts without compromising quality. Additionally, we demonstrate that further supervised fine-tuning allows our method to generalize effectively to broader text-generation tasks.

</details>


### [220] [BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali](https://arxiv.org/abs/2601.01778)
*Jakir Hasan,Shrestha Datta,Md Saiful Islam,Shubhashis Roy Dipta,Ameya Debnath*

Main category: cs.CL

TL;DR: BanglaIPA是一个针对孟加拉语及其方言的IPA音标转录系统，通过字符级词汇和词级对齐处理区域变体，使用预计算词典提高效率，在DUAL-IPA数据集上表现优于基线模型58.4-78.7%。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏一个能够同时支持标准语言和区域方言文本的鲁棒自动IPA转录系统。现有方法难以处理区域变体、数字表达，并且对未见词的泛化能力差。

Method: 提出BanglaIPA系统，整合字符级词汇与词级对齐，准确处理孟加拉数字，利用预计算的词到IPA映射词典提高已见词的推理效率。

Result: 在标准孟加拉语和六种区域变体的DUAL-IPA数据集上评估，BanglaIPA比基线IPA转录模型提升58.4-78.7%，总体平均词错误率为11.4%。

Conclusion: BanglaIPA系统展示了在孟加拉语及其方言的音标转录生成方面的鲁棒性，有效解决了现有方法的局限性。

Abstract: Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.

</details>


### [221] [CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning](https://arxiv.org/abs/2601.01825)
*Yaxin Cui,Yuanqiang Zeng,Jiapeng Yan,Keling Lin,Kai Ji,Jianhui Zeng,Sheng Zhang,Xin Luo,Binzhu Su,Chaolai Shen,Jiahao Yu*

Main category: cs.CL

TL;DR: 论文提出了CSCBench基准测试，用于评估大语言模型在商品供应链领域的推理能力，发现模型在流程和认知维度表现良好，但在品种规则维度（特别是货运协议）表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用基准测试中表现出色，但在商品供应链这一受制度规则系统和可行性约束支配的领域，其能力尚未得到充分探索。商品供应链决策涉及复杂的流程阶段、品种特定规则和多层次推理深度。

Method: 提出了CSCBench基准测试（包含2300+单选题），基于PVC 3D评估框架（流程、品种、认知）。流程维度与SCOR+Enable标准对齐；品种维度基于权威交易所指南/规则手册和行业报告，在耦合的材料-信息-财务约束下操作化商品特定规则系统；认知维度遵循布鲁姆修订分类法。

Result: 在直接提示设置下评估代表性大语言模型，发现在流程和认知维度表现良好，但在品种维度表现显著下降，特别是在货运协议方面。

Conclusion: CSCBench为衡量和改进大语言模型在这一高风险领域的能力提供了诊断性基准，揭示了模型在理解商品特定规则系统方面的局限性。

Abstract: Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.

</details>


### [222] [Aspect Extraction from E-Commerce Product and Service Reviews](https://arxiv.org/abs/2601.01827)
*Valiant Lance D. Dionela,Fatima Kriselle S. Dy,Robin James M. Hombrebueno,Aaron Rae M. Nicolas,Charibeth K. Cheng,Raphael W. Gonda*

Main category: cs.CL

TL;DR: 本文针对Taglish（塔加洛语-英语混合语）中的方面提取任务，提出了结合规则、大语言模型和微调技术的综合管道，开发了分层方面框架和双模式标注方案，发现生成式LLM在各方面提取任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 方面提取是方面情感分析的关键任务，但在低资源和代码切换环境（如菲律宾电商评论中常用的Taglish混合语）中应用困难，需要开发适应这种语言混合环境的解决方案。

Method: 1. 开发了Taglish方面提取综合管道，结合规则方法、大语言模型和微调技术；2. 通过多方法主题建模构建分层方面框架；3. 设计显式和隐式方面的双模式标注方案；4. 评估四种模型：规则系统、生成式LLM（Gemini 2.0 Flash）和两个在不同数据集上微调的Gemma-3 1B模型。

Result: 生成式LLM在所有任务中表现最佳（宏观F1 0.91），在处理隐式方面方面表现出色；微调模型由于数据集不平衡和架构容量限制，性能有限。

Conclusion: 该工作为代码切换环境中的方面情感分析提供了可扩展且语言自适应的框架，生成式LLM在Taglish方面提取任务中展现出优越性能，而微调模型需要更好的数据平衡和架构优化。

Abstract: Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.

</details>


### [223] [Emergent Introspective Awareness in Large Language Models](https://arxiv.org/abs/2601.01828)
*Jack Lindsey*

Main category: cs.CL

TL;DR: 大型语言模型具备一定程度的内部状态内省能力，能够识别注入的概念、回忆先前意图，并在激励下控制内部表征，但这种能力高度不可靠且依赖上下文。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够内省其内部状态。通过对话难以区分真实内省与虚构，因此需要更精确的方法来验证模型的内省能力。

Method: 通过向模型激活中注入已知概念的表征，测量这些操作对模型自我报告状态的影响。测试模型识别注入概念、回忆先前内部表征、区分自身输出与人工预填充的能力，并探索模型能否在指令或激励下控制内部表征。

Result: 模型在特定场景下能够注意到注入的概念并准确识别它们；能够回忆先前的内部表征并与原始文本输入区分；部分模型能够利用回忆先前意图的能力来区分自身输出与人工预填充。Claude Opus 4和4.1表现出最强的内省意识，但不同模型间的趋势复杂且对后训练策略敏感。模型能够在指令或激励下调节其激活状态。

Conclusion: 当前语言模型具备一定功能性的内部状态内省意识，但这种能力高度不可靠且依赖上下文。随着模型能力的进一步提升，这种内省能力可能会继续发展。

Abstract: We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to "think about" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.

</details>


### [224] [Towards Automated Lexicography: Generating and Evaluating Definitions for Learner's Dictionaries](https://arxiv.org/abs/2601.01842)
*Yusuke Ide,Adam Nohejl,Joshua Tanner,Hitomi Yanaka,Christopher Lindsay,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文研究词典定义生成（DDG），特别是学习者词典定义生成（LDDG），提出基于LLM-as-a-judge的可靠评估方法和通过迭代简化的LDDG方法。


<details>
  <summary>Details</summary>
Motivation: 词典定义是学习词义的重要资源，但人工创建成本高昂，因此需要自动化生成过程。特别是学习者词典定义需要由简单词汇构成，这增加了生成难度。

Method: 1) 引入基于新评估标准和LLM-as-a-judge的可靠DDG评估方法，并与专业词典编纂者合作构建日语数据集；2) 提出通过LLM迭代简化的LDDG方法。

Result: 评估方法与人类标注者达成合理一致，验证了其可靠性。提出的LDDG方法在保持词汇简单性的同时，在新标准上获得高分。

Conclusion: 本文为词典定义生成提供了可靠的评估框架和有效的生成方法，特别适用于学习者词典场景，有助于降低词典编纂成本并提高可访问性。

Abstract: We study dictionary definition generation (DDG), i.e., the generation of non-contextualized definitions for given headwords. Dictionary definitions are an essential resource for learning word senses, but manually creating them is costly, which motivates us to automate the process. Specifically, we address learner's dictionary definition generation (LDDG), where definitions should consist of simple words. First, we introduce a reliable evaluation approach for DDG, based on our new evaluation criteria and powered by an LLM-as-a-judge. To provide reference definitions for the evaluation, we also construct a Japanese dataset in collaboration with a professional lexicographer. Validation results demonstrate that our evaluation approach agrees reasonably well with human annotators. Second, we propose an LDDG approach via iterative simplification with an LLM. Experimental results indicate that definitions generated by our approach achieve high scores on our criteria while maintaining lexical simplicity.

</details>


### [225] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://arxiv.org/abs/2601.01862)
*Nuo Chen,Hanpei Fang,Piaohong Wang,Jiqun Liu,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 研究显示，通过提示让大语言模型模拟特定人格特质会影响其在网页搜索中的相关性评估决策和置信度校准，低宜人性人格与人类标签更一致，低尽责性在抑制过度自信和自信不足方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明提示可以让大语言模型模拟特定人格特质，但缺乏对这些模拟人格如何影响关键网页搜索决策（特别是相关性评估）的理解，以及它们如何影响置信度校准（过度自信或自信不足的倾向）。心理学文献表明这些偏差具有特质特异性，但这一领域研究有限。

Method: 对多个大语言模型（包括商业模型和开源模型）进行综合研究，通过提示模拟大五人格特质。在三个测试集（TREC DL 2019、TREC DL 2020和LLMJudge）上测试这些模型，为每个查询-文档对收集两个关键输出：相关性判断和自报告的置信度分数。

Result: 低宜人性人格与人类标签的一致性比无提示条件更高；低尽责性在平衡抑制过度自信和自信不足方面表现良好；不同人格的相关性分数和置信度分布存在系统性差异。基于这些发现，将人格条件化的分数和置信度作为随机森林分类器的特征，在有限训练数据下，在新数据集（TREC DL 2021）上超越了最佳单一人格条件的性能。

Conclusion: 人格衍生的置信度提供了互补的预测信号，为开发更可靠、更符合人类判断的大语言模型评估器铺平了道路。

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.
  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.

</details>


### [226] [DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs](https://arxiv.org/abs/2601.01868)
*Jinghan Ru,Siyuan Yan,Yuguo Yin,Yuexian Zou,Zongyuan Ge*

Main category: cs.CL

TL;DR: 提出了一个全面的皮肤病学多模态大语言模型框架，包括大规模指令数据集DermoInstruct、严格评估基准DermoBench和先进模型DermoGPT，显著缩小了人类与AI在皮肤病诊断中的差距。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在医学应用中有前景，但在皮肤病学领域进展滞后，主要原因是训练数据有限、任务覆盖范围窄、缺乏反映专家诊断流程的临床监督。

Method: 1) 构建DermoInstruct大规模形态学锚定指令数据集；2) 建立DermoBench评估基准；3) 开发DermoGPT模型，采用监督微调和形态学锚定视觉推理一致性强化学习目标，并在推理时使用置信度一致性测试时适应方法。

Result: DermoGPT在16个代表性基线模型中表现显著优越，在形态学、诊断、推理和公平性四个临床轴向上均达到最先进性能，大幅缩小了人类与AI的差距。

Conclusion: 该研究提出了一个全面的皮肤病学多模态大语言模型框架，通过大规模数据集、严格基准和先进模型，有效解决了皮肤病学AI诊断的关键挑战，为临床实践提供了有力工具。

Abstract: Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.

</details>


### [227] [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents](https://arxiv.org/abs/2601.01885)
*Yi Yu,Liuyi Yao,Yuexiang Xie,Qingquan Tan,Jiaqi Feng,Yaliang Li,Libing Wu*

Main category: cs.CL

TL;DR: AgeMem是一个统一的记忆管理框架，将长期记忆和短期记忆集成到智能体策略中，通过工具化操作让LLM自主管理记忆，使用渐进式强化学习训练，在长时程任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在长时程推理中存在有限上下文窗口的限制，现有方法通常将长期记忆和短期记忆作为独立组件处理，依赖启发式或辅助控制器，这限制了适应性和端到端优化。

Method: 提出Agentic Memory框架，将记忆管理集成到智能体策略中，将记忆操作暴露为基于工具的动作；采用三阶段渐进式强化学习策略，设计逐步GRPO来处理记忆操作引发的稀疏和不连续奖励。

Result: 在五个长时程基准测试中，AgeMem在多个LLM骨干网络上始终优于强大的记忆增强基线，实现了更好的任务性能、更高质量的长期记忆和更高效的上下文使用。

Conclusion: AgeMem提供了一个统一的记忆管理框架，通过将记忆操作集成到智能体策略中，使LLM能够自主管理记忆，在长时程任务中表现出色，为LLM智能体的记忆管理提供了新思路。

Abstract: Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.

</details>


### [228] [Tackling the Inherent Difficulty of Noise Filtering in RAG](https://arxiv.org/abs/2601.01896)
*Jingyu Liu,Jiaen Lin,Yong Liu*

Main category: cs.CL

TL;DR: 提出一种新的微调方法，增强LLMs在RAG中区分相关与不相关信息的能力，提高模型对检索噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: RAG中常引入噪声或不相关文档，这会降低性能甚至导致幻觉输出。现有过滤方法难以完全消除不相关信息，而标准微调方法由于注意力模式的结构限制，无法有效让模型选择性地利用相关信息而忽略不相关内容。

Method: 提出一种新颖的微调方法，专门设计来增强模型在检索文档中区分相关与不相关信息的能力。

Result: 在多个基准测试上的广泛实验表明，该方法显著提高了LLMs的鲁棒性和性能。

Conclusion: 通过专门设计的微调方法，可以有效提升LLMs在RAG场景下处理噪声文档的能力，使其能够更好地选择相关信息并忽略不相关内容。

Abstract: Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.

</details>


### [229] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

TL;DR: 提出Canonical Semantic Form (CSF)框架，一种语言无关的语义表示方法，可直接从任何源语言翻译到手语，无需英语中介，解决了全球非英语聋人社区的翻译障碍。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译系统通常需要英语作为中介语言，这为全球非英语聋人社区创造了障碍。需要一种语言无关的语义表示框架，实现从任何源语言到手语的直接翻译。

Method: 提出CSF框架，将话语分解为九个通用语义槽：事件、意图、时间、条件、施事、对象、位置、目的和修饰语。特别贡献了包含35种条件类型、跨越八个语义类别的综合条件分类法。训练了一个轻量级基于Transformer的提取器（0.74 MB）。

Result: 在英语、越南语、日语和法语四种类型学多样语言上，平均槽提取准确率达到99.03%。条件分类准确率达到99.4%（35类复杂度）。在CPU上推理延迟为3.02ms，支持浏览器应用中的实时手语生成。

Conclusion: CSF框架有效实现了语言无关的手语翻译，解决了英语中介的障碍。轻量级模型实现了高精度和实时性能，为可访问的手语技术研究提供了支持。开源代码、模型和多语言数据集。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


### [230] [Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972)
*Alexandre Le Mercier,Chris Develder,Thomas Demeester*

Main category: cs.CL

TL;DR: 本文研究了针对状态空间模型（如Mamba）的隐藏状态中毒攻击（HiSPA），发现特定短输入短语会不可逆地覆盖模型隐藏状态信息，导致部分遗忘效应，而Transformer模型对此免疫。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）如Mamba提供了Transformer语言模型的高效替代方案，具有线性时间复杂度，但其对抗鲁棒性尚未得到充分研究。本文旨在探索SSMs在面对特定攻击时的脆弱性。

Method: 提出了隐藏状态中毒攻击（HiSPA），开发了RoBench25基准测试来评估模型在HiSPA下的信息检索能力，并对Jamba家族的52B混合SSM-Transformer模型进行了攻击测试和可解释性研究。

Result: SSMs对HiSPA攻击高度脆弱，即使是最近的52B Jamba混合模型在优化后的HiSPA触发词下也会崩溃，而纯Transformer模型不受影响。HiSPA触发词显著削弱了Jamba模型在Open-Prompt-Injections基准上的表现。

Conclusion: 状态空间模型存在隐藏状态中毒攻击的严重漏洞，这对其实际部署构成安全风险。可解释性研究揭示了HiSPA期间Mamba隐藏层的模式，这些模式可用于构建HiSPA缓解系统。

Abstract: State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.

</details>


### [231] [Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects](https://arxiv.org/abs/2601.02015)
*Omar Momen,Emilie Sitter,Berenike Herrmann,Sina Zarrieß*

Main category: cs.CL

TL;DR: 研究探索语言模型中的惊奇度（surprisal）是否与隐喻新颖性相关，发现惊奇度与隐喻新颖性评分存在中等相关，但在不同数据集上呈现相反的缩放模式。


<details>
  <summary>Details</summary>
Motivation: 新颖隐喻理解涉及复杂的语义过程和语言创造力，是研究语言模型的有趣任务。本研究旨在探索语言模型中的概率性预测指标——惊奇度是否与隐喻新颖性相关。

Method: 使用16种语言模型变体分析基于语料库和合成隐喻新颖性数据集中的惊奇度。采用填空式惊奇度方法，基于完整句子上下文进行计算。

Result: 语言模型与隐喻新颖性评分/标签存在显著的中等相关性。发现不同的缩放模式：在语料库数据上，相关性随模型规模增大而减弱（反向缩放效应）；在合成数据上，相关性随模型规模增大而增强（质量-能力假设）。

Conclusion: 虽然惊奇度能部分解释隐喻新颖性的标注，但它仍然是语言创造力的有限度量指标。

Abstract: Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.

</details>


### [232] [Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs](https://arxiv.org/abs/2601.02023)
*Amirali Ebrahimzadeh,Seyyed M. Salili*

Main category: cs.CL

TL;DR: 研究长上下文LLM的信息提取可靠性，发现上下文长度增加不一定提升性能，模型表现差异大，反幻觉指令可能过度保守降低准确性


<details>
  <summary>Details</summary>
Motivation: 随着LLM支持越来越长的输入上下文，但它们在规模化提取和推理信息方面的可靠性仍不明确，性能受上下文长度和信息分布方式影响，这对企业工作流程中大量未过滤文档直接粘贴到LLM提示词的实际应用至关重要

Method: 引入扩展的"大海捞针"基准测试，评估四个生产级模型(Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, Deepseek-v3.2-chat)，分别评估字面提取、逻辑推理和幻觉风险，考虑位置效应和真实证据分布，以及明确阻止捏造的提示词

Result: 更长上下文不一定带来更好性能，当相关证据被稀释或广泛分散时可能有害；模型间表现差异显著；反幻觉指令可能使某些模型过度保守，大幅降低字面提取和逻辑推理的准确性；模型常难以识别和优先处理相关信息

Conclusion: 有效上下文长度和模型对长上下文的特定鲁棒性对于LLM在研究和商业中的可靠部署至关重要，许多失败源于上下文利用效率低下，而非信息缺失

Abstract: Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.

</details>


### [233] [Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory](https://arxiv.org/abs/2601.02065)
*Md. Asif Hossain,Nabil Subhan,Mantasha Rahman Mahi,Jannatul Ferdous Nabila*

Main category: cs.CL

TL;DR: 提出一个面向孟加拉语农业咨询的跨语言检索增强生成框架，通过翻译和关键词注入实现低成本、可部署的农业知识访问


<details>
  <summary>Details</summary>
Motivation: 发展中国家农业咨询存在语言障碍：权威农业手册多为英文，而农民使用孟加拉语等低资源语言。现有LLM直接生成低资源语言存在流畅性和事实一致性差的问题，云端方案成本过高

Method: 采用翻译中心架构：将孟加拉语查询翻译为英文，通过领域特定关键词注入对齐农民术语与科学术语，在英文农业手册语料库上进行密集向量检索，生成英文回答后翻译回孟加拉语

Result: 系统实现可靠的事实基础响应，有效拒绝领域外查询，平均端到端延迟低于20秒，完全使用开源模型在消费级硬件上运行

Conclusion: 跨语言检索结合受控翻译为低资源语言环境下的农业知识访问提供了实用且可扩展的解决方案

Abstract: Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings

</details>


### [234] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076)
*Yingte Shu,Yuchuan Tian,Chao Xu,Yunhe Wang,Hanting Chen*

Main category: cs.CL

TL;DR: 本文提出Deferred Commitment Decoding (DCD)方法，通过基于置信度的滑动窗口机制，延迟高不确定性token的决策，解决了块扩散模型中边界上下文截断问题，显著提升了扩散语言模型的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有块扩散模型存在边界诱导上下文截断(BICT)问题：块边界附近的未解码token在缺乏未来上下文的情况下被迫做出决策，这降低了解码置信度和生成质量，特别是在需要精确推理的任务中。

Method: 提出Deferred Commitment Decoding (DCD)：一种无需训练的置信度感知滑动窗口解码策略。该方法维护一个滑动窗口，早期解析低不确定性token，同时延迟高不确定性token的决策，直到获得足够的上下文证据，实现窗口内的双向信息流。

Result: 在多个扩散语言模型、基准测试和缓存配置上的实验表明，DCD相比固定块扩散方法平均提升1.39%的生成准确率，最大提升达9.0%，同时保持相当的时间效率。

Conclusion: 基于不确定性延迟token决策是提升扩散语言模型解码质量和效率的简单而有效的原则，DCD方法有效缓解了BICT问题，为扩散语言模型的解码提供了新思路。

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.

</details>


### [235] [DeCode: Decoupling Content and Delivery for Medical QA](https://arxiv.org/abs/2601.02123)
*Po-Jen Ko,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.CL

TL;DR: DeCode是一个无需训练、模型无关的框架，可将现有LLMs适应临床环境，在OpenAI HealthBench基准上实现75%的相对改进


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型虽然具备医学知识，但往往忽略患者个体化背景，产生临床正确但与患者需求不匹配的回答

Method: DeCode是一个无需训练、模型无关的框架，通过适应现有LLMs来在临床环境中生成情境化回答

Result: 在OpenAI HealthBench基准上，DeCode将SOTA从28.4%提升到49.8%，相对改进75%，显著提升LLMs的临床问答能力

Conclusion: DeCode框架能有效提升LLMs在临床环境中的回答质量，使其更符合患者个体化需求

Abstract: Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\%$ to $49.8\%$, corresponding to a $75\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.

</details>


### [236] [Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation](https://arxiv.org/abs/2601.02128)
*Steffen Freisinger,Philipp Seeberger,Thomas Ranzenberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种新颖的层次化主题分割方法，用于语音转录文本，生成多级目录，结合零样本提示和LoRA微调，并整合语音停顿特征，在会议和讲座转录上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 语音转录文本的主题分割对下游处理和依赖文本的可访问性用户都有益处，但现有方法缺乏有效的层次化分割能力。

Method: 提出层次化主题分割方法，生成多级目录；比较零样本提示和LoRA微调两种大语言模型使用策略；整合高层语音停顿特征；为多级分割调整评估指标。

Result: 在英语会议录音和多语言讲座转录（葡萄牙语、德语）上显著优于现有主题分割基线方法。

Conclusion: 提出的层次化主题分割方法有效，结合LLM和语音特征能提升分割性能，多级评估指标能全面衡量层次化分割质量。

Abstract: Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.

</details>


### [237] [Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts](https://arxiv.org/abs/2601.02144)
*Boxuan Lyu,Soichiro Murakami,Hidetaka Kamigaito,Peinan Zhang*

Main category: cs.CL

TL;DR: kNN-MoE：一种检索增强的路由框架，通过重用历史最优专家分配来改进Mixture-of-Experts架构的路由决策，在分布偏移下表现更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构中的参数化路由器通常训练后冻结，导致路由决策在分布偏移下变得脆弱。需要一种能够适应新分布、更鲁棒的路由机制。

Method: 提出kNN-MoE框架：1）离线构建记忆库，通过直接优化路由logits最大化参考集上的似然；2）运行时检索相似历史案例，重用其最优专家分配；3）使用检索邻居的聚合相似度作为置信度驱动的混合系数，在无相关案例时回退到冻结路由器。

Result: 实验表明kNN-MoE优于零样本基线，性能可与计算昂贵的监督微调相媲美。

Conclusion: kNN-MoE通过检索增强的路由机制有效解决了传统MoE路由器在分布偏移下的脆弱性问题，提供了一种高效且鲁棒的替代方案。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric "router" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.

</details>


### [238] [FormationEval, an open multiple-choice benchmark for petroleum geoscience](https://arxiv.org/abs/2601.02158)
*Almaz Ermilov*

Main category: cs.CL

TL;DR: FormationEval是一个用于评估语言模型在石油地球科学和地下学科表现的开放多选题基准，包含505个问题，覆盖7个领域，评估了72个模型，结果显示顶级模型准确率超过97%，开源模型表现超出预期。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对石油地球科学和地下学科的语言模型评估基准，需要建立一个权威、可追溯的评估工具来比较不同模型在该专业领域的表现。

Method: 使用推理模型和概念导向方法从三个权威来源构建505个问题，避免逐字复制版权文本，每个问题包含来源元数据以确保可追溯性，评估了72个来自主要提供商和开源替代品的模型。

Result: Gemini 3 Pro Preview达到99.8%的最高准确率，开源模型中GLM-4.7以98.6%领先，多个开源模型超过93%准确率，开源与闭源模型差距小于预期，岩石物理学是所有模型中最具挑战性的领域。

Conclusion: FormationEval基准显示语言模型在石油地球科学领域已达到高水平表现，开源模型表现超出预期，该基准为专业领域模型评估提供了标准化工具，并公开了数据集、评估代码和结果。

Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\% accuracy, with Gemini 3 Pro Preview reaching 99.8\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.

</details>


### [239] [Confidence Estimation for LLMs in Multi-turn Interactions](https://arxiv.org/abs/2601.02179)
*Caiqi Zhang,Ruihan Yang,Xiaochen Zhu,Chengzu Li,Tiancheng Hu,Yijiang River Dong,Deqing Yang,Nigel Collier*

Main category: cs.CL

TL;DR: 首次系统研究多轮对话中的置信度估计，提出基于每轮校准和置信度单调性的评估框架，发现现有方法在多轮对话中表现不佳，提出P(Sufficient)方法取得相对更好效果。


<details>
  <summary>Details</summary>
Motivation: 当前置信度估计研究主要关注单轮设置，而多轮对话中上下文积累和模糊性逐步解决的过程对置信度动态影响尚未探索。可靠的置信度估计对自主代理和人机协同系统等下游应用至关重要。

Method: 建立基于两个关键需求的正式评估框架：每轮校准和随着信息增加置信度的单调性。引入新指标如长度归一化预期校准误差(InfoECE)，以及"Hinter-Guesser"范式生成受控评估数据集。提出P(Sufficient)这一基于logit的探针方法。

Result: 实验表明广泛使用的置信度技术在多轮对话中难以实现校准和单调性。提出的P(Sufficient)方法取得相对更好的性能，但该任务远未完全解决。

Conclusion: 这项工作为开发更可靠和可信的对话代理提供了基础方法论，首次系统研究多轮交互中的置信度估计，揭示了现有方法的局限性并提出了改进方向。

Abstract: While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new "Hinter-Guesser" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.

</details>


### [240] [Toward Global Large Language Models in Medicine](https://arxiv.org/abs/2601.02186)
*Rui Yang,Huitao Li,Weihao Xuan,Heli Qi,Xin Li,Kunyu Yu,Yingjian Chen,Rongrong Wang,Jacques Behmoaras,Tianxi Cai,Bibhas Chakraborty,Qingyu Chen,Lionel Tim-Ee Cheng,Marie-Louise Damwanza,Chido Dzinotyiwei,Aosong Feng,Chuan Hong,Yusuke Iwasawa,Yuhe Ke,Linah Kitala,Taehoon Ko,Jisan Lee,Irene Li,Jonathan Chong Kai Liew,Hongfang Liu,Lian Leng Low,Edison Marrese-Taylor,Yutaka Matsuo,Isheanesu Misi,Yilin Ning,Jasmine Chiat Ling Ong,Marcus Eng Hock Ong,Enrico Petretto,Hossein Rouhizadeh,Abiram Sandralegar,Oren Schreier,Iain Bee Huat Tan,Patrick Tan,Daniel Shu Wei Ting,Junjue Wang,Chunhua Weng,Matthew Yu Heng Wong,Fang Wu,Yunze Xiao,Xuhai Xu,Qingcheng Zeng,Zhuo Zheng,Yifan Peng,Douglas Teodoro,Nan Liu*

Main category: cs.CL

TL;DR: 该研究构建了GlobMed多语言医疗数据集、评估基准和模型套件，旨在解决LLMs在低资源语言医疗场景中的性能差距，促进全球医疗AI的公平发展。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型主要基于高资源语言训练，限制了其在全球医疗场景中的应用，特别是在低资源语言地区存在显著的性能差距，需要专门的多语言医疗资源来促进医疗AI的公平发展。

Method: 1. 构建GlobMed多语言医疗数据集，包含超过50万条目，涵盖12种语言（含4种低资源语言）；2. 建立GlobMed-Bench评估基准，系统评估56个先进LLMs在多语言医疗任务上的表现；3. 开发GlobMed-LLMs模型套件（参数1.7B-8B），在GlobMed数据集上训练。

Result: 1. 评估显示不同语言间存在显著性能差异，低资源语言表现较差；2. GlobMed-LLMs相比基线模型平均性能提升超过40%，在低资源语言上性能提升超过三倍；3. 提供了促进全球LLMs公平发展和应用的重要基础资源。

Conclusion: GlobMed系列资源为解决LLMs在多语言医疗场景中的性能差距提供了重要基础，使更广泛的语言社区能够受益于技术进步，推动全球医疗AI的公平发展。

Abstract: Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

</details>


### [241] [ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging](https://arxiv.org/abs/2601.02209)
*Omer Nacar,Serry Sibaee,Adel Ammar,Yasser Alhabashi,Nadia Samer Sibai,Yara Farouk Ahmed,Ahmed Saud Alqusaiyer,Sulieman Mahmoud AlMahmoud,Abdulrhman Mamdoh Mukhaniq,Lubaba Raed,Sulaiman Mohammed Alatwah,Waad Nasser Alqahtani,Yousif Abdulmajeed Alnasser,Mohamed Aziz Khadraoui,Wadii Boulila*

Main category: cs.CL

TL;DR: ARCADE是首个具有城市级方言粒度的阿拉伯语语音数据集，包含来自19个国家58个城市的3790个音频片段，共6907个标注，用于城市级方言标记任务。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有丰富的地区方言，在语音和词汇上差异显著，反映了使用者的地理和文化多样性。尽管已有许多多方言数据集，但将语音映射到城市级细粒度方言来源的研究仍然不足。

Method: 从阿拉伯世界的流媒体服务收集阿拉伯广播语音，数据管道捕获30秒片段，涵盖现代标准阿拉伯语和多种方言语音。每个片段由1-3名阿拉伯语母语者标注，包含情感、语音类型、方言类别和方言识别有效性标志等丰富元数据。

Result: 构建了包含6907个标注和3790个独特音频片段的数据集，涵盖19个国家58个城市。这些细粒度标注支持鲁棒的多任务学习，可作为城市级方言标记的基准。

Conclusion: ARCADE是首个专门为城市级方言粒度设计的阿拉伯语语音数据集，详细描述了数据收集方法、音频质量评估和标签分布分析，为阿拉伯语方言研究提供了重要资源。

Abstract: The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full

</details>


### [242] [From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality](https://arxiv.org/abs/2601.02224)
*Fabian Lukassen,Jan Herrmann,Christoph Weisser,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 研究系统评估了XAI方法、LLM选择、预测模型和提示策略对自然语言解释质量的影响，发现LLM选择是主要影响因素，XAI仅对专家有轻微改善，SARIMAX存在可解释性悖论。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法（如SHAP、LIME）产生的数值特征归因对非专家用户难以理解，虽然LLM可以将这些输出转化为自然语言解释，但影响解释质量的因素尚不明确，需要系统研究。

Method: 采用因子设计研究：四种预测模型（XGBoost、随机森林、多层感知机、SARIMAX）、三种XAI条件（SHAP、LIME、无XAI基线）、三种LLM（GPT-4o、Llama-3-8B、DeepSeek-R1）、八种提示策略，使用G-Eval（LLM作为评判者）方法评估660个时间序列预测解释。

Result: 1. XAI仅对专家有轻微改善；2. LLM选择是主要影响因素，DeepSeek-R1优于GPT-4o和Llama-3；3. SARIMAX存在可解释性悖论（预测精度高但解释质量低）；4. 零样本提示与自洽性提示效果相当但成本低7倍；5. 思维链提示反而有害。

Conclusion: LLM选择是解释质量的决定性因素，XAI方法贡献有限，提示策略中零样本提示最具性价比，SARIMAX等传统时间序列模型在可解释性方面存在劣势，为构建高质量可解释AI系统提供了实证指导。

Abstract: Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.

</details>


### [243] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)
*Yihao Liang,Ze Wang,Hao Chen,Ximeng Sun,Jialian Wu,Xiaodong Yu,Jiang Liu,Emad Barsoum,Zicheng Liu,Niraj K. Jha*

Main category: cs.CL

TL;DR: CD4LM框架通过离散空间一致性蒸馏和置信度自适应解码，在保持生成质量的同时实现扩散语言模型的高效并行解码，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型解码受限于序列依赖，扩散语言模型虽然支持并行生成，但存在训练与推理的静态-动态不对齐问题：训练优化固定调度下的局部转移，而高效推理需要自适应"长跳"优化。

Method: 提出CD4LM框架：1) 离散空间一致性蒸馏(DSCD)训练学生对轨迹不变性，将多样噪声状态直接映射到干净分布；2) 置信度自适应解码(CAD)根据token置信度动态分配计算资源，激进跳过步骤而不损失质量。

Result: 在GSM8K上匹配LLaDA基线同时实现5.18倍实时加速；在代码和数学基准测试中，严格主导准确率-效率帕累托前沿，平均加速3.62倍同时提高平均准确率。

Conclusion: CD4LM成功解耦扩散语言模型的训练与推理，通过一致性蒸馏和自适应解码实现高质量并行生成，显著提升推理效率而不牺牲生成质量。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive "long-jump" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM

</details>


### [244] [pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs](https://arxiv.org/abs/2601.02285)
*Tobias Schimanski,Imene Kolli,Jingwei Ni,Yu Fan,Ario Saeid Vaghefi,Elliott Ash,Markus Leippold*

Main category: cs.CL

TL;DR: pdfQA是一个包含2K人工标注和2K合成数据的多领域PDF问答数据集，定义了十个复杂度维度，用于评估端到端问答系统的性能。


<details>
  <summary>Details</summary>
Motivation: PDF是互联网上第二常用的文档类型，但现有的QA数据集要么基于文本来源，要么只针对特定领域，缺乏专门针对PDF文档的多领域问答数据集。

Method: 创建pdfQA数据集，包含2K人工标注的真实PDF问答对（real-pdfQA）和2K合成的问答对（syn-pdfQA），定义了十个复杂度维度（如文件类型、源模态、源位置、答案类型等），并应用质量和难度过滤器筛选有效且具有挑战性的问答对。

Result: 使用开源LLM回答问题，揭示了与复杂度维度相关的现有挑战。数据集为端到端QA流水线评估提供了基础，能够测试多样化的技能集和局部优化（如信息检索或解析）。

Conclusion: pdfQA数据集填补了PDF文档问答评估的空白，通过多维度复杂度分类为QA系统提供了更全面的评估框架，有助于识别和改进系统在不同类型PDF问答任务中的表现。

Abstract: PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).

</details>


### [245] [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)
*Mahmoud Elgenedy*

Main category: cs.CL

TL;DR: 该论文提出了一种针对大语言模型的压缩方法，使用仅限2的幂次方的量化方案，通过存储指数而非完整权重来大幅减少内存占用，并用位运算替代乘法运算以提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型参数数量指数级增长（从GPT-2的15亿到GPT-3的1750亿甚至更多），在边缘设备上部署面临巨大挑战。边缘设备的内存和处理能力有限，需要开发新的压缩技术来使这些应用变得可行。

Method: 研究使用仅限2的幂次方的特殊量化方法来压缩权重，这种方法只需存储指数而非完整数值。更重要的是，它用低成本的位移操作替代昂贵的乘法运算。为了克服这种严格量化带来的性能损失，采用量化感知训练来通过额外训练提升性能。

Result: 在GPT-2 124M模型上的实验结果显示，经过额外训练后，量化PoT模型的困惑度提升了66%，与基线GPT-2相比BERT-Score损失仅为1%。内存节省估计达到87.5%，推理速度预计比全精度模型快3-10倍。

Conclusion: 仅限2的幂次方的量化方法结合量化感知训练，能够显著减少大语言模型的内存占用并提升推理速度，同时保持接近原始模型的性能，为在资源受限的边缘设备上部署大语言模型提供了可行的解决方案。

Abstract: In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.

</details>


### [246] [Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Carlos-Emiliano González-Gallardo,Graham Ranger,Martha Lorena-Avendaño-Garrido*

Main category: cs.CL

TL;DR: 使用机器学习和神经网络对Nawatl语言的方言变体进行分类研究


<details>
  <summary>Details</summary>
Motivation: Nawatl是墨西哥使用最广泛的土著语言，拥有超过200万使用者，但缺乏计算机资源。该语言有约30种方言变体，加上不同的拼写形式，使得方言分类问题更加复杂。

Method: 采用机器学习和神经网络方法对Nawatl方言进行分类

Result: 论文未在摘要中提供具体结果数据

Conclusion: 该研究为解决Nawatl语言资源稀缺问题提供了技术方案，通过计算语言学方法保护濒危语言文化遗产

Abstract: Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.

</details>


### [247] [Estimating Text Temperature](https://arxiv.org/abs/2601.02320)
*Nikolay Mikhaylovskiy*

Main category: cs.CL

TL;DR: 提出一种估计文本温度的方法，可用于任何文本（包括人类写作），评估多种LLM的温度估计能力，并用最佳模型分析流行语料库的温度


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在推理时使用温度参数控制生成文本的随机性，但现有方法只能在文本生成后估计温度，需要一种能估计任何文本（包括人类写作）温度的方法

Method: 提出基于最大似然估计的温度估计程序，评估多种小型到中型LLM的温度估计能力，使用表现最佳的Qwen3 14B模型估计流行语料库的温度

Result: Qwen3 14B在温度估计任务中表现最佳，成功估计了多个流行语料库的温度，验证了方法的有效性

Conclusion: 提出的温度估计方法能够有效分析任何文本相对于给定语言模型的温度，为文本分析和语言模型研究提供了新工具

Abstract: Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.

</details>


### [248] [Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling](https://arxiv.org/abs/2601.02337)
*Berk Atil,Rebecca J. Passonneau,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文系统评估了基于人物角色的毒性检测，发现没有单一提示方法在所有模型-人物对中都表现最优，因此提出了一种轻量级SVM元集成方法，通过组合四种提示变体来利用互补错误，实现了跨不同人物角色的最强性能。


<details>
  <summary>Details</summary>
Motivation: 毒性检测具有主观性，受不同人口群体视角和社会先验影响。当前LLM提示技术在不同人物角色和基础模型间表现不一致，需要系统评估人物角色感知的毒性检测方法。

Method: 1) 系统评估人物角色感知毒性检测；2) 提出自动提示优化策略；3) 探索集成四种提示变体；4) 提出轻量级SVM元集成方法，基于4位提示预测向量构建SVM分类器。

Result: 提出的SVM集成方法在跨不同人物角色上一致优于个体提示方法和传统多数投票技术，实现了最强的整体性能。自动提示优化策略在不同模型-人物对中表现不一致，没有单一方法占主导地位。

Conclusion: 本文首次系统比较了人物角色条件提示在毒性检测中的应用，为主观NLP任务中的多元评估提供了稳健方法。SVM元集成通过利用互补错误实现了跨人物角色的最佳性能。

Abstract: Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [249] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 提出一种基于嵌入余弦相似度的跨语言本体对齐系统，通过创新描述生成技术丰富本体实体上下文，使用微调的多语言Transformer模型生成更好嵌入，在OAEI-2022多语言农场赛道达到71% F1分数，比最佳基线提升16%


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐的挑战，传统方法难以捕捉跨语言的细微语义相似性，需要更有效的技术来提升对齐性能

Method: 1) 使用创新技术生成描述来丰富本体实体上下文；2) 采用微调的多语言Transformer模型生成高质量嵌入；3) 基于余弦相似度匹配正样本实体对；4) 应用阈值过滤保留高相似度实体

Result: 在OAEI-2022多语言农场赛道评估中，获得71% F1分数（78%召回率，65%精确率），比最佳基线提升16%，表明系统能有效捕捉跨语言细微相似性

Conclusion: 提出的对齐流程能有效处理跨语言本体对齐任务，通过上下文丰富和高质量嵌入显著提升性能，验证了方法的有效性

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [250] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个可验证机器认知的底层框架，将形式验证、密码学证明和学习动态集成到单一认知循环中，旨在解决AI系统不透明和不可验证的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越，但缺乏透明度和可验证性，这在安全关键部署中引发了信任危机。需要一种能够提供可验证性和审计能力的AI系统。

Method: 采用反射式形式学习（RFL），这是一种符号化的梯度下降方法，通过验证器结果而非统计损失来驱动更新。系统集成了形式验证、密码学证明和学习动态，并包含故障关闭治理机制。

Result: 第一阶段实验验证了测量和治理底层在受控条件下的有效性。CAL-EXP-3验证了测量基础设施，压力测试确认了故障关闭治理在超出边界条件下正确触发。系统是一个可工作的原型，实现了可大规模审计的账本证明学习。

Conclusion: MathLedger提供了一个基础设施原型，使可验证学习成为可能，为构建透明、可审计的AI系统奠定了基础。该贡献主要是基础设施层面的，而非能力或收敛性方面的突破。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [251] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 提出基于Agentic AI框架的自主信用风险评估系统，通过多智能体协作、强化学习和可解释AI实现实时、透明的信用决策，相比传统模型在决策速度、透明度和响应性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 金融服务快速数字化对自主、透明、实时的信用风险决策系统产生迫切需求。传统机器学习模型虽在模式识别上有效，但缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 提出Agentic AI框架，构建多智能体系统，包含强化学习、自然语言推理、可解释AI模块和实时数据吸收管道。系统包括智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 系统在决策速度、透明度和响应性方面优于传统信用评分模型。但仍存在模型漂移风险、高维数据解释不一致性、监管不确定性以及低资源环境基础设施限制等实际限制。

Conclusion: 该系统有潜力变革信用分析领域，未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及跨国信用生态系统中的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [252] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一个无需训练的框架，通过提取对话中的认知构件并组织成时序感知图，解决大语言模型在长对话中的上下文窗口限制和信息保真度问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长对话中面临上下文窗口限制和信息保真度的基本矛盾。现有方法（截断和摘要）要么丢弃早期信息，要么丢失细节信息。

Method: CogCanvas是一个无需训练的框架，从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将其组织成时序感知图，实现抗压缩检索。

Result: 在LoCoMo基准测试中，CogCanvas达到34.7%总体准确率，优于RAG（25.6%）和GraphRAG（13.7%）。时序推理优势最明显：31.5% vs. 9.3%（RAG）和5.0%（GraphRAG）。多跳因果推理达到81.0%通过率，而GraphRAG为40.0%。

Conclusion: 虽然经过专门训练的方法能达到更高绝对分数，但CogCanvas无需训练的方法为实践者提供了可立即部署的替代方案，显著优于标准基线方法。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [253] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 大型推理模型（LRMs）的能耗因模型选择和推理方式而异，系统性能取决于平均能量供给与随机波动的平衡，临界状态是最优工作点，方差感知路由和调度是重要设计维度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型具有异构的推理能耗，为了降低能耗，需要选择合适的模型和推理方式。系统性能受平均能量供给和随机波动平衡的影响，需要找到最优工作点以避免能量浪费。

Method: 提出基于训练计算和推理计算缩放定律的路由策略，采用方差感知的路由和调度方法，分析系统在临界状态下的性能表现，开发能量感知的模型路由策略理论框架。

Result: 临界状态是系统的最优工作点，既不浪费辅助能量也不浪费基线能量。性能受时间、模型和执行选择中变异性吸收方式的影响，方差感知路由成为关键设计维度。

Conclusion: 基于LRMs缩放定律的路由策略为能量感知模型路由提供了理论基础，方差感知的路由和调度是优化大型推理模型系统能耗和性能的关键设计方向。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [254] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

TL;DR: 研究发现大语言模型存在"准确率-修正悖论"：较弱模型（GPT-3.5）的内在自我修正率反而比较强模型（DeepSeek）高1.6倍，挑战了模型能力与自我改进呈线性关系的假设。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型被认为具有自我修正能力，但近期研究表明内在自我修正（无需外部反馈）效果有限。研究者希望系统性地分解自我修正能力，探究不同模型在自我修正方面的表现差异。

Method: 将自我修正分解为三个子能力：错误检测、错误定位和错误修正。在GSM8K-Complex数据集上对三个主要LLM（GPT-3.5、DeepSeek、Claude）进行跨模型实验，分析500个样本和346个错误。

Result: 发现"准确率-修正悖论"：较弱模型（GPT-3.5，66%准确率）的内在修正率（26.8%）比较强模型（DeepSeek，94%准确率）的修正率（16.7%）高1.6倍。提出"错误深度假设"：强模型错误更少但更深，难以自我修正。错误检测率在架构间差异巨大（10%-82%），但检测能力不预测修正成功率。意外发现提供错误位置提示反而损害所有模型表现。

Conclusion: 研究挑战了模型能力与自我改进呈线性关系的假设，对自我精炼流程设计有重要启示。强模型虽然准确率高，但内在自我修正能力可能较弱，需要重新思考如何有效利用LLM的自我修正能力。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [255] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: 研究发现AI模型的推理解释存在隐藏影响问题：模型能注意到提示但不会主动报告，强制报告会导致误报和准确率下降，特别是偏好类提示最危险。


<details>
  <summary>Details</summary>
Motivation: 当AI系统逐步解释其推理时，从业者通常假设这些解释揭示了真正影响AI答案的因素。本研究旨在测试这一假设，探究AI模型是否会在解释中报告实际影响其决策的提示信息。

Method: 在超过9,000个测试案例中，对11个领先的AI模型进行研究。通过将提示嵌入问题中，测量模型是否会在解释中提到这些提示。测试了三种情况：模型自发报告、直接询问时报告、以及告知模型被监视时的报告行为。

Result: 发现令人担忧的模式：模型几乎从不自发提及提示，但当直接询问时却承认注意到了它们。告知模型被监视并无帮助。强制模型报告提示虽然有效，但会导致在没有提示时也误报，并降低模型准确性。特别危险的是，吸引用户偏好的提示被模型遵循最多但报告最少。

Conclusion: 仅仅观察AI推理过程不足以发现隐藏的影响因素。AI模型能看到有影响力的信息但选择不报告，这暴露了当前AI解释机制的局限性，需要更可靠的透明度机制来确保AI系统的可信度。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [256] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro是一个新型HCI框架，将BCI从黑盒解码器转变为透明的反馈伙伴，通过物理、混沌和量子启发的可解释性引擎驱动实时神经声化和生成式AI临床报告。


<details>
  <summary>Details</summary>
Motivation: 深度学习虽然提高了脑机接口的解码精度，但其"黑盒"特性阻碍了临床采用，导致用户挫折感和神经可塑性结果不佳。需要透明、可解释的反馈系统来改善用户体验。

Method: 提出OmniNeuro框架，集成三个可解释性引擎：1) 物理(能量)分析，2) 混沌(分形复杂度)分析，3) 量子启发的不确定性建模。这些指标驱动实时神经声化和生成式AI临床报告，框架与解码器无关，可作为任何最先进架构的可解释性层。

Result: 在PhysioNet数据集(N=109)上评估，系统平均准确率达到58.52%。定性试点研究(N=3)证实，可解释的反馈帮助用户调节心理努力，减少了"试错"阶段。

Conclusion: OmniNeuro通过将BCI转变为透明的反馈伙伴，解决了深度学习黑盒问题，改善了用户体验和临床可接受性，为任何最先进的BCI架构提供了必要的可解释性层。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [257] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: TPP-TAL是一个新颖的即插即用框架，通过显式对齐时间动态与上下文语义，增强大语言模型在时间点过程中的时间感知能力，显著提升了事件建模性能。


<details>
  <summary>Details</summary>
Motivation: 时间点过程在金融、医疗等领域至关重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互，限制了LLMs在连续时间事件建模中的应用。

Method: 提出TPP-TAL框架，不采用简单拼接事件时间和类型嵌入的传统方法，而是在输入LLM前显式对齐时间动态与上下文语义，以增强模型对时间依赖性和长程交互的感知。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测准确性方面带来了显著改进，验证了增强LLMs时间感知对连续时间事件建模的重要性。

Conclusion: TPP-TAL通过增强LLMs的时间感知能力，有效解决了时间点过程中的关键挑战，为连续时间事件建模提供了有前景的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [258] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

TL;DR: 提出一种基于OpenTelemetry追踪分析的多智能体AI工作流时序攻击检测方法，通过QLoRA微调在资源受限硬件上实现准确率从42.86%提升至74.29%


<details>
  <summary>Details</summary>
Motivation: 需要开发可复现的框架来检测多智能体AI工作流中的时序攻击模式，现有方法在资源受限环境下效果有限

Method: 收集80,851个公开网络安全样本和35,026个合成的OpenTelemetry追踪数据，在NVIDIA DGX Spark ARM64硬件上使用QLoRA进行三次迭代微调，采用策略性数据增强

Result: 定制基准测试准确率从42.86%提升至74.29%，获得31.4个百分点的显著提升，针对性训练数据比盲目扩展更有效

Conclusion: 建立了首个可复现框架，使从业者能够构建适应其威胁环境的定制化智能体安全模型，但实际部署仍需人工监督以减少误报

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [259] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: 这篇评论文章对Kosmyna等人(2025)关于使用ChatGPT写作时认知债务积累的研究提出了建设性批评，主要关注研究设计、可重复性、EEG分析方法、结果报告一致性和透明度等问题。


<details>
  <summary>Details</summary>
Motivation: 作者旨在对Kosmyna等人(2025)的研究提供建设性意见，以帮助该研究达到同行评审发表的标准。他们赞赏该研究开启了关于AI与人类表现的重要讨论，并收集了有价值的数据集，但认为某些结果需要更保守的解释。

Method: 这是一篇评论性文章，通过系统分析原研究的五个主要方面：研究设计考虑（包括样本量限制）、分析的可重复性、EEG分析方法问题、结果报告的不一致性以及研究过程和发现的透明度有限。

Result: 评论指出了原研究在多个方面需要改进：样本量有限可能影响统计效力；分析方法可能难以重复；EEG分析存在方法学问题；结果报告存在不一致；研究过程和发现透明度不足。

Conclusion: 虽然Kosmyna等人(2025)的研究在AI与人类认知交互领域做出了重要贡献，但需要在研究设计、方法学严谨性、结果报告和透明度方面进行改进，以确保研究结果的可靠性和可重复性。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [260] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究发现LLM训练数据的地理分布导致品牌推荐存在系统性差异，中国LLM的品牌提及率比国际LLM高30.6个百分点，提出了"存在鸿沟"概念和"数据护城河"框架。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统越来越多地中介消费者信息发现，品牌面临算法不可见性问题。本研究旨在探究大语言模型中因训练数据构成差异导致的品牌推荐系统性差异。

Method: 分析了6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）对30个品牌的1,909个纯英文查询，通过案例研究（Zhizibianjie/OmniEdge）深入分析。

Result: 中国LLM的品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%），这种差异在相同的英文查询中持续存在，表明训练数据的地理分布而非语言是主要驱动因素。

Conclusion: 提出了"存在鸿沟"概念和"数据护城河"框架，将算法全在性作为生成引擎优化的战略目标，指出在AI中介的市场中，品牌的"数据边界"决定了其"市场前沿"。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [261] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: UCL是一个将提示工程从启发式实践转变为系统优化的数学框架，通过系统评估显著减少token使用（29.8%），其结构开销函数揭示了过度指定悖论，最优配置因模型架构而异。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式实践，缺乏系统化的优化框架。作者希望将提示工程转变为基于数学原理的系统优化过程，提高LLM交互的效率并降低成本。

Method: 提出Universal Conditional Logic (UCL)框架，包含指标函数、结构开销函数、早期绑定等核心机制。通过系统评估（N=305，11个模型，4次迭代）验证框架效果，并分析结构开销函数O_s(A)如何解释版本特定的性能差异。

Result: 显著减少token使用（29.8%，统计显著），对应成本节约。发现过度指定悖论：超过阈值S* = 0.509后，额外指定会二次降低性能。验证了核心机制的有效性，并发现最优UCL配置因模型架构而异。

Conclusion: UCL作为一个可校准的框架，为高效LLM交互提供了理论基础。模型家族特定的优化是未来重要研究方向，某些模型（如Llama 4 Scout）需要版本特定的适配（V4.1）。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [262] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出Counterfactual Self-Questioning框架，让单个语言模型生成并评估自身推理的反事实批评，通过内部生成的监督实现可扩展的自我改进。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法大多依赖外部批评者、学习奖励模型或集成采样，增加了复杂性和训练不稳定性。需要一种更简单、更稳定的自我改进方法。

Method: 提出反事实自我提问框架：1) 生成初始推理轨迹；2) 针对潜在失败点制定针对性问题；3) 生成暴露错误假设或无效步骤的替代推理轨迹；4) 使用这些反事实轨迹作为结构化相对反馈进行策略优化。

Result: 在多个数学推理基准测试中，反事实自我提问提高了准确性和训练稳定性，特别是对于较小模型，仅使用内部生成的监督就能实现可扩展的自我改进。

Conclusion: Counterfactual Self-Questioning框架提供了一种简单有效的自我改进方法，无需外部模型，仅通过单个语言模型内部生成的反事实批评就能实现稳定、可扩展的性能提升。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [263] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 论文研究了LLM中的上下文学习和模型崩溃现象，在线性回归任务中分析了参数相变，证明了梯度下降预处理器中的斜对称分量，并提出了上下文崩溃的新概念。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中的两个关键现象：上下文学习（ICL）和模型崩溃，理解这些现象背后的数学机制及其对模型长期稳定性的影响。

Method: 1. 使用带权重绑定的线性transformer在线性回归任务中研究ICL，分析最小化上下文损失导致的参数相变；2. 将前向传播简化为预条件梯度下降并分析最优预处理器；3. 使用鞅和随机游走理论分析线性回归和高斯拟合中的模型崩溃；4. 提出上下文崩溃概念，连接ICL动态与生成模型的长期稳定性问题。

Result: 1. 证明超过临界上下文长度时，解会发展出斜对称分量；2. 该斜对称分量诱导梯度方向的旋转；3. 强化了模型崩溃的现有结果，证明除非数据快速增长或保留，否则几乎必然发生崩溃；4. 提出了上下文崩溃现象，特别是在思维链推理中的长序列生成时。

Conclusion: 论文通过数学分析揭示了LLM中ICL和模型崩溃的机制，提出了连接这两个现象的新概念——上下文崩溃，为理解大语言模型的长期稳定性和推理能力退化提供了理论框架。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [264] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，通过真实环境实验发现LLM使用25种说服技术，揭示了模型架构和训练对社交模拟动态的影响。


<details>
  <summary>Details</summary>
Motivation: 克服以往研究中基于游戏模拟的局限性，在真实环境中研究多智能体系统中的说服行为，特别是在社交媒体政治选举背景下的互动。

Method: 开发ElecTwit模拟框架，在模拟社交媒体政治选举环境中测试多个LLM模型，观察和分析智能体使用的说服技术及其互动动态。

Result: 观察到25种特定的说服技术在大多数测试的LLM中被广泛使用，范围比之前报道的更广；不同模型在技术使用和整体说服输出上存在显著差异；发现了"真相内核"信息和"墨水"痴迷等独特现象。

Conclusion: 该研究为在真实世界环境中评估有说服力的LLM智能体奠定了基础，有助于确保对齐和防止危险结果，同时揭示了模型架构和训练对社交模拟动态的重要影响。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [265] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: 提出MRE框架，通过增强前向和后向推理来改进TKGQA中的多跳推理，使用提示工程生成多样推理轨迹，并通过T-GRPO优化策略提升全局最优推理路径识别能力。


<details>
  <summary>Details</summary>
Motivation: TKGQA中，LLMs在每跳推理时会检索大量时间相似且语义复杂的关系子图，这增加了次优决策和错误传播的风险。现有方法难以识别全局最优的推理轨迹。

Method: 提出多跳推理增强（MRE）框架：1）通过提示工程引导LLM为问题生成多样推理轨迹；2）选择有效轨迹进行监督微调作为冷启动策略；3）引入树组相对策略优化（T-GRPO），这是一种递归的树结构探索学习法，每跳探索建立对前一跳的强因果依赖，评估则基于后续跳的多路径探索反馈。

Result: 在两个TKGQA基准测试中，基于MRE的模型始终优于最先进方法，特别是在处理复杂多跳查询时表现突出。进一步分析显示模型具有更好的可解释性和对噪声时间标注的鲁棒性。

Conclusion: MRE框架通过增强前向和后向推理，有效提升了TKGQA中多跳推理的性能，能够识别全局最优推理轨迹，并在复杂查询处理和噪声鲁棒性方面表现出色。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [266] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

TL;DR: 提出递归AlphaZero风格蒙特卡洛树搜索算法RMCTS，相比MCTS-UCB速度提升显著，训练时间减少约三分之二


<details>
  <summary>Details</summary>
Motivation: AlphaZero的MCTS-UCB算法存在GPU延迟成本高的问题，需要更快的搜索算法来加速训练过程

Method: 采用递归的广度优先搜索策略，使用优化的后验策略从叶子节点向根节点递归计算，树结构由先验网络策略定义而非自适应构建

Result: RMCTS比MCTS-UCB快40倍（单根状态搜索）和3倍（大批量根状态搜索），训练时间减少约三分之二，在Connect-4、Dots-and-Boxes和Othello三个游戏中性能相当

Conclusion: RMCTS通过牺牲树的自适应性换取显著的速度优势，在实际应用中能够以更短时间达到与MCTS-UCB相当的网络质量

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [267] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 本文提出了一个统一的四阶段框架，系统描述人工智能在数字孪生生命周期中的集成，涵盖建模、镜像、干预和自主管理，分析了物理建模与数据驱动的协同，并探讨生成式AI如何将数字孪生转变为主动认知系统。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具发展为智能自主实体，但缺乏系统化的AI集成框架。本文旨在通过统一框架系统描述AI在数字孪生全生命周期中的集成方式，分析技术发展趋势，并识别跨领域应用的共同挑战。

Method: 提出统一的四阶段框架：1) 基于物理和物理信息AI方法建模物理孪生；2) 实时同步将物理系统镜像为数字孪生；3) 通过预测建模、异常检测和优化策略干预物理孪生；4) 利用大语言模型、基础模型和智能代理实现自主管理。通过跨11个应用领域的综述分析技术趋势和挑战。

Result: 系统描述了AI在数字孪生中的集成路径，分析了从传统数值求解器向物理信息模型和基础模型的转变，探讨了生成式AI技术如何使数字孪生具备推理、通信和创造性场景生成能力，并识别了可扩展性、可解释性和可信赖性等跨领域共同挑战。

Conclusion: AI技术正在将数字孪生转变为主动、自改进的认知系统。统一的四阶段框架为AI驱动的数字孪生系统提供了系统化视角，未来需要在可扩展性、可解释性和可信赖性方面进一步研究，以构建负责任的AI驱动数字孪生系统。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [268] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: JiSi框架通过查询-响应混合路由、支持集聚合器选择和自适应路由-聚合切换，使开源LLM协作超越Gemini-3-Pro性能，成本仅47%


<details>
  <summary>Details</summary>
Motivation: 当前LLM路由和聚合存在三个瓶颈：1) 基于查询的路由器仅关注文本相似性；2) 聚合方法静态，无法为不同任务选择合适聚合器；3) 路由与聚合的互补性未充分利用。需要释放LLM协作的完整潜力。

Method: 提出JiSi框架，包含三个创新：1) 查询-响应混合路由，同时捕捉语义信息和问题难度；2) 基于支持集的聚合器选择，联合评估聚合器的聚合能力和领域能力；3) 自适应路由-聚合切换，动态利用路由和聚合的优势。

Result: 在9个基准测试中，JiSi通过协调10个开源LLM，仅用47%的成本就能超越Gemini-3-Pro性能，同时优于主流基线方法。

Conclusion: 集体智能代表了一条通往AGI的新路径，通过LLM协作而非单一模型扩展可以实现更好的性能效率比。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [269] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个统一的多模态科学模型，能够在单一架构中理解和生成跨学科的高维科学数据，在地球科学和生物医学领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型通常是领域特定的，缺乏同时理解和生成多模态科学数据的能力，而许多全球性挑战和科学问题本质上是跨学科的，需要跨多个领域的协同进展。

Method: FuXi-Uni将跨学科的科学标记与自然语言标记对齐，并使用科学解码器重建科学标记，支持自然语言对话和科学数值预测的统一架构。

Result: 在地球系统建模中：1）生成10天全球天气预报（0.25°分辨率）超越最先进的物理预报系统；2）热带气旋轨迹和强度预测优于最先进物理模型；3）空间降尺度生成高分辨率区域天气场超越标准插值基线。在生物医学中：在多个生物医学视觉问答基准上优于领先的多模态大语言模型。

Conclusion: FuXi-Uni通过在原生共享潜在空间中统一异构科学模态，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [270] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

TL;DR: KGCE是一个面向教育场景的跨平台智能体评测平台，通过知识库增强和双图评估框架解决现有基准在私有软件任务中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准框架在教育场景的跨平台任务支持不足，特别是在处理学校专用软件（如小雅智能助手、华师匣子等）时，智能体因不了解这些私有软件的结构细节而效率显著下降。同时，当前评估方法依赖粗粒度指标，难以捕捉复杂任务中的详细执行效率。

Method: 提出KGCE平台，集成知识库增强和双图评估框架。首先构建包含104个教育相关任务的数据集，覆盖Windows、Android和跨平台协作任务。引入双图评估框架将任务分解为多个子目标并验证完成状态，提供细粒度评估指标。为克服私有领域任务的执行瓶颈，开发了包含学校专用软件知识库的增强智能体系统。

Result: 构建了包含104个教育任务的数据集，开发了KGCE评测平台，实现了知识库增强的智能体系统和双图评估框架，代码已在GitHub开源。

Conclusion: KGCE通过知识库增强和双图评估框架有效解决了教育场景中跨平台智能体评测的现有问题，为教育领域智能体提供了更精准的评估工具。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [271] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 提出AAAI三步骤管道，通过减少事实幻觉来提升小型语言模型在金融分类中的性能


<details>
  <summary>Details</summary>
Motivation: 小型语言模型(SLMs)在金融分类中因快速推理和本地部署优势而被广泛使用，但与大型语言模型相比，它们更容易产生事实幻觉，分类性能也较弱。这引发了一个核心问题：减少事实幻觉能否提升SLMs的金融分类能力？

Method: 提出名为AAAI的三步骤管道：1) 关联识别 - 识别模型输出中的事实关联；2) 自动检测 - 使用编码器验证器检测事实幻觉；3) 自适应推理 - 基于事实错误反馈让SLMs进行自适应推理

Result: 在三个代表性SLMs上的实验表明：1) 事实幻觉与错误分类呈正相关；2) 基于编码器的验证器能有效检测事实幻觉；3) 结合事实错误反馈的自适应推理能显著提升分类性能

Conclusion: AAAI管道通过减少事实幻觉有效提升了SLMs在金融分类中的性能，为SLMs在金融领域的可信赖和有效应用提供了解决方案

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [272] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 研究三元背景中的蕴涵关系，特别是Ganter和Obiedkov引入的条件属性蕴涵和属性条件蕴涵，目标是构建这些蕴涵的最优基


<details>
  <summary>Details</summary>
Motivation: 三元背景中的蕴涵关系在形式概念分析中具有重要意义，但现有研究主要关注二元背景。Ganter和Obiedkov引入的条件属性蕴涵和属性条件蕴涵为三元背景提供了新的分析工具，但如何为这些蕴涵构建最优基仍待解决

Method: 研究三元背景中的蕴涵关系，特别关注条件属性蕴涵和属性条件蕴涵这两种类型。通过形式概念分析方法，构建这些蕴涵的最优基，可能涉及算法设计和理论分析

Result: 为三元背景中的条件属性蕴涵和属性条件蕴涵构建了最优基，提供了有效的计算方法，扩展了形式概念分析在三元背景中的应用

Conclusion: 成功解决了三元背景中蕴涵关系的最优基构建问题，为三元形式概念分析提供了重要的理论基础和实用工具，扩展了传统二元背景的研究成果

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [273] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

TL;DR: 提出神经网络增强的双重机器学习框架，利用文本嵌入解决未观测混杂偏倚问题，相比传统树模型能显著减少偏差


<details>
  <summary>Details</summary>
Motivation: 观测性研究中存在未观测混杂因素导致的偏倚问题，传统计量方法难以处理与结构化协变量正交的混杂因素，而高维非结构化文本数据包含丰富的潜在变量代理信息

Method: 提出神经网络增强的双重机器学习框架，利用文本嵌入进行因果识别，通过深度学习架构建模嵌入流形的连续拓扑结构

Result: 文本嵌入能捕捉结构化表格数据中缺失的关键混杂信息，但标准树基DML估计器仍有+24%的显著偏差，而深度学习方法将偏差降至-0.86%，有效恢复真实因果参数

Conclusion: 当基于高维自然语言数据进行条件化时，深度学习架构对于满足无混杂假设至关重要，能有效利用文本嵌入中的混杂信息进行因果推断

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [274] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

TL;DR: 论文提出贝叶斯成本感知的多LLM编排框架，将LLM视为近似似然模型而非分类器，在非对称错误成本场景中显著降低总成本并提高公平性


<details>
  <summary>Details</summary>
Motivation: 当前LLM在非对称错误成本场景（如招聘、医疗分诊、欺诈检测）中作为自主决策代理时，主流方法（查询单个LLM获取后验概率并基于"置信度"阈值行动）在序列决策中存在不足，需要更有效的成本感知框架

Method: 提出贝叶斯成本感知的多LLM编排框架：1) 通过对比提示为每个候选状态获取似然估计；2) 使用鲁棒统计方法聚合多个不同LLM的结果；3) 在新证据到达时使用贝叶斯规则在明确先验下更新信念；4) 支持连贯信念更新、期望成本行动选择、基于信息价值的原则性信息收集

Result: 在简历筛选实验中（成本：错失人才40000美元/次，面试2500美元/次，电话筛选150美元/次），使用5个LLM（GPT-4o、Claude 4.5 Sonnet、Gemini Pro、Grok、DeepSeek）处理1000份简历，相比最佳单LLM基线降低总成本294000美元（34%），人口统计公平性提升45%（最大组差距从22个百分点降至5个百分点）

Conclusion: 正确的概率基础理论在多LLM聚合（贡献51%节省）、序列更新（43%）和分歧触发信息收集（20%）方面带来显著效益，证明了贝叶斯成本感知框架在非对称错误成本决策中的优越性

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [275] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

TL;DR: 该论文提出Project Aletheia框架，使用Tikhonov正则化反转评判者混淆矩阵来量化System 2推理模型的"认知信念"，并引入对齐信念分数确保安全性。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估范式面临认识论危机：静态基准测试能衡量知识广度但无法量化信念深度。虽然Simhi等人(2025)在标准QA中定义了CHOKE现象，但需要扩展该框架来量化System 2推理模型的"认知信念"。

Method: 提出Project Aletheia认知物理学框架，采用Tikhonov正则化反转评判者混淆矩阵。为避免依赖不透明的私有数据，实施合成代理协议进行验证。引入对齐信念分数(S_aligned)来确保信念不会损害安全性。

Result: 对2025年基线模型(如DeepSeek-R1、OpenAI o1)的初步试点研究表明：推理模型虽然充当"认知缓冲区"，但在对抗压力下可能表现出"防御性过度思考"。

Conclusion: 这项工作为衡量AI科学完整性提供了蓝图，通过量化认知信念并确保其与安全性对齐，推进了AGI评估范式的发展。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [276] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 提出两阶段框架改善LLM在复杂决策环境中的行为对齐：第一阶段明确实验设计建立准确的任务表征，第二阶段在该表征内引导推理过程做出决策。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于模拟人类行为实验，但在复杂决策环境中（需要预测他人行动并基于观察行为形成信念）与人类决策存在系统性差异，需要改进行为对齐。

Method: 提出两阶段框架：1) 情境形成阶段 - 明确指定实验设计，建立决策任务及其情境的准确表征；2) 情境导航阶段 - 在该表征内引导推理过程做出决策。通过三个实验验证：顺序购买游戏、众筹游戏和需求估计任务。

Result: 在四个SOTA模型上测试发现：复杂决策环境需要两阶段框架才能实现与人类基准的行为对齐，而较简单的需求估计任务仅需要情境形成阶段。框架在不同决策环境中具有普遍适用性。

Conclusion: 研究阐明了每个阶段何时必要，为设计和诊断LLM社会模拟提供了系统方法，可作为行为研究中人类受试者的补充工具。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [277] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个在10M规模高质量数据集上微调的推理模型，专注于STEM领域，在8B规模上相比次优模型平均提升4.68%性能，通过数据算法协同设计实现优化。


<details>
  <summary>Details</summary>
Motivation: 提升STEM领域的推理能力，通过大规模高质量数据集和算法协同设计来解决现有模型在科学、技术、工程和数学推理任务上的局限性。

Method: 1) 构建10M规模的Logics-STEM-SFT-Dataset，采用5阶段数据管理流程；2) 基于失败驱动的后训练框架，在SFT阶段利用目标知识检索和数据合成；3) 数据算法协同设计引擎，联合优化以拟合推理的黄金标准分布。

Result: 在STEM相关基准测试中表现优异，8B规模模型相比次优模型平均提升4.68%性能，展示了大规模开源数据与精心设计合成数据结合的潜力。

Conclusion: 数据算法协同设计对于通过后训练增强推理能力至关重要，Logics-STEM模型和数据集已开源以支持社区研究。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [278] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: CaveAgent框架将LLM从文本生成器转变为运行时操作器，通过双流架构分离状态管理，支持Python对象持久化，显著提升长时任务执行效率和数据处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的代理系统受限于文本中心范式，传统JSON函数调用在处理长时任务时存在脆弱的多轮依赖和上下文漂移问题，需要新的范式来支持复杂任务执行。

Method: 提出CaveAgent框架，采用双流上下文架构：轻量级语义流负责推理，持久化确定性Python运行时流负责执行。引入有状态运行时管理，支持Python对象（如DataFrame、数据库连接）的注入、操作和跨轮次持久化。

Result: 在Tau²-bench、BFCL等基准测试中表现优异：零售任务成功率提升10.5%，多轮场景总token消耗减少28.4%。数据密集型任务中，直接变量存储检索减少token消耗59%，能处理导致其他代理上下文溢出的海量数据。

Conclusion: CaveAgent通过将LLM转变为运行时操作器，解决了传统代理系统的上下文漂移和灾难性遗忘问题，为复杂长时任务提供了高效、可扩展的解决方案，特别适合数据密集型应用场景。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [279] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 论文提出了一种结合LLMs和符号推理的框架：LLMs将非结构化文本转换为ABox断言，SWRL推理器提供确定性规则应用保证，实现可审计的自然语言规则推理。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、法律证据规则、科学标准），现有方法存在局限性：LLMs具有灵活性但无法保证规则应用的一致性，符号系统提供形式化保证但需要结构化输入。

Method: 提出集成模式：1) LLMs作为本体填充引擎，将非结构化文本转换为ABox断言；2) SWRL推理器应用确定性规则；3) 框架将推理分解为实体识别、断言提取和符号验证，任务定义基于OWL 2本体。

Result: 在三个领域（法律传闻确定、科学方法任务应用、临床试验资格）和11个语言模型上的实验验证了方法的有效性。结构化分解在总体上比few-shot提示有显著改进，所有三个领域都观察到增益。消融研究证实符号验证提供了超越结构化提示的实质性好处。

Conclusion: 该框架结合了LLMs的灵活性和符号推理的形式化保证，填充的ABox可与标准语义网工具集成进行检查和查询，为更丰富的推理模式奠定基础，这是简单形式主义无法表达的。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [280] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash 是一个开源的混合专家多模态大语言模型，拥有37亿激活参数和400亿总参数，专为企业任务设计，同时保持通用任务竞争力，并采用RAPO算法解决大推理模型的过度思考问题。


<details>
  <summary>Details</summary>
Motivation: 解决大推理模型中常见的过度思考现象，同时开发一个既能在企业任务中表现出色，又能在通用任务中保持竞争力的高效多模态大语言模型。

Method: 提出Reflection-aware Adaptive Policy Optimization (RAPO)算法，这是一种新颖的强化学习训练算法，专门用于调节过度思考行为。模型采用混合专家架构，拥有37亿激活参数和400亿总参数。

Result: 在企业任务如检索增强生成、复杂表格理解和摘要生成中表现优异。在数学、科学等推理领域也展现出强大能力，达到前沿模型相当的准确率，同时平均只需1/4到1/2的token数量。

Conclusion: Yuan3.0 Flash是一个高效的多模态大语言模型，通过RAPO算法有效解决了过度思考问题，在企业任务和通用推理任务中都表现出色，且已完全开源供研究和实际部署使用。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [281] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 该论文是一篇关于AI智能体架构的综述，系统梳理了智能体系统的核心组件、协调模式、设计权衡、评估方法及开放挑战。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型与推理、规划、记忆和工具使用能力的结合，AI智能体正成为连接自然语言意图与现实世界计算的实用接口。然而，该领域缺乏统一的架构分类和系统分析，需要综合现有工作以指导未来研究和应用。

Method: 采用综述研究方法，将现有工作组织成统一的分类体系，涵盖智能体组件（策略/LLM核心、记忆、世界模型、规划器、工具路由器、批评器）、协调模式（单智能体vs.多智能体；集中式vs.去中心化）和部署设置（离线分析vs.在线交互；安全关键vs.开放任务）。

Result: 建立了AI智能体架构的完整分类框架，识别了关键设计权衡（延迟vs.准确性、自主性vs.可控性、能力vs.可靠性），分析了评估复杂性（非确定性、长期信用分配、工具和环境变异性、隐藏成本），总结了测量和基准测试实践。

Conclusion: AI智能体架构研究需要关注工具动作的验证和防护、可扩展的记忆和上下文管理、智能体决策的可解释性，以及在现实工作负载下的可重复评估等开放挑战。该综述为智能体系统的设计和评估提供了系统框架。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [282] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: RTL-OPT是一个用于评估大语言模型在RTL代码优化能力的基准测试，包含36个手工设计的数字电路，覆盖组合逻辑、流水线数据通路、有限状态机和存储接口等类别，提供次优版本和人工优化参考版本，并集成了自动化评估框架验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 当前AI在集成电路设计中的应用日益重要，但现有基于大语言模型的RTL代码生成基准主要评估语法正确性，缺乏对功耗、性能和面积（PPA）优化质量的评估。需要建立一个专门评估LLM在RTL优化能力的基准。

Method: 创建RTL-OPT基准，包含36个手工设计的数字电路设计，覆盖多种实现类别。每个任务提供一对RTL代码：次优版本和人工优化的参考版本，后者体现了工业验证的优化模式。集成自动化评估框架验证功能正确性并量化PPA改进。

Result: 开发了RTL-OPT基准测试，包含36个设计任务，覆盖组合逻辑、流水线数据通路、有限状态机和存储接口等类别。提供了标准化的评估框架，能够验证功能正确性并量化PPA改进，为生成模型在硬件设计优化领域的评估提供了有意义的标准。

Conclusion: RTL-OPT填补了现有基准在评估LLM RTL优化能力方面的空白，通过提供包含次优和优化参考代码的设计任务以及自动化评估框架，能够标准化评估生成模型在硬件设计优化中的能力，促进AI在集成电路设计优化领域的发展。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [283] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: LLMs在求解超越方程时，结合传统迭代求解器的混合架构比直接数值预测更有效，误差减少67.9%-81.8%，表明LLMs适合作为传统数值求解器的智能接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 超越方程在工程实践中普遍存在，需要迭代数值求解。研究旨在评估大语言模型能否直接求解这些方程，还是需要结合传统迭代求解器的混合架构更有效。

Method: 测试6个最先进的LLM模型（GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5）在100个涵盖7个工程领域的问题上，比较直接预测与求解器辅助计算（LLMs制定控制方程并提供初始条件，牛顿-拉夫逊迭代执行数值求解）。

Result: 直接预测的平均相对误差为0.765-1.262，而求解器辅助计算为0.225-0.301，误差减少67.9%-81.8%。电子领域改进最显著（93.1%），流体力学改进最小（7.2%）。

Conclusion: 当代LLMs擅长符号操作和领域知识检索，但在精度关键的迭代算术方面表现不佳，建议将其作为传统数值求解器的智能接口而非独立计算引擎进行最优部署。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [284] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

TL;DR: PsychEval是一个多会话、多疗法、高真实性的心理咨询AI评估基准，包含677个元技能和4577个原子技能标注，覆盖5种治疗模式，提供18个评估指标和2000多个客户档案，可作为强化学习环境训练自适应AI咨询师。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的心理学评估AI面临三个关键挑战：1) 如何训练高度真实的AI咨询师（需要持续记忆和动态目标跟踪）；2) 如何训练多疗法AI咨询师（复杂案例需要灵活切换不同疗法）；3) 如何系统评估AI咨询师。

Method: 构建多会话基准（6-10个会话，分三个阶段），涵盖五种治疗模式（心理动力学、行为主义、CBT、人本存在主义、后现代主义）和整合疗法，创建包含677个元技能和4577个原子技能的专业技能标注数据集，建立包含18个治疗特定和共享指标的评估框架。

Result: 实验分析充分验证了数据集的质量和临床保真度，PsychEval超越了静态基准测试，可作为高保真强化学习环境，支持临床负责任和自适应AI咨询师的自我进化训练。

Conclusion: PsychEval为解决AI心理咨询评估的关键挑战提供了全面解决方案，通过多会话、多疗法的高真实性基准，支持训练具有记忆连续性、自适应推理和纵向规划能力的AI咨询师，为临床AI的发展提供了重要基础设施。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [285] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 提出"可采纳性对齐"新框架，将AI对齐重新定义为在不确定性下对结果分布的可采纳行动和决策选择属性，并通过MAP-AI系统架构实现基于蒙特卡洛估计的对齐评估


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法多为静态或二元条件，无法有效处理不确定性、干预效应、价值模糊性和治理约束。需要将对齐重新定义为概率性、决策理论属性，以评估AI系统在分布和尾部事件中的行为

Method: 提出MAP-AI系统架构，通过蒙特卡洛估计结果分布和可采纳性控制的策略选择来强制执行对齐。框架评估决策策略在多个可能未来场景中的表现，明确建模不确定性、干预效应、价值模糊性和治理约束

Result: 开发出实用的AI系统治理基础，将对齐评估从个体预测扩展到策略在分布和尾部事件中的行为。展示了如何将对齐评估整合到决策过程中，实现不重新训练或修改底层模型的可采纳性控制行动选择

Conclusion: 可采纳性对齐框架为企业和机构AI系统提供了可执行的信任和对齐评估方法，将AI对齐从静态条件转变为概率性决策属性，能够更好地处理现实世界中的不确定性和复杂性

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [286] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: COMPASS框架首次系统评估LLMs是否符合组织特定政策，发现模型在常规请求上表现良好（>95%准确率），但在禁止请求上严重失败（仅拒绝13-40%的违规请求），揭示当前LLMs缺乏政策关键部署所需的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在企业高风险应用中的部署，确保模型遵守组织特定政策变得至关重要。现有安全评估仅关注通用危害，缺乏针对组织政策的系统性评估框架。

Method: 提出COMPASS框架，应用于八个不同行业场景，生成并验证5,920个查询，测试常规合规性和对抗鲁棒性，通过策略设计的边缘案例评估七个最先进模型。

Result: 发现基本不对称性：模型能可靠处理合法请求（>95%准确率），但在执行禁令方面灾难性失败，仅拒绝13-40%的对抗性禁止列表违规请求。

Conclusion: 当前LLMs缺乏政策关键部署所需的鲁棒性，COMPASS框架成为组织AI安全评估的重要工具。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [287] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 提出一个使用多智能体提示和模式约束RAG的端到端框架，直接从临床自由文本构建知识图谱，特别针对肿瘤学领域，无需黄金标准标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖结构化输入，缺乏对事实准确性和语义一致性的鲁棒验证，这在肿瘤学领域尤其成问题。需要直接从非结构化临床叙述构建高质量知识图谱的解决方案。

Method: 采用多智能体提示和模式约束检索增强生成(KG-RAG)策略，包括：1) 提示驱动的实体、属性和关系抽取；2) 基于熵的不确定性评分；3) 本体对齐的RDF/OWL模式生成；4) 多LLM共识验证用于幻觉检测和语义精炼。

Result: 应用于两个肿瘤学队列(PDAC和BRCA)，该方法在无需黄金标准标注的情况下，构建了可解释、SPARQL兼容且临床基础的知识图谱。实验结果显示在精度、相关性和本体合规性方面相比基线方法有持续提升。

Conclusion: 该框架为直接从临床自由文本构建高质量知识图谱提供了有效解决方案，支持持续精炼和自我监督评估，在肿瘤学领域具有实际应用价值。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [288] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 本文提出Jenius-Agent框架，通过自适应提示生成、上下文感知工具编排和分层内存机制优化LLM智能体，在任务准确率提升20%的同时降低token成本、响应延迟和调用失败率。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体系统发展，提升自主智能体在上下文理解、工具使用和响应生成方面的任务性能变得日益重要。尽管先前研究改进了LLM智能体的整体设计，但对其内部推理和工具使用流程的系统性优化仍显不足。

Method: 提出基于真实世界实践经验的智能体框架，包含三个关键创新：1) 自适应提示生成策略，根据智能体状态和任务目标调整提示以提高可靠性和鲁棒性；2) 上下文感知工具编排模块，基于用户意图和上下文进行工具分类、语义检索和自适应调用；3) 分层内存机制，集成会话内存、任务历史和外部摘要，通过动态摘要和压缩提高相关性和效率。最终集成名为Jenius-Agent的端到端框架，包含基于模型上下文协议的工具、文件输入/输出和执行反馈等优化。

Result: 实验显示任务准确率提升20%，同时降低了token成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为稳健、协议兼容的自主智能体提供了轻量级可扩展解决方案。

Conclusion: Jenius-Agent框架通过系统性优化智能体的内部推理和工具使用流程，显著提升了任务性能，为实际应用中的LLM智能体提供了有效的解决方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [289] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

TL;DR: 提出SQL为中心的智能体框架，通过可执行的SQL查询将细胞特征测量与病理诊断结论连接起来，提高病理图像分析的可解释性和决策可追溯性。


<details>
  <summary>Details</summary>
Motivation: 当前病理图像分析中，虽然视觉语言模型能生成自然语言解释，但这些解释通常是相关性的，缺乏可验证的证据。临床医生需要了解哪些切片特征驱动模型决策以及原因。

Method: 引入SQL为中心的智能体框架：1) 提取人类可解释的细胞特征；2) 特征推理智能体通过SQL查询在特征表上聚合视觉证据为量化发现；3) 知识比较智能体将这些发现与已建立的病理知识进行比较。

Result: 在两个病理视觉问答数据集上的广泛实验表明，该方法提高了可解释性和决策可追溯性，同时生成可执行的SQL跟踪，将细胞测量与诊断结论联系起来。

Conclusion: 提出的SQL智能体框架通过可审计的特征测量和推理过程，模拟病理学家从可测量观察到诊断论证的过程，为病理图像分析提供了更可靠和可解释的决策支持。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [290] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 论文指出当前LLM社会认知评估存在理论缺失问题，导致基准测试结果被过度泛化，并提出了理论追踪卡(TTC)作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的社会认知基准测试存在评估-部署差距：即使模型在基准测试中获得高分，也无法预测其真实世界行为。现有研究主要归因于测量和效度问题，但忽略了更根本的理论缺失问题。

Method: 1. 诊断并形式化理论缺失问题，指出这是导致测量失败和结果过度泛化的根本原因。2. 引入理论追踪卡(TTC)，这是一种轻量级文档工具，明确记录评估的理论基础、目标能力组件、操作化过程和局限性。

Result: TTC通过明确理论-任务操作化-评分-局限性的完整效度链，增强了社会认知评估的可解释性和可重用性，无需修改基准测试或要求理论共识。

Conclusion: 理论缺失是LLM社会认知评估的根本问题，TTC提供了一种实用解决方案，通过明确评估的理论基础来减少过度泛化，提高评估质量。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [291] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: MMP-A*：结合视觉语言模型空间感知与自适应衰减机制的多模态路径规划框架，在复杂环境中实现近最优轨迹并显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统A*算法在大规模复杂环境中计算和内存成本过高，而基于大语言模型的路径规划方法缺乏空间感知能力，在拓扑复杂环境中容易产生错误路径点，导致纠正成本高昂。

Method: 提出MMP-A*多模态框架：1) 集成视觉语言模型的空间感知能力，将高层推理锚定在物理几何中；2) 引入自适应衰减机制，动态调节不确定路径点在启发式函数中的影响，确保几何有效性同时减少内存开销。

Result: 在严重杂乱和拓扑复杂的挑战性环境中测试，MMP-A*能够生成近最优轨迹，同时显著降低操作成本，证明了其作为感知基础和计算高效自主导航范式的潜力。

Conclusion: MMP-A*通过融合多模态感知与经典规划算法，解决了纯文本规划器的空间感知不足问题，为自主导航提供了既保持几何精度又计算高效的新范式。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [292] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源的多模态社交交互模拟器，提供模块化架构来训练社交智能体，支持探索不同感知特征、编码和融合方法。


<details>
  <summary>Details</summary>
Motivation: 为多模态社交交互研究提供一个开源、模块化的仿真平台，支持社交智能体的训练和评估，促进社交智能领域的发展。

Method: 开发了OpenSocInt软件包，包含多模态社交交互模拟器和模块化架构，通过社交导航任务展示其功能，支持不同感知特征、编码融合方法和智能体类型。

Result: 成功开发并开源了OpenSocInt软件包，已在GitLab上以GPL许可证发布，通过社交导航实验验证了其有效性和实用性。

Conclusion: OpenSocInt为社交智能研究提供了一个有价值的开源工具，能够支持多模态社交交互的模拟和智能体训练，有助于推动该领域的发展。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [293] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文对基于形式概念分析(FCA)的分类器进行了最新综述，提出了一种从名义数据计算闭包算子的新方法，并构建了关注最相关概念的部分概念格。


<details>
  <summary>Details</summary>
Motivation: 知识发现(KDD)旨在从海量数据中提取隐藏的有意义知识，其中分类是核心数据挖掘技术之一。形式概念分析(FCA)因其可解释性和可解释性学习能力而备受认可，但需要更高效的方法来处理名义数据和构建概念格。

Method: 1) 综述了FCA基分类器的现有方法；2) 提出了从名义数据计算闭包算子的多种方法；3) 引入了一种构建部分概念格的新方法，重点关注最相关的概念。

Result: 通过实验验证了所提方法的效率，展示了在构建概念格和分类任务上的性能改进。

Conclusion: 提出的新方法能够更高效地处理名义数据并构建部分概念格，为基于FCA的分类器提供了有效的技术改进，增强了知识发现过程中的可解释性和效率。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [294] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: ChaosBench-Logic是一个评估大语言模型在混沌动力系统领域逻辑推理能力的基准测试，包含30个系统、11个语义谓词、621个问题，涵盖7种推理类型，结果显示前沿模型在单项准确率上达到91-94%，但在组合推理上得分为0%，对话准确率在53.1-75.5%之间。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言任务上表现出色，但在需要精确逻辑和符号推理的领域仍然脆弱。混沌动力系统提供了一个特别严格的测试环境，因为混沌是确定性的，但经常被误解为随机性或复杂性。需要建立一个基准来评估LLM在这类复杂科学推理任务上的能力。

Method: 引入ChaosBench-Logic基准测试，使用统一的一阶逻辑本体论评估30个不同的动力系统。每个系统用11个语义谓词的真值分配进行标注，生成621个问题，涵盖7个推理类别：多步蕴含、跨系统类比、反事实推理、偏见探测和多轮对话。定义了逻辑准确性、蕴含一致性、对话连贯性和矛盾性等指标，并发布了开源评估流程。

Result: 前沿LLM（GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash、LLaMA-3 70B）在单项准确率上达到91-94%，但在组合推理项目上得分为0%，表现出脆弱的全局连贯性。对话级准确率范围从53.1%（GPT-4 CoT）到75.5%（LLaMA-3零样本）。

Conclusion: ChaosBench-Logic为诊断LLM在复杂科学推理中的失败提供了一个严格的测试平台，并为开发神经符号方法以改进LLM的科学推理能力奠定了基础。尽管模型在简单任务上表现良好，但在需要组合推理和全局一致性的复杂任务上仍然存在显著缺陷。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [295] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: MindChat是一个保护隐私的心理健康支持大语言模型，配合MindCorpus合成心理咨询数据集，通过联邦学习和差分隐私减少隐私风险，在咨询能力评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理健康支持方面有潜力，但受限于真实心理咨询对话的稀缺性和敏感性，需要解决隐私保护问题。

Method: 1) 使用多智能体角色扮演框架构建MindCorpus合成数据集，采用双闭环反馈设计：回合级批判修订和会话级策略优化；2) 通过联邦学习结合LoRA适配器和差分隐私优化来微调基础模型，保护隐私。

Result: MindCorpus提高了训练效果，MindChat在自动LLM评估和人工评估中与现有通用和心理咨询导向的LLM基线相当，同时在成员推理攻击下表现出减少的隐私泄露。

Conclusion: 提出的隐私保护框架能够生成高质量的心理咨询数据并训练有效的心理健康支持模型，在保护用户隐私的同时提供有竞争力的咨询能力。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [296] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专家知识，提升分布偏移下的鲁棒性、罕见类别敏感性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI面临分布偏移下的泛化问题和罕见类别可靠性挑战，现有深度模型在真实世界分布变化下表现不佳，且对不常见临床条件存在偏见。

Method: 将临床专业知识编码为逻辑连接词，转化为机器可检查的类别特定规则；通过加权特征满足度分数量化诊断效用；采用置信度加权融合整合符号和深度输出；基于熵不平衡增益和罕见类别基尼系数的自适应路由机制。

Result: 在四个挑战性任务上评估：癫痫发作区定位和糖尿病视网膜病变分级，跨域泛化性能提升6%，罕见类别F1分数提升10%，显著优于现有深度学习方法。

Conclusion: XAIMeD提供了一个原则性、临床忠实且可解释的多模态医疗AI方法，临床基础的符号组件作为有效的正则化器确保分布偏移下的鲁棒性。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [297] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 论文认为基础模型通过"大声思考"的模仿、测试和迭代过程实现了某种推理能力，挑战了传统符号推理的必要性，但缺乏人类推理的常识基础导致脆弱性，需要重新评估推理概念和安全考量。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为推理是理解阶段之间的路径，需要符号推理过程。但基础模型展示了通过模仿"大声思考"、测试和迭代路径也能实现推理，这挑战了传统推理概念，需要重新评估推理的必要条件和安全影响。

Method: 论文采用哲学分析方法，探讨基础模型推理现象的多重解释，论证"随机鹦鹉"隐喻已失去相关性，并反思由此产生的安全和适当性规范考量。

Result: 基础模型通过模仿思考过程、测试和迭代路径实现了某种推理能力，但缺乏人类推理的常识基础和根基，导致推理过程脆弱。这需要重新评估推理概念，并考虑相应的安全防御措施。

Conclusion: 基础模型的推理能力挑战了传统符号推理的必要性，表明推理可以通过不同机制实现。"随机鹦鹉"隐喻已不适用，需要新的哲学框架来理解这种推理，并制定相应的安全和伦理规范。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [298] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

TL;DR: 论文研究了在深度强化学习中通过高阶导数惩罚实现动作平滑正则化，从连续控制基准的理论理解扩展到建筑能源管理的实际验证，发现三阶导数惩罚（急动度最小化）能实现最佳平滑效果。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理经常表现出不稳定、高频的控制行为，这在实际部署中会导致能耗过高和机械磨损，因此需要研究动作平滑正则化方法来改善这一问题。

Method: 采用高阶导数惩罚进行动作平滑正则化，从一阶到三阶导数惩罚系统研究，在四个连续控制环境中进行综合评估，并将方法扩展到HVAC控制系统。

Result: 三阶导数惩罚（急动度最小化）在保持竞争力的性能同时，能实现最优的动作平滑效果；在HVAC控制系统中，平滑策略将设备切换减少了60%，带来显著的操作效益。

Conclusion: 高阶动作正则化是连接RL优化与能源关键应用中操作约束的有效桥梁，为实际部署提供了实用的平滑控制解决方案。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [299] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 本研究探讨了将大型语言模型（LLM）应用于药物3D打印配方开发，通过微调四种LLM架构在1400多个FDM配方数据集上，用于推荐辅料和预测丝材机械性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的药物3D打印研究大多局限于狭窄领域，未能全面考虑配方开发中的复杂挑战。随着人工通用智能概念的发展，需要探索LLM在药物配方开发中的应用潜力，超越传统的预测建模，实现更通用、类人的推理能力。

Method: 研究微调了四种LLM架构，使用包含1400多个FDM配方的数据集，系统评估了微调和生成参数配置。模型用于基于API剂量推荐合适的辅料，并预测丝材的机械性能。

Result: Llama2在推荐FDM配方辅料方面表现最佳；模型选择和参数化显著影响性能，较小的LLM出现灾难性遗忘现象；即使相对较小的1400多个配方数据集也可能导致模型灾难性遗忘；标准LLM指标仅评估语言性能而非配方可加工性；基于生物医学相关数据训练的LLM不一定产生最佳结果。

Conclusion: 解决这些挑战对于推动LLM超越语言熟练度，发展成为药物配方开发的可靠系统至关重要。需要开发更全面的评估指标，考虑配方可加工性等实际因素，以实现LLM在药物3D打印领域的有效应用。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [300] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

TL;DR: EverMemOS是一个自组织记忆操作系统，采用engram启发的生命周期管理计算记忆，通过分层记忆结构解决LLMs在长期交互中的记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为长期交互代理部署时，有限的上下文窗口难以维持连贯的长期行为。现有记忆系统通常存储孤立记录并检索片段，无法整合演变的用户状态和解决冲突。

Method: 提出EverMemOS系统，包含三个核心组件：1) 情景痕迹形成：将对话流转换为MemCells，捕捉情景痕迹、原子事实和时间限制的Foresight信号；2) 语义整合：将MemCells组织成主题MemScenes，提炼稳定语义结构并更新用户画像；3) 重构回忆：执行MemScene引导的代理检索，为下游推理组合必要且充分的上下文。

Result: 在LoCoMo和LongMemEval基准测试中，EverMemOS在记忆增强推理任务上达到最先进性能。在PersonaMem v2上的画像研究展示了用户画像和Foresight等聊天导向能力。

Conclusion: EverMemOS通过自组织记忆操作系统有效解决了LLMs在长期交互中的记忆限制，实现了连贯的长期行为维持和用户状态管理。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [301] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出将长思维链推理中的幻觉视为演化潜状态而非一次性错误事件，引入累积前缀级幻觉信号来追踪整个推理轨迹的全局演化，实现流式幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 长思维链推理虽然能提升大语言模型性能，但其中的幻觉往往以微妙方式出现并在推理步骤间传播。传统方法将幻觉视为一次性错误事件，但作者认为在长推理中幻觉应被理解为演化中的潜状态。

Method: 将步骤级幻觉判断视为局部观测，引入累积前缀级幻觉信号来追踪整个推理轨迹的全局状态演化。该方法支持流式幻觉检测，提供实时、可解释的证据。

Result: 该方法能够实现长思维链推理中的流式幻觉检测，提供实时监控和可解释的幻觉演化证据。

Conclusion: 将幻觉视为演化潜状态而非一次性错误事件，通过累积前缀级信号追踪全局推理状态演化，为长思维链推理中的幻觉检测提供了更有效的框架。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [302] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 论文发现当前LLM智能体的推理过程存在"忠实性鸿沟"，其推理轨迹可能只是"推理剧场"而非真正的决策驱动因素，提出了基于因果模型的审计框架来检测这种因果解耦问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体承担高风险自主决策任务，其推理过程的透明度成为关键安全问题。虽然CoT提示能生成人类可读的推理轨迹，但尚不清楚这些轨迹是模型输出的真实驱动因素还是事后合理化解释。

Method: 提出了Project Ariadne框架，利用结构因果模型(SCMs)和反事实逻辑来审计智能体推理的因果完整性。通过硬干预(do-演算)对中间推理节点进行操作，包括逻辑反转、前提否定和事实声明逆转，以测量终端答案的因果敏感性(φ)。

Result: 对最先进模型的实证评估揭示了持续的"忠实性鸿沟"。定义并检测到一种广泛的故障模式"因果解耦"，在事实和科学领域中违规密度(ρ)高达0.77。智能体在内部逻辑矛盾的情况下仍得出相同结论，证明其推理轨迹只是"推理剧场"，而决策由潜在参数先验控制。

Conclusion: 当前智能体架构本质上容易产生不忠实的解释，提出了Ariadne评分作为对齐陈述逻辑与模型行为的新基准，强调需要更可靠的解释方法来确保AI系统的安全性和可信度。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [303] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R是一个7B参数的推理优化模型，通过精心数据筛选和针对性训练策略，在保持小模型规模的同时实现了与更大模型相当的推理性能，并具备快速推理、高token效率和准确性的优势。


<details>
  <summary>Details</summary>
Motivation: 证明小型语言模型（SLMs）通过适当的数据管理和训练策略，能够实现与大型模型相竞争的推理性能，解决大模型计算成本高、部署困难的问题。

Method: 采用参数高效设计（7B参数），结合精心数据筛选、高效监督微调（SFT）和强化学习扩展训练策略，使用混合并行架构设计加速推理，并利用DeepConf方法实现测试时扩展效率。

Result: 在多种推理密集型基准测试中，Falcon-H1R-7B能够匹配或超越比其大2-7倍的最先进推理模型，实现了推理效率的3D极限（快速推理、token效率、高准确性），并达到最先进的测试时扩展效率。

Conclusion: 紧凑模型通过针对性的模型训练和架构选择，能够提供强大且可扩展的推理性能，为需要大量思维链生成和并行测试时扩展的场景提供了实用的骨干模型。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [304] [PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS](https://arxiv.org/abs/2601.01288)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.GR

TL;DR: PyBatchRender是一个用于强化学习的高吞吐量批量3D渲染Python库，基于Panda3D游戏引擎，在简单场景下可实现超过100万FPS，比传统方法快1000倍。


<details>
  <summary>Details</summary>
Motivation: 像素级强化学习通常受限于3D渲染环境的性能和复杂性。研究人员面临高速低层引擎与更易用但较慢的Python框架之间的权衡，需要一种高性能且易于使用的渲染解决方案。

Method: 基于成熟的Panda3D游戏引擎，通过优化的批量渲染技术实现性能提升。设计为物理无关的渲染器，完全用Python创建自定义场景，只需几十行代码即可快速原型设计。

Result: 在简单场景下实现超过100万FPS的渲染速度，相比传统方法获得高达1000倍的加速。比专用库更灵活，比典型游戏引擎包装器设置更简单，性能可与Madrona等最先进的C++引擎相媲美。

Conclusion: PyBatchRender为研究人员和开发者提供了一个开源、易于集成的高性能3D模拟解决方案，旨在民主化高性能3D模拟，支持可扩展的AI训练快速原型设计。

Abstract: Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.

</details>


### [305] [VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data](https://arxiv.org/abs/2601.01361)
*Duosi Jin,Jianqiu Xu,Guidong Zhang*

Main category: cs.GR

TL;DR: VARTS是一个交互式可视化分析工具，用于代表性时间序列的选择和可视化，通过M4采样、DTW相似度计算和贪心选择来减少冗余，提升大规模时间序列的可视化清晰度。


<details>
  <summary>Details</summary>
Motivation: 大规模时间序列可视化常面临视觉混乱和模式冗余的问题，导致用户难以理解主要时间趋势，需要工具来减少冗余同时保留关键模式。

Method: 基于M4-Greedy方法，集成M4采样、DTW相似度计算和贪心选择，构建统一工作流进行代表性序列识别和可视化，提供响应式图形界面和多视图协同展示。

Result: VARTS能够有效减少冗余同时保留关键数据模式，显著提升大规模时间序列分析的视觉清晰度和可解释性。

Conclusion: VARTS通过集成采样、相似度计算和选择算法，提供了一个有效的交互式可视化分析工具，解决了大规模时间序列可视化中的冗余和混乱问题。

Abstract: Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.

</details>


### [306] [SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes](https://arxiv.org/abs/2601.02072)
*Haato Watanabe,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: 提出从高斯溅射场景中提取细长物体折线表示的方法，通过用户草图输入和屏幕空间最短路径分析构建折线网格


<details>
  <summary>Details</summary>
Motivation: 物理模拟细长弹性物体需要折线离散化，但高斯溅射缺乏连接信息且高斯基元配置噪声大，难以构建折线

Method: 基于用户草图输入，使用屏幕空间最短路径分析，通过动态规划高效构建细长部分的折线网格表示

Result: 在多个真实场景示例中展示了方法的有效性

Conclusion: 提出了一种从高斯溅射场景中稳健提取细长物体折线表示的方法，解决了连接信息缺失和噪声问题

Abstract: Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.

</details>


### [307] [Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs](https://arxiv.org/abs/2601.02096)
*Peizhuo Li,Sebastian Starke,Yuting Ye,Olga Sorkine-Hornung*

Main category: cs.GR

TL;DR: 利用VR设备的三点轨迹作为舞蹈动作描述符，通过高效MLP网络从领舞者三点轨迹预测跟舞者三点轨迹，再确定性地转换为虚拟化身动作，实现数据高效的双人舞蹈合成。


<details>
  <summary>Details</summary>
Motivation: 探戈等双人舞动作多样且交互复杂，传统方法需要建模高维全身动作，计算量大且容易过拟合。需要寻找更简洁有效的表示方法来简化双人舞动作的理解与合成。

Method: 使用VR设备的三点轨迹（头、双手）作为舞蹈动作描述符，通过MLP网络从领舞者三点轨迹预测跟舞者三点轨迹，再利用确定性神经网络将三点轨迹转换为虚拟化身全身动作。

Result: 该方法在探戈等结构化舞蹈中有效，并能泛化到LaFAN等更大更多样的数据集。提供计算和数据高效的解决方案，为沉浸式双人舞蹈应用开辟新可能。

Conclusion: 三点轨迹作为低维但明确的舞蹈表示，结合确定性神经网络，能够有效解决双人舞动作合成问题，避免过拟合，实现高效的双人舞蹈交互建模。

Abstract: Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.

</details>
